{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZoctXCue9UMQ",
        "outputId": "270cb279-ab52-4fc3-f696-bcbffd9ed858"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.7/dist-packages (1.18.1)\n",
            "Collecting google-cloud-storage\n",
            "  Downloading google_cloud_storage-1.43.0-py2.py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (3.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (1.15.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (2.23.0)\n",
            "Collecting google-cloud-core<3.0dev,>=1.6.0\n",
            "  Downloading google_cloud_core-2.2.1-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (1.35.0)\n",
            "Collecting google-api-core<3.0dev,>=1.29.0\n",
            "  Downloading google_api_core-2.3.0-py2.py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 48.9 MB/s \n",
            "\u001b[?25hCollecting google-resumable-media<3.0dev,>=1.3.0\n",
            "  Downloading google_resumable_media-2.1.0-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0dev,>=1.29.0->google-cloud-storage) (57.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0dev,>=1.29.0->google-cloud-storage) (1.53.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.8)\n",
            "Collecting google-crc32c<2.0dev,>=1.0\n",
            "  Downloading google_crc32c-1.3.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38 kB)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2021.10.8)\n",
            "Installing collected packages: google-crc32c, google-api-core, google-resumable-media, google-cloud-core, google-cloud-storage\n",
            "  Attempting uninstall: google-api-core\n",
            "    Found existing installation: google-api-core 1.26.3\n",
            "    Uninstalling google-api-core-1.26.3:\n",
            "      Successfully uninstalled google-api-core-1.26.3\n",
            "  Attempting uninstall: google-resumable-media\n",
            "    Found existing installation: google-resumable-media 0.4.1\n",
            "    Uninstalling google-resumable-media-0.4.1:\n",
            "      Successfully uninstalled google-resumable-media-0.4.1\n",
            "  Attempting uninstall: google-cloud-core\n",
            "    Found existing installation: google-cloud-core 1.0.3\n",
            "    Uninstalling google-cloud-core-1.0.3:\n",
            "      Successfully uninstalled google-cloud-core-1.0.3\n",
            "  Attempting uninstall: google-cloud-storage\n",
            "    Found existing installation: google-cloud-storage 1.18.1\n",
            "    Uninstalling google-cloud-storage-1.18.1:\n",
            "      Successfully uninstalled google-cloud-storage-1.18.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-cloud-translate 1.5.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.3.0 which is incompatible.\n",
            "google-cloud-translate 1.5.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.2.1 which is incompatible.\n",
            "google-cloud-language 1.2.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.3.0 which is incompatible.\n",
            "google-cloud-firestore 1.7.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.3.0 which is incompatible.\n",
            "google-cloud-firestore 1.7.0 requires google-cloud-core<2.0dev,>=1.0.3, but you have google-cloud-core 2.2.1 which is incompatible.\n",
            "google-cloud-datastore 1.8.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.3.0 which is incompatible.\n",
            "google-cloud-datastore 1.8.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.2.1 which is incompatible.\n",
            "google-cloud-bigquery 1.21.0 requires google-cloud-core<2.0dev,>=1.0.3, but you have google-cloud-core 2.2.1 which is incompatible.\n",
            "google-cloud-bigquery 1.21.0 requires google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1, but you have google-resumable-media 2.1.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 1.1.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.3.0 which is incompatible.\n",
            "google-api-python-client 1.12.8 requires google-api-core<2dev,>=1.21.0, but you have google-api-core 2.3.0 which is incompatible.\n",
            "firebase-admin 4.4.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\", but you have google-api-core 2.3.0 which is incompatible.\u001b[0m\n",
            "Successfully installed google-api-core-2.3.0 google-cloud-core-2.2.1 google-cloud-storage-1.43.0 google-crc32c-1.3.0 google-resumable-media-2.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install --upgrade google-cloud-storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANTEwVFDT175"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from argparse import Namespace\n",
        "from collections import Counter\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm_notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGEtcjkaU1H8",
        "outputId": "fdbe98c1-3792-4eca-c743-a66908483aaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6T85q6D9VGh",
        "outputId": "1519b575-8dd9-42f8-b44d-64f33968a700"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting allennlp\n",
            "  Downloading allennlp-2.8.0-py3-none-any.whl (738 kB)\n",
            "\u001b[K     |████████████████████████████████| 738 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting wandb<0.13.0,>=0.10.0\n",
            "  Downloading wandb-0.12.7-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 36.0 MB/s \n",
            "\u001b[?25hCollecting transformers<4.13,>=4.1\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 67.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.3.4)\n",
            "Collecting checklist==0.0.11\n",
            "  Downloading checklist-0.0.11.tar.gz (12.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.1 MB 24.6 MB/s \n",
            "\u001b[?25hCollecting fairscale==0.4.0\n",
            "  Downloading fairscale-0.4.0.tar.gz (190 kB)\n",
            "\u001b[K     |████████████████████████████████| 190 kB 67.5 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sqlitedict\n",
            "  Downloading sqlitedict-1.7.0.tar.gz (28 kB)\n",
            "Requirement already satisfied: torch<1.11.0,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.0.1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 52.4 MB/s \n",
            "\u001b[?25hCollecting tensorboardX>=1.2\n",
            "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 70.7 MB/s \n",
            "\u001b[?25hCollecting overrides==3.1.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.1.0)\n",
            "Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.1.0)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.7/dist-packages (from allennlp) (4.62.3)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.99)\n",
            "Collecting jsonnet>=0.10.0\n",
            "  Downloading jsonnet-0.17.0.tar.gz (259 kB)\n",
            "\u001b[K     |████████████████████████████████| 259 kB 63.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.2.5)\n",
            "Collecting filelock<3.4,>=3.3\n",
            "  Downloading filelock-3.3.2-py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.7/dist-packages (from allennlp) (2.23.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.6.4)\n",
            "Requirement already satisfied: spacy<3.2,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (2.2.4)\n",
            "Collecting datasets<2.0,>=1.2.1\n",
            "  Downloading datasets-1.16.1-py3-none-any.whl (298 kB)\n",
            "\u001b[K     |████████████████████████████████| 298 kB 52.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.16\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 695 kB/s \n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from allennlp) (8.12.0)\n",
            "Requirement already satisfied: torchvision<0.12.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.11.1+cu111)\n",
            "Collecting base58\n",
            "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting cached-path<0.4.0,>=0.3.1\n",
            "  Downloading cached_path-0.3.4-py3-none-any.whl (26 kB)\n",
            "Collecting munch>=2.5\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: jupyter>=1.0 in /usr/local/lib/python3.7/dist-packages (from checklist==0.0.11->allennlp) (1.0.0)\n",
            "Requirement already satisfied: ipywidgets>=7.5 in /usr/local/lib/python3.7/dist-packages (from checklist==0.0.11->allennlp) (7.6.5)\n",
            "Collecting patternfork-nosql\n",
            "  Downloading patternfork_nosql-3.6.tar.gz (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 61.9 MB/s \n",
            "\u001b[?25hCollecting iso-639\n",
            "  Downloading iso-639-0.4.5.tar.gz (167 kB)\n",
            "\u001b[K     |████████████████████████████████| 167 kB 64.5 MB/s \n",
            "\u001b[?25hCollecting boto3<2.0,>=1.0\n",
            "  Downloading boto3-1.20.23-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 66.1 MB/s \n",
            "\u001b[?25hCollecting cached-path<0.4.0,>=0.3.1\n",
            "  Downloading cached_path-0.3.3-py3-none-any.whl (26 kB)\n",
            "  Downloading cached_path-0.3.2-py3-none-any.whl (26 kB)\n",
            "Collecting huggingface-hub>=0.0.16\n",
            "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-cloud-storage<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from cached-path<0.4.0,>=0.3.1->allennlp) (1.43.0)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.9 MB/s \n",
            "\u001b[?25hCollecting botocore<1.24.0,>=1.23.23\n",
            "  Downloading botocore-1.23.23-py3-none-any.whl (8.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.4 MB 53.7 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.23->boto3<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 72.9 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 75.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets<2.0,>=1.2.1->allennlp) (1.1.5)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 72.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets<2.0,>=1.2.1->allennlp) (0.70.12.2)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 56.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets<2.0,>=1.2.1->allennlp) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets<2.0,>=1.2.1->allennlp) (4.8.2)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets<2.0,>=1.2.1->allennlp) (3.0.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (3.17.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (2.1.0)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (1.35.0)\n",
            "Requirement already satisfied: google-api-core<3.0dev,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (2.3.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (2.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0dev,>=1.29.0->google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (57.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0dev,>=1.29.0->google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (1.53.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (4.2.4)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.7/dist-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp) (3.10.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp) (3.13)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (3.5.2)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (5.1.3)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (4.10.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (5.5.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (5.1.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (1.0.2)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist==0.0.11->allennlp) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist==0.0.11->allennlp) (5.3.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (4.4.2)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist==0.0.11->allennlp) (5.2.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist==0.0.11->allennlp) (5.2.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist==0.0.11->allennlp) (5.6.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist==0.0.11->allennlp) (5.3.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (4.9.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets<2.0,>=1.2.1->allennlp) (3.0.6)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (0.2.5)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage<2.0,>=1.0->cached-path<0.4.0,>=0.3.1->allennlp) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp) (2021.10.8)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 72.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2,>=2.1.0->allennlp) (1.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2,>=2.1.0->allennlp) (0.8.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2,>=2.1.0->allennlp) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2,>=2.1.0->allennlp) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2,>=2.1.0->allennlp) (3.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2,>=2.1.0->allennlp) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2,>=2.1.0->allennlp) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2,>=2.1.0->allennlp) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2,>=2.1.0->allennlp) (1.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets<2.0,>=1.2.1->allennlp) (3.6.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision<0.12.0,>=0.8.1->allennlp) (7.1.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 72.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.13,>=4.1->allennlp) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 61.5 MB/s \n",
            "\u001b[?25hCollecting pyyaml\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 60.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (7.1.2)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (5.4.8)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.0-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 68.9 MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (2.3)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Collecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 72.2 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0->checklist==0.0.11->allennlp) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0->checklist==0.0.11->allennlp) (0.12.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0->checklist==0.0.11->allennlp) (2.11.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.5->checklist==0.0.11->allennlp) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter>=1.0->checklist==0.0.11->allennlp) (0.7.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 76.0 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 71.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0,>=1.2.1->allennlp) (2.0.8)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets<2.0,>=1.2.1->allennlp) (21.2.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 53.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->allennlp) (1.5.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter>=1.0->checklist==0.0.11->allennlp) (2.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (1.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (4.1.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (0.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (0.5.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets<2.0,>=1.2.1->allennlp) (2018.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist==0.0.11->allennlp) (0.16.0)\n",
            "Collecting backports.csv\n",
            "  Downloading backports.csv-1.0.7-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist==0.0.11->allennlp) (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist==0.0.11->allennlp) (4.2.6)\n",
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.8-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 12.0 MB/s \n",
            "\u001b[?25hCollecting pdfminer.six\n",
            "  Downloading pdfminer.six-20211012-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 56.2 MB/s \n",
            "\u001b[?25hCollecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 37.4 MB/s \n",
            "\u001b[?25hCollecting cherrypy\n",
            "  Downloading CherryPy-18.6.1-py2.py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 62.7 MB/s \n",
            "\u001b[?25hCollecting cheroot>=8.2.1\n",
            "  Downloading cheroot-8.5.2-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 7.9 MB/s \n",
            "\u001b[?25hCollecting jaraco.collections\n",
            "  Downloading jaraco.collections-3.4.0-py3-none-any.whl (10 kB)\n",
            "Collecting portend>=2.1.1\n",
            "  Downloading portend-3.1.0-py3-none-any.whl (5.3 kB)\n",
            "Collecting zc.lockfile\n",
            "  Downloading zc.lockfile-2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting jaraco.functools\n",
            "  Downloading jaraco.functools-3.4.0-py3-none-any.whl (6.9 kB)\n",
            "Collecting tempora>=1.8\n",
            "  Downloading tempora-4.1.2-py3-none-any.whl (15 kB)\n",
            "Collecting sgmllib3k\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "Collecting jaraco.classes\n",
            "  Downloading jaraco.classes-3.2.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting jaraco.text\n",
            "  Downloading jaraco.text-3.6.0-py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from jaraco.text->jaraco.collections->cherrypy->patternfork-nosql->checklist==0.0.11->allennlp) (5.4.0)\n",
            "Collecting cryptography\n",
            "  Downloading cryptography-36.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 21.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six->patternfork-nosql->checklist==0.0.11->allennlp) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six->patternfork-nosql->checklist==0.0.11->allennlp) (2.21)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (1.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (1.11.0)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter>=1.0->checklist==0.0.11->allennlp) (1.11.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.13,>=4.1->allennlp) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->allennlp) (3.0.0)\n",
            "Building wheels for collected packages: checklist, fairscale, overrides, jsonnet, subprocess32, iso-639, pathtools, patternfork-nosql, python-docx, sgmllib3k, sqlitedict\n",
            "  Building wheel for checklist (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for checklist: filename=checklist-0.0.11-py3-none-any.whl size=12165633 sha256=1f9ed89754b741328e8dd63db1efafc28c176957150781537f9b1f43d02a1312\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/8a/07/6446879be434879c27671c83443727d74cecf6b630c8a24d03\n",
            "  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.0-py3-none-any.whl size=239949 sha256=64efbfb847b3cc00546a398de2b2bd1309fb304f3f0414317e9d596cb7985877\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/8e/a3/7a2f33ac996114b816d88e55cf1235a1e058f30211e39bd719\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10186 sha256=c2b74901aa5dba9c75268b7ac8262269ac38979151631d91aa85824a77797e3a\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.17.0-cp37-cp37m-linux_x86_64.whl size=3388680 sha256=99820b0144c76da9105e1116107968bcd88dff4a95c20a942f0ec36431d3681f\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/28/7e/287c6b19f7161bb03c6986a3c46b51d0d7d9a1805346634e3a\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=e6aa5451ec41500306b6d0aed8fd594924a367c39ef36313c9c81eb1f4dd664b\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for iso-639 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iso-639: filename=iso_639-0.4.5-py3-none-any.whl size=169061 sha256=9549948b272f5e18b393df6d0e09c52ab7e9d12204417fe10143e76cb321e178\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/60/19/6d020fc92138ed1b113a18271e83ea4b5525fe770cb45b9a2e\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=1ae7a485d928403d8f5ea91d7f5169c60a77321319d603473c162f13aebaa3ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "  Building wheel for patternfork-nosql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for patternfork-nosql: filename=patternfork_nosql-3.6-py3-none-any.whl size=22332806 sha256=cd08f7f7d000c68d970cc4a066da7ef6055afab7f65a06c78b5807007ebc40b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/72/8f/5305fe28168f93b658da9ed433b9a1d3ec90594faa0c9aaf4b\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184508 sha256=e3399227328b6528a1a0eca87d70ecae07eee47f4b8251beac893d2c95aa35a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6065 sha256=453e873b1f4fcd5dfa2f9999aaf1d549a1a4de8156409c49d6c1543032c85962\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-py3-none-any.whl size=14392 sha256=97d621a470bf188efed3c45d08a9d183960fc43f7bbcadb9100955bd12042f85\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/94/06/18c0e83e9e227da8f3582810b51f319bbfd181e508676a56c8\n",
            "Successfully built checklist fairscale overrides jsonnet subprocess32 iso-639 pathtools patternfork-nosql python-docx sgmllib3k sqlitedict\n",
            "Installing collected packages: urllib3, jaraco.functools, tempora, multidict, jmespath, jaraco.text, jaraco.classes, frozenlist, zc.lockfile, yarl, smmap, sgmllib3k, pyyaml, portend, jaraco.collections, filelock, cryptography, cheroot, botocore, asynctest, async-timeout, aiosignal, tokenizers, sacremoses, s3transfer, python-docx, pdfminer.six, huggingface-hub, gitdb, fsspec, feedparser, cherrypy, backports.csv, aiohttp, yaspin, xxhash, transformers, subprocess32, shortuuid, sentry-sdk, patternfork-nosql, pathtools, overrides, munch, iso-639, GitPython, docker-pycreds, configparser, boto3, wandb, tensorboardX, sqlitedict, sentencepiece, jsonnet, fairscale, datasets, checklist, cached-path, base58, allennlp\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.4.0\n",
            "    Uninstalling filelock-3.4.0:\n",
            "      Successfully uninstalled filelock-3.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "firebase-admin 4.4.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\", but you have google-api-core 2.3.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.24 aiohttp-3.8.1 aiosignal-1.2.0 allennlp-2.8.0 async-timeout-4.0.1 asynctest-0.13.0 backports.csv-1.0.7 base58-2.1.1 boto3-1.20.23 botocore-1.23.23 cached-path-0.3.2 checklist-0.0.11 cheroot-8.5.2 cherrypy-18.6.1 configparser-5.2.0 cryptography-36.0.0 datasets-1.16.1 docker-pycreds-0.4.0 fairscale-0.4.0 feedparser-6.0.8 filelock-3.3.2 frozenlist-1.2.0 fsspec-2021.11.1 gitdb-4.0.9 huggingface-hub-0.1.2 iso-639-0.4.5 jaraco.classes-3.2.1 jaraco.collections-3.4.0 jaraco.functools-3.4.0 jaraco.text-3.6.0 jmespath-0.10.0 jsonnet-0.17.0 multidict-5.2.0 munch-2.5.0 overrides-3.1.0 pathtools-0.1.2 patternfork-nosql-3.6 pdfminer.six-20211012 portend-3.1.0 python-docx-0.8.11 pyyaml-6.0 s3transfer-0.5.0 sacremoses-0.0.46 sentencepiece-0.1.96 sentry-sdk-1.5.0 sgmllib3k-1.0.0 shortuuid-1.0.8 smmap-5.0.0 sqlitedict-1.7.0 subprocess32-3.5.4 tempora-4.1.2 tensorboardX-2.4.1 tokenizers-0.10.3 transformers-4.12.5 urllib3-1.25.11 wandb-0.12.7 xxhash-2.0.2 yarl-1.7.2 yaspin-2.1.0 zc.lockfile-2.0\n"
          ]
        }
      ],
      "source": [
        "pip install allennlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VTR7aA49aVQ"
      },
      "outputs": [],
      "source": [
        "from allennlp.modules.elmo import Elmo, batch_to_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-KD66NkeZM8",
        "outputId": "ccf31992-f8f2-48d9-b382-ba7ec1d60d7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "display.max_colwidth : int or None\n",
            "    The maximum width in characters of a column in the repr of\n",
            "    a pandas data structure. When the column overflows, a \"...\"\n",
            "    placeholder is embedded in the output. A 'None' value means unlimited.\n",
            "    [default: 50] [currently: 400]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('max_rows', 99999)\n",
        "pd.set_option('max_colwidth', 400)\n",
        "pd.describe_option('max_colwidth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5KToPScUvnh"
      },
      "outputs": [],
      "source": [
        "!unzip -q \"/content/gdrive/MyDrive/final_cit_map_function.zip\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYUKb_CYXn_J"
      },
      "outputs": [],
      "source": [
        "!unzip -q \"/content/gdrive/MyDrive/archive (2).zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H74ahCR1QRFd"
      },
      "outputs": [],
      "source": [
        "citation = pd.DataFrame(columns=['Text_Tokens','Cit_func','citseg_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyfH1bUFmQP6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "paths=[]\n",
        "d = \"/content/per_func_map_organised_small\"\n",
        "for path in os.listdir(d):\n",
        "    full_path = os.path.join(d, path)\n",
        "    if os.path.isfile(full_path):\n",
        "        paths.append(full_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNXK0SmmVHwJ",
        "outputId": "28ddddca-ae49-45b7-ddff-572e6f72033c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/per_func_map_organised_small/CoCoGM.per_func.map_organised_small.json\n",
            "/content/per_func_map_organised_small/CoCoR0.per_func.map_organised_small.json\n",
            "/content/per_func_map_organised_small/PSup.per_func.map_organised_small.json\n",
            "/content/per_func_map_organised_small/PSim.per_func.map_organised_small.json\n",
            "/content/per_func_map_organised_small/PMot.per_func.map_organised_small.json\n",
            "/content/per_func_map_organised_small/CoCoXY.per_func.map_organised_small.json\n",
            "/content/per_func_map_organised_small/Weak.per_func.map_organised_small.json\n",
            "/content/per_func_map_organised_small/PModi.per_func.map_organised_small.json\n",
            "/content/per_func_map_organised_small/Future.per_func.map_organised_small.json\n",
            "/content/per_func_map_organised_small/Neut.per_func.map_organised_small.json\n",
            "/content/per_func_map_organised_small/CoCo-.per_func.map_organised_small.json\n",
            "/content/per_func_map_organised_small/PUse.per_func.map_organised_small.json\n",
            "/content/per_func_map_organised_small/PBas.per_func.map_organised_small.json\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(paths)):\n",
        "  path = paths[i]\n",
        "  print(path)\n",
        "  f=open(path)\n",
        "  data=json.load(f)\n",
        "  for i in data.values():\n",
        "    citation_contexts=i['citation_contexts']\n",
        "    for j in range(len(citation_contexts)):\n",
        "      a=[]\n",
        "      tokens=citation_contexts[j]['citance']['tokens_pp']\n",
        "      left = citation_contexts[j]['left_ctx']\n",
        "      left_tokens=[]\n",
        "      for l in range(len(left)):\n",
        "        left_tokens.append(left[l]['tokens_pp'])\n",
        "      right = citation_contexts[j]['right_ctx']\n",
        "      right_tokens=[]\n",
        "      for r in range(len(right)):\n",
        "        right_tokens.append(right[r]['tokens_pp'])\n",
        "      \n",
        "      left_tokens=[item for tokens in left_tokens for item in tokens]\n",
        "      right_tokens=[item for tokens in right_tokens for item in tokens]\n",
        "      l=len(left_tokens)\n",
        "      tokens = left_tokens + tokens + right_tokens\n",
        "      for cit_refs in range(len(citation_contexts[j]['cit_refs'])):\n",
        "         citseg_id=citation_contexts[j]['cit_refs'][cit_refs]['citseg_id']\n",
        "         if citseg_id not in  a:\n",
        "            a.append(citseg_id)\n",
        "            c=citation_contexts[j]['cit_refs'][cit_refs]['citseg_id']\n",
        "            c = c + l\n",
        "            f=citation_contexts[j]['cit_refs'][cit_refs]['function_agreed']\n",
        "            citation = citation.append({'Text_Tokens':tokens, 'Cit_func':f,'citseg_id':c},ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4oDLqCpVdiH"
      },
      "outputs": [],
      "source": [
        "#split the subset by rating to create new train, val and test splits\n",
        "import collections\n",
        "by_rating = collections.defaultdict(list)\n",
        "for _,row in citation.iterrows():\n",
        "  by_rating[row.Cit_func].append(row.to_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzaJJtt8aArE"
      },
      "outputs": [],
      "source": [
        "#create split data\n",
        "seed =1021\n",
        "final_list = []\n",
        "np.random.seed(seed)\n",
        "train_proportion = 0.8\n",
        "val_proportion = 0.2\n",
        "#test_proportion = 0.05\n",
        "\n",
        "for _, item_list in sorted(by_rating.items()):\n",
        "  np.random.shuffle(item_list)\n",
        "\n",
        "  n_total = len(item_list)\n",
        "  n_train = int(train_proportion * n_total)\n",
        "  n_val = int(val_proportion * n_total)\n",
        "  #n_test = int(test_proportion * n_total)\n",
        "\n",
        "\n",
        "  #give data points  split attribute\n",
        "\n",
        "  for item in item_list[:n_train]:\n",
        "    item['split'] = 'train'\n",
        "\n",
        "  #for item in item_list[n_train:n_train+n_val]:\n",
        "   # item['split'] = 'val'\n",
        "\n",
        "  for item in item_list[n_train:n_train+n_val]:\n",
        "    item['split'] = 'val'\n",
        "\n",
        "  #for item in item_list[n_train+n_val:n_train+n_val+n_test]:\n",
        "   # item['split'] = 'test'\n",
        "\n",
        "\n",
        "  #Add to final list\n",
        "\n",
        "  final_list.extend(item_list)\n",
        "\n",
        "\n",
        "final_citation = pd.DataFrame(final_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_36UW99zAAv"
      },
      "outputs": [],
      "source": [
        "final_citation=final_citation.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "eDWF2doEWhda",
        "outputId": "b04d5441-3e58-4b86-9136-b3918e46f574"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Neut      1475\n",
              "PUse       761\n",
              "CoCoGM     300\n",
              "PMot       290\n",
              "PSim       210\n",
              "Weak       160\n",
              "CoCoXY     156\n",
              "PBas       101\n",
              "PSup       100\n",
              "CoCoR0     100\n",
              "Future      85\n",
              "CoCo-       80\n",
              "PModi       65\n",
              "Name: Cit_func, dtype: int64"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n"
          ]
        }
      ],
      "source": [
        "display(final_citation.Cit_func.value_counts())                   # Inspecting the Number of Ratings.\n",
        "print(\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "ooayU1pWFZBN",
        "outputId": "60015e0d-86dc-48e4-e90f-4c502de2aa18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f74b73c5b10>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "final_citation.groupby(['Cit_func','split']).size().unstack(level=1)  \n",
        "a=final_citation.groupby(['Cit_func','split']).size().unstack(level=1)  \n",
        "a.plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa69mq7WwoP_",
        "outputId": "ef36aa16-22cb-4489-b7f8-d6a5f71dd602"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cit_func  split\n",
              "CoCo-     train      64\n",
              "          val        16\n",
              "CoCoGM    train     240\n",
              "          val        60\n",
              "CoCoR0    train      80\n",
              "          val        20\n",
              "CoCoXY    train     125\n",
              "          val        31\n",
              "Future    train      68\n",
              "          val        17\n",
              "Neut      train    1180\n",
              "          val       295\n",
              "PBas      train      81\n",
              "          val        20\n",
              "PModi     train      52\n",
              "          val        13\n",
              "PMot      train     232\n",
              "          val        58\n",
              "PSim      train     168\n",
              "          val        42\n",
              "PSup      train      80\n",
              "          val        20\n",
              "PUse      train     609\n",
              "          val       152\n",
              "Weak      train     128\n",
              "          val        32\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "final_citation.groupby(['Cit_func','split']).size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5zBHkhSzKIn"
      },
      "outputs": [],
      "source": [
        "# final_citation.drop(final_citation.query('Cit_func == \"CoCoGM\" & split == \"train\"').sample(n=50).index,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sg5YVUJn-nD2"
      },
      "outputs": [],
      "source": [
        "final_citation.drop(final_citation.query('Cit_func == \"Neut\" & split == \"train\"').sample(n=400).index,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8fHzsc3-ovV"
      },
      "outputs": [],
      "source": [
        "# final_citation.drop(final_citation.query('Cit_func == \"PMot\" & split == \"train\"').sample(n=50).index,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncfpGfYh9vrH"
      },
      "outputs": [],
      "source": [
        "final_citation.drop(final_citation.query('Cit_func == \"PUse\" & split == \"train\"').sample(n=200).index,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3me_vg8_9pv"
      },
      "outputs": [],
      "source": [
        "# final_citation.drop(final_citation.query('Cit_func == \"Neut\" & split == \"val\"').sample(n=100).index,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjI48Zm-2HD_",
        "outputId": "e06d0ccd-f272-4636-c37a-de3263be8769"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cit_func  split\n",
              "CoCo-     train     64\n",
              "          val       16\n",
              "CoCoGM    train    240\n",
              "          val       60\n",
              "CoCoR0    train     80\n",
              "          val       20\n",
              "CoCoXY    train    125\n",
              "          val       31\n",
              "Future    train     68\n",
              "          val       17\n",
              "Neut      train    780\n",
              "          val      295\n",
              "PBas      train     81\n",
              "          val       20\n",
              "PModi     train     52\n",
              "          val       13\n",
              "PMot      train    232\n",
              "          val       58\n",
              "PSim      train    168\n",
              "          val       42\n",
              "PSup      train     80\n",
              "          val       20\n",
              "PUse      train    409\n",
              "          val      152\n",
              "Weak      train    128\n",
              "          val       32\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "final_citation.groupby(['Cit_func','split']).size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "eSwzxmsg0I4e",
        "outputId": "b01daf04-58aa-41be-ff11-873b8d31e55d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f74b7220a10>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "final_citation.groupby(['Cit_func','split']).size().unstack(level=1)  \n",
        "a=final_citation.groupby(['Cit_func','split']).size().unstack(level=1)  \n",
        "a.plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "DrPdgJ2oDLGW",
        "outputId": "18027189-cf9b-466b-fdab-233493c71e64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f74b708e4d0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD4CAYAAAD7CAEUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbsklEQVR4nO3debQeVZ3u8e9DggmDhCFZGCN0bEi0IQkRgkpEOniFK0LLoHcheG+DTXeaVlG0XQiyvIJDiw0q2kugcwUnMAyOTAtogUAQBE6ATMjYBAQZRUAkYIjP/aP2C29OTpJTOe+Qc87zWeus89auXfXunQr5sXdV7Z9sExER0V8bdbsBERExuCRwRERELQkcERFRSwJHRETUksARERG1jOx2A9pt7NixnjhxYrebERExqCxYsOAp2+P62jfkA8fEiRPp6enpdjMiIgYVSQ+uaV+mqiIiopYEjoiIqCWBIyIiahny9zgWP/IsE4+/rGXnW3bK/i07V0TEYNTyEYeklZLukLRE0kWSNi3llnRuU72Rkp6UdGnN8y+TNLZ8vrG1rY+IiHVpx1TVctvTbU8B/gwcXcr/BEyRtEnZ3gd4ZCBfZHvmQI6PiIj62n2PYz6wY9P25UBjrucwYG5jh6StJf1c0iJJv5Y0rZRvI+kqSUslfQdQ0zHPt7n9ERHRS9sCh6SRwH7A4qbi84EPShoNTANubtp3MnC77WnAZ4EflPLPAzfY3hn4GbB9P757tqQeST0rX3h24J2JiIhXtCNwbCLpDqAHeAg4u7HD9iJgItVo4/Jex+0J/LDUuwbYRtIWwF7AuaX8MuAP62qA7Tm2Z9ieMWLTMQPuUEREvKodT1Uttz19LfsvBk4DZgHbtOH7IyKijbrxHsc5wMm2F/cqnw98CEDSLOAp288B1wOHl/L9gK0619SIiOit4+9x2H4Y+FYfu04CzpG0CHgBOKKUnwzMlbQUuJFq+qvfpk4YQ0/evYiIaJmWBw7bm/e33PY8YF75/DRwUB91fg/sW+e7IiKifbLkSERE1JLAERERtSRwRERELQkcERFRSwJHRETUksARERG1JB/HACU/R0QMN20ZcUh6naTzJd0vaYGkyyVNXkv9yaXOvZJuk3ShpG3b0baIiBiYlo84JIlqFdvv2/5gKdsF2Ba4p4/6o4HLgE/ZvqSUzQLGAY+3un0RETEw7Rhx7A2ssH1Wo8D2QuAGSaeWzICLJR1adh8O3NQIGqX+PNtLJI2W9N1S/3ZJe7ehvRERUUM77nFMARb0UX4IMB3YBRgL3Crp+rXUB/goYNtTJb0ZuErSZNsvrq0BkmYDswFGbDFu/XoRERF96uRTVXsCc22vtP04cB2wez+OaeTiuAt4EFjjvZKG5OOIiGifdgSOpcBubayPpC9LuqMkjIqIiA5qR+C4BhhVposAKPnDnwEOlTRC0jiqzH63AD8CZkrav6n+XpKmsGqOjslUaWPvtn2i7enrSBgVERFt0PLAYdvAwcC7y+O4S4GvUAWIRcBCquBynO3HbC8HDgCOKY/j3gl8BHgSOAPYSNJi4ALgSNsvtbrNERHRf6r+nR+6ZsyY4Z6enm43IyJiUJG0wPaMvvZlyZGIiKglgSMiImpJ4IiIiFoSOCIiopYEjoiIqCWBIyIiakngiIiIWpLIqUWS0CkihouWBQ5JK4HFTUUH2V62hrqzgD/bvrFV3x8REZ3RyhHH8hprR80Cngf6HTgkjbT98vo0LCIiWqet9zgkLZM0tnyeIWmepInA0cAnywq375T0PUkfaDru+fJ7lqT5ki4G7iwLJJ4q6VZJiyT9czvbHxERq2vliGOTpmXOH7B9cF+VbC+TdBbwvO3TACQdtZbz7gpMsf1AWXH3Wdu7SxoF/ErSVbYfaD4giZwiItqnW1NVddzSFBj2BaY1jU7GAJOAVQKH7TnAHIBR4ycN7VUcIyI6rN1PVb3Mq9Nho/tTT9JGwGua9v2p6bOAY2xf2cpGRkRE/7X7PY5lvJrd7/1N5X8EXruGeu8DNl7D+a4E/kXSxlAld5K0WasaGxER69buEcfJwNmSvgjMayq/BPixpAOBY4D/B/xC0kLgClYdZTT7DjARuE2SqJI9HbS2BkydMIaevGMREdEySeQUERGrSSKniIhomQSOiIioJYEjIiJqSeCIiIhaEjgiIqKWBI6IiKglgSMiImpJIqc2SWKniBiqao84JL1O0vmS7pe0QNLlkiavpf7kUudeSbdJulDStmupP0vSs2XJ9bsknda0T5K+Jem+sqz6rnXbHxERA1MrcJRlPn4GzLO9g+3dgBOAPgOBpNHAZcCZtifZ3hU4A1jXWufzy0q7bwEOkPSOUr4f1Wq4k6iWTT+zTvsjImLg6o449gZW2D6rUWB7IXBDSbC0RNJiSYeW3YcDN9m+pKn+PNtLJI2W9N1S/3ZJe/f+MtvLgTuACaXoQOAHrvwa2FLS+Jp9iIiIAah7j2MKsKCP8kOA6cAuwFjgVknXr6U+wEcB254q6c3AVb2nvCRtRTW6uL4UTQB+21Tl4VL2aK/jksgpIqJNWvVU1Z7AXNsrbT8OXAfs3o9jzgWwfRfwINAIHO8sK+U+Alxp+7E6jbE9x/YM2zNGbDqmzqEREbEOdQPHUl7Nm9GO+g3zbe8C7AwcJamRWfARYLumem8oZRER0SF1A8c1wKgyFQSApGnAM8ChkkZIGgfsBdwC/AiYKWn/pvp7SZoCzAc+VMomA9sDdzd/WUkZewrwmVJ0MfD35emqt1PlH19lmioiItqr1j0O25Z0MHC6pM8AL1Jl7zsW2BxYCBg4rjG9JOmAUv90YAWwCPgE1dNVZ0paTJU69kjbL1UPbq3iLODTkiYClwPvBe4DXgA+vK42J5FTRERrJZFTRESsJomcIiKiZRI4IiKilgSOiIioJYEjIiJqSeCIiIhaEjgiIqKW5ONok+TjiIihqiMjDkkrS36NJZIukrRpKT9R0tKSW+MOSW/rRHsiImL9dWrEsbzk10DSecDRkm4CDgB2LW+MjwVe06H2RETEeurGPY75wI7AeOAp2y8B2H7K9u8AJC0rgQRJMyTNK59PkvRDSTeVjIL/1IX2R0QMax0NHJJGUmXxWwxcBWwn6R5JZ0j6236eZhrwLmAP4P9Ken17WhsREX3pVODYRNIdQA/wEHC27eepllyfDTwJXCDpyH6c6xe2l9t+CrgWeGvvCpJmS+qR1LPyhWdb1omIiOjCPY5mtlcC84B5ZZXcI4DvUa2W2whqo3sfto5tbM8B5gCMGj9paK/iGBHRYV17j0PSmyRNaiqaTpUFEKql2hsJoN7f69ADS77ybYBZwK3tbGdERKyqm+9xbA78h6QtqUYY91HyhAMnA2dL+iLViKTZIqopqrHAFxs31CMiojMGVT4OSScBz9s+rb/HJB9HRER9yccREREtM6iWHLF9UrfbEBEx3GXEERERtSRwRERELQkcERFRSwJHRETUksARERG1DKqnqtZHEjlFRLRWx0Yca0nm1ChfKOk2STM71aaIiKivk1NVy21Ptz0F+DNwdK/yXYATgK90sE0REVFTt+5xNJI59bYF8AcASZtLurqMQhZLOrCUbybpsjJCWSLp0A62OyJi2Ov4PY6mZE5XlKJGro7RVFkB31XKXwQOtv1cyQb4a0kXA+8Bfmd7/3K+MX18x2zKgokjthjXzu5ERAw7nRxxrJbMqZQ3pqreTBUUfiBJgIB/k7QI+CUwAdiWKnvgPpK+KumdtlfL1GR7ju0ZtmeM2HS1uBIREQPQyRFHn8mcmtm+qYwuxgHvLb93s71C0jJgtO17JO1a9n9J0tW2v9DuxkdERGWDehxX0puBEcDvgTHAEyVo7A38VanzeuBp2+dKegb4x641OCJiGNoQAkdjCguq6akjbK+UdB5wSUkp2wPcVepMBU6V9BdgBfAvHW9xRMQwNqgSOa2PJHKKiKgviZwiIqJlEjgiIqKWBI6IiKglgSMiImpJ4IiIiFoSOCIiopYEjoiIqGVDeAGwrbqVyKkVkgwqIjZEtUcckl4n6XxJ90taIOlySZPXUn9yqXNvWSL9QknbrqX+IZKubtresyR62kXSPZI2adp3maTD6vYhIiLWX63AUVat/Rkwz/YOtnejSr7UZyCQNBq4DDjT9iTbuwJnUC1e2CfbPwVeknS4pI1L/Y/YXgj8FDixnPsgYGPbc+v0ISIiBqbuVNXewArbZzUKbC9U5VSqPBsGvmT7AuBw4CbblzTVnwevBJUzgRnAy8CnbF9bqn2Main1nYFbbd9Yyr8A3C7px8ApwN/VbH9ERAxQ3cAxBVjQR/khwHRgF2AscKuk69dSH+CjgG1PLaviXiVpsu0Xbf+3pAuoAsgOjQNsvyDp08D1wNdt39vXiZPIKSKifVr1VNWewFzbK20/DlwH7N6PY84FsH0X8CAwGUDSCGAf4HnKcuoNZfTyDNUUVp+SyCkion3qBo6lwG5trN/wEapMf0cB3y73Vpr9pfxERESH1Q0c1wCjylQQAJKmUY0ADpU0QtI4YC/gFuBHwExJ+zfV30vSFGA+8KFSNhnYHrhb0uuATwHH2b4CeIQka4qI2GDUusdh25IOBk6X9BngRWAZcCywObCQ6ub4cbYfA5B0QKl/OlXipUXAJ6imms4siZpeBo60/ZKkrwP/bvvJ8rXHAvMl/cT203U7OHXCGHryPkRERMskkVNERKwmiZwiIqJlEjgiIqKWBI6IiKglgSMiImpJ4IiIiFoSOCIiopYEjoiIqCWJnDZwSeYUERuato04JH1D0rFN21dK+k7T9tckfarmOb8n6QOtbGdERNTTzqmqXwEzASRtRLXc+s5N+2cCN/ZxXEREbMDaGThuBPYon3cGlgB/lLSVpFHA3wCWdF1JQXulpPEAkv5J0q2SFkr6iaRNe59c0hfLCGREG/sQERG9tC1w2P4d8LKk7alGFzcBN1MFkxnAb4BvAB8oKWjPAb5cDv+p7d1t71LqHdV87pJtcBzwYdsre3+3pNmSeiT1rHzh2fZ0MCJimGr3zfEbqYLGTODrwITy+Vmq5dL3Bf6rpNsYATxajpsi6UvAllSr7l7ZdM7PATfbns0a2J4DzAEYNX7S0F7FMSKiw9odOBr3OaZSTVX9FvhX4DlgHjDB9h59HPc94KCSz/xIYFbTvluB3SRtvT7LrEdExMC0+z2OG4EDgKdLWtmnqUYRewBzgXGS9gCQtLGkxs3z1wKPStqYkuypyRXAKcBlkl7b5vZHREQv7R5xLKZ6mupHvco2t/1EebT2W5LGlLacTpVu9nNU90OeLL9XCRC2LypB42JJ77W9fE0NSCKniIjWSiKniIhYTRI5RUREyyRwRERELQkcERFRSwJHRETUksARERG1JHBEREQtyccxhCWXR0S0Q8dGHJJWSrpD0hJJFzVWvJV0oqSlkhaV/W8r5d+RtFOn2hcREf3TyRHHctvTASSdBxwt6SaqJUl2tf2SpLHAawBs/2MH2xYREf3UrXsc84EdgfHAU7ZfArD9VFmOHUnzJM0on5+XdGoZmfxS0lvL/v+W9L4u9SEiYljqeOCQNBLYj2rNqquA7STdI+kMSX+7hsM2A66xvTPwR+BLwD7AwcAXOtDsiIgoOhk4NpF0B9ADPAScbft5YDdgNtWChheUZdR7+zPVqrhQBZzrbK8onyf2rpxEThER7dOVexzNSga/ecA8SYuBI6jycTRb4VdXY/wL0Jja+ksZwfQ+ZxI5RUS0SVff45D0JkmTmoqmAw92qz0REbFu3X6PY3PgPyRtCbwM3Ec1bRURERuo5OOIiIjVJB9HRES0TAJHRETUksARERG1JHBEREQtCRwREVFLAkdERNSSwBEREbV0+wXAthvOiZzaKUmiIoavDSGRkyWd21RvpKQnJV26jvPNkjSz3e2OiIhVdXKqarnt6banUK12e3Qp/xMwRdImZXsf4JF+nG8WkMAREdFh3U7k1HA50Jj7OAyY29ghaWtJPy+pZX8taZqkiVSB55NlFPPODrU7ImLY63Yip4bzgQ9KGg1MA25u2ncycLvtacBngR/YXgacBXyjjGLm9/qO5OOIiGiTriZyauywvYgqIdNhVKOPZnsCPyz1rgG2kbTF2r7I9hzbM2zPGLHpmNb1ICIiup/IqcnFwGlU9y626UiLIiKitg3pPY5zgJNtL+5VPh/4EFRPUgFP2X6OKvf4azvawoiI2HDe47D9MPCtPnadBJwjaRHwAlVqWYBLgB9LOhA4pvd9joapE8bQk3cOIiJapmOBw/bm/S23PY8qDzm2nwYO6qPOPVQ30iMiooM2pKmqiIgYBBI4IiKilgSOiIioJYEjIiJqSeCIiIhaEjgiIqKWBI6IiKhlg3kBsF2SyKn9ktQpYnjp14hD0usknS/pfkkLJF0uafJa6k8ude6VdJukCyVtu47veKukeU3HXCZpatl3Ukn4tGNT/WNL2Yz+djYiIgZunYFDkoCfAfNs72B7N+AEoM9AUJZGvww40/Yk27sCZwDj1vId2wIXAp9tOuYrwA5N1RYDH2za/l/A0nW1PyIiWqs/I469gRW2z2oU2F4I3CDp1JIKdrGkQ8vuw4GbbF/SVH+e7SWSRkv6bql/u6S9S5WPAd+3fWPTMTfY/nlTO34OHAggaQfgWeCp9ehzREQMQH8CxxRgQR/lhwDTgV2AdwOnShq/lvoAHwVseypV7o3vlxHKzsBt62jHc8BvJU2hGnlcsKaKSeQUEdE+A3mqak9gru2Vth8HrgN278cx5wLYvgt4EFjtXomkmyX9RtI3e+06nypoHEQ1fdanJHKKiGif/gSOpcBuNc5Zt37jmF0bG7bfBnwO6P2v/qXA/wEeKjk5IiKiw/oTOK4BRkma3SiQNA14BjhU0ghJ44C9gFuAHwEzJe3fVH+vMsXUnJRpMrA9cDfwbeBISTObvnfT3g2x/QLwGeDLtXoZEREts873OGxb0sHA6ZI+A7wILAOOBTYHFgIGjrP9GICkA0r904EVwCLgE1RPV50paTHwMnCk7ZeAx8rN9a9KmgA8QXXj+wt9tOf8Oh1MIqeIiNaS7W63oa1mzJjhnp6ebjcjImJQkbTAdp/vyWXJkYiIqCWBIyIiakngiIiIWhI4IiKilgSOiIioJYEjIiJqSeCIiIhaksgpokuSACsGq46NOCStlHRHWYb9IkmbSpooaUmveidJ+nSn2hUREfV0cqpque3ptqcAfwaO7uB3R0REi3TrHsd8YMd1VZL0cUl3Slok6fxStpmkcyTdUpJBHdj21kZExCs6fo9D0khgP+CKflQ/Hnij7ZckbVnKTgSusf0PpewWSb+0/aem75gNzAYYscUaM9ZGRMR66OSIYxNJdwA9wEPA2VSr6valUb4IOE/S/6ZaTRdgX+D4cq55wGiq5dlfPTiJnCIi2qaTI47ltqc3F0j6PbBVr3pbAw+Uz/tT5fn4O+BESVMBAe+3fXeb2xsREX3o6nsctp8HHpX0LgBJWwPvAW6QtBGwne1rqZI3jaHK/3ElcIwklWPe0pXGR0QMUx3LxyHpedub91G+E1UGwMbI41Tb50naGLiWKmAIONf2KZI2AU4HZlIFvgdsH7Cm700+joiI+taWj6NjU1V9BY1Sfiewdx/lK4A9+yhfDvxzyxsYERH9kiVHIiKilgSOiIioJYEjIiJqSeCIiIhaEjgiIqKWBI6IiKgl+TgiIoagduZ76WQ+Dkv6WtP2pyWdtJ7n2lLSR1rWuIiI6LdOTlW9BBwiaWwLzrUlkMAREdEFnQwcLwNzgE/23iFpnKSfSLq1/LyjlK+SDbBkD5wInALsUDIKntqZ5kdEBHT+Hse3gUWS/r1X+TeBb9i+QdL2VAsZ/s1aznM8MKX3arsNyccREdE+HQ0ctp+T9APg48Dypl3vBnYqC94CbCGpz7Wt+vk9c6hGN4waP6kzqzhGRAwT3Xiq6nTgNuC7TWUbAW+3/WJzRUkvs+p02uj2Ny8iItam4+9x2H4auBA4qqn4KuCYxoakxhTUMmDXUrYr8MZS/kfgte1ua0RErK5bLwB+DWh+uurjwAxJiyTdCRxdyn8CbC1pKfAx4B4A278HflVulufmeEREB3UskVO3JJFTRER9a0vklCVHIiKilgSOiIioJYEjIiJqGfL3OCT9Ebi72+3ooLHAU91uRIekr0PXcOrvhtrXv7Ld5xvUQ351XODuNd3gGYok9QyX/qavQ9dw6u9g7GumqiIiopYEjoiIqGU4BI453W5Ahw2n/qavQ9dw6u+g6+uQvzkeERGtNRxGHBER0UIJHBERUcuQDhyS3iPpbkn3STq+2+0ZKEnbSbpW0p2Slkr6RCnfWtJ/Sbq3/N6qlEvSt0r/F5UVhgcVSSMk3S7p0rL9Rkk3lz5dIOk1pXxU2b6v7J/YzXavD0lbSvqxpLsk/UbSHkP12kr6ZPk7vETSXEmjh8q1lXSOpCckLWkqq30dJR1R6t8r6Yhu9GVNhmzgkDSCKuPgfsBOwGGSdupuqwbsZeBfbe8EvB34aOnT8cDVticBV5dtqPo+qfzMBs7sfJMH7BPAb5q2v0qVLXJH4A+8ujz/UcAfSvk3Sr3B5pvAFbbfDOxC1e8hd20lTaCsiG17CjAC+CBD59p+D3hPr7Ja11HS1sDngbcBbwU+3wg2GwTbQ/IH2AO4smn7BOCEbrerxX38BbAP1Zvx40vZeKqXHgH+Ezisqf4r9QbDD/AGqv/I3gVcCojqDduRva8xVbrhPcrnkaWeut2HGn0dAzzQu81D8doCE4DfAluXa3Up8D+H0rUFJgJL1vc6AocB/9lUvkq9bv8M2REHr/7lbHi4lA0JZbj+FuBmYFvbj5ZdjwHbls+D/c/gdOA44C9lexvgGdsvl+3m/rzS17L/2VJ/sHgj8CTw3TI19x1JmzEEr63tR4DTgIeAR6mu1QKG7rWF+tdxg76+QzlwDFklH/tPgGNtP9e8z9X/ngz6Z6wlHQA8YXtBt9vSISOpsl2eafstwJ94dToDGFLXdivgQKpg+XpgM1af2hmyhsJ1HMqB4xFgu6btN5SyQU3SxlRB4zzbPy3Fj0saX/aPB54o5YP5z+AdwPskLQPOp5qu+iawpaTGGmvN/Xmlr2X/GOD3nWzwAD0MPGz75rL9Y6pAMhSv7buBB2w/aXsF8FOq6z1Ury3Uv44b9PUdyoHjVmBSeVLjNVQ33y7ucpsGRJKAs4Hf2P56066LgcZTF0dQ3ftolP99eXLj7cCzTcPlDZrtE2y/wfZEqmt3je0PAdcCHyjVeve18WfwgVJ/0Pxfne3HgN9KelMp+h/AnQzBa0s1RfV2SZuWv9ONvg7Ja1vUvY5XAvtK2qqM0PYtZRuGbt9kaecP8F6qPOX3Ayd2uz0t6M+eVEPcRcAd5ee9VPO9VwP3Ar8Eti71RfVk2f3AYqqnWLrej/Xo9yzg0vL5r4FbgPuAi4BRpXx02b6v7P/rbrd7Pfo5Hegp1/fnwFZD9doCJwN3AUuAHwKjhsq1BeZS3btZQTWSPGp9riPwD6XP9wEf7na/mn+y5EhERNQylKeqIiKiDRI4IiKilgSOiIioJYEjIiJqSeCIiIhaEjgiIqKWBI6IiKjl/wPOWs2z1V2oUwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        " final_citation.Cit_func.value_counts().plot(kind='barh')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "qxlcTHfGWmPy",
        "outputId": "a54c3482-8a02-4426-b5be-6502f0042fe7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train    2507\n",
              "val       776\n",
              "Name: split, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(final_citation.split.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gv1qsdkHvGcY"
      },
      "outputs": [],
      "source": [
        "final_citation['Cit_func'].replace({'PSim':'Comparison or Contrast','Neut':'Background','CoCoXY':'Background','Weak':'Comparison or Contrast',\n",
        "                                    'CoCoGM':'Comparison or Contrast','PUse':'Uses','PBas':'Extends','PModi':'Extends','CoCoR0':'Comparison or Contrast',\n",
        "                                    'PMot':'Motivation','CoCo-':'Comparison or Contrast','PSup':'Comparison or Contrast'\n",
        "                                    }, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r73UdjAtR9j3",
        "outputId": "f946a5cc-2e99-4321-ae6a-9fb21525fc0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Comparison or Contrast', 'Background', 'Future', 'Extends',\n",
              "       'Motivation', 'Uses'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "final_citation['Cit_func'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "hQQowCK9vJCm",
        "outputId": "93cafd40-0d64-4262-eb5e-e89df04c49ca"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train    2507\n",
              "val       776\n",
              "Name: split, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(final_citation.split.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "yukj4Y_nvLpm",
        "outputId": "454df96f-2dd8-4ba1-81f8-1bf6af5f2aad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f74b6fc0110>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        " final_citation.Cit_func.value_counts().plot(kind='barh')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "UZ5DNMZuvMR0",
        "outputId": "8a2bc6db-6aff-47fc-8508-1cd76ec84fde"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f74b6f74f50>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAF0CAYAAADYVHlQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfZzVdZ338dcbGAW8AUTyBtiGNe9RMNF09Wq92XZRU6w0Mi0qk2uvtCxbjdpu6G7jqraUrfDy0rq0LCXU1ZR1NwzU8i5AEElUNAzwDllFvEFBP9cfv9/AYZxhhuGc+c75nvfz8ZjH/H7fc87M5zwG3vOd7+/7+34VEZiZWV56pS7AzMyqz+FuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpahPqkLANh1112jubk5dRlmZnVl3rx5z0XEkLYe6xHh3tzczNy5c1OXYWZWVyQ90d5jHpYxM8uQw93MLEMOdzOzDPWIMXczs65Yv349K1asYN26dalLqam+ffsybNgwmpqaOv0ah7uZ1a0VK1aw00470dzcjKTU5dRERLB69WpWrFjBiBEjOv06D8uYWd1at24dgwcPzjbYASQxePDgrf7rxOFuZnUt52Bv0ZX36HA3M9tKkydP5vvf/z4AX/3qV5k1axYAF198Ma+88krK0jaq6zH35km3dOl1y6acVOVKzKxRfeMb39h4fPHFF3PWWWfRv3//hBUV3HM3MwNefvllTjrpJEaNGsXIkSO59tpraW5u5qKLLuKggw7i8MMPZ+nSpW953cc+9jFmzJjB1KlTefLJJzn22GM59thjE7yDzTnczcyAW2+9lT333JOFCxfy4IMPMnbsWAAGDBjAokWLOO+88/jsZz/b7us/85nPsOeeezJ79mxmz57dXWW3y+FuZgYcdNBB/Pa3v+ULX/gCd955JwMGDADgjDPO2Pj57rvvTlniVqnrMXczs2rZZ599mD9/PjNnzuTLX/4yxx9/PLD5TJV6mpnjnruZGfDkk0/Sv39/zjrrLC688ELmz58PwLXXXrvx85FHHrnFr7HTTjuxdu3amtfaGe65m5kBixYt4sILL6RXr140NTUxbdo0TjvtNJ5//nkOPvhgtt9+e371q19t8WtMnDiRsWPHbhx7T0kRkbQAgDFjxkRX1nP3VEizxvbQQw+x//771+zrt+w1seuuu9bse3RWW+9V0ryIGNPW8z0sY2aWIQ/LmJm1Y9myZalL6DL33M3MMuRwNzPLkMPdzCxDDnczsww53M3MuuiFF17gJz/5yVa/7sQTT+SFF16oQUWbeLaMmWWjq/e+tKeje2Jawv1Tn/rUZu0bNmygT5/243XmzJlVqW9LHO5mZl00adIkHnvsMUaPHk1TUxN9+/Zl0KBBLFmyhEceeYRTTz2V5cuXs27dOs4//3wmTpwIbLo56qWXXuKEE07g6KOP5q677mLo0KHceOON9OvXb5tr87CMmVkXTZkyhb322osFCxbwve99j/nz53PJJZfwyCOPAPDTn/6UefPmMXfuXKZOncrq1avf8jUeffRRzj33XBYvXszAgQO57rrrqlKbe+5mZlVy+OGHM2LEiI3nU6dO5YYbbgBg+fLlPProowwePHiz14wYMYLRo0cDcOihh1btximHu5lZleywww4bj+fMmcOsWbO4++676d+/P8cccwzr1q17y2u23377jce9e/fm1VdfrUotHpYxM+uiLS3xu2bNGgYNGkT//v1ZsmQJ99xzT7fW1qmeu6TPAZ8EAlgEfBzYA7gGGAzMAz4SEa9L2h64CjgUWA2Mj4hl1S/dzCytwYMHc9RRRzFy5Ej69evHbrvttvGxsWPHcumll7L//vuz7777csQRR3RrbR0u+StpKPB74ICIeFXSdGAmcCJwfURcI+lSYGFETJP0KeDgiPhHSR8C3hcR47f0Pbzkr5l1Ra2X/O1JarXkbx+gn6Q+QH/gKeA4YEb5+JXAqeXxuPKc8vHjVU97U5mZZaDDcI+IlcD3gb9QhPoaimGYFyJiQ/m0FcDQ8ngosLx87Yby+ZtfHgYkTZQ0V9LcVatWbev7MDOzCh2Gu6RBFL3xEcCewA7A2G39xhFxWUSMiYgxQ4YM2dYvZ2ZmFTozLPN3wJ8jYlVErAeuB44CBpbDNADDgJXl8UpgOED5+ACKC6tmZtZNOhPufwGOkNS/HDs/HvgTMBs4rXzOBODG8vim8pzy8d9FT9io1cysgXRmzP1eiguj8ymmQfYCLgO+AFwgaSnFmPoV5UuuAAaX7RcAk2pQt5mZbUGn5rlHxNeAr7Vqfhw4vI3nrgNO3/bSzMzysuOOO/LSSy91y/fy8gNmlo/JA6r89dZU9+t1I4e7mVkXTZo0ieHDh3PuuecCMHnyZPr06cPs2bN5/vnnWb9+Pd/61rcYN25ct9fmtWXMzLpo/PjxTJ8+feP59OnTmTBhAjfccAPz589n9uzZfP7znyfFnBL33M3MuuiQQw7h2Wef5cknn2TVqlUMGjSI3Xffnc997nPccccd9OrVi5UrV/LMM8+w++67d2ttDvcezGvnmPV8p59+OjNmzODpp59m/PjxXH311axatYp58+bR1NREc3Nzm0v91prD3cxsG4wfP55zzjmH5557jttvv53p06fztre9jaamJmbPns0TTzyRpC6Hu5nZNjjwwANZu3YtQ4cOZY899uDMM8/k5JNP5qCDDmLMmDHst99+SepyuJtZPhJNXVy0aNHG41133ZW77767zed11xx38GwZM7MsOdzNzDLkcDczy5DD3czqWiMsOtuV9+hwN7O61bdvX1avXp11wEcEq1evpm/fvlv1Os+WMbO6NWzYMFasWEHuW3X27duXYcOGbdVrHO5mVreampoYMWJE6jJ6JA/LmJllyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llqFPhLmmgpBmSlkh6SNKRknaR9FtJj5afB5XPlaSpkpZKekDSO2v7FszMrLXO9twvAW6NiP2AUcBDwCTgtojYG7itPAc4Adi7/JgITKtqxWZm1qEOw13SAODdwBUAEfF6RLwAjAOuLJ92JXBqeTwOuCoK9wADJe1R9crNzKxdnem5jwBWAT+TdL+kyyXtAOwWEU+Vz3ka2K08Hgosr3j9irLNzMy6SWfCvQ/wTmBaRBwCvMymIRgAIiKA2JpvLGmipLmS5q5atWprXmpmZh3oTLivAFZExL3l+QyKsH+mZbil/Pxs+fhKYHjF64eVbZuJiMsiYkxEjBkyZEhX6zczszZ0GO4R8TSwXNK+ZdPxwJ+Am4AJZdsE4Mby+Cbgo+WsmSOANRXDN2Zm1g36dPJ5nwaulrQd8DjwcYpfDNMlnQ08AXywfO5M4ERgKfBK+VwzM+tGnQr3iFgAjGnjoePbeG4A525jXWZmtg18h6qZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYY6He6Seku6X9LN5fkISfdKWirpWknble3bl+dLy8eba1O6mZm1Z2t67ucDD1Wc/2/ghxHxDuB54Oyy/Wzg+bL9h+XzzMysG/XpzJMkDQNOAr4NXCBJwHHAh8unXAlMBqYB48pjgBnAjyQpIqJ6ZZuZ1U7zpFu69LplU06qciVd19me+8XARcCb5flg4IWI2FCerwCGlsdDgeUA5eNryuebmVk36TDcJb0XeDYi5lXzG0uaKGmupLmrVq2q5pc2M2t4nem5HwWcImkZcA3FcMwlwEBJLcM6w4CV5fFKYDhA+fgAYHXrLxoRl0XEmIgYM2TIkG16E2ZmtrkOwz0ivhgRwyKiGfgQ8LuIOBOYDZxWPm0CcGN5fFN5Tvn47zzebmbWvbZlnvsXKC6uLqUYU7+ibL8CGFy2XwBM2rYSzcxsa3VqtkyLiJgDzCmPHwcOb+M564DTq1CbmZl1ke9QNTPLkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczsww53M3MMrRVC4dlY/KALr5uTXXrMDOrEffczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDXmBtlmtk2aJ93Spdctm3JSlSux9rjnbmaWIYe7mVmGHO5mZhnqMNwlDZc0W9KfJC2WdH7Zvouk30p6tPw8qGyXpKmSlkp6QNI7a/0mzMxsc53puW8APh8RBwBHAOdKOgCYBNwWEXsDt5XnACcAe5cfE4FpVa/azMy2qMNwj4inImJ+ebwWeAgYCowDriyfdiVwank8DrgqCvcAAyXtUfXKzcysXVs15i6pGTgEuBfYLSKeKh96GtitPB4KLK942YqyzczMukmnw13SjsB1wGcj4sXKxyIigNiabyxpoqS5kuauWrVqa15qZmYd6FS4S2qiCParI+L6svmZluGW8vOzZftKYHjFy4eVbZuJiMsiYkxEjBkyZEhX6zczszZ0eIeqJAFXAA9FxA8qHroJmABMKT/fWNF+nqRrgHcBayqGb6w7TB7QxdetqW4dZpZMZ5YfOAr4CLBI0oKy7UsUoT5d0tnAE8AHy8dmAicCS4FXgI9XtWIzM+tQh+EeEb8H1M7Dx7fx/ADO3ca6zMxsG/gOVTOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5G32zMyqpQfdQOieu5lZhhzuZmYZcribmWXIY+6WTPOkW7r0umVTTqpyJWb5cc/dzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczswx5yV+zGvByxpaae+5mZhlyz93Muk8P2kA6d+65m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyLNlrP54xoVZh9xzNzPLkMPdzCxDDnczswzVZMxd0ljgEqA3cHlETKnF9zHLjq8nWJVUvecuqTfwY+AE4ADgDEkHVPv7mJlZ+2oxLHM4sDQiHo+I14FrgHE1+D5mZtaOWoT7UGB5xfmKss3MzLqJIqK6X1A6DRgbEZ8szz8CvCsizmv1vInAxPJ0X+DhqhayZbsCz3Xj9+tufn/1K+f3Bn5/1fb2iBjS1gO1uKC6EhhecT6sbNtMRFwGXFaD798hSXMjYkyK790d/P7qV87vDfz+ulMthmX+COwtaYSk7YAPATfV4PuYmVk7qt5zj4gNks4D/pNiKuRPI2Jxtb+PmZm1rybz3CNiJjCzFl+7SpIMB3Ujv7/6lfN7A7+/blP1C6pmZpaelx8wM8uQwz0DkkZ0ps3MGofDPQ/XtdE2o9urMLMeI/vNOiT9Bmj3wkJEnNKN5VSVpP2AA4EBkt5f8dDOQN80VdWGpKOABRHxsqSzgHcCl0TEE4lLqwpJbwf2johZkvoBfSJibeq6qkHSEOAcoJmKzImIT6SqqZok7QWsiIjXJB0DHAxcFREvpKwr+3AHvl9+fj+wO/CL8vwM4JkkFVXPvsB7gYHAyRXtayn+M+VkGjBK0ijg88DlwFXA3yatqgoknUNxt/YuwF4UN/5dChyfsq4quhG4E5gFvJG4llq4Dhgj6R0Us2VuBH4JnJiyqIaZLdPWnWM96W6ybSHpyIi4O3UdtSRpfkS8U9JXgZURcUVLW+ratpWkBRQL7t0bEYeUbYsi4qC0lVWHpAURMTp1HbVS8W/zQmBdRPybpPtbfpapNNKY+w6S/rrlpLzguEPCeqrpfZJ2ltQk6TZJq8qhi5yslfRF4CzgFkm9gKbENVXLa+UKqgBI6sMWhhLr0M2SkvZia2y9pDOACcDNZVvyf5uNFO6fA+ZImiPpdmA28NnENVXL30fEixRDNMuAdwAXJq2o+sYDrwFnR8TTFEMX30tbUtXcLulLQD9J7wF+DfwmcU3VdD5FwK+TtLb8eDF1UVX0ceBI4NsR8eey4/jzxDU1zrAMgKTtgf3K0yUR8VrKeqpF0uKIOFDS5cCMiLhV0sKIGJW6NuuYJAGfBP4eEMXSHZdHI/3nrHPlRfC/iojuXN12ixrhgmqlQ9l0xX6UJCLiqrQlVcVvJC0BXgX+Vzk7YV3imqpC0lq2PNtp524sp+rKncsWR8R+wP9NXU+tSDoFeHd5Oicibt7S8+uJpJMpJm5sB4yQNBr4RuqZeA3Tc5f0c4qZCAvYdMU+IuIz6aqqHkm7AGsi4g1J/YGdy+GLLEj6JvAUxZ+7As4E9oiIryYtrAok3Qh8OiL+krqWWpA0BTgMuLpsOgOYGxFfTFdV9UiaBxxH8Uur5YL4gxExMmldDRTuDwEH5PqnrqSRFHvWbpzfnslfJQC0NcyUy9CTpDuAQ4D7gJdb2lP3/KpF0gPA6Ih4szzvDdwfEQenraw6JN0TEUdUzpCR9EDq99dIwzIPUsxzfyp1IdUm6WvAMRThPpNic/LfU8wDz8XLks6k2JM3KHp/L2/5JXXjK6kL6AYDgf8ujwekLKQGFkv6MNBb0t7AZ4C7EtfUUD332cBoit7RxgupOfSOJC0CRlH0hkZJ2g34RUS8J3FpVSOpGbgEOIoi3P8AfDYilqWryjqjnCY4hWKGmijG3idFxLVJC6uSchj0n9n8gvg3IyLpda9GCvc272SMiNu7u5Zqk3RfRBxejv0dS3GH6kPlRTrr4VpdNN6OYo70y/V+sbiSpD0oxt0B7svpelClcshph3JqclINMyyTQ4hvwVxJAylmW8wDXgKyumM15/VJImKnluNyWuQ44Ih0FVWHpP0iYomklruIV5Sf95S0Z0TMT1VbNUn6JfCPFBM1/gjsLOmSiEh6H0Yj9dyz7B2VYTAsIpaX580UM2UeSFlXtUm6i2J9knlUrE8SEW2tiFn3esLt69tK0mURMbEcEm0tIuK4bi+qBlqWVyivCb0TmATM8wXVbpJr7ygiQtJM4KDyfFnaimqmf0R8IXURtdBqRc9ewBgyuE8hIiaWhye0Hn+WlNOqpU2SmoBTgR9FxHpJyXvNjbT8wEZR+HfgH1LXUiXzJR3W8dPqWs7rk5xc8fEPFNdMxiWtqLramjmSfDZJFV0K/Jlirao7yuWbk4+5N9KwTFu9o7+NiCMTlVQ15d2p7wCeoJgeKIrfYVnMI4aNw2o7AK+XHy3vsa6H1aBYqz4i/tBRW72RtDswlGKZ7Q9T/Myg2G/g0nq/4C/pgspTimHfVRTTkJdHxIYkhZUaZliGzdc730CxwFYuvaNc/gJpV+WwWob+jWKstqO2evMPwMcoFnn7QUX7WuBLKQqqsrb+Tb6dYlrkZIp7MpJpmJ57ziT9PCI+0lFbPSuvk5wJjIiIb0oaTrH8wH2JS+sySUcCf0OxOukPKx7aGXhfDnffAkj6QK4XvttSLgUyK/VeAw3Tc5c0jKI3dFTZdCdwfkSsaP9VdePAypNyru2hiWqplZ8Ab1Ks4fFNiumeP2bT3Ol6tB2wI8X/w8pe4IvAaUkqqoGIuE7SSRT/TiuXx/hGuqpqJyL+u+yMJNUw4Q78jGLrq9PL87PKtrq9i7PcvKJlHfCWCziiGJO+LFlhtfGucreb+wEi4nlJ26UualuU917cLun/RSZ7wbZF0qVAf4ob7C6n+MVVt39xdUTSscDzyetolGEZtbHVV1tt9UjSd3JZYa89ku6lGML4YxnyQ4D/qve54LBxaYy3/EfMaB74AxFxcMXnHYH/iIj/kbq2bVEu+9H657YL8CTw0YhY0v1VbdJIPffVKrae+1V5fgawOmE9VRMRX5Q0lOJiTuXdm3ekq6rqpgI3AG+T9G2K3l8uC279U8VxX+ADFBf9c/Fq+fkVSXtS/L/bI2E91fLeVucBrI6IHrGgXSOF+ycoxtx/SPFDuItie6y6V66X/SHgT1SsVQ9kE+4RcXW5ds7xFENPp0bEQ4nLqoqImNeq6Q+Schq2uLlcHuN7wHyKf5t1vzFJTx9Ka4hhmfIC41URcWbqWmpB0sPAwblsG9iWnGcElbMrWvSiuBg+NSL2TVRSzajY6rJvRKxJXUvuGqLnXu5O9HZJ20XFLvMZeZxirZxsw528ZwRV9tw3UNzteHaiWqqu3KzjGuDaiHiMvP+d9hgNEe6lxyn+3L2JzXe7+UH7L6kbrwALJN3G5mvV1/0Wgh3MCKrrP+0l/VVE/CUiRqSupcZOBsYD0yW9CVwLTM91W8GeoiGGZWDjbkVvERFf7+5aqk3ShLbaI+LK7q6lVnKcESRpfsuNLpKui4gPpK6p1sqdir4CnBkRvVPXk7OG6bnnEOLtiYgryznf+5RND0fE+pQ11cDSypNyWObLdf5zrbzR5a+TVdENysW0xpcfbwAXpa0ofw0T7pJ+w1vnpK4B5gL/J/WWWNtC0jHAlRTr5QgYLmlCZlMhj5f0AYqx6MEUN6DV+wYs0c5xVsp7FJqAXwOnR8TjiUtqCI00LHMJMIRN89zHU9zmHRSbW9TtrItyiuCHI+Lh8nwf4FcRkcsFRwAkjadYcuBlivdb76smvsGmVTz7UVw7gYxWvASQtG/Lv03rPo0U7n+MiMPaapO0OCIObO+1PV3LnX8dtdWzcqz2SmARsD/FnP4LIuKVLb7QkpF0VkT8otXSuBtlMpmhx2qYYRlgx5bZCVDMVKBYtAmKmRf1bK6kyynWzYZi3Zy5Ceuphd8A50bEbeWiTBdQ7FdZt7+UG8AO5ee2lsZtjF5lQo3Ucz+RYseUxyj+7B0BfAqYA5wTERenq27blDeGnAscXTbdAUzL6aYmSTtHqx3lJe0TEY+kqsk6J9fNSHq6Rgp3USyx2rL7y8MU45p1G4Dl4llDIuJPrdoPBJ6NiFVpKqseSRdFxHfL49Mj4tcVj/1LROSw6UPWKqd8bqnNqquR9lC9IiJei4iFEbEQ6A3MTF3UNvo3YNc22ncBLunmWmrlQxXHree5j+3OQmzrSDpS0ueBIZIuqPiYTPH/z2qokcJ9paSfAEgaBPyWTWPU9eodbU13jIg7gVwupqqd47bOrWdpvRlJy0dWm5H0VA1zQTUiviLpu+XGAYcCUzLY+mtL+4o2dVsVtbWlueCNMaZYp1pvRlKu405EvJS4tIaQfbhLen/F6b0Utz7fB4Sk90fE9Wkqq4qlkk6MiM2GlySdQLGWTg5GlWvKiLeuL9O3/ZdZD7JTuYPWLgCSngMmRMSDacvKW/YXVCX9bAsPR0R8otuKqbJy7vctFGvTt6wsOAY4EnivZ5JYTyDpLuCfI2J2eX4M8C8R8TdJC8tc9uGeu3Ia5IeBkWXTYuCX9bycguVF0sKIGNVRm1VXw4S7pCuB8yPihfJ8EPCv9dxzN6sHkm6g2IHp52XTWcChEfG+dFXlr5FmyxzcEuwAEfE8UPebK5vVgU9QrOt0ffkxpGyzGsr+gmqFXpIGlaHesrVZI71/syTK/3N1v3FMvWmkcPtX4G5Jv6aYaXEa8O20JW273PeHtfpV7nrWrog4pbtqaUQNM+YOG2/LP7Y8/V3r2/brlaTfA8dluj+s1SlJq4DlFMts30urm87KefBWIw0V7gCS3kbF/Ogc9nGUdBXFMrg57g9rdar8q/I9wBkUd0zfQrHPwOKkhTWIhrmgKukUSY9S7Cx/O8WuRf+RtKjqeQy4meLnWXmbt1kyEfFGRNwaEROAIyi2Spwj6bzEpTWEhum5S1oIHAfMiohDJB0LnBURZycurWp8e7f1NOV9GCdR9N6bKf66/GlErExZVyNopAuq6yNitaReknpFxGxJdbuGeyVJIynmEFfe3v1R//lrKZXDhSMpVl/9upcb6F6N1HOfBZwKfIdimdxngcNyuAXat3dbTyTpTTZdA6oMmqz2iO2pGincdwBepRiXPhMYAFwdEauTFlYFvr3bzFprmGGZiGjpQbwp6RZgdeTzm+1xSV9h89u7c1kV0sy6IPvZMpKOkDRH0vWSDpH0IPAg8IykXHbyqby9+zqKYSff3m3WwLIflpE0F/gSxTDMZcAJEXGPpP0o5tx6fRkzy072PXegT0T8V7mx8tMRcQ9ARCxJXJeZWc00Qri/WXH8aqvH8v6zxcwaViMMy7xBMR1LQD/glZaHgL4Rkcteo2ZmG2Uf7o1A0hDgHIo7ADfOgPJGJGaNq2GmQmbuRuBOYBbwRuJazKwHcM89A5IWRMTo1HWYWc/RCBdUG8HNkk5MXYSZ9RzuuWdA0lpgB+B1YH3Z7LU7zBqYw93MLEO+oJoJSacA7y5P50TEzSnrMbO03HPPgKQpwGHA1WXTGcDciPhiuqrMLCWHewYkPQCMjog3y/PewP0RcXDayswsFc+WycfAiuMByaowsx7BY+55+A5wv6TZFMsqvBuYlLYkM0vJwzKZkLQHxbg7wH0R8XTKeswsLQ/LZEDSUcCLEXETsDNwkaS3Jy7LzBJyuOdhGvCKpFHABcBjwFVpSzKzlBzuedhQ7gc7DvhxRPwY2ClxTWaWkC+o5mGtpC9SbIz9bkm9AK9Tb9bA3HPPw3jgNeDs8kLqMOB7aUsys5Q8W8bMLEMelqljkn4fEUeXq0JW/pYWXhXSrKG5525mliGPudc5Sb0lLUldh5n1LA73OhcRbwAPS/qr1LWYWc/hMfc8DAIWS7oPeLmlMSJOSVeSmaXkcM/DV1IXYGY9iy+ompllyGPuGZB0hKQ/SnpJ0uuS3pD0Yuq6zCwdh3sefkSxtd6jQD/gk8CPk1ZkZkk53DMREUuB3hHxRkT8DBiburMuE8sAAAQRSURBVCYzS8cXVPPwiqTtgAWSvgs8hX9xmzU0B0AePkLxszyPYirkcOADSSsys6Q8WyYTZc99P4o1Zh6OiNcTl2RmCTncMyDpJOBSih2YBIwA/mdE/EfSwswsGYd7Bsq1Zd5bXlRF0l7ALRGxX9rKzCwVj7nnYW1LsJceB9amKsbM0nPPPQOSpgFvB6ZTjLmfDvwFmAUQEdenq87MUnC4Z0DSz7bwcETEJ7qtGDPrERzuZmYZ8k1MGZA0Avg00EzFz9RL/po1Lod7Hv4duAL4DfBm4lrMrAfwsEwGJN0bEe9KXYeZ9RwO9wxI+jCwN/BfwGst7RExP1lRZpaUh2XycBDF+jLHsWlYJspzM2tA7rlnQNJS4ACvJ2NmLXyHah4eBAamLsLMeg4Py+RhILBE0h/ZfMzdUyHNGpTDPQ9fS12AmfUsHnPPhKTdgMPK0/si4tmU9ZhZWh5zz4CkDwL3USwY9kHgXkmnpa3KzFJyzz0DkhYC72nprUsaAsyKiFFpKzOzVNxzz0OvVsMwq/HP1qyh+YJqHm6V9J/Ar8rz8YC32DNrYB6WyYSk9wNHl6d3RsQNKesxs7Qc7nVM0juA3SLiD63ajwaeiojH0lRmZql5XLa+XQy82Eb7mvIxM2tQDvf6tltELGrdWLY1d385ZtZTONzr25bWk+nXbVWYWY/jcK9vcyWd07pR0ieBeQnqMbMewhdU61i55MANwOtsCvMxwHbA+yLi6VS1mVlaDvcMSDoWGFmeLo6I36Wsx8zSc7ibmWXIY+5mZhlyuJuZZcjhbmaWIYe7ZUnS7pKukfSYpHmSZkp6t6QZ5eOjJZ3YwdfYXtIsSQskje+eys2qw6tCWnYkiWKK6JUR8aGybRSwc0S0bGIymmLa6MwtfKlDACJidA3LNasJ99wtR8cC6yPi0paGiFgILJf0oKTtgG8A49vrlUt6G/AL4LDyOXtJWiZp1/LxMZLmlMeTJf1U0hxJj0v6TMXX+aikByQtlPTzmr5rswruuVuORrKFO3Qj4nVJXwXGRMR57Tzn2fJO33+KiPcCFH8QtGs/il8qOwEPS5oG7AN8GfibiHhO0i5dejdmXeBwN6uOWyLiNeA1Sc8CuwHHAb+OiOcAIuK/UxZojcXDMpajxcChNfi6G9j0f6Zvq8deqzh+A3ecLDGHu+Xod8D2kia2NEg6GBhe8Zy1FEMoW2MZm35pfKCTdZwuaXBZg4dlrNs43C07Uayp8T7g78qpkIuB7wCVC6nNBg7YymmOXwcukTSXonfeUR2LgW8Dt0taCPxga96H2bbw2jJmZhlyz93MLEO+6GMNT9LHgfNbNf8hIs5NUY9ZNXhYxswsQx6WMTPLkMPdzCxDDnczsww53M3MMuRwNzPL0P8H/EZ6XVlQRtEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "final_citation.groupby(['Cit_func','split']).size().unstack(level=1)  \n",
        "a=final_citation.groupby(['Cit_func','split']).size().unstack(level=1)  \n",
        "a.plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuqhpXxPD_jp"
      },
      "outputs": [],
      "source": [
        "final_citation = final_citation.sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUARtdxNT5Oa"
      },
      "outputs": [],
      "source": [
        "class Vocabulary(object):\n",
        "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
        "\n",
        "    def __init__(self, token_to_idx=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
        "        \"\"\"\n",
        "\n",
        "        if token_to_idx is None:\n",
        "            token_to_idx = {}\n",
        "        self._token_to_idx = token_to_idx\n",
        "\n",
        "        self._idx_to_token = {idx: token \n",
        "                              for token, idx in self._token_to_idx.items()}\n",
        "        \n",
        "    def to_serializable(self):\n",
        "        \"\"\" returns a dictionary that can be serialized \"\"\"\n",
        "        return {'token_to_idx': self._token_to_idx}\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        \"\"\" instantiates the Vocabulary from a serialized dictionary \"\"\"\n",
        "        return cls(**contents)\n",
        "\n",
        "    def add_token(self, token):\n",
        "        \"\"\"Update mapping dicts based on the token.\n",
        "\n",
        "        Args:\n",
        "            token (str): the item to add into the Vocabulary\n",
        "        Returns:\n",
        "            index (int): the integer corresponding to the token\n",
        "        \"\"\"\n",
        "        if token in self._token_to_idx:\n",
        "            index = self._token_to_idx[token]\n",
        "        else:\n",
        "            index = len(self._token_to_idx)\n",
        "            self._token_to_idx[token] = index\n",
        "            self._idx_to_token[index] = token\n",
        "        return index#,token\n",
        "            \n",
        "    def add_many(self, tokens):\n",
        "        \"\"\"Add a list of tokens into the Vocabulary\n",
        "        \n",
        "        Args:\n",
        "            tokens (list): a list of string tokens\n",
        "        Returns:\n",
        "            indices (list): a list of indices corresponding to the tokens\n",
        "        \"\"\"\n",
        "        return [self.add_token(token) for token in tokens]\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        \"\"\"Retrieve the index associated with the token \n",
        "        \n",
        "        Args:\n",
        "            token (str): the token to look up \n",
        "        Returns:\n",
        "            index (int): the index corresponding to the token\n",
        "        \"\"\"\n",
        "        return self._token_to_idx[token]\n",
        "\n",
        "    def lookup_index(self, index):\n",
        "        \"\"\"Return the token associated with the index\n",
        "        \n",
        "        Args: \n",
        "            index (int): the index to look up\n",
        "        Returns:\n",
        "            token (str): the token corresponding to the index\n",
        "        Raises:\n",
        "            KeyError: if the index is not in the Vocabulary\n",
        "        \"\"\"\n",
        "        if index not in self._idx_to_token:\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "        return self._idx_to_token[index]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._token_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_zeQ_QVUB87"
      },
      "outputs": [],
      "source": [
        "class SequenceVocabulary(Vocabulary):\n",
        "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
        "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
        "                 end_seq_token=\"<END>\"):\n",
        "\n",
        "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
        "\n",
        "        self._mask_token = mask_token\n",
        "        self._unk_token = unk_token\n",
        "        self._begin_seq_token = begin_seq_token\n",
        "        self._end_seq_token = end_seq_token\n",
        "\n",
        "        self.mask_index = self.add_token(self._mask_token)\n",
        "        self.unk_index = self.add_token(self._unk_token)\n",
        "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
        "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        contents = super(SequenceVocabulary, self).to_serializable()\n",
        "        contents.update({'unk_token': self._unk_token,\n",
        "                         'mask_token': self._mask_token,\n",
        "                         'begin_seq_token': self._begin_seq_token,\n",
        "                         'end_seq_token': self._end_seq_token})\n",
        "        return contents\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        \"\"\"Retrieve the index associated with the token \n",
        "          or the UNK index if token isn't present.\n",
        "        \n",
        "        Args:\n",
        "            token (str): the token to look up \n",
        "        Returns:\n",
        "            index (int): the index corresponding to the token\n",
        "        Notes:\n",
        "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
        "              for the UNK functionality \n",
        "        \"\"\"\n",
        "        if self.unk_index >= 0:\n",
        "            return self._token_to_idx.get(token, self.unk_index)\n",
        "        else:\n",
        "            return self._token_to_idx[token]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rt6OYhb_UF2h"
      },
      "outputs": [],
      "source": [
        "class CitationVectorizer(object):\n",
        "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"    \n",
        "    def __init__(self, title_vocab, category_vocab):\n",
        "        self.title_vocab = title_vocab\n",
        "        self.category_vocab = category_vocab\n",
        "\n",
        "    def vectorize(self, title, vector_length=-1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            title (str): the string of words separated by a space\n",
        "            vector_length (int): an argument for forcing the length of index vector\n",
        "        Returns:\n",
        "            the vetorized title (numpy.array)\n",
        "        \"\"\"\n",
        "        indices = [self.title_vocab.begin_seq_index]\n",
        "        indices.extend(self.title_vocab.lookup_token(token) \n",
        "                       for token in title)\n",
        "        indices.append(self.title_vocab.end_seq_index)\n",
        "\n",
        "        if vector_length < 0:\n",
        "            vector_length = len(indices)\n",
        "\n",
        "        out_vector = np.zeros(vector_length, dtype=np.int64)\n",
        "        out_vector[:len(indices)] = indices\n",
        "        out_vector[len(indices):] = self.title_vocab.mask_index\n",
        "        return out_vector\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, citation_df, cutoff=0):\n",
        "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
        "        \n",
        "        Args:\n",
        "            citation_df (pandas.DataFrame): the target dataset\n",
        "            cutoff (int): frequency threshold for including in Vocabulary \n",
        "        Returns:\n",
        "            an instance of the CitationVectorizer\n",
        "        \"\"\"\n",
        "        category_vocab = Vocabulary()     \n",
        "        for category in sorted(set(citation_df.Cit_func)):\n",
        "            category_vocab.add_token(category)\n",
        "            #a=category_vocab.add_token(category)\n",
        "            #print(a)\n",
        "        word_counts = Counter()\n",
        "        for title in citation_df.Text_Tokens:\n",
        "          # print(\"title is %s\"%title)\n",
        "          for token in title:\n",
        "              # print(\"token is %s\"%token)\n",
        "              #if token not in string.punctuation:\n",
        "              word_counts[token] += 1\n",
        "        \n",
        "        title_vocab = SequenceVocabulary()\n",
        "        for word, word_count in word_counts.items():\n",
        "            # print(\"word:word_count are %s:%d\"%(word,word_count))\n",
        "            if word_count >= cutoff:\n",
        "                title_vocab.add_token(word)\n",
        "        return cls(title_vocab, category_vocab)\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        \n",
        "        title_vocab = \\\n",
        "            SequenceVocabulary.from_serializable(contents['title_vocab'])\n",
        "        category_vocab =  \\\n",
        "            Vocabulary.from_serializable(contents['category_vocab'])\n",
        "\n",
        "        return cls(title_vocab=title_vocab, category_vocab=category_vocab)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        return {'title_vocab': self.title_vocab.to_serializable(),\n",
        "                'category_vocab': self.category_vocab.to_serializable()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axn0K6ErUJsV"
      },
      "outputs": [],
      "source": [
        "class CitationDataset(Dataset):\n",
        "    def __init__(self, citation_df, vectorizer):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            citation_df (pandas.DataFrame): the dataset\n",
        "            vectorizer (CitationVectorizer): vectorizer instatiated from dataset\n",
        "        \"\"\"\n",
        "        self.citation_df = citation_df\n",
        "        self._vectorizer = vectorizer\n",
        "\n",
        "        # +1 if only using begin_seq, +2 if using both begin and end seq tokens\n",
        "        measure_len = lambda context: len(context)\n",
        "        self._max_seq_length = max(map(measure_len, citation_df.Text_Tokens)) + 2\n",
        "        \n",
        "\n",
        "        self.train_df = self.citation_df[self.citation_df.split=='train']\n",
        "        self.train_size = len(self.train_df)\n",
        "\n",
        "        self.val_df = self.citation_df[self.citation_df.split=='val']\n",
        "        self.validation_size = len(self.val_df)\n",
        "\n",
        "        self.test_df = self.citation_df[self.citation_df.split=='test']\n",
        "        self.test_size = len(self.test_df)\n",
        "\n",
        "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
        "                             'val': (self.val_df, self.validation_size),\n",
        "                             'test': (self.test_df, self.test_size)}\n",
        "\n",
        "        self.set_split('train')\n",
        "\n",
        "        # Class weights\n",
        "        class_counts = citation_df.Cit_func.value_counts().to_dict()\n",
        "        def sort_key(item):\n",
        "            return self._vectorizer.category_vocab.lookup_token(item[0])\n",
        "        sorted_counts = sorted(class_counts.items(), key=sort_key)\n",
        "        frequencies = [count for _, count in sorted_counts]\n",
        "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n",
        "\n",
        "        \n",
        "        \n",
        "    @classmethod\n",
        "    def load_dataset_and_make_vectorizer(cls, citation_csv):\n",
        "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
        "        \n",
        "        Args:\n",
        "            citation_csv (str): location of the dataset\n",
        "        Returns:\n",
        "            an instance of citationDataset\n",
        "        \"\"\"\n",
        "        citation_df = citation_csv\n",
        "        train_citation_df = citation_df[citation_df.split=='train']\n",
        "        return cls(citation_df, CitationVectorizer.from_dataframe(train_citation_df))\n",
        "\n",
        "    @classmethod\n",
        "    def load_dataset_and_load_vectorizer(cls, citation_csv, vectorizer_filepath):\n",
        "        \"\"\"Load dataset and the corresponding vectorizer. \n",
        "        Used in the case in the vectorizer has been cached for re-use\n",
        "        \n",
        "        Args:\n",
        "            surname_csv (str): location of the dataset\n",
        "            vectorizer_filepath (str): location of the saved vectorizer\n",
        "        Returns:\n",
        "            an instance of SurnameDataset\n",
        "        \"\"\"\n",
        "        \n",
        "        citation_df = citation_csv\n",
        "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
        "        return cls(citation_csv, vectorizer)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_vectorizer_only(vectorizer_filepath):\n",
        "        \"\"\"a static method for loading the vectorizer from file\n",
        "        \n",
        "        Args:\n",
        "            vectorizer_filepath (str): the location of the serialized vectorizer\n",
        "        Returns:\n",
        "            an instance of functionVectorizer\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath) as fp:\n",
        "            return NameVectorizer.from_serializable(json.load(fp))\n",
        "\n",
        "    def save_vectorizer(self, vectorizer_filepath):\n",
        "        \"\"\"saves the vectorizer to disk using json\n",
        "        \n",
        "        Args:\n",
        "            vectorizer_filepath (str): the location to save the vectorizer\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath, \"w\") as fp:\n",
        "            json.dump(self._vectorizer.to_serializable(), fp)\n",
        "\n",
        "    def get_vectorizer(self):\n",
        "        \"\"\" returns the vectorizer \"\"\"\n",
        "        return self._vectorizer\n",
        "\n",
        "    def set_split(self, split=\"train\"):\n",
        "        \"\"\" selects the splits in the dataset using a column in the dataframe \"\"\"\n",
        "        self._target_split = split\n",
        "        self._target_df, self._target_size = self._lookup_dict[split]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._target_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"the primary entry point method for PyTorch datasets\n",
        "        \n",
        "        Args:\n",
        "            index (int): the index to the data point \n",
        "        Returns:\n",
        "            a dictionary holding the data point's features (x_data) and label (y_target)\n",
        "        \"\"\"\n",
        "        \n",
        "        \n",
        "        row = self._target_df.iloc[index]\n",
        "        citseg= row.citseg_id\n",
        "\n",
        "        # title_vector = \\\n",
        "        #     self._vectorizer.vectorize(row.Text_Tokens, self._max_seq_length)\n",
        "\n",
        "        # category_index = row.Cit_func\n",
        "        #print(category_index)\n",
        "        category_index = self._vectorizer.category_vocab.lookup_token(row.Cit_func)\n",
        "        # print(\"title_vector\")\n",
        "        title_vector=row.Text_Tokens\n",
        "        # print(title_vector)\n",
        "        \n",
        "        # return {'x_data': title_vector,\n",
        "        #         'y_target': category_index,\n",
        "        #         'citseg_id':citseg\n",
        "        #         }\n",
        "\n",
        "        return title_vector, category_index , citseg\n",
        "\n",
        "    def get_num_batches(self, batch_size):\n",
        "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
        "        \n",
        "        Args:\n",
        "            batch_size (int)\n",
        "        Returns:\n",
        "            number of batches in the dataset\n",
        "        \"\"\"\n",
        "        return len(self) // batch_size\n",
        "\n",
        "def my_collate(batch):\n",
        "   print(batch)\n",
        "   return batch\n",
        "\n",
        "def batchify(data, bsz, shuffle=False,device=\"cpu\"):\n",
        "    if shuffle:\n",
        "        random.shuffle(data)\n",
        "    sents,tags,citseg = zip(*data)\n",
        "    nbatch = (len(sents)+bsz-1) // bsz\n",
        "    # downsample biggest class\n",
        "    # sents, tags = balance_tags(sents, tags)\n",
        "\n",
        "    for i in range(nbatch):\n",
        "\n",
        "        batch = sents[i*bsz:(i+1)*bsz]\n",
        "        batch1 = batch\n",
        "        batch_tags = tags[i*bsz:(i+1)*bsz]\n",
        "        citseg_id  = citseg[i*bsz:(i+1)*bsz]\n",
        "        batch = batch_to_ids(batch)\n",
        "        batch_tags = torch.tensor(batch_tags).long()\n",
        "        citseg_id = torch.tensor(citseg_id).long()\n",
        "        # lengths = [torch.tensor(l).long() for l in lengths]\n",
        "        # print(\"batch\")\n",
        "        # print(batch)\n",
        "        # print(\"batch_tags\")\n",
        "        # print(device)\n",
        "        # print(batch_tags)\n",
        "        batch=batch.to(device)\n",
        "        batch_tags=batch_tags.to(device)\n",
        "        citseg_id = citseg_id.to(device)\n",
        "        # yield (batch, batch_tags, lengths)\n",
        "        yield (batch, batch_tags, citseg_id,batch1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TU_aL0p7u-MS"
      },
      "outputs": [],
      "source": [
        "# bilstm output of citeseg\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import os\n",
        "import numpy as np\n",
        "from allennlp.modules.elmo import Elmo\n",
        "\n",
        "class CitationClassifier1(nn.Module):\n",
        "    def __init__(self,hidden_dim,num_layers, label_size,dropout=0.5):\n",
        "        super(CitationClassifier1, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.hidden_dim = hidden_dim\n",
        "        options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
        "        weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
        "        self.elmo = Elmo(options_file, weight_file, 1, dropout=dropout, do_layer_norm=False)\n",
        "        # elmo output\n",
        "#         Dict with keys:\n",
        "#         ``'elmo_representations'``: ``List[torch.Tensor]``\n",
        "#             A ``num_output_representations`` list of ELMo representations for the input sequence.\n",
        "#             Each representation is shape ``(batch_size, timesteps, embedding_dim)``\n",
        "#         ``'mask'``:  ``torch.Tensor``\n",
        "#             Shape ``(batch_size, timesteps)`` long tensor with sequence mask.\n",
        "        self.lstm = nn.LSTM(1024, hidden_dim,num_layers, bidirectional=True, batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_dim*2, 120)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(120, label_size)\n",
        "        self.act=nn.Softmax()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for name, param in self.hidden2label.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "        for name, param in self.conv1.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "        \n",
        "    def forward(self, sentences,citseg_id):\n",
        "        # print(\"sentences.shape\")\n",
        "        # print(sentences.shape)\n",
        "        elmo_out = self.elmo(sentences)\n",
        "        x = elmo_out['elmo_representations'][0]\n",
        "        # print(\"x.shape\")\n",
        "        # print(x.shape)\n",
        "        packed_output, (hidden, cell) = self.lstm(x)\n",
        "        packed_output=packed_output[torch.arange(packed_output.size(0)),citseg_id.long()]\n",
        "        # print(packed_output.shape)\n",
        "        out = self.fc1(packed_output)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        pred1= self.act(out)\n",
        "        return pred1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rW4nBxBa1f-v"
      },
      "outputs": [],
      "source": [
        "# h1 + hn + citseg\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import os\n",
        "import numpy as np\n",
        "from allennlp.modules.elmo import Elmo\n",
        "\n",
        "class CitationClassifier3(nn.Module):\n",
        "    def __init__(self,hidden_dim,num_layers, label_size,dropout=0.5):\n",
        "        super(CitationClassifier3, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.hidden_dim = hidden_dim\n",
        "        options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
        "        weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
        "        self.elmo = Elmo(options_file, weight_file, 1, dropout=dropout, do_layer_norm=False)\n",
        "        # elmo output\n",
        "#         Dict with keys:\n",
        "#         ``'elmo_representations'``: ``List[torch.Tensor]``\n",
        "#             A ``num_output_representations`` list of ELMo representations for the input sequence.\n",
        "#             Each representation is shape ``(batch_size, timesteps, embedding_dim)``\n",
        "#         ``'mask'``:  ``torch.Tensor``\n",
        "#             Shape ``(batch_size, timesteps)`` long tensor with sequence mask.\n",
        "        self.lstm = nn.LSTM(1024, hidden_dim,num_layers, bidirectional=True, batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_dim*6, 120)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(120, label_size)\n",
        "        self.act=nn.Softmax()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for name, param in self.hidden2label.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "        for name, param in self.conv1.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "        \n",
        "    def forward(self, sentences,citseg_id):\n",
        "        # print(\"sentences.shape\")\n",
        "        # print(sentences.shape)\n",
        "        elmo_out = self.elmo(sentences)\n",
        "        x = elmo_out['elmo_representations'][0]\n",
        "        # print(\"x.shape\")\n",
        "        s=sentences.shape[1]\n",
        "        packed_output, (hidden, cell) = self.lstm(x)\n",
        "        h_1 = packed_output[torch.arange(packed_output.size(0)),0]\n",
        "        h_n = packed_output[torch.arange(packed_output.size(0)),s-1]\n",
        "        packed_output=packed_output[torch.arange(packed_output.size(0)),citseg_id.long()]\n",
        "        # print(packed_output.shape)\n",
        "        h_1h_n=torch.cat([h_1,packed_output,h_n],dim=1)\n",
        "        out = self.fc1(h_1h_n)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        pred1= self.act(out)\n",
        "        return pred1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugtizegM0YaQ"
      },
      "outputs": [],
      "source": [
        "# attention\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import os\n",
        "import numpy as np\n",
        "from allennlp.modules.elmo import Elmo\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "        \n",
        "        self.supports_masking = True\n",
        "\n",
        "        self.bias = bias\n",
        "        self.feature_dim = feature_dim\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "        \n",
        "        weight = torch.zeros(feature_dim, 1)\n",
        "        nn.init.kaiming_uniform_(weight)\n",
        "        self.weight = nn.Parameter(weight)\n",
        "        \n",
        "        if bias:\n",
        "            self.b = nn.Parameter(torch.zeros(step_dim))\n",
        "        \n",
        "    def forward(self, x, mask=None):\n",
        "        # print(\"x.shape\")\n",
        "        # print(x.shape)\n",
        "        feature_dim = self.feature_dim \n",
        "        # print(feature_dim)\n",
        "        step_dim = self.step_dim\n",
        "        # print(step_dim)\n",
        "\n",
        "        eij = torch.mm(x.contiguous().view(-1, feature_dim), self.weight).view(-1, step_dim)\n",
        "        # print(\"eij.shape\")\n",
        "        # print(eij.shape)\n",
        "        \n",
        "        if self.bias:\n",
        "            eij = eij + self.b\n",
        "            \n",
        "        eij = torch.tanh(eij)\n",
        "        a = torch.exp(eij)\n",
        "        \n",
        "        if mask is not None:\n",
        "            a = a * mask\n",
        "\n",
        "        a = a / (torch.sum(a, 1, keepdim=True) + 1e-10)\n",
        "\n",
        "        weighted_input = x * torch.unsqueeze(a, -1)\n",
        "        # print(\"weighted_input.shape\")\n",
        "        # print(weighted_input.shape)\n",
        "        return (weighted_input)\n",
        "\n",
        "class CitationClassifier(nn.Module):\n",
        "    def __init__(self,hidden_dim,num_layers, label_size,dropout=0.5):\n",
        "        super(CitationClassifier, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.hidden_dim = hidden_dim\n",
        "        options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
        "        weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
        "        self.elmo = Elmo(options_file, weight_file, 1, dropout=dropout, do_layer_norm=False)\n",
        "        # elmo output\n",
        "#         Dict with keys:\n",
        "#         ``'elmo_representations'``: ``List[torch.Tensor]``\n",
        "#             A ``num_output_representations`` list of ELMo representations for the input sequence.\n",
        "#             Each representation is shape ``(batch_size, timesteps, embedding_dim)``\n",
        "#         ``'mask'``:  ``torch.Tensor``\n",
        "#             Shape ``(batch_size, timesteps)`` long tensor with sequence mask.\n",
        "        self.lstm = nn.LSTM(1024, hidden_dim,num_layers, bidirectional=True, batch_first=True)\n",
        "        # self.attention_layer = Attention(hidden_dim*2)\n",
        "        self.fc1 = nn.Linear(hidden_dim*2, 120)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(120, label_size)\n",
        "        self.act=nn.Softmax()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for name, param in self.hidden2label.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "        for name, param in self.conv1.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "        \n",
        "    def forward(self, sentences,citseg_id):\n",
        "        # print(\"sentences.shape\")\n",
        "        # print(sentences.shape)\n",
        "        elmo_out = self.elmo(sentences)\n",
        "        x = elmo_out['elmo_representations'][0]\n",
        "        # print(elmo_out['elmo_representations'][0].shape)\n",
        "        # print(\"x.shape\")\n",
        "        # print(x.shape)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.lstm(x)\n",
        "        l=packed_output.shape[1]\n",
        "        l=torch.tensor(l)\n",
        "        l=l.cuda()\n",
        "        h=torch.tensor(64)\n",
        "        h=h.cuda()\n",
        "        self.attention_layer = Attention(h,l).cuda()\n",
        "        packed_output = self.attention_layer(packed_output)\n",
        "        # print(packed_output.shape)\n",
        "        packed_output=packed_output[torch.arange(packed_output.size(0)),citseg_id.long()]\n",
        "        # print(packed_output.shape)\n",
        "        out = self.fc1(packed_output)\n",
        "        # print(out.shape)\n",
        "        out = self.relu(out)\n",
        "        # print(out.shape)\n",
        "        out = self.fc2(out)\n",
        "        # print(out.shape)\n",
        "        pred1= self.act(out)\n",
        "        # print(pred1.shape)\n",
        "        return pred1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAlRjYJJUQN4"
      },
      "outputs": [],
      "source": [
        "def make_train_state(args):\n",
        "    return {'stop_early': False,\n",
        "            'early_stopping_step': 0,\n",
        "            'early_stopping_best_val': 1e8,\n",
        "            'learning_rate': args.learning_rate,\n",
        "            'epoch_index': 0,\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': [],\n",
        "            'test_loss': -1,\n",
        "            'test_acc': -1,\n",
        "            'model_filename': args.model_state_file}\n",
        "\n",
        "def update_train_state(args, model, train_state):\n",
        "    \"\"\"Handle the training state updates.\n",
        "\n",
        "    Components:\n",
        "     - Early Stopping: Prevent overfitting.\n",
        "     - Model Checkpoint: Model is saved if the model is better\n",
        "\n",
        "    :param args: main arguments\n",
        "    :param model: model to train\n",
        "    :param train_state: a dictionary representing the training state values\n",
        "    :returns:\n",
        "        a new train_state\n",
        "    \"\"\"\n",
        "\n",
        "    # Save one model at least\n",
        "    if train_state['epoch_index'] == 0:\n",
        "        torch.save(model.state_dict(), train_state['model_filename'])\n",
        "        train_state['stop_early'] = False\n",
        "\n",
        "    # Save model if performance improved\n",
        "    elif train_state['epoch_index'] >= 1:\n",
        "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
        "\n",
        "        # If loss worsened\n",
        "        if loss_t >= train_state['early_stopping_best_val']:\n",
        "            # Update step\n",
        "            train_state['early_stopping_step'] += 1\n",
        "        # Loss decreased\n",
        "        else:\n",
        "            # Save the best model\n",
        "            if loss_t < train_state['early_stopping_best_val']:\n",
        "                torch.save(model.state_dict(), train_state['model_filename'])\n",
        "\n",
        "            # Reset early stopping step\n",
        "            train_state['early_stopping_step'] = 0\n",
        "\n",
        "        # Stop early ?\n",
        "        train_state['stop_early'] = \\\n",
        "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
        "\n",
        "    return train_state\n",
        "\n",
        "def compute_accuracy(y_pred, y_target):\n",
        "    _, y_pred_indices = y_pred.max(dim=1)\n",
        "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
        "    return n_correct / len(y_pred_indices) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4MhhdldUTqS"
      },
      "outputs": [],
      "source": [
        "def set_seed_everywhere(seed, cuda):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def handle_dirs(dirpath):\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)\n",
        "        \n",
        "def load_glove_from_file(glove_filepath):\n",
        "    \"\"\"\n",
        "    Load the GloVe embeddings \n",
        "    \n",
        "    Args:\n",
        "        glove_filepath (str): path to the glove embeddings file \n",
        "    Returns:\n",
        "        word_to_index (dict), embeddings (numpy.ndarary)\n",
        "    \"\"\"\n",
        "\n",
        "    word_to_index = {}\n",
        "    embeddings = []\n",
        "    with open(glove_filepath, \"r\") as fp:\n",
        "        for index, line in enumerate(fp):\n",
        "            line = line.split(\" \") # each line: word num1 num2 ...\n",
        "            word_to_index[line[0]] = index # word = line[0] \n",
        "            embedding_i = np.array([float(val) for val in line[1:]])\n",
        "            embeddings.append(embedding_i)\n",
        "    return word_to_index, np.stack(embeddings)\n",
        "\n",
        "def make_embedding_matrix(glove_filepath, words):\n",
        "    \"\"\"\n",
        "    Create embedding matrix for a specific set of words.\n",
        "    \n",
        "    Args:\n",
        "        glove_filepath (str): file path to the glove embeddigns\n",
        "        words (list): list of words in the dataset\n",
        "    \"\"\"\n",
        "    word_to_idx, glove_embeddings = load_glove_from_file(glove_filepath)\n",
        "    embedding_size = glove_embeddings.shape[1]\n",
        "    final_embeddings = np.zeros((len(words), embedding_size))\n",
        "\n",
        "    for i, word in enumerate(words):\n",
        "        if word in word_to_idx:\n",
        "            final_embeddings[i, :] = glove_embeddings[word_to_idx[word]]\n",
        "        else:\n",
        "            embedding_i = torch.ones(1, embedding_size)\n",
        "            torch.nn.init.xavier_uniform_(embedding_i)\n",
        "            final_embeddings[i, :] = embedding_i\n",
        "    print(final_embeddings)\n",
        "    print(final_embeddings.shape)\n",
        "    return final_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myuZwu5LUWhP"
      },
      "outputs": [],
      "source": [
        "from argparse import Namespace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw2QwqzRUZB2",
        "outputId": "acf72721-bc6d-40db-d8af-4675fcdd1265"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expanded filepaths: \n",
            "\tmodel_storage/ch5/document_classification/vectorizer.json\n",
            "\tmodel_storage/ch5/document_classification/model.pth\n",
            "Using CUDA: True\n"
          ]
        }
      ],
      "source": [
        "args = Namespace(\n",
        "    # Data and Path hyper parameters\n",
        "    citation_csv=final_citation,\n",
        "    vectorizer_file=\"vectorizer.json\",\n",
        "    model_state_file=\"model.pth\",\n",
        "    save_dir=\"model_storage/ch5/document_classification\",\n",
        "    # Model hyper parameters\n",
        "    glove_filepath='/content/glove.6B.300d.txt', \n",
        "    use_glove=False,\n",
        "    embedding_size=300, \n",
        "    hidden_dim=32,\n",
        "    # Training hyper parameter\n",
        "    seed=1337, \n",
        "    learning_rate=0.001, \n",
        "    dropout_p=0.1, \n",
        "    batch_size=30, \n",
        "    num_epochs=20, \n",
        "    num_layers=2,\n",
        "    early_stopping_criteria=5, \n",
        "    # Runtime option\n",
        "    cuda=True, \n",
        "    catch_keyboard_interrupt=True, \n",
        "    reload_from_files=False,\n",
        "    expand_filepaths_to_save_dir=True\n",
        ") \n",
        "\n",
        "if args.expand_filepaths_to_save_dir:\n",
        "    args.vectorizer_file = os.path.join(args.save_dir,\n",
        "                                        args.vectorizer_file)\n",
        "\n",
        "    args.model_state_file = os.path.join(args.save_dir,\n",
        "                                         args.model_state_file)\n",
        "    \n",
        "    print(\"Expanded filepaths: \")\n",
        "    print(\"\\t{}\".format(args.vectorizer_file))\n",
        "    print(\"\\t{}\".format(args.model_state_file))\n",
        "    \n",
        "# Check CUDA\n",
        "if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "    \n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "print(\"Using CUDA: {}\".format(args.cuda))\n",
        "\n",
        "# Set seed for reproducibility\n",
        "set_seed_everywhere(args.seed, args.cuda)\n",
        "\n",
        "# handle dirs\n",
        "handle_dirs(args.save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLVLaMikZR6o"
      },
      "outputs": [],
      "source": [
        "args.use_glove = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GbN5qWPZdOS",
        "outputId": "57760e35-f977-4d6b-a88c-a88602a1e399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16728\n",
            "[[-0.11907164 -0.00123771  0.03475953 ...  0.10838436 -0.02188396\n",
            "  -0.09059642]\n",
            " [-0.03658002  0.06027976 -0.01801901 ...  0.11394491 -0.03662597\n",
            "  -0.09734906]\n",
            " [-0.07221913 -0.02466366 -0.03699218 ...  0.0299247  -0.07259606\n",
            "  -0.04028996]\n",
            " ...\n",
            " [ 0.024889   -0.15851    -0.19032    ... -0.17296    -0.33603\n",
            "  -0.25569   ]\n",
            " [ 0.37002    -0.45283     0.70053    ...  0.69341     0.24019\n",
            "   0.065249  ]\n",
            " [ 0.10476776 -0.07515869  0.02444218 ...  0.06867117 -0.13481018\n",
            "  -0.01800561]]\n",
            "(16728, 300)\n",
            "Using pre-trained embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "downloading: 100%|##########| 336/336 [00:00<00:00, 1.07MiB/s]\n",
            "downloading: 100%|##########| 357M/357M [00:16<00:00, 22.9MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CitationClassifier1(\n",
            "  (elmo): Elmo(\n",
            "    (_elmo_lstm): _ElmoBiLm(\n",
            "      (_token_embedder): _ElmoCharacterEncoder(\n",
            "        (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
            "        (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
            "        (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
            "        (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
            "        (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
            "        (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
            "        (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
            "        (_highways): Highway(\n",
            "          (_layers): ModuleList(\n",
            "            (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
            "            (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
            "          )\n",
            "        )\n",
            "        (_projection): Linear(in_features=2048, out_features=512, bias=True)\n",
            "      )\n",
            "      (_elmo_lstm): ElmoLstm(\n",
            "        (forward_layer_0): LstmCellWithProjection(\n",
            "          (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
            "          (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
            "          (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
            "        )\n",
            "        (backward_layer_0): LstmCellWithProjection(\n",
            "          (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
            "          (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
            "          (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
            "        )\n",
            "        (forward_layer_1): LstmCellWithProjection(\n",
            "          (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
            "          (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
            "          (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
            "        )\n",
            "        (backward_layer_1): LstmCellWithProjection(\n",
            "          (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
            "          (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
            "          (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (_dropout): Dropout(p=0.5, inplace=False)\n",
            "    (scalar_mix_0): ScalarMix(\n",
            "      (scalar_parameters): ParameterList(\n",
            "          (0): Parameter containing: [torch.FloatTensor of size 1]\n",
            "          (1): Parameter containing: [torch.FloatTensor of size 1]\n",
            "          (2): Parameter containing: [torch.FloatTensor of size 1]\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (lstm): LSTM(1024, 32, num_layers=2, batch_first=True, bidirectional=True)\n",
            "  (fc1): Linear(in_features=64, out_features=120, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=120, out_features=6, bias=True)\n",
            "  (act): Softmax(dim=None)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "if args.reload_from_files:\n",
        "    # training from a checkpoint\n",
        "    dataset = CitationDataset.load_dataset_and_load_vectorizer(args.citation_csv,\n",
        "                                                              args.vectorizer_file)\n",
        "else:\n",
        "    # create dataset and vectorizer\n",
        "    dataset = CitationDataset.load_dataset_and_make_vectorizer(args.citation_csv)\n",
        "    dataset.save_vectorizer(args.vectorizer_file)\n",
        "vectorizer = dataset.get_vectorizer()\n",
        "print(len(vectorizer.title_vocab))\n",
        "# Use GloVe or randomly initialized embeddings\n",
        "if args.use_glove:\n",
        "    words = vectorizer.title_vocab._token_to_idx.keys()\n",
        "    embeddings = make_embedding_matrix(glove_filepath=args.glove_filepath, \n",
        "                                       words=words)\n",
        "    print(\"Using pre-trained embeddings\")\n",
        "else:\n",
        "    print(\"Not using pre-trained embeddings\")\n",
        "    embeddings = None\n",
        "\n",
        "classifier = CitationClassifier1(hidden_dim=args.hidden_dim,num_layers=args.num_layers,label_size=len(vectorizer.category_vocab))\n",
        "\n",
        "print(classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-rHukDMJeKn",
        "outputId": "2ccc687c-affd-462c-c905-1c3d22e80f33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16728, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624,
          "referenced_widgets": [
            "03548bea8145471ca8238d9f6375eaa5",
            "012b46362ca74fb589238f178b6cc7b2",
            "2ee857958b40428d893f4b3cf0c92f8c",
            "b1fee2be454f45c9bcad277b5cf9aa18",
            "c01ae07344844aa6bd239fee264d0c01",
            "739f1789866e4a9989d057ac55ca0b94",
            "82439f1d3d9e4a7f941c508a95219eb6",
            "05ced7f11e8349a886b2a16ce9c18388",
            "e60d8603fffd4bb7a56051838a37b2f3",
            "e70ea070996243e398542af4993c3d87",
            "51f8fbffd0f3470bbe5fc90f6e5c69e3",
            "a04915a4b9b0440a83f1abd353bb2fc9",
            "84080c71cd0f460496ddb2b6ccc78872",
            "650712c76dbc4277b5d0468d4b5f84fc",
            "52dd054586774fd78f42d7931435b4f8",
            "647633f5e81b478995096f06839b91fa",
            "23ff315bf0b2436f96044e03a86ea0e7",
            "03245cd096a34e83a198670063e5f4d4",
            "73276a84c02e4f70b521c355bcbdacdd",
            "0157f3e4474b426caaa0d1acf7516dc8",
            "c04b45c7c6aa481885815a6dd902153a",
            "ec4e678a393e44fa98a9f33d17fb890a",
            "c745ef9c7d1242dba73b618d1924e0ce",
            "3a8b29d33ac9417fa11d62ad59eab9e8",
            "609252dad3a742d0a427e097b8c41052",
            "4bd1353be4ae43639501722bb5addaa4",
            "f4e8ed03f508409c9f2e644880dae3ef",
            "da14b2f2eeb44811a3f9861768342a60",
            "4e4a84b978b8404da7faddbad80529ef",
            "2eb0cabdf6f3420080a50aeaa2faebaf",
            "efc5e86fb4264983973fa3cbd07cd7f8",
            "4fe923411b7e4051b9b90df4446f5e4a",
            "130be9244f2b461cac8aa69ea62450e0"
          ]
        },
        "id": "4vMsRIWTZlxE",
        "outputId": "92708b0c-5c64-435c-919c-9c0f2f391d51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03548bea8145471ca8238d9f6375eaa5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "training routine:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a04915a4b9b0440a83f1abd353bb2fc9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "split=train:   0%|          | 0/83 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c745ef9c7d1242dba73b618d1924e0ce",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "split=val:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\t val_loss=1.7101590083195612\t val_acc=26.1439842209073\n",
            "Epoch 1\t val_loss=1.6574645042419434\t val_acc=25.650887573964496\n",
            "Epoch 2\t val_loss=1.632040514395787\t val_acc=27.91913214990138\n",
            "Epoch 3\t val_loss=1.6401293919636655\t val_acc=26.213017751479292\n",
            "Epoch 4\t val_loss=1.6056073491389935\t val_acc=35.88757396449704\n",
            "Epoch 5\t val_loss=1.5934086579542894\t val_acc=32.86982248520711\n",
            "Epoch 6\t val_loss=1.5809554045016945\t val_acc=38.23471400394478\n",
            "Epoch 7\t val_loss=1.5645172871076143\t val_acc=41.696252465483234\n",
            "Epoch 8\t val_loss=1.6140728134375353\t val_acc=32.81065088757397\n",
            "Epoch 9\t val_loss=1.553067331130688\t val_acc=42.850098619329394\n",
            "Epoch 10\t val_loss=1.5372824806433458\t val_acc=45.02958579881657\n",
            "Epoch 11\t val_loss=1.518640536528367\t val_acc=43.836291913214986\n",
            "Epoch 12\t val_loss=1.5339737763771646\t val_acc=46.33136094674557\n",
            "Epoch 13\t val_loss=1.560791437442486\t val_acc=41.5483234714004\n",
            "Epoch 14\t val_loss=1.4917304194890535\t val_acc=49.684418145956606\n",
            "Epoch 15\t val_loss=1.487618469274961\t val_acc=51.518737672583825\n",
            "Epoch 16\t val_loss=1.48040372133255\t val_acc=51.75542406311637\n",
            "Epoch 17\t val_loss=1.469194127963139\t val_acc=49.70414201183432\n",
            "Epoch 18\t val_loss=1.4809985023278456\t val_acc=52.820512820512825\n",
            "Epoch 19\t val_loss=1.4802833382899947\t val_acc=50.23668639053255\n"
          ]
        }
      ],
      "source": [
        "predictions=[]\n",
        "prediction=[]\n",
        "y=[]\n",
        "classifier = classifier.to(args.device)\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\n",
        "    \n",
        "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
        "optimizer = optim.RMSprop(classifier.parameters(), lr=args.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                           mode='min', factor=0.5,\n",
        "                                           patience=1)\n",
        "\n",
        "train_state = make_train_state(args)\n",
        "\n",
        "epoch_bar = tqdm_notebook(desc='training routine', \n",
        "                          total=args.num_epochs,\n",
        "                          position=0)\n",
        "\n",
        "dataset.set_split('train')\n",
        "train_bar = tqdm_notebook(desc='split=train',\n",
        "                          total=dataset.get_num_batches(args.batch_size), \n",
        "                          position=1, \n",
        "                          leave=True)\n",
        "dataset.set_split('val')\n",
        "val_bar = tqdm_notebook(desc='split=val',\n",
        "                        total=dataset.get_num_batches(args.batch_size), \n",
        "                        position=1, \n",
        "                        leave=True)\n",
        "\n",
        "try:\n",
        "    for epoch_index in range(args.num_epochs):\n",
        "        train_state['epoch_index'] = epoch_index\n",
        "\n",
        "        # Iterate over training dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
        "\n",
        "        dataset.set_split('train')\n",
        "        batch_generator = batchify(dataset,bsz=args.batch_size,device=args.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        classifier.train()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # the training routine is these 5 steps:\n",
        "\n",
        "            # --------------------------------------\n",
        "            # step 1. zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # step 2. compute the output\n",
        "            y_pred = classifier(batch_dict[0],batch_dict[2])\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = loss_func(y_pred, batch_dict[1])\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # step 4. use loss to produce gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # step 5. use optimizer to take gradient step\n",
        "            optimizer.step()\n",
        "            # -----------------------------------------\n",
        "            # compute the accuracy\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict[1])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            # update bar\n",
        "            train_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                                  epoch=epoch_index)\n",
        "            train_bar.update()\n",
        "\n",
        "        train_state['train_loss'].append(running_loss)\n",
        "        train_state['train_acc'].append(running_acc)\n",
        "\n",
        "        # Iterate over val dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
        "        dataset.set_split('val')\n",
        "        batch_generator = batchify(dataset,bsz=args.batch_size,device=args.device)\n",
        "        running_loss = 0.\n",
        "        running_acc = 0.\n",
        "        classifier.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "            # compute the output\n",
        "            y_pred =  classifier(batch_dict[0],batch_dict[2])\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = loss_func(y_pred, batch_dict[1])\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            _, predictions = y_pred.max(dim=1)\n",
        "            prediction.append(predictions)\n",
        "            y.append(batch_dict[1])\n",
        "\n",
        "            # compute the accuracy\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict[1])\n",
        "            \n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                            epoch=epoch_index)\n",
        "            val_bar.update()\n",
        "        print('Epoch {}\\t val_loss={}\\t val_acc={}'.format(epoch_index, running_loss, running_acc))\n",
        "\n",
        "        train_state['val_loss'].append(running_loss)\n",
        "        train_state['val_acc'].append(running_acc)\n",
        "        # print(\"Test loss: {};\".format(train_state['val_loss']))\n",
        "        # print(\"Test Accuracy: {}\".format(train_state['val_acc']))\n",
        "\n",
        "        train_state = update_train_state(args=args, model=classifier,\n",
        "                                         train_state=train_state)\n",
        "\n",
        "        scheduler.step(train_state['val_loss'][-1])\n",
        "\n",
        "        if train_state['stop_early']:\n",
        "            break\n",
        "\n",
        "        train_bar.n = 0\n",
        "        val_bar.n = 0\n",
        "        epoch_bar.update()\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Exiting loop\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fAHiZ3G80Q6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "befb52ab-9750-4eb1-9ba4-897e585e140a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val loss: [1.7101590083195612, 1.6574645042419434, 1.632040514395787, 1.6401293919636655, 1.6056073491389935, 1.5934086579542894, 1.5809554045016945, 1.5645172871076143, 1.6140728134375353, 1.553067331130688, 1.5372824806433458, 1.518640536528367, 1.5339737763771646, 1.560791437442486, 1.4917304194890535, 1.487618469274961, 1.48040372133255, 1.469194127963139, 1.4809985023278456, 1.4802833382899947];\n",
            "val Accuracy: [26.1439842209073, 25.650887573964496, 27.91913214990138, 26.213017751479292, 35.88757396449704, 32.86982248520711, 38.23471400394478, 41.696252465483234, 32.81065088757397, 42.850098619329394, 45.02958579881657, 43.836291913214986, 46.33136094674557, 41.5483234714004, 49.684418145956606, 51.518737672583825, 51.75542406311637, 49.70414201183432, 52.820512820512825, 50.23668639053255]\n"
          ]
        }
      ],
      "source": [
        "print(\"val loss: {};\".format(train_state['val_loss']))\n",
        "print(\"val Accuracy: {}\".format(train_state['val_acc']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GK0AkqEZZs6p",
        "outputId": "01ce1fe0-5450-41df-fc71-815ddefad604"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ],
      "source": [
        "# compute the loss & accuracy on the test set using the best available model\n",
        "\n",
        "classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
        "\n",
        "classifier = classifier.to(args.device)\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\n",
        "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
        "\n",
        "dataset.set_split('val')\n",
        "batch_generator = batchify(dataset,bsz=args.batch_size,device=args.device)\n",
        "running_loss = 0.\n",
        "running_acc = 0.\n",
        "classifier.eval()\n",
        "predictions=[]\n",
        "prediction=[]\n",
        "y=[]\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "    # compute the output\n",
        "    y_pred =  classifier(batch_dict[0],batch_dict[2])\n",
        "\n",
        "    \n",
        "    # compute the loss\n",
        "    loss = loss_func(y_pred, batch_dict[1])\n",
        "    loss_t = loss.item()\n",
        "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "    _, predictions = y_pred.max(dim=1)\n",
        "    prediction.append(predictions)\n",
        "    y.append(batch_dict[1])\n",
        "    # compute the accuracy\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict[1])\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss\n",
        "train_state['test_acc'] = running_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNNX4LE5DSV_",
        "outputId": "85a8b461-a7ee-400b-b6d3-17a931db980f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 1, 0, 2, 1, 1, 0, 1, 1, 1, 4, 0, 0, 3, 0, 5, 0, 0, 0, 4, 0, 0, 0,\n",
              "        5, 0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "y.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CphVTe2mDUo-",
        "outputId": "9fe82e90-5fde-470d-9864-9a476abcb2b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 0, 5, 4, 2, 1, 0, 5, 2, 1, 1, 3, 1, 2, 3, 0, 5, 0, 4, 4, 4, 0, 3, 5,\n",
              "        5, 1], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "prediction.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8340BlcKyz-"
      },
      "outputs": [],
      "source": [
        "y_tensor = torch.stack(y)\n",
        "pred_tensor = torch.stack(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liQoFAbmLsK7"
      },
      "outputs": [],
      "source": [
        "true_y=y_tensor.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0QCzC_BL7lE"
      },
      "outputs": [],
      "source": [
        "pred_y=pred_tensor.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JkaI7xbRC9N",
        "outputId": "2e2be12b-81ae-42f4-de28-d5263c0a3217"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "true_y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VgYgN2KRwKW"
      },
      "outputs": [],
      "source": [
        "pred_y=pred_y.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuF_x0RtRgVA"
      },
      "outputs": [],
      "source": [
        "true_y=true_y.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVP0sn8L-QXE",
        "outputId": "b96c1466-5857-4954-ddeb-6e07e78d1e8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "            Background       0.71      0.37      0.49       312\n",
            "Comparison or Contrast       0.58      0.51      0.54       184\n",
            "               Extends       0.17      0.34      0.23        32\n",
            "                Future       0.30      0.81      0.43        16\n",
            "            Motivation       0.28      0.57      0.37        56\n",
            "                  Uses       0.56      0.75      0.65       150\n",
            "\n",
            "              accuracy                           0.50       750\n",
            "             macro avg       0.43      0.56      0.45       750\n",
            "          weighted avg       0.58      0.50      0.51       750\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = [\"Background\",\"Comparison or Contrast\",\"Extends\",\"Future\",\"Motivation\",\"Uses\"]\n",
        "#target_names = [\"Future\",\"Neut\",\"PSim\",\"compare_contrast\",\"support\"]\n",
        "print(classification_report(true_y, pred_y, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvBWioETavYX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Generate the confusion matrix\n",
        "cf_matrix = confusion_matrix(true_y, pred_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0UOfbp5qYWO",
        "outputId": "11b655fc-6553-4841-c6e7-66f1d414acdf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[116,  48,  28,  15,  52,  53],\n",
              "       [ 26,  93,   9,   6,  26,  24],\n",
              "       [  3,   8,  11,   1,   3,   6],\n",
              "       [  1,   0,   0,  13,   2,   0],\n",
              "       [  9,   5,   3,   3,  32,   4],\n",
              "       [  9,   7,  14,   6,   1, 113]])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "cf_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "id": "HAtF8sgfcK9_",
        "outputId": "2bd1d600-3c89-4436-e753-150a6540c1ed"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(15, 15))\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues',fmt=\"d\")\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Category')\n",
        "ax.set_ylabel('Actual Category ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([\"Background\",\"Comparison or Contrast\",\"Extends\",\"Future\",\"Motivation\",\"Uses\"])\n",
        "ax.yaxis.set_ticklabels([\"Background\",\"Comparison or Contrast\",\"Extends\",\"Future\",\"Motivation\",\"Uses\"])\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUmMjpJdisng",
        "outputId": "4314de14-0f06-4d0d-ef33-18f45997fdf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CitationClassifier3(\n",
            "  (elmo): Elmo(\n",
            "    (_elmo_lstm): _ElmoBiLm(\n",
            "      (_token_embedder): _ElmoCharacterEncoder(\n",
            "        (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
            "        (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
            "        (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
            "        (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
            "        (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
            "        (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
            "        (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
            "        (_highways): Highway(\n",
            "          (_layers): ModuleList(\n",
            "            (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
            "            (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
            "          )\n",
            "        )\n",
            "        (_projection): Linear(in_features=2048, out_features=512, bias=True)\n",
            "      )\n",
            "      (_elmo_lstm): ElmoLstm(\n",
            "        (forward_layer_0): LstmCellWithProjection(\n",
            "          (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
            "          (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
            "          (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
            "        )\n",
            "        (backward_layer_0): LstmCellWithProjection(\n",
            "          (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
            "          (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
            "          (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
            "        )\n",
            "        (forward_layer_1): LstmCellWithProjection(\n",
            "          (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
            "          (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
            "          (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
            "        )\n",
            "        (backward_layer_1): LstmCellWithProjection(\n",
            "          (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
            "          (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
            "          (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (_dropout): Dropout(p=0.5, inplace=False)\n",
            "    (scalar_mix_0): ScalarMix(\n",
            "      (scalar_parameters): ParameterList(\n",
            "          (0): Parameter containing: [torch.FloatTensor of size 1]\n",
            "          (1): Parameter containing: [torch.FloatTensor of size 1]\n",
            "          (2): Parameter containing: [torch.FloatTensor of size 1]\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (lstm): LSTM(1024, 32, num_layers=2, batch_first=True, bidirectional=True)\n",
            "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=120, out_features=6, bias=True)\n",
            "  (act): Softmax(dim=None)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "classifier = CitationClassifier3(hidden_dim=args.hidden_dim,num_layers=args.num_layers,label_size=len(vectorizer.category_vocab))\n",
        "\n",
        "print(classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ek8jyXei0Rp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624,
          "referenced_widgets": [
            "1f5e3dd48a8a4dbc9f56aef5182b1832",
            "f01bc57f3d9b484dba2a5158e7b6a334",
            "581f72be3d604868b0f2ed71069f449c",
            "d89ba4367b894825b73b80a243efc287",
            "5e163eb23ddb4408be01d6658879f943",
            "8d7440718d8e4d79af562de54ea6f415",
            "e77cea3af48246f39440a8f2940acf5e",
            "1fb9f6b26bdf40e1925427519e02c0d6",
            "cd4c1cd4c49f4e91ad2d7b8c5d672354",
            "ef051299aa524714a302c3f796b2946e",
            "22545a7dd6624d9eb1e39f493136c1fa",
            "7a68b4aa93f64c65bb9967cb05a5802a",
            "1d75e25eddaa42ff9a60739156ca6b79",
            "44036aacaf2a4f00a3024f64362031b1",
            "d81d91b5ca93425aa945a6f5ebf52511",
            "e0806f683b744234a2565aa0692c92d7",
            "61b1640ca27948f6897a9dcd5615fbc8",
            "bb88a2a537524587a90b7c8ad9dd3983",
            "f818b79fcc994eb9b1af161d4592a335",
            "c25ee4568fae4060b303817ef72c08a4",
            "a89f53194dc34b168860272fe510416b",
            "90fdca6387144598a6c70a0982091991",
            "fbbf8c098d3f485b9459577522f7c64d",
            "5687b1e6af9446889f8a62a9e67bec93",
            "4b94c3e183c347dfad905ab5eb67ad2a",
            "f43733946f28468092c2c74ea04573a1",
            "c4be538a77ec4e66970ed51daa8e42f1",
            "4697afdfab2d4f0889e9eca734ad172f",
            "65d7748b17e7426699bfde525eb3ccbb",
            "9e8641913eb24a8b8d16a1390c45b1a7",
            "9b99bf73f8e744a38ae98e9b564108a5",
            "3d7034d94d084334b878afac6b66f357",
            "3faee3e35bfa4e95ab87b967795d5845"
          ]
        },
        "outputId": "3b75ee85-fe21-4312-cdd7-0e666f016709"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f5e3dd48a8a4dbc9f56aef5182b1832",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "training routine:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a68b4aa93f64c65bb9967cb05a5802a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "split=train:   0%|          | 0/83 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbbf8c098d3f485b9459577522f7c64d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "split=val:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\t val_loss=1.7040097071574285\t val_acc=32.0414201183432\n",
            "Epoch 1\t val_loss=1.7086031895417433\t val_acc=16.104536489151876\n",
            "Epoch 2\t val_loss=1.6155250026629524\t val_acc=38.658777120315584\n",
            "Epoch 3\t val_loss=1.6013162365326514\t val_acc=36.99211045364893\n",
            "Epoch 4\t val_loss=1.6076056086100068\t val_acc=42.7810650887574\n",
            "Epoch 5\t val_loss=1.6176516505388117\t val_acc=37.8895463510848\n",
            "Epoch 6\t val_loss=1.5910389790168173\t val_acc=44.72386587771203\n",
            "Epoch 7\t val_loss=1.573326367598314\t val_acc=45.108481262327416\n",
            "Epoch 8\t val_loss=1.5615248313316932\t val_acc=46.242603550295854\n",
            "Epoch 9\t val_loss=1.5696505674949064\t val_acc=45.62130177514793\n",
            "Epoch 10\t val_loss=1.538526695508223\t val_acc=49.319526627218934\n",
            "Epoch 11\t val_loss=1.5354863817875204\t val_acc=47.761341222879686\n",
            "Epoch 12\t val_loss=1.5472676020402178\t val_acc=49.812623274161744\n",
            "Epoch 13\t val_loss=1.5280023033802321\t val_acc=50.68047337278107\n",
            "Epoch 14\t val_loss=1.5298414138647227\t val_acc=50.838264299802766\n",
            "Epoch 15\t val_loss=1.5440385616742647\t val_acc=48.31360946745562\n",
            "Epoch 16\t val_loss=1.517979750266442\t val_acc=55.14792899408285\n",
            "Epoch 17\t val_loss=1.5227738252052894\t val_acc=54.87179487179487\n",
            "Epoch 18\t val_loss=1.5221631756195655\t val_acc=54.467455621301774\n",
            "Epoch 19\t val_loss=1.5228570149495049\t val_acc=55.936883629191314\n"
          ]
        }
      ],
      "source": [
        "predictions=[]\n",
        "prediction=[]\n",
        "y=[]\n",
        "classifier = classifier.to(args.device)\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\n",
        "    \n",
        "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
        "optimizer = optim.RMSprop(classifier.parameters(), lr=args.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                           mode='min', factor=0.5,\n",
        "                                           patience=1)\n",
        "\n",
        "train_state = make_train_state(args)\n",
        "\n",
        "epoch_bar = tqdm_notebook(desc='training routine', \n",
        "                          total=args.num_epochs,\n",
        "                          position=0)\n",
        "\n",
        "dataset.set_split('train')\n",
        "train_bar = tqdm_notebook(desc='split=train',\n",
        "                          total=dataset.get_num_batches(args.batch_size), \n",
        "                          position=1, \n",
        "                          leave=True)\n",
        "dataset.set_split('val')\n",
        "val_bar = tqdm_notebook(desc='split=val',\n",
        "                        total=dataset.get_num_batches(args.batch_size), \n",
        "                        position=1, \n",
        "                        leave=True)\n",
        "\n",
        "try:\n",
        "    for epoch_index in range(args.num_epochs):\n",
        "        train_state['epoch_index'] = epoch_index\n",
        "\n",
        "        # Iterate over training dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
        "\n",
        "        dataset.set_split('train')\n",
        "        batch_generator = batchify(dataset,bsz=args.batch_size,device=args.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        classifier.train()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # the training routine is these 5 steps:\n",
        "\n",
        "            # --------------------------------------\n",
        "            # step 1. zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # step 2. compute the output\n",
        "            y_pred = classifier(batch_dict[0],batch_dict[2])\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = loss_func(y_pred, batch_dict[1])\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # step 4. use loss to produce gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # step 5. use optimizer to take gradient step\n",
        "            optimizer.step()\n",
        "            # -----------------------------------------\n",
        "            # compute the accuracy\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict[1])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            # update bar\n",
        "            train_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                                  epoch=epoch_index)\n",
        "            train_bar.update()\n",
        "\n",
        "        train_state['train_loss'].append(running_loss)\n",
        "        train_state['train_acc'].append(running_acc)\n",
        "\n",
        "        # Iterate over val dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
        "        dataset.set_split('val')\n",
        "        batch_generator = batchify(dataset,bsz=args.batch_size,device=args.device)\n",
        "        running_loss = 0.\n",
        "        running_acc = 0.\n",
        "        classifier.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "            # compute the output\n",
        "            y_pred =  classifier(batch_dict[0],batch_dict[2])\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = loss_func(y_pred, batch_dict[1])\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            _, predictions = y_pred.max(dim=1)\n",
        "            prediction.append(predictions)\n",
        "            y.append(batch_dict[1])\n",
        "\n",
        "            # compute the accuracy\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict[1])\n",
        "            \n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                            epoch=epoch_index)\n",
        "            val_bar.update()\n",
        "        print('Epoch {}\\t val_loss={}\\t val_acc={}'.format(epoch_index, running_loss, running_acc))\n",
        "\n",
        "        train_state['val_loss'].append(running_loss)\n",
        "        train_state['val_acc'].append(running_acc)\n",
        "        # print(\"Test loss: {};\".format(train_state['val_loss']))\n",
        "        # print(\"Test Accuracy: {}\".format(train_state['val_acc']))\n",
        "\n",
        "        train_state = update_train_state(args=args, model=classifier,\n",
        "                                         train_state=train_state)\n",
        "\n",
        "        scheduler.step(train_state['val_loss'][-1])\n",
        "\n",
        "        if train_state['stop_early']:\n",
        "            break\n",
        "\n",
        "        train_bar.n = 0\n",
        "        val_bar.n = 0\n",
        "        epoch_bar.update()\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Exiting loop\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ir28CNayjFpq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a15503fc-3643-40a5-9c73-5a71d5d53d03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ],
      "source": [
        "# compute the loss & accuracy on the test set using the best available model\n",
        "\n",
        "classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
        "\n",
        "classifier = classifier.to(args.device)\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\n",
        "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
        "\n",
        "dataset.set_split('val')\n",
        "batch_generator = batchify(dataset,bsz=args.batch_size,device=args.device)\n",
        "running_loss = 0.\n",
        "running_acc = 0.\n",
        "classifier.eval()\n",
        "predictions=[]\n",
        "prediction=[]\n",
        "y=[]\n",
        "sent=[]\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "    # compute the output\n",
        "    y_pred =  classifier(batch_dict[0],batch_dict[2])\n",
        "    sent.append(batch_dict[3])\n",
        "\n",
        "    \n",
        "    # compute the loss\n",
        "    loss = loss_func(y_pred, batch_dict[1])\n",
        "    loss_t = loss.item()\n",
        "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "    _, predictions = y_pred.max(dim=1)\n",
        "    prediction.append(predictions)\n",
        "    y.append(batch_dict[1])\n",
        "    # compute the accuracy\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict[1])\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss\n",
        "train_state['test_acc'] = running_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxsox4kremAC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d315838-cf96-4846-c04f-c3f71c3ecd4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['However',\n",
              "  ',',\n",
              "  'for',\n",
              "  'the',\n",
              "  'purposes',\n",
              "  'of',\n",
              "  'this',\n",
              "  'implementation',\n",
              "  ',',\n",
              "  'we',\n",
              "  'have',\n",
              "  'taken',\n",
              "  'the',\n",
              "  'most',\n",
              "  'constrained',\n",
              "  'position',\n",
              "  '.',\n",
              "  'Note',\n",
              "  'that',\n",
              "  ',',\n",
              "  'since',\n",
              "  'we',\n",
              "  'do',\n",
              "  'not',\n",
              "  'deal',\n",
              "  'with',\n",
              "  'such',\n",
              "  'Full',\n",
              "  'Attachment',\n",
              "  'model',\n",
              "  'has',\n",
              "  'been',\n",
              "  'argued',\n",
              "  'for',\n",
              "  ',',\n",
              "  'especially',\n",
              "  'with',\n",
              "  'regard',\n",
              "  'to',\n",
              "  'the',\n",
              "  'processing',\n",
              "  'of',\n",
              "  'headfinal',\n",
              "  'languages',\n",
              "  ',',\n",
              "  'where',\n",
              "  'evidence',\n",
              "  'has',\n",
              "  'been',\n",
              "  'found',\n",
              "  'of',\n",
              "  'pre-head',\n",
              "  'structuring',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.',\n",
              "  'Such',\n",
              "  'models',\n",
              "  'have',\n",
              "  'also',\n",
              "  'been',\n",
              "  'explored',\n",
              "  'computationally',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.'],\n",
              " ['In',\n",
              "  'the',\n",
              "  'field',\n",
              "  'of',\n",
              "  'statistical',\n",
              "  'parsing',\n",
              "  ',',\n",
              "  'various',\n",
              "  'probabilistic',\n",
              "  'evaluation',\n",
              "  'models',\n",
              "  'have',\n",
              "  'been',\n",
              "  'proposed',\n",
              "  'where',\n",
              "  'different',\n",
              "  'models',\n",
              "  'use',\n",
              "  'different',\n",
              "  'feature',\n",
              "  'types',\n",
              "  '[',\n",
              "  'CITSEG',\n",
              "  ']',\n",
              "  '[',\n",
              "  'CITSEG',\n",
              "  ']',\n",
              "  '[',\n",
              "  'CITSEG',\n",
              "  ']',\n",
              "  '[',\n",
              "  'CITSEG',\n",
              "  ']',\n",
              "  '[',\n",
              "  'CITSEG',\n",
              "  ']',\n",
              "  '[',\n",
              "  'CITSEG',\n",
              "  ']',\n",
              "  '[',\n",
              "  'CITSEG',\n",
              "  ']',\n",
              "  '[',\n",
              "  'CITSEG',\n",
              "  ']',\n",
              "  '.',\n",
              "  'How',\n",
              "  'to',\n",
              "  'evaluate',\n",
              "  'the',\n",
              "  'different',\n",
              "  'feature',\n",
              "  'types',\n",
              "  \"'\",\n",
              "  'effects',\n",
              "  'for',\n",
              "  'syntactic',\n",
              "  'parsing',\n",
              "  '?',\n",
              "  'The',\n",
              "  'paper',\n",
              "  'proposes',\n",
              "  'an',\n",
              "  'information',\n",
              "  '-',\n",
              "  'theory',\n",
              "  '-',\n",
              "  'based',\n",
              "  'feature',\n",
              "  'types',\n",
              "  'analysis',\n",
              "  'model',\n",
              "  ',',\n",
              "  'which',\n",
              "  'uses',\n",
              "  'the',\n",
              "  'measures',\n",
              "  'of',\n",
              "  'predictive',\n",
              "  'information',\n",
              "  'quantity',\n",
              "  ',',\n",
              "  'predictive',\n",
              "  'information',\n",
              "  'gain',\n",
              "  ',',\n",
              "  'predictive',\n",
              "  'information',\n",
              "  'redundancy',\n",
              "  'and',\n",
              "  'predictive',\n",
              "  'information',\n",
              "  'summation',\n",
              "  'to',\n",
              "  'quantitatively',\n",
              "  'analyse',\n",
              "  'the',\n",
              "  'different',\n",
              "  'contextual',\n",
              "  'feature',\n",
              "  'types',\n",
              "  \"'\",\n",
              "  'or',\n",
              "  'feature',\n",
              "  'types',\n",
              "  'combination',\n",
              "  \"'s\",\n",
              "  'predictive',\n",
              "  'power',\n",
              "  'for',\n",
              "  'syntactic',\n",
              "  'structure',\n",
              "  '.',\n",
              "  'In',\n",
              "  'the',\n",
              "  'following',\n",
              "  ',',\n",
              "  'Section',\n",
              "  '2',\n",
              "  'describes',\n",
              "  'the',\n",
              "  'probabilistic',\n",
              "  'evaluation',\n",
              "  'model',\n",
              "  'for',\n",
              "  'syntactic',\n",
              "  'trees',\n",
              "  ';',\n",
              "  'Section',\n",
              "  '3',\n",
              "  'proposes',\n",
              "  'an',\n",
              "  'information',\n",
              "  '-',\n",
              "  'theory',\n",
              "  '-',\n",
              "  'based',\n",
              "  'feature',\n",
              "  'type',\n",
              "  'analysis',\n",
              "  'model',\n",
              "  ';',\n",
              "  'Section',\n",
              "  '4',\n",
              "  'introduces',\n",
              "  'several',\n",
              "  'experimental',\n",
              "  'issues',\n",
              "  ';',\n",
              "  'Section',\n",
              "  '5',\n",
              "  'quantitatively',\n",
              "  'analyses',\n",
              "  'the',\n",
              "  'different',\n",
              "  'contextual',\n",
              "  'feature',\n",
              "  'types',\n",
              "  'or',\n",
              "  'feature',\n",
              "  'types',\n",
              "  'combination',\n",
              "  'in',\n",
              "  'the',\n",
              "  'view',\n",
              "  'of',\n",
              "  'information',\n",
              "  'theory',\n",
              "  'and',\n",
              "  'draws',\n",
              "  'a',\n",
              "  'series',\n",
              "  'of',\n",
              "  'conclusion',\n",
              "  'on',\n",
              "  'their',\n",
              "  'predictive',\n",
              "  'powers',\n",
              "  'for',\n",
              "  'syntactic',\n",
              "  'structures',\n",
              "  '.'],\n",
              " ['We',\n",
              "  'write',\n",
              "  'REGD',\n",
              "  'wn',\n",
              "  '.',\n",
              "  'k',\n",
              "  '/',\n",
              "  'for',\n",
              "  'the',\n",
              "  'well',\n",
              "  '-',\n",
              "  'nested',\n",
              "  'subclass',\n",
              "  'of',\n",
              "  'REGD.',\n",
              "  'k/',\n",
              "  ',',\n",
              "  'and',\n",
              "  'LCCFL.',\n",
              "  'k',\n",
              "  '/',\n",
              "  'for',\n",
              "  'the',\n",
              "  'class',\n",
              "  'of',\n",
              "  'all',\n",
              "  'dependency',\n",
              "  'languages',\n",
              "  'generated',\n",
              "  'by',\n",
              "  'lexicalized',\n",
              "  'ccfgs',\n",
              "  'with',\n",
              "  'a',\n",
              "  'fan',\n",
              "  '-',\n",
              "  'out',\n",
              "  'of',\n",
              "  'at',\n",
              "  'most',\n",
              "  'k.',\n",
              "  'Proposition',\n",
              "  '5.',\n",
              "  'REGD',\n",
              "  'wn',\n",
              "  '.k/',\n",
              "  'D',\n",
              "  'LCCFL',\n",
              "  '.k',\n",
              "  'C',\n",
              "  '1',\n",
              "  '/',\n",
              "  'As',\n",
              "  'a',\n",
              "  'special',\n",
              "  'case',\n",
              "  ',',\n",
              "  'Coupled',\n",
              "  '-',\n",
              "  'Context',\n",
              "  '-',\n",
              "  'Free',\n",
              "  'Grammars',\n",
              "  'with',\n",
              "  'fan',\n",
              "  '-',\n",
              "  'out',\n",
              "  '2',\n",
              "  'are',\n",
              "  'equivalent',\n",
              "  'to',\n",
              "  'Tree',\n",
              "  'Adjoining',\n",
              "  'Grammars',\n",
              "  '(',\n",
              "  'tags',\n",
              "  ')',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.',\n",
              "  'This',\n",
              "  'enables',\n",
              "  'us',\n",
              "  'to',\n",
              "  'generalize',\n",
              "  'a',\n",
              "  'previous',\n",
              "  'result',\n",
              "  'on',\n",
              "  'the',\n",
              "  'class',\n",
              "  'of',\n",
              "  'dependency',\n",
              "  'structures',\n",
              "  'generated',\n",
              "  'by',\n",
              "  'lexicalized',\n",
              "  'tags',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  'to',\n",
              "  'the',\n",
              "  'class',\n",
              "  'of',\n",
              "  'generated',\n",
              "  'dependency',\n",
              "  'languages',\n",
              "  ',',\n",
              "  'LTAL',\n",
              "  '.',\n",
              "  'Proposition',\n",
              "  '6',\n",
              "  '.',\n",
              "  'REGD',\n",
              "  'wn',\n",
              "  '.',\n",
              "  '1',\n",
              "  '/',\n",
              "  'D',\n",
              "  'LTAL'],\n",
              " ['The',\n",
              "  'highest',\n",
              "  'ranking',\n",
              "  'translated',\n",
              "  'pairs',\n",
              "  'are',\n",
              "  'shown',\n",
              "  'in',\n",
              "  'Table',\n",
              "  '5',\n",
              "  '.',\n",
              "  'The',\n",
              "  'only',\n",
              "  'Chinese',\n",
              "  'unknown',\n",
              "  'words',\n",
              "  'which',\n",
              "  'are',\n",
              "  'not',\n",
              "  'correctly',\n",
              "  'translated',\n",
              "  'in',\n",
              "  'the',\n",
              "  'above',\n",
              "  'list',\n",
              "  'are',\n",
              "  '9',\n",
              "  'Related',\n",
              "  'work',\n",
              "  'Using',\n",
              "  'vector',\n",
              "  'space',\n",
              "  'model',\n",
              "  'and',\n",
              "  'similarity',\n",
              "  'measures',\n",
              "  'for',\n",
              "  'ranking',\n",
              "  'is',\n",
              "  'a',\n",
              "  'common',\n",
              "  'approach',\n",
              "  'in',\n",
              "  'IR',\n",
              "  'for',\n",
              "  'query',\n",
              "  '/',\n",
              "  'text',\n",
              "  'and',\n",
              "  'text',\n",
              "  '/',\n",
              "  'text',\n",
              "  'comparisons',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.',\n",
              "  'This',\n",
              "  'approach',\n",
              "  'has',\n",
              "  'also',\n",
              "  'been',\n",
              "  'used',\n",
              "  'by',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ';',\n",
              "  '1',\n",
              "  'Lunar',\n",
              "  'is',\n",
              "  'not',\n",
              "  'an',\n",
              "  'unknown',\n",
              "  'word',\n",
              "  'in',\n",
              "  'English',\n",
              "  ',',\n",
              "  'Yeltsin',\n",
              "  'finds',\n",
              "  'its',\n",
              "  'translation',\n",
              "  'in',\n",
              "  'the',\n",
              "  '4',\n",
              "  '-',\n",
              "  'th',\n",
              "  'candidate',\n",
              "  '.',\n",
              "  '1994',\n",
              "  ')',\n",
              "  'for',\n",
              "  'sense',\n",
              "  'disambiguation',\n",
              "  'between',\n",
              "  'multiple',\n",
              "  'usages',\n",
              "  'of',\n",
              "  'the',\n",
              "  'same',\n",
              "  'word',\n",
              "  '.',\n",
              "  'Some',\n",
              "  'of',\n",
              "  'the',\n",
              "  'early',\n",
              "  'statistical',\n",
              "  'terminology',\n",
              "  'translation',\n",
              "  'methods',\n",
              "  'are',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ';',\n",
              "  'Kay',\n",
              "  'and',\n",
              "  'RCITSEG',\n",
              "  ')',\n",
              "  '.',\n",
              "  'These',\n",
              "  'algorithms',\n",
              "  'all',\n",
              "  'require',\n",
              "  'parallel',\n",
              "  ',',\n",
              "  'translated',\n",
              "  'texts',\n",
              "  'as',\n",
              "  'input',\n",
              "  '.'],\n",
              " ['Most',\n",
              "  'of',\n",
              "  'the',\n",
              "  'recent',\n",
              "  'corpus',\n",
              "  '-',\n",
              "  'based',\n",
              "  'POS',\n",
              "  'taggers',\n",
              "  'in',\n",
              "  'the',\n",
              "  'literature',\n",
              "  'are',\n",
              "  'either',\n",
              "  'statistically',\n",
              "  'based',\n",
              "  ',',\n",
              "  'and',\n",
              "  'use',\n",
              "  'Markov',\n",
              "  'Model',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  'or',\n",
              "  'Statistical',\n",
              "  'Decision',\n",
              "  'Tree',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  'The',\n",
              "  'Maximum',\n",
              "  'Entropy',\n",
              "  '(',\n",
              "  'MaxEnt',\n",
              "  ')',\n",
              "  'tagger',\n",
              "  'presented',\n",
              "  'in',\n",
              "  'this',\n",
              "  'paper',\n",
              "  'combines',\n",
              "  'the',\n",
              "  'advantages',\n",
              "  'of',\n",
              "  'all',\n",
              "  'these',\n",
              "  'methods',\n",
              "  '.',\n",
              "  'It',\n",
              "  'uses',\n",
              "  'a',\n",
              "  'rich',\n",
              "  'feature',\n",
              "  'representation',\n",
              "  ',',\n",
              "  'like',\n",
              "  'TBL',\n",
              "  'and',\n",
              "  'SDT',\n",
              "  ',',\n",
              "  'and',\n",
              "  'generates',\n",
              "  'a',\n",
              "  'tag',\n",
              "  'probability',\n",
              "  'distribution',\n",
              "  'for',\n",
              "  'each',\n",
              "  'word',\n",
              "  ',',\n",
              "  'like',\n",
              "  'Decision',\n",
              "  'Tree',\n",
              "  'and',\n",
              "  'Markov',\n",
              "  'Model',\n",
              "  'techniques',\n",
              "  '.',\n",
              "  '5',\n",
              "  'The',\n",
              "  'mapping',\n",
              "  'from',\n",
              "  'article',\n",
              "  'to',\n",
              "  'annotator',\n",
              "  'is',\n",
              "  'in',\n",
              "  'the',\n",
              "  'file',\n",
              "  'doc',\n",
              "  '/',\n",
              "  'wsj',\n",
              "  '.',\n",
              "  'wht',\n",
              "  'on',\n",
              "  'the',\n",
              "  'Treebank',\n",
              "  'CDROM',\n",
              "  '.',\n",
              "  '6',\n",
              "  'The',\n",
              "  'single',\n",
              "  '-',\n",
              "  'annotator',\n",
              "  'training',\n",
              "  'data',\n",
              "  'was',\n",
              "  'obtained',\n",
              "  'by',\n",
              "  'extracting',\n",
              "  'those',\n",
              "  'articles',\n",
              "  'tagged',\n",
              "  'by',\n",
              "  '\"',\n",
              "  'maryann',\n",
              "  '\"',\n",
              "  'in',\n",
              "  'the',\n",
              "  'Treebank',\n",
              "  'v.5',\n",
              "  'CDROM',\n",
              "  '.'],\n",
              " ['Each',\n",
              "  'node',\n",
              "  'is',\n",
              "  'subsequently',\n",
              "  'assigned',\n",
              "  'the',\n",
              "  'relevant',\n",
              "  'category',\n",
              "  'based',\n",
              "  'on',\n",
              "  'its',\n",
              "  'constituent',\n",
              "  'type',\n",
              "  'and',\n",
              "  'surface',\n",
              "  'configuration',\n",
              "  '.',\n",
              "  'The',\n",
              "  'algorithm',\n",
              "  'handles',\n",
              "  '\"',\n",
              "  'like',\n",
              "  '\"',\n",
              "  'coordination',\n",
              "  'and',\n",
              "  'exploits',\n",
              "  'the',\n",
              "  'traces',\n",
              "  'used',\n",
              "  'in',\n",
              "  'the',\n",
              "  'treebank',\n",
              "  'in',\n",
              "  'order',\n",
              "  'to',\n",
              "  'interpret',\n",
              "  'LDDs',\n",
              "  '.',\n",
              "  'Unlike',\n",
              "  'our',\n",
              "  'approach',\n",
              "  ',',\n",
              "  'those',\n",
              "  'of',\n",
              "  'CITSEG',\n",
              "  'include',\n",
              "  'a',\n",
              "  'substantial',\n",
              "  'initial',\n",
              "  'correction',\n",
              "  'and',\n",
              "  'clean',\n",
              "  '-',\n",
              "  'up',\n",
              "  'of',\n",
              "  'the',\n",
              "  'Penn',\n",
              "  '-',\n",
              "  'II',\n",
              "  'trees',\n",
              "  '.',\n",
              "  'CITSEG',\n",
              "  'and',\n",
              "  'Nakanishi',\n",
              "  ',',\n",
              "  'Miyao',\n",
              "  ',',\n",
              "  'and',\n",
              "  'Tsujii',\n",
              "  '(',\n",
              "  '2004',\n",
              "  ')',\n",
              "  'describe',\n",
              "  'a',\n",
              "  'methodology',\n",
              "  'for',\n",
              "  'acquiring',\n",
              "  'an',\n",
              "  'English',\n",
              "  'HPSG',\n",
              "  'from',\n",
              "  'the',\n",
              "  'Penn',\n",
              "  '-',\n",
              "  'II',\n",
              "  'Treebank',\n",
              "  '.',\n",
              "  'Manually',\n",
              "  'defined',\n",
              "  'heuristics',\n",
              "  'are',\n",
              "  'used',\n",
              "  'to',\n",
              "  'automatically',\n",
              "  'annotate',\n",
              "  'each',\n",
              "  'tree',\n",
              "  'in',\n",
              "  'the',\n",
              "  'treebank',\n",
              "  'with',\n",
              "  'partially',\n",
              "  'specified',\n",
              "  'HPSG',\n",
              "  'derivation',\n",
              "  'trees',\n",
              "  ':',\n",
              "  'Head',\n",
              "  '/',\n",
              "  'argument',\n",
              "  '/',\n",
              "  'modifier',\n",
              "  'distinctions',\n",
              "  'are',\n",
              "  'made',\n",
              "  'for',\n",
              "  'each',\n",
              "  'node',\n",
              "  'in',\n",
              "  'the',\n",
              "  'tree',\n",
              "  'based',\n",
              "  'on',\n",
              "  'CITSEG',\n",
              "  ',',\n",
              "  'the',\n",
              "  'whole',\n",
              "  'tree',\n",
              "  'is',\n",
              "  'then',\n",
              "  'converted',\n",
              "  'to',\n",
              "  'a',\n",
              "  'binary',\n",
              "  'tree',\n",
              "  ';',\n",
              "  'heuristics',\n",
              "  'are',\n",
              "  'applied',\n",
              "  'to',\n",
              "  'deal',\n",
              "  'with',\n",
              "  'phenomena',\n",
              "  'such',\n",
              "  'as',\n",
              "  'LDDs',\n",
              "  'and',\n",
              "  'coordination',\n",
              "  'and',\n",
              "  'to',\n",
              "  'correct',\n",
              "  'some',\n",
              "  'errors',\n",
              "  'in',\n",
              "  'the',\n",
              "  'treebank',\n",
              "  ',',\n",
              "  'and',\n",
              "  'finally',\n",
              "  'an',\n",
              "  'HPSG',\n",
              "  'category',\n",
              "  'is',\n",
              "  'assigned',\n",
              "  'to',\n",
              "  'each',\n",
              "  'node',\n",
              "  'in',\n",
              "  'the',\n",
              "  'tree',\n",
              "  'in',\n",
              "  'accordance',\n",
              "  'with',\n",
              "  'its',\n",
              "  'CFG',\n",
              "  'category',\n",
              "  '.'],\n",
              " ['4',\n",
              "  '.',\n",
              "  'A',\n",
              "  'subcategorization',\n",
              "  'dictionary',\n",
              "  'obtained',\n",
              "  'automatically',\n",
              "  'from',\n",
              "  'corpora',\n",
              "  'can',\n",
              "  'be',\n",
              "  'updated',\n",
              "  'quickly',\n",
              "  'and',\n",
              "  'easily',\n",
              "  'as',\n",
              "  'different',\n",
              "  'usages',\n",
              "  'develop',\n",
              "  '.',\n",
              "  'Dictionaries',\n",
              "  'produced',\n",
              "  'by',\n",
              "  'hand',\n",
              "  'always',\n",
              "  'substantially',\n",
              "  'lag',\n",
              "  'real',\n",
              "  'language',\n",
              "  'use',\n",
              "  '.',\n",
              "  'The',\n",
              "  'last',\n",
              "  'two',\n",
              "  'points',\n",
              "  'do',\n",
              "  'not',\n",
              "  'argue',\n",
              "  'against',\n",
              "  'the',\n",
              "  'use',\n",
              "  'of',\n",
              "  'existing',\n",
              "  'dictionaries',\n",
              "  ',',\n",
              "  'but',\n",
              "  'show',\n",
              "  'that',\n",
              "  'the',\n",
              "  'incomplete',\n",
              "  'information',\n",
              "  'that',\n",
              "  'they',\n",
              "  'provide',\n",
              "  'needs',\n",
              "  'to',\n",
              "  'be',\n",
              "  'supplemented',\n",
              "  'with',\n",
              "  'further',\n",
              "  'knowledge',\n",
              "  'that',\n",
              "  'is',\n",
              "  'best',\n",
              "  'collected',\n",
              "  'automatically',\n",
              "  ')',\n",
              "  'The',\n",
              "  'desire',\n",
              "  'to',\n",
              "  'combine',\n",
              "  'hand',\n",
              "  '-',\n",
              "  'coded',\n",
              "  'and',\n",
              "  'automatically',\n",
              "  'learned',\n",
              "  'knowledge',\n",
              "  '1',\n",
              "  'A',\n",
              "  'point',\n",
              "  'made',\n",
              "  'by',\n",
              "  'CITSEG',\n",
              "  '.',\n",
              "  'Arbitrary',\n",
              "  'gaps',\n",
              "  'in',\n",
              "  'listing',\n",
              "  'can',\n",
              "  'be',\n",
              "  'smoothed',\n",
              "  'with',\n",
              "  'a',\n",
              "  'program',\n",
              "  'such',\n",
              "  'as',\n",
              "  'the',\n",
              "  'work',\n",
              "  'presented',\n",
              "  'here',\n",
              "  '.',\n",
              "  'For',\n",
              "  'example',\n",
              "  ',',\n",
              "  'among',\n",
              "  'the',\n",
              "  '27',\n",
              "  'verbs',\n",
              "  'that',\n",
              "  'most',\n",
              "  'commonly',\n",
              "  'cooccurred',\n",
              "  'with',\n",
              "  'from',\n",
              "  ',',\n",
              "  'Church',\n",
              "  'and',\n",
              "  'Hanks',\n",
              "  'found',\n",
              "  '7',\n",
              "  'for',\n",
              "  'which',\n",
              "  'this',\n",
              "  'suggests',\n",
              "  'that',\n",
              "  'we',\n",
              "  'should',\n",
              "  'aim',\n",
              "  'for',\n",
              "  'a',\n",
              "  'high',\n",
              "  'precision',\n",
              "  'learner',\n",
              "  '(',\n",
              "  'even',\n",
              "  'at',\n",
              "  'some',\n",
              "  'cost',\n",
              "  'in',\n",
              "  'coverage',\n",
              "  ')',\n",
              "  ',',\n",
              "  'and',\n",
              "  'that',\n",
              "  'is',\n",
              "  'the',\n",
              "  'approach',\n",
              "  'adopted',\n",
              "  'here',\n",
              "  '.'],\n",
              " ['It',\n",
              "  'has',\n",
              "  'been',\n",
              "  'noted',\n",
              "  'in',\n",
              "  'previous',\n",
              "  'work',\n",
              "  'that',\n",
              "  'the',\n",
              "  'felicity',\n",
              "  'of',\n",
              "  'certain',\n",
              "  'forms',\n",
              "  'of',\n",
              "  'ellipsis',\n",
              "  'is',\n",
              "  'dependent',\n",
              "  'on',\n",
              "  'the',\n",
              "  'type',\n",
              "  'of',\n",
              "  'coherence',\n",
              "  'relationship',\n",
              "  'extant',\n",
              "  'between',\n",
              "  'the',\n",
              "  'antecedent',\n",
              "  'and',\n",
              "  'elided',\n",
              "  'clauses',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.',\n",
              "  'In',\n",
              "  'this',\n",
              "  'section',\n",
              "  'we',\n",
              "  'review',\n",
              "  'the',\n",
              "  'relevant',\n",
              "  'facts',\n",
              "  'for',\n",
              "  'two',\n",
              "  'such',\n",
              "  'forms',\n",
              "  'of',\n",
              "  'ellipsis',\n",
              "  ',',\n",
              "  'namely',\n",
              "  'gapping',\n",
              "  'and',\n",
              "  'VP',\n",
              "  '-',\n",
              "  'ellipsis',\n",
              "  ',',\n",
              "  'and',\n",
              "  'also',\n",
              "  'compare',\n",
              "  'these',\n",
              "  'with',\n",
              "  'facts',\n",
              "  'concerning',\n",
              "  'non-elliptical',\n",
              "  'event',\n",
              "  'reference',\n",
              "  '.',\n",
              "  'Gapping',\n",
              "  'is',\n",
              "  'characterized',\n",
              "  'by',\n",
              "  'an',\n",
              "  'antecedent',\n",
              "  'sentence',\n",
              "  '(',\n",
              "  'henceforth',\n",
              "  'called',\n",
              "  'the',\n",
              "  'source',\n",
              "  'sentence',\n",
              "  ')',\n",
              "  'and',\n",
              "  'the',\n",
              "  'elision',\n",
              "  'of',\n",
              "  'all',\n",
              "  'but',\n",
              "  'two',\n",
              "  'constituents',\n",
              "  '(',\n",
              "  'and',\n",
              "  'in',\n",
              "  'limited',\n",
              "  'circumstances',\n",
              "  ',',\n",
              "  'more',\n",
              "  'than',\n",
              "  'two',\n",
              "  'constituents',\n",
              "  ')',\n",
              "  'in',\n",
              "  'one',\n",
              "  'or',\n",
              "  'more',\n",
              "  'subsequent',\n",
              "  'target',\n",
              "  'sentences',\n",
              "  ',',\n",
              "  'as',\n",
              "  'exemplified',\n",
              "  'in',\n",
              "  'sentence',\n",
              "  '(',\n",
              "  '1',\n",
              "  ')',\n",
              "  ':',\n",
              "  '(',\n",
              "  '1',\n",
              "  ')',\n",
              "  'Bill',\n",
              "  'became',\n",
              "  'upset',\n",
              "  ',',\n",
              "  'and',\n",
              "  'Hillary',\n",
              "  'angry',\n",
              "  '.'],\n",
              " ['(',\n",
              "  'The',\n",
              "  'latter',\n",
              "  'is',\n",
              "  'kept',\n",
              "  'track',\n",
              "  'of',\n",
              "  'by',\n",
              "  'array',\n",
              "  'normalization',\n",
              "  'in',\n",
              "  'the',\n",
              "  'pseudocode',\n",
              "  '.',\n",
              "  ')',\n",
              "  'Discussion',\n",
              "  '.',\n",
              "  'The',\n",
              "  'intuition',\n",
              "  'behind',\n",
              "  'this',\n",
              "  'algorithm',\n",
              "  'is',\n",
              "  'essentially',\n",
              "  'the',\n",
              "  'same',\n",
              "  'intuition',\n",
              "  'exploited',\n",
              "  'by',\n",
              "  'CITSEG',\n",
              "  ',',\n",
              "  'and',\n",
              "  'others',\n",
              "  ':',\n",
              "  'the',\n",
              "  'most',\n",
              "  'plausible',\n",
              "  'assignment',\n",
              "  'of',\n",
              "  'senses',\n",
              "  'to',\n",
              "  'multiple',\n",
              "  'co-occurring',\n",
              "  'words',\n",
              "  'is',\n",
              "  'the',\n",
              "  'one',\n",
              "  'that',\n",
              "  'maximizes',\n",
              "  'relatedness',\n",
              "  'of',\n",
              "  'meaning',\n",
              "  'among',\n",
              "  'the',\n",
              "  'senses',\n",
              "  'chosen',\n",
              "  '.',\n",
              "  'Here',\n",
              "  'I',\n",
              "  'make',\n",
              "  'an',\n",
              "  'explicit',\n",
              "  'comparison',\n",
              "  'with',\n",
              "  'Sussna',\n",
              "  \"'s\",\n",
              "  'approach',\n",
              "  ',',\n",
              "  'since',\n",
              "  'it',\n",
              "  'is',\n",
              "  'the',\n",
              "  'most',\n",
              "  'similar',\n",
              "  'of',\n",
              "  'previous',\n",
              "  'work',\n",
              "  '.',\n",
              "  'Sussna',\n",
              "  'gives',\n",
              "  'as',\n",
              "  'an',\n",
              "  'example',\n",
              "  'of',\n",
              "  'the',\n",
              "  'problem',\n",
              "  'he',\n",
              "  'is',\n",
              "  'solving',\n",
              "  'the',\n",
              "  'following',\n",
              "  'paragraph',\n",
              "  'from',\n",
              "  'the',\n",
              "  'corpus',\n",
              "  'of',\n",
              "  '1963',\n",
              "  'Time',\n",
              "  'magazine',\n",
              "  'articles',\n",
              "  'used',\n",
              "  'in',\n",
              "  'information',\n",
              "  'retrieval',\n",
              "  'research',\n",
              "  '(',\n",
              "  'uppercase',\n",
              "  'in',\n",
              "  'the',\n",
              "  'Time',\n",
              "  'corpus',\n",
              "  ',',\n",
              "  'lowercase',\n",
              "  'here',\n",
              "  'for',\n",
              "  'readability',\n",
              "  ';',\n",
              "  'punctuation',\n",
              "  'is',\n",
              "  'as',\n",
              "  'it',\n",
              "  'appears',\n",
              "  'in',\n",
              "  'the',\n",
              "  'original',\n",
              "  'corpus',\n",
              "  ')',\n",
              "  ':',\n",
              "  'the',\n",
              "  'allies',\n",
              "  'after',\n",
              "  'nassau',\n",
              "  'in',\n",
              "  'december',\n",
              "  '1960',\n",
              "  ',',\n",
              "  'the',\n",
              "  'u.s.',\n",
              "  'first',\n",
              "  'proposed',\n",
              "  'to',\n",
              "  'help',\n",
              "  'nato',\n",
              "  'develop',\n",
              "  'its',\n",
              "  'own',\n",
              "  'nuclear',\n",
              "  'strike',\n",
              "  'force',\n",
              "  ',',\n",
              "  'but',\n",
              "  'europe',\n",
              "  'made',\n",
              "  'no',\n",
              "  'attempt',\n",
              "  'to',\n",
              "  'devise',\n",
              "  'a',\n",
              "  'plan',\n",
              "  '.',\n",
              "  'last',\n",
              "  'week',\n",
              "  ',',\n",
              "  'as',\n",
              "  'they',\n",
              "  'studied',\n",
              "  'the',\n",
              "  'nassau',\n",
              "  'accord',\n",
              "  'between',\n",
              "  'president',\n",
              "  'kennedy',\n",
              "  'and',\n",
              "  'prime',\n",
              "  'minister',\n",
              "  'macmillan',\n",
              "  ',',\n",
              "  'europeans',\n",
              "  'saw',\n",
              "  'emerging',\n",
              "  'the',\n",
              "  'first',\n",
              "  'outlines',\n",
              "  'of',\n",
              "  'the',\n",
              "  'nuclear',\n",
              "  'nato',\n",
              "  'that',\n",
              "  'the',\n",
              "  'u.s.',\n",
              "  'wants',\n",
              "  'and',\n",
              "  'will',\n",
              "  'support',\n",
              "  ',',\n",
              "  'it',\n",
              "  'all',\n",
              "  'sprang',\n",
              "  'from',\n",
              "  'the',\n",
              "  'anglo',\n",
              "  '-',\n",
              "  'u.s',\n",
              "  ',',\n",
              "  'crisis',\n",
              "  'over',\n",
              "  'cancellation',\n",
              "  'of',\n",
              "  'the',\n",
              "  'bug-ridden',\n",
              "  'skybolt',\n",
              "  'missile',\n",
              "  ',',\n",
              "  'and',\n",
              "  'the',\n",
              "  'u.s.',\n",
              "  'offer',\n",
              "  'to',\n",
              "  'supply',\n",
              "  'britain',\n",
              "  'and',\n",
              "  'france',\n",
              "  'with',\n",
              "  'the',\n",
              "  'proved',\n",
              "  'polaris',\n",
              "  '(',\n",
              "  'time',\n",
              "  ',',\n",
              "  'dec.',\n",
              "  '28',\n",
              "  ')',\n",
              "  'From',\n",
              "  'this',\n",
              "  ',',\n",
              "  'Sussna',\n",
              "  'extracts',\n",
              "  'the',\n",
              "  'following',\n",
              "  'noun',\n",
              "  'grouping',\n",
              "  'to',\n",
              "  'disambiguate',\n",
              "  ':',\n",
              "  'allies',\n",
              "  'strike',\n",
              "  'force',\n",
              "  'attempt',\n",
              "  'plan',\n",
              "  'week',\n",
              "  'accord',\n",
              "  'president',\n",
              "  'prime',\n",
              "  'minister',\n",
              "  'outlines',\n",
              "  'support',\n",
              "  'crisis',\n",
              "  'cancellation',\n",
              "  'bug',\n",
              "  'missile',\n",
              "  'france',\n",
              "  'polaris',\n",
              "  'time',\n",
              "  'These',\n",
              "  'are',\n",
              "  'the',\n",
              "  'non-stopword',\n",
              "  'nouns',\n",
              "  'in',\n",
              "  'the',\n",
              "  'paragraph',\n",
              "  'that',\n",
              "  'appear',\n",
              "  'in',\n",
              "  'WordNet',\n",
              "  '(',\n",
              "  'he',\n",
              "  'used',\n",
              "  'version',\n",
              "  '1.2',\n",
              "  ')',\n",
              "  '.'],\n",
              " ['We',\n",
              "  'can',\n",
              "  'implement',\n",
              "  'a',\n",
              "  'deductive',\n",
              "  'theory',\n",
              "  'of',\n",
              "  'quantifier',\n",
              "  'scope',\n",
              "  'using',\n",
              "  'the',\n",
              "  'conditional',\n",
              "  'equivalence',\n",
              "  'mechanism',\n",
              "  '.',\n",
              "  'The',\n",
              "  'version',\n",
              "  'proposed',\n",
              "  'here',\n",
              "  'combines',\n",
              "  'a',\n",
              "  'basic',\n",
              "  'insight',\n",
              "  'from',\n",
              "  'CITSEG',\n",
              "  'with',\n",
              "  'higher',\n",
              "  '-',\n",
              "  'order',\n",
              "  'unification',\n",
              "  'to',\n",
              "  'give',\n",
              "  'an',\n",
              "  'analysis',\n",
              "  'that',\n",
              "  'has',\n",
              "  'a',\n",
              "  'strong',\n",
              "  'resemblance',\n",
              "  'to',\n",
              "  'that',\n",
              "  'proposed',\n",
              "  'in',\n",
              "  'CITSEG',\n",
              "  ',',\n",
              "  'with',\n",
              "  'some',\n",
              "  'differences',\n",
              "  'that',\n",
              "  'are',\n",
              "  'commented',\n",
              "  'on',\n",
              "  'below',\n",
              "  '.',\n",
              "  'Like',\n",
              "  'Pereira',\n",
              "  \"'s\",\n",
              "  'approach',\n",
              "  ',',\n",
              "  'it',\n",
              "  'avoids',\n",
              "  'the',\n",
              "  'need',\n",
              "  'for',\n",
              "  'a',\n",
              "  'free',\n",
              "  'variable',\n",
              "  'constraint',\n",
              "  ',',\n",
              "  'nor',\n",
              "  'does',\n",
              "  'it',\n",
              "  'need',\n",
              "  'the',\n",
              "  'explicit',\n",
              "  'recursion',\n",
              "  'on',\n",
              "  'the',\n",
              "  'quantifier',\n",
              "  'restriction',\n",
              "  'imposed',\n",
              "  'by',\n",
              "  'Lewin',\n",
              "  '.',\n",
              "  'We',\n",
              "  'analyze',\n",
              "  'quantified',\n",
              "  'NPs',\n",
              "  'at',\n",
              "  'the',\n",
              "  'QLF',\n",
              "  'level',\n",
              "  'as',\n",
              "  'illustrated',\n",
              "  'in',\n",
              "  'the',\n",
              "  'QLF',\n",
              "  'for',\n",
              "  ':',\n",
              "  '(',\n",
              "  '19',\n",
              "  ')',\n",
              "  'Every',\n",
              "  'manager',\n",
              "  'uses',\n",
              "  'a',\n",
              "  'computer',\n",
              "  '.'],\n",
              " ['Such',\n",
              "  'unbalanced',\n",
              "  'classes',\n",
              "  'create',\n",
              "  'problems',\n",
              "  'for',\n",
              "  'the',\n",
              "  'majority',\n",
              "  'of',\n",
              "  'inductive',\n",
              "  'learning',\n",
              "  'systems',\n",
              "  '.',\n",
              "  'A',\n",
              "  'distinctive',\n",
              "  'feature',\n",
              "  'of',\n",
              "  'our',\n",
              "  'work',\n",
              "  'is',\n",
              "  'the',\n",
              "  'fact',\n",
              "  'that',\n",
              "  'we',\n",
              "  'used',\n",
              "  'machine',\n",
              "  'learning',\n",
              "  'techniques',\n",
              "  'to',\n",
              "  'improve',\n",
              "  'an',\n",
              "  'existing',\n",
              "  'rule',\n",
              "  '-',\n",
              "  'based',\n",
              "  'natural',\n",
              "  'language',\n",
              "  'processor',\n",
              "  'from',\n",
              "  'the',\n",
              "  'inside',\n",
              "  '.',\n",
              "  'This',\n",
              "  'contrasts',\n",
              "  'with',\n",
              "  'approaches',\n",
              "  'where',\n",
              "  'there',\n",
              "  'are',\n",
              "  'essentially',\n",
              "  'no',\n",
              "  'explicit',\n",
              "  'rules',\n",
              "  ',',\n",
              "  'such',\n",
              "  'as',\n",
              "  'neural',\n",
              "  'networks',\n",
              "  '(',\n",
              "  'e.g.',\n",
              "  '[',\n",
              "  'CITSEG',\n",
              "  ']',\n",
              "  ')',\n",
              "  ',',\n",
              "  'or',\n",
              "  'approaches',\n",
              "  'where',\n",
              "  'the',\n",
              "  'machine',\n",
              "  'learning',\n",
              "  'algorithms',\n",
              "  'attempt',\n",
              "  'to',\n",
              "  'infer--',\n",
              "  'via',\n",
              "  'deduction',\n",
              "  '(',\n",
              "  'e.g.',\n",
              "  '[',\n",
              "  'CITSEG',\n",
              "  ']',\n",
              "  ')',\n",
              "  ',',\n",
              "  'induction',\n",
              "  '(',\n",
              "  'e.g.',\n",
              "  '[',\n",
              "  'CITSEG',\n",
              "  ']',\n",
              "  ';',\n",
              "  '[',\n",
              "  'CITSEG',\n",
              "  ']',\n",
              "  ')',\n",
              "  'under',\n",
              "  'user',\n",
              "  'cooperation',\n",
              "  '(',\n",
              "  'e.g.',\n",
              "  '[',\n",
              "  'CITSEG',\n",
              "  ']',\n",
              "  ';',\n",
              "  '[',\n",
              "  'CITSEG',\n",
              "  ']',\n",
              "  ')',\n",
              "  ',',\n",
              "  'transformation',\n",
              "  '-',\n",
              "  'based',\n",
              "  'error-driven',\n",
              "  'learning',\n",
              "  '(',\n",
              "  'e.g.',\n",
              "  '[',\n",
              "  'CITSEG',\n",
              "  ']',\n",
              "  ')',\n",
              "  ',',\n",
              "  'or',\n",
              "  'even',\n",
              "  'decision',\n",
              "  'trees',\n",
              "  '(',\n",
              "  'e.g.',\n",
              "  '[',\n",
              "  'CITSEG',\n",
              "  ']',\n",
              "  ')',\n",
              "  '--a',\n",
              "  'grammar',\n",
              "  'from',\n",
              "  'raw',\n",
              "  'or',\n",
              "  'preprocessed',\n",
              "  'data',\n",
              "  '.',\n",
              "  'In',\n",
              "  'our',\n",
              "  'work',\n",
              "  ',',\n",
              "  'we',\n",
              "  'do',\n",
              "  'not',\n",
              "  'wish',\n",
              "  'to',\n",
              "  'acquire',\n",
              "  'a',\n",
              "  'grammar',\n",
              "  ':',\n",
              "  'we',\n",
              "  'have',\n",
              "  'one',\n",
              "  'and',\n",
              "  'want',\n",
              "  'to',\n",
              "  'devise',\n",
              "  'a',\n",
              "  'mechanism',\n",
              "  'to',\n",
              "  'make',\n",
              "  'some',\n",
              "  'of',\n",
              "  'its',\n",
              "  'parts',\n",
              "  'adaptable',\n",
              "  'to',\n",
              "  'the',\n",
              "  'corpus',\n",
              "  'at',\n",
              "  'hand',\n",
              "  'or',\n",
              "  ',',\n",
              "  'to',\n",
              "  'improve',\n",
              "  'some',\n",
              "  'aspect',\n",
              "  'of',\n",
              "  'its',\n",
              "  'performance',\n",
              "  '.',\n",
              "  'Other',\n",
              "  'researchers',\n",
              "  ',',\n",
              "  'such',\n",
              "  'as',\n",
              "  '[',\n",
              "  'CITSEG',\n",
              "  ']',\n",
              "  ',',\n",
              "  'have',\n",
              "  'compared',\n",
              "  'neural',\n",
              "  'networks',\n",
              "  'and',\n",
              "  'machine',\n",
              "  'learning',\n",
              "  'methods',\n",
              "  'at',\n",
              "  'the',\n",
              "  'task',\n",
              "  'of',\n",
              "  'sentence',\n",
              "  'classification',\n",
              "  '.',\n",
              "  'In',\n",
              "  'this',\n",
              "  'task',\n",
              "  ',',\n",
              "  'the',\n",
              "  'system',\n",
              "  'must',\n",
              "  'classify',\n",
              "  'a',\n",
              "  'string',\n",
              "  'as',\n",
              "  'either',\n",
              "  'grammatical',\n",
              "  'or',\n",
              "  'not',\n",
              "  '.'],\n",
              " ['Similarly',\n",
              "  ',',\n",
              "  'web',\n",
              "  'documents',\n",
              "  'no',\n",
              "  'longer',\n",
              "  'exist',\n",
              "  'on',\n",
              "  'their',\n",
              "  'own',\n",
              "  'and',\n",
              "  'they',\n",
              "  'are',\n",
              "  'naturally',\n",
              "  'associated',\n",
              "  'with',\n",
              "  'other',\n",
              "  'documents',\n",
              "  'and',\n",
              "  'diverse',\n",
              "  'users',\n",
              "  '.',\n",
              "  'All',\n",
              "  'these',\n",
              "  'information',\n",
              "  'can',\n",
              "  'be',\n",
              "  'considered',\n",
              "  'as',\n",
              "  'the',\n",
              "  'potential',\n",
              "  'data',\n",
              "  'source',\n",
              "  'for',\n",
              "  'document',\n",
              "  'understanding',\n",
              "  'and',\n",
              "  'personalization',\n",
              "  '.',\n",
              "  'For',\n",
              "  'generating',\n",
              "  'a',\n",
              "  'personalized',\n",
              "  'summary',\n",
              "  ',',\n",
              "  'traditional',\n",
              "  'methods',\n",
              "  'usually',\n",
              "  'require',\n",
              "  'that',\n",
              "  'a',\n",
              "  'user',\n",
              "  'explicitly',\n",
              "  'provides',\n",
              "  'his',\n",
              "  'interest',\n",
              "  'aspects',\n",
              "  ',',\n",
              "  'such',\n",
              "  'as',\n",
              "  'specifying',\n",
              "  'the',\n",
              "  'categories',\n",
              "  'he',\n",
              "  'prefers',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  'or',\n",
              "  'clicking',\n",
              "  'a',\n",
              "  'subset',\n",
              "  'of',\n",
              "  'sentences',\n",
              "  'in',\n",
              "  'a',\n",
              "  'document',\n",
              "  'according',\n",
              "  'to',\n",
              "  'his',\n",
              "  'interests',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.',\n",
              "  'However',\n",
              "  ',',\n",
              "  'most',\n",
              "  'users',\n",
              "  'are',\n",
              "  'reluctant',\n",
              "  'to',\n",
              "  'provide',\n",
              "  'such',\n",
              "  'information',\n",
              "  ',',\n",
              "  'thus',\n",
              "  'it',\n",
              "  'is',\n",
              "  'more',\n",
              "  'meaningful',\n",
              "  'to',\n",
              "  'infer',\n",
              "  'a',\n",
              "  'user',\n",
              "  \"'s\",\n",
              "  'interests',\n",
              "  'implicitly',\n",
              "  '.',\n",
              "  'To',\n",
              "  'address',\n",
              "  'these',\n",
              "  'concerns',\n",
              "  ',',\n",
              "  'we',\n",
              "  'present',\n",
              "  'an',\n",
              "  'unsupervised',\n",
              "  'approach',\n",
              "  'for',\n",
              "  'personalized',\n",
              "  'summarization',\n",
              "  '.',\n",
              "  'The',\n",
              "  'underlying',\n",
              "  'assumption',\n",
              "  'is',\n",
              "  'that',\n",
              "  'it',\n",
              "  'is',\n",
              "  'beneficial',\n",
              "  'to',\n",
              "  'understand',\n",
              "  'both',\n",
              "  'a',\n",
              "  'single',\n",
              "  'document',\n",
              "  'and',\n",
              "  'a',\n",
              "  'single',\n",
              "  'user',\n",
              "  'better',\n",
              "  'if',\n",
              "  'appropriate',\n",
              "  'social',\n",
              "  'context',\n",
              "  'can',\n",
              "  'be',\n",
              "  'leveraged',\n",
              "  'under',\n",
              "  'some',\n",
              "  'constraints',\n",
              "  '.'],\n",
              " ['Seclion',\n",
              "  '2',\n",
              "  'inlfoduced',\n",
              "  'a',\n",
              "  'range',\n",
              "  'of',\n",
              "  'factors',\n",
              "  'motivated',\n",
              "  'by',\n",
              "  'the',\n",
              "  'coqms',\n",
              "  'analysis',\n",
              "  'that',\n",
              "  'were',\n",
              "  'hypothesized',\n",
              "  'to',\n",
              "  'determine',\n",
              "  'when',\n",
              "  'ExpliciI-Wm',\n",
              "  '-fant',\n",
              "  'is',\n",
              "  'an',\n",
              "  'efleelive',\n",
              "  'slralegy',\n",
              "  '.',\n",
              "  'This',\n",
              "  'seclion',\n",
              "  'discusses',\n",
              "  'how',\n",
              "  'Design',\n",
              "  '-',\n",
              "  'World',\n",
              "  'SUl',\n",
              "  ')',\n",
              "  'ports',\n",
              "  'Ihc',\n",
              "  \"plu'iunetfization\",\n",
              "  'of',\n",
              "  'these',\n",
              "  '[',\n",
              "  '~',\n",
              "  'ICIOfS.',\n",
              "  'The',\n",
              "  'agent',\n",
              "  'architecture',\n",
              "  'R/r',\n",
              "  'deliberalion',\n",
              "  'and',\n",
              "  'means',\n",
              "  '-',\n",
              "  'end',\n",
              "  'reasoning',\n",
              "  'is',\n",
              "  'based',\n",
              "  'on',\n",
              "  'the',\n",
              "  'IRMA',\n",
              "  'architeclure',\n",
              "  ',',\n",
              "  'also',\n",
              "  'used',\n",
              "  'in',\n",
              "  'the',\n",
              "  \"'l\",\n",
              "  '-',\n",
              "  \"'ile\",\n",
              "  ',',\n",
              "  'World',\n",
              "  'simulation',\n",
              "  'environment',\n",
              "  'IPollack',\n",
              "  'and',\n",
              "  'R.inguclte',\n",
              "  ',',\n",
              "  '19901',\n",
              "  ',',\n",
              "  'with',\n",
              "  'Ihe',\n",
              "  'addition',\n",
              "  'of',\n",
              "  'a',\n",
              "  'model',\n",
              "  'o',\n",
              "  '1',\n",
              "  \"'\",\n",
              "  'lira-ile',\n",
              "  '(l',\n",
              "  'Allenlkm',\n",
              "  '/',\n",
              "  'Working',\n",
              "  'Illell',\n",
              "  'IOfy',\n",
              "  ',',\n",
              "  'AWM',\n",
              "  ',',\n",
              "  '[',\n",
              "  'CITSEG',\n",
              "  ']',\n",
              "  'inchldes',\n",
              "  'a',\n",
              "  'fullef',\n",
              "  'disctlssion',\n",
              "  'of',\n",
              "  'tile',\n",
              "  'l',\n",
              "  ')esig',\n",
              "  ',',\n",
              "  '>',\n",
              "  'WorM',\n",
              "  'deliberation',\n",
              "  'and',\n",
              "  'melms',\n",
              "  '-',\n",
              "  'end',\n",
              "  'reasoning',\n",
              "  'mechanism',\n",
              "  'and',\n",
              "  'Ihe',\n",
              "  'underlying',\n",
              "  'mechanisms',\n",
              "  'assumed',\n",
              "  'in',\n",
              "  'collaborative',\n",
              "  'planning',\n",
              "  '.',\n",
              "  'We',\n",
              "  'hypolhcsizcd',\n",
              "  'lhal',\n",
              "  'a',\n",
              "  'warrant',\n",
              "  'Inllsi',\n",
              "  'be',\n",
              "  ',',\n",
              "  \"'q\",\n",
              "  'AIJENT',\n",
              "  'for',\n",
              "  'hoth',\n",
              "  'agents',\n",
              "  '(',\n",
              "  'as',\n",
              "  'shown',\n",
              "  'by',\n",
              "  'example',\n",
              "  '2',\n",
              "  ')',\n",
              "  '.',\n",
              "  'In',\n",
              "  'l',\n",
              "  ')',\n",
              "  'esign',\n",
              "  '-',\n",
              "  'Wodd',\n",
              "  ',',\n",
              "  'salience',\n",
              "  'is',\n",
              "  'modeled',\n",
              "  'by',\n",
              "  'AWM',\n",
              "  'model',\n",
              "  ',',\n",
              "  'adapted',\n",
              "  'lronl',\n",
              "  '[',\n",
              "  'CITSEG',\n",
              "  'I.',\n",
              "  'While',\n",
              "  'the',\n",
              "  'AWM',\n",
              "  'model',\n",
              "  'is',\n",
              "  'extremely',\n",
              "  'sin',\n",
              "  '>',\n",
              "  'pie',\n",
              "  ',',\n",
              "  '[',\n",
              "  ',',\n",
              "  'andauer',\n",
              "  'showed',\n",
              "  'thai',\n",
              "  'it',\n",
              "  'could',\n",
              "  'be',\n",
              "  \"pm'ameterized\",\n",
              "  'lo',\n",
              "  '1il',\n",
              "  'many',\n",
              "  'empirical',\n",
              "  'resells',\n",
              "  'on',\n",
              "  'human',\n",
              "  'memory',\n",
              "  'and',\n",
              "  'learning',\n",
              "  '[',\n",
              "  'CITSEG',\n",
              "  '.',\n",
              "  'AWM',\n",
              "  'consists',\n",
              "  'of',\n",
              "  'a',\n",
              "  'three',\n",
              "  'dimensional',\n",
              "  'slsace',\n",
              "  'in',\n",
              "  'which',\n",
              "  'propositions',\n",
              "  'acquired',\n",
              "  'Dora',\n",
              "  'perceiving',\n",
              "  'the',\n",
              "  'world',\n",
              "  'are',\n",
              "  'stored',\n",
              "  'in',\n",
              "  'chronological',\n",
              "  'sequence',\n",
              "  'according',\n",
              "  '1o',\n",
              "  'tile',\n",
              "  'localion',\n",
              "  'o',\n",
              "  '1',\n",
              "  \"'\",\n",
              "  'a',\n",
              "  'moving',\n",
              "  'memory',\n",
              "  'pointef',\n",
              "  '.'],\n",
              " ['General',\n",
              "  '-',\n",
              "  'purpose',\n",
              "  'natural',\n",
              "  'language',\n",
              "  '(',\n",
              "  'NL',\n",
              "  ')',\n",
              "  'analysis',\n",
              "  'systems',\n",
              "  'have',\n",
              "  'recently',\n",
              "  'started',\n",
              "  'to',\n",
              "  'use',\n",
              "  'declarative',\n",
              "  'unification',\n",
              "  '-',\n",
              "  'based',\n",
              "  'sentence',\n",
              "  'grammar',\n",
              "  'formalisms',\n",
              "  ';',\n",
              "  'systems',\n",
              "  'of',\n",
              "  'this',\n",
              "  'type',\n",
              "  'include',\n",
              "  'SRI',\n",
              "  \"'s\",\n",
              "  'CLARE',\n",
              "  'system',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  'and',\n",
              "  'the',\n",
              "  'A1vey',\n",
              "  'NL',\n",
              "  'Tools',\n",
              "  '(',\n",
              "  'ANLT',\n",
              "  ';',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.',\n",
              "  'Using',\n",
              "  'a',\n",
              "  'declarative',\n",
              "  'formalism',\n",
              "  'helps',\n",
              "  'ease',\n",
              "  'the',\n",
              "  'task',\n",
              "  'of',\n",
              "  'developing',\n",
              "  'and',\n",
              "  'maintaining',\n",
              "  'the',\n",
              "  'grammar',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.',\n",
              "  'In',\n",
              "  'addition',\n",
              "  'to',\n",
              "  'syntactic',\n",
              "  'processing',\n",
              "  ',',\n",
              "  'the',\n",
              "  'systems',\n",
              "  'incorporate',\n",
              "  'lexical',\n",
              "  ',',\n",
              "  'morphological',\n",
              "  ',',\n",
              "  'and',\n",
              "  'semantic',\n",
              "  'processing',\n",
              "  ',',\n",
              "  'and',\n",
              "  'have',\n",
              "  'been',\n",
              "  'applied',\n",
              "  'successfully',\n",
              "  'to',\n",
              "  'the',\n",
              "  'analysis',\n",
              "  'of',\n",
              "  'naturally',\n",
              "  '-',\n",
              "  'occurring',\n",
              "  'texts',\n",
              "  '(',\n",
              "  'e.g',\n",
              "  '.',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.'],\n",
              " ['The',\n",
              "  'method',\n",
              "  'was',\n",
              "  'tested',\n",
              "  'on',\n",
              "  'ATIS',\n",
              "  'trees',\n",
              "  'obtaining',\n",
              "  'results',\n",
              "  'that',\n",
              "  'to',\n",
              "  'the',\n",
              "  'best',\n",
              "  'of',\n",
              "  'our',\n",
              "  'knowledge',\n",
              "  'are',\n",
              "  'not',\n",
              "  'exceeded',\n",
              "  'by',\n",
              "  'other',\n",
              "  'stochastic',\n",
              "  'parsers',\n",
              "  '.',\n",
              "  'Moreover',\n",
              "  ',',\n",
              "  'the',\n",
              "  'results',\n",
              "  'of',\n",
              "  'a',\n",
              "  'less-',\n",
              "  'than-optimal',\n",
              "  'version',\n",
              "  'of',\n",
              "  'DOP',\n",
              "  'on',\n",
              "  'the',\n",
              "  'Wall',\n",
              "  'Street',\n",
              "  'Journal',\n",
              "  'corpus',\n",
              "  'suggest',\n",
              "  'that',\n",
              "  'the',\n",
              "  'approach',\n",
              "  'can',\n",
              "  'be',\n",
              "  'succesfully',\n",
              "  'extended',\n",
              "  'to',\n",
              "  'larger',\n",
              "  'domains',\n",
              "  '.',\n",
              "  'As',\n",
              "  'future',\n",
              "  'research',\n",
              "  ',',\n",
              "  'we',\n",
              "  'will',\n",
              "  'apply',\n",
              "  'the',\n",
              "  'full',\n",
              "  'DOP',\n",
              "  'model',\n",
              "  'on',\n",
              "  'WSJ',\n",
              "  'word',\n",
              "  'strings',\n",
              "  'in',\n",
              "  'order',\n",
              "  'to',\n",
              "  'compare',\n",
              "  'our',\n",
              "  'results',\n",
              "  'with',\n",
              "  'the',\n",
              "  'best',\n",
              "  'known',\n",
              "  'parsers',\n",
              "  'on',\n",
              "  'this',\n",
              "  'domain',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.'],\n",
              " ['The',\n",
              "  'former',\n",
              "  'stem',\n",
              "  'from',\n",
              "  'the',\n",
              "  'work',\n",
              "  'of',\n",
              "  'Halliday',\n",
              "  'and',\n",
              "  'Hasan',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.',\n",
              "  'They',\n",
              "  'proposed',\n",
              "  'that',\n",
              "  'text',\n",
              "  'segments',\n",
              "  'with',\n",
              "  'similar',\n",
              "  'vocabulary',\n",
              "  'are',\n",
              "  'likely',\n",
              "  'to',\n",
              "  'be',\n",
              "  'part',\n",
              "  'of',\n",
              "  'a',\n",
              "  'coherent',\n",
              "  'topic',\n",
              "  'segment',\n",
              "  '.',\n",
              "  'hnplementations',\n",
              "  'of',\n",
              "  'this',\n",
              "  'idea',\n",
              "  'use',\n",
              "  'word',\n",
              "  'stem',\n",
              "  'repetition',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  ',',\n",
              "  'context',\n",
              "  'vectors',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  ',',\n",
              "  'entity',\n",
              "  'repetition',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  ',',\n",
              "  'semantic',\n",
              "  'similarity',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  ',',\n",
              "  'word',\n",
              "  'distance',\n",
              "  'model',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  'and',\n",
              "  'word',\n",
              "  'frequency',\n",
              "  'model',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  'to',\n",
              "  'detect',\n",
              "  'cohesion',\n",
              "  '.',\n",
              "  'Methods',\n",
              "  'for',\n",
              "  'finding',\n",
              "  'the',\n",
              "  'topic',\n",
              "  'boundaries',\n",
              "  'include',\n",
              "  'sliding',\n",
              "  'window',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  ',',\n",
              "  'lexical',\n",
              "  'chains',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  ',',\n",
              "  'dynamic',\n",
              "  'programming',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  ',',\n",
              "  'agglomerative',\n",
              "  'clustering',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  'and',\n",
              "  'divisive',\n",
              "  'clustering',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.',\n",
              "  'Lexical',\n",
              "  'cohesion',\n",
              "  'methods',\n",
              "  'are',\n",
              "  'typically',\n",
              "  'used',\n",
              "  'for',\n",
              "  'segmenting',\n",
              "  'written',\n",
              "  'text',\n",
              "  'in',\n",
              "  'a',\n",
              "  'collection',\n",
              "  'to',\n",
              "  'improve',\n",
              "  'information',\n",
              "  'retrieval',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.',\n",
              "  'Multi-source',\n",
              "  'methods',\n",
              "  'combine',\n",
              "  'lexical',\n",
              "  'cohesion',\n",
              "  'with',\n",
              "  'other',\n",
              "  'indicators',\n",
              "  'of',\n",
              "  'topic',\n",
              "  'shift',\n",
              "  'such',\n",
              "  'as',\n",
              "  'cue',\n",
              "  'phrases',\n",
              "  ',',\n",
              "  'prosodic',\n",
              "  'features',\n",
              "  ',',\n",
              "  'reference',\n",
              "  ',',\n",
              "  'syntax',\n",
              "  'and',\n",
              "  'lexical',\n",
              "  'attraction',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  'using',\n",
              "  'decision',\n",
              "  'trees',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  'and',\n",
              "  'probabilistic',\n",
              "  'models',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.'],\n",
              " ['3',\n",
              "  'ReVerb',\n",
              "  'template',\n",
              "  'extractions',\n",
              "  '/',\n",
              "  'instantiations',\n",
              "  'are',\n",
              "  'in',\n",
              "  'the',\n",
              "  'form',\n",
              "  'of',\n",
              "  'a',\n",
              "  'tuple',\n",
              "  '(',\n",
              "  'x',\n",
              "  ',',\n",
              "  'pred',\n",
              "  ',',\n",
              "  'y',\n",
              "  ')',\n",
              "  ',',\n",
              "  'containing',\n",
              "  'pred',\n",
              "  ',',\n",
              "  'a',\n",
              "  'verb',\n",
              "  'predicate',\n",
              "  ',',\n",
              "  'x',\n",
              "  ',',\n",
              "  'the',\n",
              "  'argument',\n",
              "  'instantiation',\n",
              "  'of',\n",
              "  'the',\n",
              "  'template',\n",
              "  \"'s\",\n",
              "  'slot',\n",
              "  'X',\n",
              "  ',',\n",
              "  'and',\n",
              "  'y',\n",
              "  ',',\n",
              "  'the',\n",
              "  'instantiation',\n",
              "  'of',\n",
              "  'the',\n",
              "  'template',\n",
              "  \"'s\",\n",
              "  'slot',\n",
              "  'Y',\n",
              "  '.',\n",
              "  'ReVerb',\n",
              "  'includes',\n",
              "  'over',\n",
              "  '600,000',\n",
              "  'different',\n",
              "  'templates',\n",
              "  'that',\n",
              "  'comprise',\n",
              "  'a',\n",
              "  'verb',\n",
              "  'but',\n",
              "  'may',\n",
              "  'also',\n",
              "  'include',\n",
              "  'other',\n",
              "  'words',\n",
              "  ',',\n",
              "  'for',\n",
              "  'example',\n",
              "  \"'\",\n",
              "  'X',\n",
              "  'can',\n",
              "  'accommodate',\n",
              "  'up',\n",
              "  'to',\n",
              "  'Y',\n",
              "  \"'.\",\n",
              "  'Yet',\n",
              "  ',',\n",
              "  'many',\n",
              "  'of',\n",
              "  'these',\n",
              "  'templates',\n",
              "  'share',\n",
              "  'a',\n",
              "  'similar',\n",
              "  'meaning',\n",
              "  ',',\n",
              "  'e.g.',\n",
              "  \"'\",\n",
              "  'X',\n",
              "  'accommodate',\n",
              "  'up',\n",
              "  'to',\n",
              "  \"Y'\",\n",
              "  ',',\n",
              "  \"'\",\n",
              "  'X',\n",
              "  'can',\n",
              "  'accommodate',\n",
              "  'up',\n",
              "  'to',\n",
              "  \"Y'\",\n",
              "  ',',\n",
              "  \"'\",\n",
              "  'X',\n",
              "  'will',\n",
              "  'accommodate',\n",
              "  'up',\n",
              "  'to',\n",
              "  \"Y'\",\n",
              "  ',',\n",
              "  'etc',\n",
              "  '.',\n",
              "  'Following',\n",
              "  'CITSEG',\n",
              "  ',',\n",
              "  'we',\n",
              "  'clustered',\n",
              "  'templates',\n",
              "  'that',\n",
              "  'share',\n",
              "  'their',\n",
              "  'main',\n",
              "  'verb',\n",
              "  'predicate',\n",
              "  'in',\n",
              "  'order',\n",
              "  'to',\n",
              "  'scale',\n",
              "  'down',\n",
              "  'the',\n",
              "  'number',\n",
              "  'of',\n",
              "  'different',\n",
              "  'predicates',\n",
              "  'in',\n",
              "  'the',\n",
              "  'corpus',\n",
              "  'and',\n",
              "  'collect',\n",
              "  'richer',\n",
              "  'word',\n",
              "  'cooccurrence',\n",
              "  'statistics',\n",
              "  'per',\n",
              "  'predicate',\n",
              "  '.',\n",
              "  'Next',\n",
              "  ',',\n",
              "  'we',\n",
              "  'applied',\n",
              "  'some',\n",
              "  'clean',\n",
              "  '-',\n",
              "  'up',\n",
              "  'preprocessing',\n",
              "  'to',\n",
              "  'the',\n",
              "  'ReVerb',\n",
              "  'extractions',\n",
              "  '.',\n",
              "  'This',\n",
              "  'includes',\n",
              "  'discarding',\n",
              "  'stop',\n",
              "  'words',\n",
              "  ',',\n",
              "  'rare',\n",
              "  'words',\n",
              "  'and',\n",
              "  'non-alphabetical',\n",
              "  'words',\n",
              "  'instantiating',\n",
              "  'either',\n",
              "  'the',\n",
              "  'X',\n",
              "  'or',\n",
              "  'the',\n",
              "  'Y',\n",
              "  'arguments',\n",
              "  '.',\n",
              "  'In',\n",
              "  'addition',\n",
              "  ',',\n",
              "  'we',\n",
              "  'discarded',\n",
              "  'all',\n",
              "  'predicates',\n",
              "  'that',\n",
              "  'co-occur',\n",
              "  'with',\n",
              "  'less',\n",
              "  'than',\n",
              "  '100',\n",
              "  'unique',\n",
              "  'argument',\n",
              "  'words',\n",
              "  'in',\n",
              "  'each',\n",
              "  'slot',\n",
              "  '.'],\n",
              " ['Passive',\n",
              "  'subjects',\n",
              "  '(',\n",
              "  'the',\n",
              "  'car',\n",
              "  'was',\n",
              "  'bought',\n",
              "  ')',\n",
              "  'were',\n",
              "  'converted',\n",
              "  'to',\n",
              "  'objects',\n",
              "  '(',\n",
              "  'bought',\n",
              "  'car',\n",
              "  ')',\n",
              "  '.',\n",
              "  'We',\n",
              "  'set',\n",
              "  'the',\n",
              "  'MI-threshold',\n",
              "  ',',\n",
              "  'τ',\n",
              "  ',',\n",
              "  'to',\n",
              "  'be',\n",
              "  '0',\n",
              "  ',',\n",
              "  'and',\n",
              "  'the',\n",
              "  'negative',\n",
              "  '-',\n",
              "  'to',\n",
              "  '-',\n",
              "  'positive',\n",
              "  'ratio',\n",
              "  ',',\n",
              "  'K',\n",
              "  ',',\n",
              "  'to',\n",
              "  'be',\n",
              "  '2.',\n",
              "  'Numerous',\n",
              "  'previous',\n",
              "  'pseudodisambiguation',\n",
              "  'evaluations',\n",
              "  'only',\n",
              "  'include',\n",
              "  'arguments',\n",
              "  'that',\n",
              "  'occur',\n",
              "  'between',\n",
              "  '30',\n",
              "  'and',\n",
              "  '3000',\n",
              "  'times',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.',\n",
              "  'Presumably',\n",
              "  'the',\n",
              "  'lower',\n",
              "  'bound',\n",
              "  'is',\n",
              "  'to',\n",
              "  'help',\n",
              "  'ensure',\n",
              "  'the',\n",
              "  'negative',\n",
              "  'argument',\n",
              "  'is',\n",
              "  'unobserved',\n",
              "  'because',\n",
              "  'it',\n",
              "  'is',\n",
              "  'unsuitable',\n",
              "  ',',\n",
              "  'not',\n",
              "  'because',\n",
              "  'of',\n",
              "  'data',\n",
              "  'sparseness',\n",
              "  '.',\n",
              "  'We',\n",
              "  'wish',\n",
              "  'to',\n",
              "  'use',\n",
              "  'our',\n",
              "  'model',\n",
              "  'on',\n",
              "  'arguments',\n",
              "  'of',\n",
              "  'any',\n",
              "  'frequency',\n",
              "  ',',\n",
              "  'including',\n",
              "  'those',\n",
              "  'that',\n",
              "  'never',\n",
              "  'occurred',\n",
              "  'in',\n",
              "  'the',\n",
              "  'training',\n",
              "  'corpus',\n",
              "  '(',\n",
              "  'and',\n",
              "  'therefore',\n",
              "  'have',\n",
              "  'empty',\n",
              "  'cooccurrence',\n",
              "  'features',\n",
              "  '(',\n",
              "  'Section',\n",
              "  '3.3.1',\n",
              "  ')',\n",
              "  ')',\n",
              "  '.',\n",
              "  'We',\n",
              "  'proceed',\n",
              "  'as',\n",
              "  'follows',\n",
              "  ':',\n",
              "  'first',\n",
              "  ',',\n",
              "  'we',\n",
              "  'exclude',\n",
              "  'pairs',\n",
              "  'whenever',\n",
              "  'the',\n",
              "  'noun',\n",
              "  'occurs',\n",
              "  'less',\n",
              "  'than',\n",
              "  '3',\n",
              "  'times',\n",
              "  'in',\n",
              "  'our',\n",
              "  'corpus',\n",
              "  ',',\n",
              "  'removing',\n",
              "  'many',\n",
              "  'misspellings',\n",
              "  'and',\n",
              "  'other',\n",
              "  'noun',\n",
              "  'noise',\n",
              "  '.'],\n",
              " ['Tense',\n",
              "  'interpretation',\n",
              "  'has',\n",
              "  'received',\n",
              "  'much',\n",
              "  'attention',\n",
              "  'in',\n",
              "  'linguistics',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  'and',\n",
              "  'natural',\n",
              "  'language',\n",
              "  'processing',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.',\n",
              "  'Several',\n",
              "  'researchers',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  'have',\n",
              "  'sought',\n",
              "  'to',\n",
              "  'explain',\n",
              "  'the',\n",
              "  'temporal',\n",
              "  'relations',\n",
              "  'induced',\n",
              "  'by',\n",
              "  'tense',\n",
              "  'by',\n",
              "  'treating',\n",
              "  'it',\n",
              "  'as',\n",
              "  'anaphoric',\n",
              "  ',',\n",
              "  'drawing',\n",
              "  'on',\n",
              "  'Reichenbach',\n",
              "  \"'s\",\n",
              "  'separation',\n",
              "  'between',\n",
              "  'event',\n",
              "  ',',\n",
              "  'speech',\n",
              "  ',',\n",
              "  'and',\n",
              "  'reference',\n",
              "  'times',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.',\n",
              "  'Specifically',\n",
              "  ',',\n",
              "  'to',\n",
              "  'account',\n",
              "  'for',\n",
              "  'the',\n",
              "  'forward',\n",
              "  'progression',\n",
              "  'of',\n",
              "  'time',\n",
              "  'induced',\n",
              "  'by',\n",
              "  'successive',\n",
              "  'simple',\n",
              "  'past',\n",
              "  'tenses',\n",
              "  'in',\n",
              "  'a',\n",
              "  'narrative',\n",
              "  ',',\n",
              "  'they',\n",
              "  'treat',\n",
              "  'the',\n",
              "  'simple',\n",
              "  'past',\n",
              "  'as',\n",
              "  'referring',\n",
              "  'to',\n",
              "  'a',\n",
              "  'time',\n",
              "  'evoked',\n",
              "  'by',\n",
              "  'a',\n",
              "  'previous',\n",
              "  'past',\n",
              "  'tense',\n",
              "  '.',\n",
              "  'For',\n",
              "  'instance',\n",
              "  ',',\n",
              "  'in',\n",
              "  'CITSEG',\n",
              "  \"'s\",\n",
              "  'proposal',\n",
              "  ',',\n",
              "  'accomplishments',\n",
              "  'and',\n",
              "  'achievements',\n",
              "  'x',\n",
              "  'introduce',\n",
              "  'a',\n",
              "  'new',\n",
              "  'reference',\n",
              "  'point',\n",
              "  'that',\n",
              "  'is',\n",
              "  'temporally',\n",
              "  'ordered',\n",
              "  'after',\n",
              "  'the',\n",
              "  'time',\n",
              "  'of',\n",
              "  'the',\n",
              "  'event',\n",
              "  'itself',\n",
              "  ',',\n",
              "  '\"',\n",
              "  'ensuring',\n",
              "  'that',\n",
              "  'two',\n",
              "  'consecutive',\n",
              "  'accomplishments',\n",
              "  'or',\n",
              "  'achievements',\n",
              "  'in',\n",
              "  'a',\n",
              "  'discourse',\n",
              "  'are',\n",
              "  'always',\n",
              "  'ordered',\n",
              "  'in',\n",
              "  'a',\n",
              "  'temporal',\n",
              "  'sequence',\n",
              "  '.',\n",
              "  '\"',\n",
              "  'On',\n",
              "  'the',\n",
              "  'other',\n",
              "  'hand',\n",
              "  ',',\n",
              "  'CITSEG',\n",
              "  'take',\n",
              "  'the',\n",
              "  'view',\n",
              "  'that',\n",
              "  'temporal',\n",
              "  'relations',\n",
              "  'are',\n",
              "  'resolved',\n",
              "  'purely',\n",
              "  'as',\n",
              "  'a',\n",
              "  'by-product',\n",
              "  'of',\n",
              "  'reasoning',\n",
              "  'about',\n",
              "  'coherence',\n",
              "  'relations',\n",
              "  'holding',\n",
              "  'between',\n",
              "  'utterances',\n",
              "  ',',\n",
              "  'and',\n",
              "  'in',\n",
              "  'doing',\n",
              "  'so',\n",
              "  ',',\n",
              "  'argue',\n",
              "  'that',\n",
              "  'treating',\n",
              "  'simple',\n",
              "  'and',\n",
              "  'complex',\n",
              "  'tenses',\n",
              "  'as',\n",
              "  'anaphoric',\n",
              "  'is',\n",
              "  'unnecessary',\n",
              "  '.',\n",
              "  'This',\n",
              "  'approach',\n",
              "  'parallels',\n",
              "  'the',\n",
              "  'treatment',\n",
              "  'of',\n",
              "  'pronoun',\n",
              "  'resolution',\n",
              "  'espoused',\n",
              "  'by',\n",
              "  'CITSEG',\n",
              "  ',',\n",
              "  'in',\n",
              "  'which',\n",
              "  'pronouns',\n",
              "  'are',\n",
              "  'modeled',\n",
              "  'as',\n",
              "  'free',\n",
              "  'variables',\n",
              "  'that',\n",
              "  'are',\n",
              "  'bound',\n",
              "  'as',\n",
              "  'a',\n",
              "  'byproduct',\n",
              "  'of',\n",
              "  'coherence',\n",
              "  'resolution',\n",
              "  '.'],\n",
              " ['Over',\n",
              "  'the',\n",
              "  'last',\n",
              "  '20',\n",
              "  'years',\n",
              "  ',',\n",
              "  'statistical',\n",
              "  'language',\n",
              "  'models',\n",
              "  '(',\n",
              "  'SLMs',\n",
              "  ')',\n",
              "  'have',\n",
              "  'been',\n",
              "  'used',\n",
              "  'successfully',\n",
              "  'in',\n",
              "  'many',\n",
              "  'tasks',\n",
              "  'in',\n",
              "  'natural',\n",
              "  'language',\n",
              "  'processing',\n",
              "  ',',\n",
              "  'and',\n",
              "  'the',\n",
              "  'data',\n",
              "  'available',\n",
              "  'for',\n",
              "  'modeling',\n",
              "  'has',\n",
              "  'steadily',\n",
              "  'grown',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.',\n",
              "  'CITSEG',\n",
              "  'first',\n",
              "  'applied',\n",
              "  'SLMs',\n",
              "  'to',\n",
              "  'statistical',\n",
              "  'natural',\n",
              "  'language',\n",
              "  'generation',\n",
              "  '(',\n",
              "  'SNLG',\n",
              "  ')',\n",
              "  ',',\n",
              "  'showing',\n",
              "  'that',\n",
              "  'high',\n",
              "  'quality',\n",
              "  'paraphrases',\n",
              "  'can',\n",
              "  'be',\n",
              "  'generated',\n",
              "  'from',\n",
              "  'an',\n",
              "  'underspecified',\n",
              "  'representation',\n",
              "  'of',\n",
              "  'meaning',\n",
              "  ',',\n",
              "  'by',\n",
              "  'first',\n",
              "  'applying',\n",
              "  'a',\n",
              "  'very',\n",
              "  'underconstrained',\n",
              "  ',',\n",
              "  'rule',\n",
              "  '-',\n",
              "  'based',\n",
              "  'overgeneration',\n",
              "  'phase',\n",
              "  ',',\n",
              "  'whose',\n",
              "  'outputs',\n",
              "  'are',\n",
              "  'then',\n",
              "  'ranked',\n",
              "  'by',\n",
              "  'an',\n",
              "  'SLM',\n",
              "  'scoring',\n",
              "  'phase',\n",
              "  '.',\n",
              "  'Since',\n",
              "  'then',\n",
              "  ',',\n",
              "  'research',\n",
              "  'in',\n",
              "  'SNLG',\n",
              "  'has',\n",
              "  'explored',\n",
              "  'a',\n",
              "  'range',\n",
              "  'of',\n",
              "  'models',\n",
              "  'for',\n",
              "  'both',\n",
              "  'dialogue',\n",
              "  'and',\n",
              "  'text',\n",
              "  'generation',\n",
              "  '.',\n",
              "  'One',\n",
              "  'line',\n",
              "  'of',\n",
              "  'work',\n",
              "  'has',\n",
              "  'primarily',\n",
              "  'focused',\n",
              "  'on',\n",
              "  'grammaticality',\n",
              "  'and',\n",
              "  'naturalness',\n",
              "  ',',\n",
              "  'scoring',\n",
              "  'the',\n",
              "  'overgener',\n",
              "  '-',\n",
              "  'ation',\n",
              "  'phase',\n",
              "  'with',\n",
              "  'a',\n",
              "  'SLM',\n",
              "  ',',\n",
              "  'and',\n",
              "  'evaluating',\n",
              "  'against',\n",
              "  'a',\n",
              "  'gold',\n",
              "  '-',\n",
              "  'standard',\n",
              "  'corpus',\n",
              "  ',',\n",
              "  'using',\n",
              "  'string',\n",
              "  'or',\n",
              "  'tree',\n",
              "  '-',\n",
              "  'match',\n",
              "  'metrics',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.',\n",
              "  'Another',\n",
              "  'thread',\n",
              "  'investigates',\n",
              "  'SNLG',\n",
              "  'scoring',\n",
              "  'models',\n",
              "  'trained',\n",
              "  'using',\n",
              "  'higher',\n",
              "  '-',\n",
              "  'level',\n",
              "  'linguistic',\n",
              "  'features',\n",
              "  'to',\n",
              "  'replicate',\n",
              "  'human',\n",
              "  'judgments',\n",
              "  'of',\n",
              "  'utterance',\n",
              "  'quality',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.'],\n",
              " ['The',\n",
              "  'Naive',\n",
              "  'Bayesian',\n",
              "  'classifier',\n",
              "  'has',\n",
              "  'emerged',\n",
              "  'as',\n",
              "  'a',\n",
              "  'consistently',\n",
              "  'strong',\n",
              "  'performer',\n",
              "  'in',\n",
              "  'a',\n",
              "  'wide',\n",
              "  'range',\n",
              "  'of',\n",
              "  'comparative',\n",
              "  'studies',\n",
              "  'of',\n",
              "  'machine',\n",
              "  'learning',\n",
              "  'methodologies',\n",
              "  '.',\n",
              "  'A',\n",
              "  'recent',\n",
              "  'survey',\n",
              "  'of',\n",
              "  'such',\n",
              "  'results',\n",
              "  ',',\n",
              "  'as',\n",
              "  'well',\n",
              "  'as',\n",
              "  'possible',\n",
              "  'explanations',\n",
              "  'for',\n",
              "  'its',\n",
              "  'success',\n",
              "  ',',\n",
              "  'is',\n",
              "  'presented',\n",
              "  'in',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.',\n",
              "  'A',\n",
              "  'similar',\n",
              "  'finding',\n",
              "  'has',\n",
              "  'emerged',\n",
              "  'in',\n",
              "  'word',\n",
              "  'sense',\n",
              "  'disambiguation',\n",
              "  ',',\n",
              "  'where',\n",
              "  'a',\n",
              "  'number',\n",
              "  'of',\n",
              "  'comparative',\n",
              "  'studies',\n",
              "  'have',\n",
              "  'all',\n",
              "  'reported',\n",
              "  'that',\n",
              "  'no',\n",
              "  'method',\n",
              "  'achieves',\n",
              "  'significantly',\n",
              "  'greater',\n",
              "  'accuracy',\n",
              "  'than',\n",
              "  'the',\n",
              "  'Naive',\n",
              "  'Bayesian',\n",
              "  'classifier',\n",
              "  '(',\n",
              "  'e.g.',\n",
              "  ',',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  ',',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  ',',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  ',',\n",
              "  ')',\n",
              "  '.',\n",
              "  'In',\n",
              "  'many',\n",
              "  'ensemble',\n",
              "  'approaches',\n",
              "  'the',\n",
              "  'member',\n",
              "  'classitiers',\n",
              "  'are',\n",
              "  'learned',\n",
              "  'with',\n",
              "  'different',\n",
              "  'algorithms',\n",
              "  'that',\n",
              "  'are',\n",
              "  'trained',\n",
              "  'with',\n",
              "  'the',\n",
              "  'same',\n",
              "  'data',\n",
              "  '.',\n",
              "  'For',\n",
              "  'example',\n",
              "  ',',\n",
              "  'an',\n",
              "  'ensemble',\n",
              "  'could',\n",
              "  'consist',\n",
              "  'of',\n",
              "  'a',\n",
              "  'decision',\n",
              "  'tree',\n",
              "  ',',\n",
              "  'a',\n",
              "  'neural',\n",
              "  'network',\n",
              "  ',',\n",
              "  'and',\n",
              "  'a',\n",
              "  'nearest',\n",
              "  'neighbor',\n",
              "  'classifier',\n",
              "  ',',\n",
              "  'all',\n",
              "  'of',\n",
              "  'which',\n",
              "  'are',\n",
              "  'learned',\n",
              "  'from',\n",
              "  'exactly',\n",
              "  'the',\n",
              "  'same',\n",
              "  'set',\n",
              "  'of',\n",
              "  'training',\n",
              "  'data',\n",
              "  '.'],\n",
              " ['PAS',\n",
              "  'is',\n",
              "  'the',\n",
              "  'sole',\n",
              "  'level',\n",
              "  'of',\n",
              "  'representation',\n",
              "  'in',\n",
              "  'Combinatory',\n",
              "  'Categorial',\n",
              "  'Grammar',\n",
              "  '(',\n",
              "  'CCG',\n",
              "  ')',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.',\n",
              "  'All',\n",
              "  'formulations',\n",
              "  'assume',\n",
              "  'a',\n",
              "  'prominence',\n",
              "  '-',\n",
              "  'based',\n",
              "  'structured',\n",
              "  'representation',\n",
              "  'for',\n",
              "  'PAS',\n",
              "  ',',\n",
              "  'although',\n",
              "  'they',\n",
              "  'differ',\n",
              "  'in',\n",
              "  'the',\n",
              "  'terms',\n",
              "  'used',\n",
              "  'for',\n",
              "  'defining',\n",
              "  'prominence',\n",
              "  '.',\n",
              "  'For',\n",
              "  'instance',\n",
              "  ',',\n",
              "  'CITSEG',\n",
              "  'defines',\n",
              "  'the',\n",
              "  'thematic',\n",
              "  'hierarchy',\n",
              "  'as',\n",
              "  ':',\n",
              "  'Agent',\n",
              "  '>',\n",
              "  'Experiencer',\n",
              "  '>',\n",
              "  'Goal',\n",
              "  '/',\n",
              "  'Location',\n",
              "  '/',\n",
              "  'Source',\n",
              "  '>',\n",
              "  'Theme',\n",
              "  '\"',\n",
              "  'Thanks',\n",
              "  'to',\n",
              "  'Mark',\n",
              "  'Steedman',\n",
              "  'for',\n",
              "  'discussion',\n",
              "  'and',\n",
              "  'material',\n",
              "  ',',\n",
              "  'and',\n",
              "  'to',\n",
              "  'the',\n",
              "  'anonymous',\n",
              "  'reviewer',\n",
              "  'of',\n",
              "  'an',\n",
              "  'extended',\n",
              "  'version',\n",
              "  'whose',\n",
              "  'comments',\n",
              "  'led',\n",
              "  'to',\n",
              "  'significant',\n",
              "  'revisions',\n",
              "  '.',\n",
              "  'This',\n",
              "  'research',\n",
              "  'is',\n",
              "  'supported',\n",
              "  'by',\n",
              "  'TUBITAK',\n",
              "  '(',\n",
              "  'EEEAG',\n",
              "  '-',\n",
              "  '90',\n",
              "  ')',\n",
              "  'and',\n",
              "  'NATO',\n",
              "  'Science',\n",
              "  'Division',\n",
              "  '(',\n",
              "  'TU',\n",
              "  '-',\n",
              "  'LANGUAGE',\n",
              "  ')',\n",
              "  '.',\n",
              "  'whereas',\n",
              "  'LFG',\n",
              "  'accounts',\n",
              "  'make',\n",
              "  'use',\n",
              "  'of',\n",
              "  'the',\n",
              "  'following',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  ':'],\n",
              " ['First',\n",
              "  ',',\n",
              "  'we',\n",
              "  'consider',\n",
              "  'the',\n",
              "  'past',\n",
              "  'perfect',\n",
              "  ',',\n",
              "  'as',\n",
              "  'in',\n",
              "  'sentence',\n",
              "  '2',\n",
              "  '.',\n",
              "  'CITSEG',\n",
              "  'gives',\n",
              "  'this',\n",
              "  'example',\n",
              "  'to',\n",
              "  'illustrate',\n",
              "  'the',\n",
              "  'inability',\n",
              "  'to',\n",
              "  'interpret',\n",
              "  'temporal',\n",
              "  'connectives',\n",
              "  'without',\n",
              "  'the',\n",
              "  'use',\n",
              "  'of',\n",
              "  'the',\n",
              "  'reference',\n",
              "  'times',\n",
              "  '.',\n",
              "  'According',\n",
              "  'to',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  ',',\n",
              "  'the',\n",
              "  'subordinate',\n",
              "  'clause',\n",
              "  'determines',\n",
              "  'the',\n",
              "  'reference',\n",
              "  'time',\n",
              "  'of',\n",
              "  'the',\n",
              "  'verb',\n",
              "  ',',\n",
              "  'which',\n",
              "  'lies',\n",
              "  'anteriorly',\n",
              "  'to',\n",
              "  'the',\n",
              "  'event',\n",
              "  'time',\n",
              "  '.',\n",
              "  'Trying',\n",
              "  'to',\n",
              "  'use',\n",
              "  'the',\n",
              "  'event',\n",
              "  'times',\n",
              "  'would',\n",
              "  'give',\n",
              "  'the',\n",
              "  'wrong',\n",
              "  'analysis',\n",
              "  '.',\n",
              "  'This',\n",
              "  'would',\n",
              "  'seem',\n",
              "  'to',\n",
              "  'be',\n",
              "  'troublesome',\n",
              "  'for',\n",
              "  'our',\n",
              "  'approach',\n",
              "  ',',\n",
              "  'which',\n",
              "  'uses',\n",
              "  'the',\n",
              "  'location',\n",
              "  'time',\n",
              "  'of',\n",
              "  'the',\n",
              "  'event',\n",
              "  'in',\n",
              "  'the',\n",
              "  'main',\n",
              "  'clause',\n",
              "  ',',\n",
              "  'and',\n",
              "  'not',\n",
              "  'its',\n",
              "  'reference',\n",
              "  'time',\n",
              "  '.',\n",
              "  'However',\n",
              "  ',',\n",
              "  'this',\n",
              "  'is',\n",
              "  'not',\n",
              "  'a',\n",
              "  'problem',\n",
              "  ',',\n",
              "  'since',\n",
              "  'our',\n",
              "  'analysis',\n",
              "  'of',\n",
              "  'the',\n",
              "  'perfect',\n",
              "  'by',\n",
              "  'the',\n",
              "  'use',\n",
              "  'of',\n",
              "  'the',\n",
              "  'operator',\n",
              "  'perf',\n",
              "  ',',\n",
              "  'analyses',\n",
              "  'the',\n",
              "  'eventuality',\n",
              "  'referred',\n",
              "  'to',\n",
              "  'by',\n",
              "  'the',\n",
              "  'main',\n",
              "  'clause',\n",
              "  ',',\n",
              "  'as',\n",
              "  'the',\n",
              "  'result',\n",
              "  'state',\n",
              "  'of',\n",
              "  'a',\n",
              "  'previous',\n",
              "  'event',\n",
              "  '.'],\n",
              " ['The',\n",
              "  'centering',\n",
              "  'algorithm',\n",
              "  'as',\n",
              "  'defined',\n",
              "  'by',\n",
              "  'CITSEG',\n",
              "  ',',\n",
              "  '(',\n",
              "  'BFP',\n",
              "  'algorithm',\n",
              "  ')',\n",
              "  ',',\n",
              "  'is',\n",
              "  'derived',\n",
              "  'from',\n",
              "  'a',\n",
              "  'set',\n",
              "  'of',\n",
              "  'rules',\n",
              "  'and',\n",
              "  'constraints',\n",
              "  'put',\n",
              "  'forth',\n",
              "  'by',\n",
              "  'Grosz',\n",
              "  ',',\n",
              "  'Joshi',\n",
              "  'and',\n",
              "  'Weinstein',\n",
              "  '[',\n",
              "  'CITSEG',\n",
              "  ']',\n",
              "  '.',\n",
              "  'We',\n",
              "  'shall',\n",
              "  'not',\n",
              "  'reproduce',\n",
              "  'this',\n",
              "  'algorithm',\n",
              "  'here',\n",
              "  '(',\n",
              "  'See',\n",
              "  '[',\n",
              "  'BFP87',\n",
              "  ']',\n",
              "  ')',\n",
              "  '.',\n",
              "  'There',\n",
              "  'are',\n",
              "  'two',\n",
              "  'main',\n",
              "  'structures',\n",
              "  'in',\n",
              "  'the',\n",
              "  'centering',\n",
              "  'algorithm',\n",
              "  ',',\n",
              "  'the',\n",
              "  'CB',\n",
              "  ',',\n",
              "  'the',\n",
              "  'BACKWARD',\n",
              "  'LOOKING',\n",
              "  'CENTER',\n",
              "  ',',\n",
              "  'which',\n",
              "  'is',\n",
              "  'what',\n",
              "  'the',\n",
              "  'discourse',\n",
              "  'is',\n",
              "  \"'\",\n",
              "  'about',\n",
              "  \"'\",\n",
              "  ',',\n",
              "  'and',\n",
              "  'an',\n",
              "  'ordered',\n",
              "  'list',\n",
              "  ',',\n",
              "  'CF',\n",
              "  ',',\n",
              "  'of',\n",
              "  'FORWARD',\n",
              "  'LOOKING',\n",
              "  'CENTERS',\n",
              "  ',',\n",
              "  'which',\n",
              "  'are',\n",
              "  'the',\n",
              "  'discourse',\n",
              "  'entities',\n",
              "  'available',\n",
              "  'to',\n",
              "  'the',\n",
              "  'next',\n",
              "  'utterance',\n",
              "  'for',\n",
              "  'pronorninalization',\n",
              "  '.',\n",
              "  'The',\n",
              "  'centering',\n",
              "  'framework',\n",
              "  'predicts',\n",
              "  'that',\n",
              "  'in',\n",
              "  'a',\n",
              "  'local',\n",
              "  'coherent',\n",
              "  'stretch',\n",
              "  'of',\n",
              "  'dialogue',\n",
              "  ',',\n",
              "  'speakers',\n",
              "  'will',\n",
              "  'prefer',\n",
              "  'to',\n",
              "  'CONTINUE',\n",
              "  'talking',\n",
              "  'about',\n",
              "  'the',\n",
              "  'same',\n",
              "  'discourse',\n",
              "  'entity',\n",
              "  ',',\n",
              "  'that',\n",
              "  'the',\n",
              "  'CB',\n",
              "  'will',\n",
              "  'be',\n",
              "  'the',\n",
              "  'highest',\n",
              "  'ranked',\n",
              "  'entity',\n",
              "  'of',\n",
              "  'the',\n",
              "  'previous',\n",
              "  'utterance',\n",
              "  \"'s\",\n",
              "  'forward',\n",
              "  'centers',\n",
              "  'that',\n",
              "  'is',\n",
              "  'realized',\n",
              "  'in',\n",
              "  'the',\n",
              "  'current',\n",
              "  'utterance',\n",
              "  ',',\n",
              "  'and',\n",
              "  'that',\n",
              "  'if',\n",
              "  'anything',\n",
              "  'is',\n",
              "  'pronominalized',\n",
              "  'the',\n",
              "  'CB',\n",
              "  'must',\n",
              "  'be',\n",
              "  '.'],\n",
              " ['Description',\n",
              "  'of',\n",
              "  'the',\n",
              "  'System',\n",
              "  '2.1',\n",
              "  'Overview',\n",
              "  'The',\n",
              "  'system',\n",
              "  'consists',\n",
              "  'of',\n",
              "  'the',\n",
              "  'following',\n",
              "  'six',\n",
              "  'components',\n",
              "  'which',\n",
              "  'are',\n",
              "  'applied',\n",
              "  'in',\n",
              "  'sequence',\n",
              "  'to',\n",
              "  'sentences',\n",
              "  'containing',\n",
              "  'a',\n",
              "  'specific',\n",
              "  'predicate',\n",
              "  'in',\n",
              "  'order',\n",
              "  'to',\n",
              "  'retrieve',\n",
              "  'a',\n",
              "  'set',\n",
              "  'of',\n",
              "  'subcategorization',\n",
              "  'classes',\n",
              "  'for',\n",
              "  'that',\n",
              "  'predicate',\n",
              "  ':',\n",
              "  '1',\n",
              "  '.',\n",
              "  'A',\n",
              "  'tagger',\n",
              "  ',',\n",
              "  'a',\n",
              "  'first',\n",
              "  '-',\n",
              "  'order',\n",
              "  'HMM',\n",
              "  'part',\n",
              "  '-of',\n",
              "  '-',\n",
              "  'speech',\n",
              "  '(',\n",
              "  'PoS',\n",
              "  ')',\n",
              "  'and',\n",
              "  'punctuation',\n",
              "  'tag',\n",
              "  'disambiguator',\n",
              "  ',',\n",
              "  'is',\n",
              "  'used',\n",
              "  'to',\n",
              "  'assign',\n",
              "  'and',\n",
              "  'rank',\n",
              "  'tags',\n",
              "  'for',\n",
              "  'each',\n",
              "  'word',\n",
              "  'and',\n",
              "  'punctuation',\n",
              "  'token',\n",
              "  'in',\n",
              "  'sequences',\n",
              "  'of',\n",
              "  'sentences',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.',\n",
              "  '2',\n",
              "  '.',\n",
              "  'A',\n",
              "  'lemmatizer',\n",
              "  'is',\n",
              "  'used',\n",
              "  'to',\n",
              "  'replace',\n",
              "  'word',\n",
              "  '-',\n",
              "  'tag',\n",
              "  'pairs',\n",
              "  'with',\n",
              "  'lemma-tag',\n",
              "  'pairs',\n",
              "  ',',\n",
              "  'where',\n",
              "  'a',\n",
              "  'lemma',\n",
              "  'is',\n",
              "  'the',\n",
              "  'morphological',\n",
              "  'base',\n",
              "  'or',\n",
              "  'dictionary',\n",
              "  'headword',\n",
              "  'form',\n",
              "  'appropriate',\n",
              "  'for',\n",
              "  'the',\n",
              "  'word',\n",
              "  ',',\n",
              "  'given',\n",
              "  'the',\n",
              "  'PoS',\n",
              "  'assignment',\n",
              "  'made',\n",
              "  'by',\n",
              "  'the',\n",
              "  'tagger',\n",
              "  '.',\n",
              "  'We',\n",
              "  'use',\n",
              "  'an',\n",
              "  'enhanced',\n",
              "  'version',\n",
              "  'of',\n",
              "  'the',\n",
              "  'GATE',\n",
              "  'project',\n",
              "  'stemmer',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.',\n",
              "  '3',\n",
              "  '.',\n",
              "  'A',\n",
              "  'probabilistic',\n",
              "  'LR',\n",
              "  'parser',\n",
              "  ',',\n",
              "  'trained',\n",
              "  'on',\n",
              "  'a',\n",
              "  'treebank',\n",
              "  ',',\n",
              "  'returns',\n",
              "  'ranked',\n",
              "  'analyses',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  ',',\n",
              "  'using',\n",
              "  'a',\n",
              "  'grammar',\n",
              "  'written',\n",
              "  'in',\n",
              "  'a',\n",
              "  'feature',\n",
              "  '-',\n",
              "  'based',\n",
              "  'unification',\n",
              "  'grammar',\n",
              "  'formalism',\n",
              "  'which',\n",
              "  'assigns',\n",
              "  \"'\",\n",
              "  'shallow',\n",
              "  \"'\",\n",
              "  'phrase',\n",
              "  'structure',\n",
              "  'analyses',\n",
              "  'to',\n",
              "  'tag',\n",
              "  'networks',\n",
              "  '(',\n",
              "  'or',\n",
              "  \"'\",\n",
              "  'lattices',\n",
              "  \"'\",\n",
              "  ')',\n",
              "  'returned',\n",
              "  'by',\n",
              "  'the',\n",
              "  'tagger',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.'],\n",
              " ['More',\n",
              "  'recent',\n",
              "  'work',\n",
              "  'on',\n",
              "  'spoken',\n",
              "  'language',\n",
              "  'interfaces',\n",
              "  'to',\n",
              "  'semi-antonomous',\n",
              "  'robots',\n",
              "  'include',\n",
              "  'SRrs',\n",
              "  'Flakey',\n",
              "  'robot',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  'and',\n",
              "  'NCARArs',\n",
              "  'Inter',\n",
              "  'BOT',\n",
              "  'project',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.',\n",
              "  'A',\n",
              "  'number',\n",
              "  'of',\n",
              "  'other',\n",
              "  'systems',\n",
              "  'have',\n",
              "  'addressed',\n",
              "  'part',\n",
              "  'of',\n",
              "  'the',\n",
              "  'task',\n",
              "  '.',\n",
              "  'Com-mand',\n",
              "  'Talk',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  ',',\n",
              "  'Circuit',\n",
              "  'Fix',\n",
              "  '-',\n",
              "  'It',\n",
              "  'Shop',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  'and',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  'are',\n",
              "  'spoken',\n",
              "  'language',\n",
              "  'systems',\n",
              "  'but',\n",
              "  'they',\n",
              "  'interface',\n",
              "  'to',\n",
              "  'simulation',\n",
              "  'or',\n",
              "  'help',\n",
              "  'facilities',\n",
              "  'rather',\n",
              "  'than',\n",
              "  'semi-autonomous',\n",
              "  'agents',\n",
              "  '.',\n",
              "  'Jack',\n",
              "  \"'s\",\n",
              "  'MOOse',\n",
              "  'Lodge',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  'takes',\n",
              "  'text',\n",
              "  'rather',\n",
              "  'than',\n",
              "  'speech',\n",
              "  'as',\n",
              "  'natural',\n",
              "  'language',\n",
              "  'input',\n",
              "  'and',\n",
              "  'the',\n",
              "  'avatars',\n",
              "  'being',\n",
              "  'controlled',\n",
              "  'are',\n",
              "  'not',\n",
              "  'semi-autonomous',\n",
              "  '.',\n",
              "  'Other',\n",
              "  'researchers',\n",
              "  'have',\n",
              "  'considered',\n",
              "  'particular',\n",
              "  'aspects',\n",
              "  'of',\n",
              "  'the',\n",
              "  'problem',\n",
              "  'such',\n",
              "  'as',\n",
              "  'accounting',\n",
              "  'for',\n",
              "  'various',\n",
              "  'aspects',\n",
              "  'of',\n",
              "  'actions',\n",
              "  '(',\n",
              "  'CITSEG',\n",
              "  ')',\n",
              "  '.',\n",
              "  'In',\n",
              "  'most',\n",
              "  'of',\n",
              "  'this',\n",
              "  'and',\n",
              "  'other',\n",
              "  'related',\n",
              "  'work',\n",
              "  'the',\n",
              "  'treatment',\n",
              "  'is',\n",
              "  'some',\n",
              "  'variant',\n",
              "  'of',\n",
              "  'the',\n",
              "  'following',\n",
              "  '.'])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "sent.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4ROvTclesUU"
      },
      "outputs": [],
      "source": [
        "flat_list = [item for sent in sent for item in sent]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_86VHieDn0u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "648b6d99-17ad-4f0d-927f-755da45b6be6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 1, 0, 2, 1, 1, 0, 1, 1, 1, 4, 0, 0, 3, 0, 5, 0, 0, 0, 4, 0, 0, 0,\n",
              "        5, 0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "y.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYHmGxguDoye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89747bfe-757e-4fee-bb0f-3888775d1568"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 1, 5, 1, 2, 1, 0, 4, 1, 1, 1, 1, 0, 0, 1, 0, 5, 4, 0, 4, 4, 0, 0, 2,\n",
              "        5, 0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "prediction.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmYC_I7MjGSf"
      },
      "outputs": [],
      "source": [
        "y_tensor = torch.stack(y)\n",
        "pred_tensor = torch.stack(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXaM2ghAezHQ"
      },
      "outputs": [],
      "source": [
        "missclass = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76kpzw9-jKnY"
      },
      "outputs": [],
      "source": [
        "true_y=y_tensor.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXTxR1QnjOHA"
      },
      "outputs": [],
      "source": [
        "pred_y=pred_tensor.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vclBr5NfjSov"
      },
      "outputs": [],
      "source": [
        "pred_y=pred_y.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHdhYkILjW6f"
      },
      "outputs": [],
      "source": [
        "true_y=true_y.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mU8vyWklfe-O"
      },
      "outputs": [],
      "source": [
        "missclass['prediction']=pred_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFhgxK6Le2fz"
      },
      "outputs": [],
      "source": [
        "missclass['sent']=flat_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rb_welsue5Sm"
      },
      "outputs": [],
      "source": [
        "missclass['true']=true_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-33HxSL-fgkh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "853d44fe-a85b-490b-d2ed-8d01fbe74822"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prediction</th>\n",
              "      <th>sent</th>\n",
              "      <th>true</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[All, experiments, used, gold, tokenization, /, segmentation, ., Unlike, the, ATB, ,, the, FTB, does, not, contain, the, raw, source, documents, ,, so, we, could, not, start, from, raw, text, for, both, languages, ., We, previously, showed, that, segmentation, errors, decrease, Arabic, parsing, accuracy, by, about, 2.0, %, F1, (, CITSEG, ), ., Morphological, analysis, accuracy, was, another, e...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>[Following, G&amp;G, ,, we, require, that, the, prosody, rules, build, a, binary, tree, whose, terminals, are, phonological, words, and, whose, node, labels, are, indices, that, mark, boundary, salience, ., An, alternative, representation, based, on, CITSEG, is, presented, in, CITSEG, ,, which, contends, that, prosody, ,, including, prosodic, phrasing, ,, is, more, properly, represented, as, a, gr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>[For, a, cogent, introduction, to, genetic, search, and, an, explanation, of, why, it, works, ,, the, reader, is, referred, to, (, CITSEG, ), ., Before, presenting, the, version, of, the, algorithm, used, in, the, implementation, ,, !, ., ~hall, informally, define, the, key, data, types, it, uses, ah, ,, ng, with, tim, standard, operations, on, those, types, ., g, ,, ,, ne, A, line, ;, at, enc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>[In, order, to, train, the, POS, -, based, reordering, model, ,, probabilistic, rules, were, learned, based, on, the, POS, tags, from, the, TreeTagger, (, CITSEG, ), of, the, training, corpus, and, the, alignment, ., As, described, in, CITSEG, ,, continuous, reordering, rules, are, extracted, ., This, modeling, of, short, -, range, reorderings, was, extended, so, that, it, can, cover, also, lo...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>[For, instance, ,, purpose-oriented, extracts, less, than, 10, sentences, long, are, generated, containing, a, predetermined, number, of, AIM, ,, SOLU, -, TION, and, BACKGROUND, zones, ., As, the, emphasis, of, this, approach, was, the, identification, of, the, argumentative, zones, ,, less, attention, was, given, to, the, sentence, selection, criteria, for, the, extractive, summaries, ., The,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4</td>\n",
              "      <td>[While, self-, training, has, worked, in, several, domains, ,, the, early, results, on, self, -, training, for, parsing, were, negative, (, CITSEG, ), ., However, more, recent, results, have, shown, that, it, can, indeed, improve, parser, performance, (, CITSEG, ), ., One, possible, use, for, this, technique, is, for, parser, adaptation, -, initially, training, the, parser, on, one, type, of, ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5</td>\n",
              "      <td>[That, is, ,, the, text, between, the, relevant, segment, boundaries, is, not, reordered, nor, mixed, with, the, text, outside, these, boundaries, ., 3, Thus, the, text, in, the, target, language, segment, comes, only, from, the, corresponding, source, language, segment, ., We, use, the, Moses, statistical, MT, (, SMT, ), toolkit, (, CITSEG, ), to, perform, the, translation, ., In, Moses, ,, t...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, second, stage, of, our, dependency, parser, is, a, reranker, that, operates, on, the, output, of, the, k, -best, MST, parser, ., Features, in, this, model, are, not, constrained, as, in, the, edge, -, factored, model, ., Many, of, the, model, features, have, been, inspired, by, the, constituency, -, based, features, presented, in, CITSEG, ., We, have, also, included, features, that, expl...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5</td>\n",
              "      <td>[During, the, categorization, phase, ,, the, representation, is, used, to, assign, the, appropriate, class, to, a, new, document, vector, ., Several, pruning, or, specialization, heuristics, can, be, used, to, control, the, amount, of, generalization, ., We, used, ID3, (, CITSEG, ), ,, C4.5, (, CITSEG, ), and, C5.0, ,, RIPPER, (, CITSEG, ), ,, and, the, Naive, Bayes, inducer, (, CITSEG, ), con...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4</td>\n",
              "      <td>[Keyword, -, based, search, engines, have, been, one, of, the, most, highly, utilized, internet, tools, in, recent, years, ., Nevertheless, ,, search, performance, remains, unsatisfactory, at, most, e-commerce, sites, (, CITSEG, ), ., Librarians, and, search, professionals, have, traditionally, favored, Boolean, keyword, search, systems, ,, which, ,, when, successful, ,, return, a, small, set,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>[Machine, learning, based, classifiers, and, maximum, entropy, models, which, ,, in, principle, ,, are, not, restricted, to, features, of, these, forms, have, used, them, nevertheless, ,, perhaps, under, the, influence, of, probabilistic, methods, (, CITSEG, ), ., It, has, been, argued, that, the, information, available, in, the, local, context, of, each, word, should, be, augmented, by, globa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>5</td>\n",
              "      <td>[To, test, the, performance, of, the, combined, task, on, automatic, parse, trees, ,, we, employ, two, different, configurations, ., First, ,, we, train, the, various, classifiers, on, sections, 2, to, 21, using, gold, argument, labels, and, automatic, parse, trees, produced, by, Charniak, 's, reranking, parser, (, CITSEG, ), ,, and, test, them, on, section, 23, with, automatic, parse, trees, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>[On, the, other, hand, if, the, text, unit, is, the, sub-sentence, we, lace, one, major, problem, ,, that, is, the, possibility, that, the, resulting, translation, of, the, whole, sentence, will, be, of, low, quality, ,, due, to, Ixmndary, friction, and, incorrect, chunking, ., In, practice, ,, EBMT, systems, that, operate, at, sub-sentence, level, involve, the, dynamic, derivation, of, the, o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>5</td>\n",
              "      <td>[In, this, evaluation, we, tried, two, different, taggers, ., First, ,, we, used, a, tagger, which, was, a, c, ++, re-implementation, of, the, LISP, implemented, HMM, Xerox, tagger, described, in, (, CITSEG, ), ., The, other, tagger, was, the, rule, -, based, tagger, of, Brill, (, CITSEG, ), ., Both, of, the, taggers, come, with, data, and, word, -, guessing, components, pre-trained, on, the, ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>4</td>\n",
              "      <td>[word, sense, disambiguation, ,, information, retrieval, ,, natural, language, generation, and, so, on, ., Also, ,, the, use, of, collocations, in, different, applications, has, been, discussed, by, various, authors, (, (, CITSEG, ), ,, (, CITSEG, ), ,, (, CITSEG, ), etc., ), ., However, ,, collocations, are, not, only, considered, usefnl, ,, but, also, a, problem, both, in, certain, applicati...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>[In, particular, ,, an, agent, may, be, obliged, to, do, an, action, that, is, contrary, to, his, goals, (, for, example, ,, consider, a, child, who, has, to, apologize, for, hitting, her, younger, brother, ), ., Obligations, also, can, not, be, reduced, to, simple, expectations, ,, although, obligations, may, act, as, a, source, of, expectations, ., Expectations, can, be, used, to, guide, the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>[There, are, more, sophisticated, surface, generation, packages, ,, such, as, FUF, /, SURGE, (, CITSEG, ), ,, KPML, (, CITSEG, ), ,, MUMBLE, (, CITSEG, ), ,, and, RealPro, (, CITSEG, ), ,, which, produce, natural, language, text, from, an, abstract, semantic, representation, ., These, packages, require, linguistic, sophistication, in, order, to, write, the, abstract, semantic, representation, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>[This, distinction, is, characterized, by, means, of, the, atomicity, feature, ., In, (, 26, ), (, i, ), ,, the, event, is, associated, with, the, features, [, +d, ,, +t, ,, -, a, ], ,, whereas, ,, in, (, 26, ), (, ii, ), the, event, is, associated, with, the, features, [, +d, ,, +t, ,, +a, ], ., According, to, [, CITSEG, ], (, in, the, spirit, of, [, CITSEG, ], ), ,, predicates, are, allowed,...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>[It, does, not, make, sense, to, fix, absolute, v~dues, li)r, the, retrievld, ,, inference, lind, communication, cost, plu~uncters, in, relation, to, human, processing, ., However, ,, Design, -, World, supports, exploring, issues, about, the, relative, costs, of, vlu'ions, processes, ., These, relative, costs, might, v,, 'u, 'y, depending, ,, on, the, language, that, the, agents, are, communic...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2</td>\n",
              "      <td>[The, linguistic, studies, ,, used, for, the, typologies, of, CoL, verbs, and, spatial, prepositions, ,, have, been, realized, on, verbs, considered, without, any, adjuncts, ,, in, their, atemporal, form, and, independently, of, any, context, ,, on, the, one, hand, ,, and, on, prepositions, considered, independently, of, any, context, ,, on, the, other, ., This, methodology, ,, discussed, in, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, probability, model, in, NLG2, is, a, conditional, distribution, over, V, U, *, stop, ,, ,, where, V, is, the, generation, vocabulary, and, where, ., stop., is, a, special, \", stop, \", symbol, ., The, generation, vocabulary, V, consists, of, all, the, words, seen, in, the, training, data, ., The, form, of, the, maximum, entropy, probability, model, is, identical, to, the, one, used, in, (...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>4</td>\n",
              "      <td>[Several, efficient, ,, accurate, and, robust, approaches, to, data-driven, dependency, parsing, have, been, proposed, recently, (, CITSEG, ), for, syntactic, analysis, of, natural, language, using, bilexical, dependency, relations, (, CITSEG, ), ., Much, of, the, appeal, of, these, approaches, is, tied, to, the, use, of, a, simple, formalism, ,, which, allows, for, the, use, of, efficient, pa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1</td>\n",
              "      <td>[It, is, interesting, to, compare, this, analysis, with, that, described, in, CITSEG, ., Recall, that, in, their, treatment, ,, quantified, noun, phrases, are, treated, in, two, stages, :, firstly, ,, what, they, call, a, \", free, variable, \", of, type, e, is, introduced, in, the, NP, position, ,, with, an, associated, \", quantifier, assumption, ,, \", which, is, added, as, a, kind, of, premise...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>5</td>\n",
              "      <td>[Our, experiments, will, result, in, different, classifications, of, the, data, and, we, need, to, find, out, how, to, combine, these, ., For, this, purpose, we, have, evaluated, different, voting, mechanisms, ,, effectively, the, voting, methods, as, described, in, (, CITSEG, ), ., All, combination, methods, assign, some, weight, to, the, results, of, the, individual, classifier, ., For, each...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1</td>\n",
              "      <td>[Neither, model, explicitly, addresses, composite, (, feature, of, feature, ), or, implicit, features, ., Other, systems, (, CITSEG, ), also, look, at, Web, product, reviews, but, they, do, not, extract, opinions, about, particular, product, features, ., OPINE, 's, use, of, meronymy, lexico-syntactic, patterns, is, similar, to, that, of, many, others, ,, from, (, CITSEG, ), to, (, CITSEG, ), ....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>[He, also, uses, a, class, -, based, selection, measure, ,, but, based, on, WordNet, classes, ., However, ,, the, task, of, his, evaluation, was, to, select, WordNet-senses, for, the, objects, rather, than, the, objects, themselves, ,, so, the, results, cannot, becompared, directly, ., The, same, is, true, for, the, Senseval, evaluation, exercise, CITSEGthere, word, senses, from, the, Hector-d...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2</td>\n",
              "      <td>[The, Maxim, of, Manner, seems, to, us, to, be, more, relevant, for, critiquing, the, style, of, a, written, passage, or, for, natural, language, generation, ;, in, the, case, of, text, generation, ,, it, can, be, construed, as, a, requirement, that, the, produced, text, be, coherent, and, cohesive, ., We, do, not, claim, that, Gla, is, the, best, or, unique, way, of, expressing, the, rule, \",...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, stochastic, model, generating, dependency, trees, is, very, similar, to, other, statistical, dependency, models, ,, e.g., ,, to, that, of, Alshawi, ,, 1996, ., Formulating, it, using, Gorn, 's, notation, and, the, L, and, F, variables, ,, though, ,, is, concise, ,, elegant, and, novel, ., Nothing, prevents, conditioning, the, random, variables, on, arbitrary, portions, of, the, partial, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, used, ID3, (, CITSEG, ), ,, C4.5, (, CITSEG, ), and, C5.0, ,, RIPPER, (, CITSEG, ), ,, and, the, Naive, Bayes, inducer, (, CITSEG, ), contained, in, the, MLCq, -, q-library, ., ID3, ,, C4.5, and, C5.0, produce, decision, trees, ,, RIPPER, isa, rulebased, learner, and, the, Naive, Bayes, algorithm, computes, conditional, probabilities, of, the, classes, from, the, instances, ., Support, Ve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0</td>\n",
              "      <td>[Some, examples, of, language, reuse, include, collocation, analysis, (, CITSEG, ), ,, the, use, of, entire, factual, sentences, extracted, from, corpora, (, e.g., ,, \", ', Toy, Story, ', is, the, Academy, Award, winning, animated, film, developed, by, Pixar, ~, ', ), ,, and, summarization, using, sentence, extraction, (, CITSEG, ), ., In, the, case, of, summarization, through, sentence, extra...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>5</td>\n",
              "      <td>[This, is, supported, by, the, fact, that, many, of, the, cognate, answers, resemble, orthographic, principles, from, other, languages, ,, e.g., for, skeletons, we, find, *, skellets, ,, *, skelleton, (, s, ), ,, *, skelets, ,, *, skelletts, ,, *, skeletton, (, s, ), ,, *, skeltons, ,, *, skeletes, ,, and, *, skelette, (s, ), ., 11, In, order, to, account, for, this, phenomenon, ,, we, estimat...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, Framework, for, Estimating, the, Referent, Prior, to, the, pronoun, resolution, process, ,, sentences, are, transformed, into, a, case, structure, by, a, case, structure, analyzer, (, CITSEG, ), ., The, antecedents, of, pronouns, are, determined, by, heuristic, rules, from, left, to, right, ., Using, these, rules, ,, our, system, assigns, points, to, possible, antecedents, ,, and, judges...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>5</td>\n",
              "      <td>[In, such, scenarios, ,, average, micro-F, scores, tend, to, be, slightly, higher, as, they, are, a, weighted, measure, ., To, avoid, this, bias, ,, we, also, report, the, macro-F, scores, ., Furthermore, ,, to, ensure, there, is, enough, data, for, training, each, class, ,, we, use, 10, -, fold, cross-validation, (, CITSEG, ), in, all, our, experiments, ., We, represent, each, citation, as, a...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>1</td>\n",
              "      <td>[By, combining, Pierrehumbert, and, Hirschberg, 's, (, 1990, ), analysis, of, intonational, meaning, with, CITSEG, 's, theory, of, centering, in, discourse, ,, the, attentional, affect, of, pitch, accents, becomes, evident, ,, and, the, paradox, of, pitch, accented, pronominals, unravels, ., My, goal, here, is, to, develop, an, analysis, and, a, line, of, inquiry, and, to, suggest, that, my, d...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2</td>\n",
              "      <td>[Other, lexicalized, grammars, collapse, syntactic, and, ordering, information, and, are, forced, to, represent, ordering, alternatives, by, lexical, ambiguity, ,, most, notable, L-TAG, (, CITSEG, ), and, some, versions, of, CG, (, CITSEG, ), ., This, is, not, necessary, in, our, approach, ,, which, drastically, reduces, the, search, space, for, parsing, ., This, property, is, shared, by, the,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0</td>\n",
              "      <td>[lO, |, ,, :o, /, It, is, then, possible, to, specify, operations, which, act, as, purely, applicative, operations, with, respect, to, the, left, and, right, arguments, lists, ,, but, more, like, composition, with, respect, to, the, wh-list, ., This, is, very, similar, to, the, way, in, which, wh-movement, is, dealt, with, in, GPSG, (, CITSEG, ), and, HPSG, ,, where, wh-arguments, are, treated...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, put, a, dummy, letter, \", $, \", ,, which, has, a, positive, similarity, only, t.o, itself, ,, at, the, end, of, both, English, and, katakana, words, ., One, may, notice, that, matching, plausible, symbols, can, be, seen, as, finding, the, path, which, maximizes, the, total, similarity, from, the, first, to, last, letters, ., The, best, path, can, easily, be, found, by, ,, for, example, ,,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>5</td>\n",
              "      <td>[There, does, not, appear, to, be, an, English, source, of, this, kind, ,, so, it, is, planned, to, compile, one, ., For, comparison, ,, a, variety, of, other, data, has, been, collected, ., Preliminary, tests, used, generated, errors, ,, from, a, program, that, produces, random, Damerau, slips, according, to, an, observed, distribution, (, CITSEG, ), ,, using, confusion, matrices, where, appr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>5</td>\n",
              "      <td>[As, part, of, MUC, (, CITSEG, ), ,, coreference, resolution, was, evaluated, as, a, sub-task, of, information, extraction, ,, which, involved, negotiating, a, definition, of, coreference, relations, that, could, be, reliably, evaluated, ., The, final, definition, included, only, ', identity, ', relations, between, text, strings, :, proper, nouns, ,, common, nouns, and, pronouns, ., Other, pos...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0</td>\n",
              "      <td>[Combinatory, Categorial, Grammar, (, CCG, ,, CITSEG, ), is, a, compositional, ,, semantically, transparent, formalism, that, is, both, linguistically, expressive, and, computationally, tractable, ., It, has, been, used, for, a, variety, of, tasks, ,, such, as, wide, -, coverage, parsing, (, CITSEG, ), ,, sentence, realization, (, CITSEG, ), ,, learning, semantic, parsers, (, CITSEG, ), ,, dia...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>2</td>\n",
              "      <td>[The, DSynt, Ss, and, SSynt, Ss, correspond, closely, to, the, equivalent, structures, of, the, Meaning, -, Text, Theory, (, MTT, ;, CITSEG, ), :, both, structures, are, unordered, syntactic, representations, ,, but, a, DSyntS, only, includes, full, meaning, -, bearing, lexemes, while, a, SSyntS, also, contains, function, words, such, as, determiners, ,, auxiliaries, ,, and, strongly, governed...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>5</td>\n",
              "      <td>[Learn, from, Question, -, Answer, Pairs, ., We, first, compare, our, system, (, henceforth, ,, LJK11, ), with, CITSEG, (, henceforth, ,, CGCR10, ), ,, which, is, most, similar, to, our, work, in, that, it, also, learns, from, question, -, answer, pairs, without, using, annotated, logical, forms, ., CGCR10, works, with, the, FunQL, language, and, casts, semantic, parsing, as, integer, linear, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>4</td>\n",
              "      <td>[These, links, refine, cooccurrence, based, contexts, by, utilizing, syntactic, indications, of, how, words, are, related, ., Dependency, parsed, features, have, proven, highly, effective, for, word, representations, in, many, NLP, applications, ,, e.g., ,, (, CITSEG, ), ., We, follow, CITSEG, using, the, sentence, as, contexts, and, all, words, with, a, dependency, path, of, length, 3, or, le...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0</td>\n",
              "      <td>[A, prime, example, of, the, latter, is, WordNet, which, has, been, used, to, 1, The, author, is, currently, at, Texas, Instruments, and, all, inquiries, should, be, addressed, to, rajeev@csc.ti.com, ., provide, such, semantic, classes, (, CITSEG, ), to, assist, in, text, understanding, ., Our, efforts, to, obtain, such, semantic, clusters, with, limited, human, intervention, have, been, descr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, use, the, dataset, from, Athar, (, 2011, ), as, our, starting, point, ,, which, consists, of, 8,736, citations, in, the, ACL, Anthology, (, CITSEG, ), that, cite, a, target, set, of, 310, ACL, Anthology, papers, ., The, citation, summary, data, from, the, ACL, Anthology, Network, 1, (, CITSEG, ), is, used, ., This, dataset, is, rather, large, ,, and, since, manual, annotation, of, context...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, simplest, part-of, -, speech, taggers, are, bigram, or, trigram, models, (, CITSEG, ), ., They, require, a, relatively, large, tagged, training, text, ., Transformation, -, based, tagging, as, introduced, by, CITSEG, also, requires, a, handtagged, text, for, training, ., No, pretagged, text, is, nec-essary, for, Hidden, Markov, Models, (, CITSEG, ), .]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>1</td>\n",
              "      <td>[It, could, be, used, for, instance, ,, in, combination, with, the, parser, and, the, semantic, construction, module, described, in, (, CITSEG, ), ,, to, support, textual, entailment, recognition, or, answer, detection, in, question, answering, ., Reversible, realisers, ., The, realiser, presented, here, differs, in, mainly, two, ways, from, existing, reversible, realisers, such, as, (, CITSEG...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>1</td>\n",
              "      <td>[While, CITSEG, use, a, partial, parser, to, acquire, training, data, ,, such, machinery, appears, unnecessary, for, noun, compounds, ., CITSEG, has, proposed, the, use, of, simple, word, patterns, for, the, acquisition, of, verb, subcategorisation, information, ., An, analogous, approach, to, compounds, is, used, in, CITSEG, and, constitutes, one, scheme, evaluated, below, ., While, such, pat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0</td>\n",
              "      <td>[Although, there, are, a, number, of, e, orts, to, construct, reusable, testsuites, ,, none, has, to, my, knowledge, explored, how, existing, grammars, can, be, exploited, ., CITSEG, ,, testsuites, have, been, drawn, up, from, a, linguistic, viewpoint, ,, informed, by, the, study, of, linguistics, and, re, ecting, the, grammatical, issues, that, linguists, have, concerned, themselves, with, CI...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0</td>\n",
              "      <td>[This, approach, is, quite, right, when, the, tagger, error, rate, is, larger, enough, than, the, test, corpus, error, rate, ,, nevertheless, ,, the, current, POS, taggers, have, reached, a, performance, level, that, invalidates, this, choice, ,, since, the, tagger, error, rate, is, getting, too, close, to, the, error, rate, of, the, test, corpus, ., Since, we, want, to, study, the, relationsh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>0</td>\n",
              "      <td>[Various, definitions, for, the, context, have, been, used, :, distance, -, based, context, (, e.g., in, a, sentence, (, CITSEG, ), ,, in, a, paragraph, (, CITSEG, ), ,, in, a, predefined, window, (, CITSEG, ), ), ,, and, syntactic, -, based, context, (, e.g., predecessors, and, successors, in, dependency, trees, (, CITSEG, ), ,, certain, dependency, position, (, CITSEG, ), ), ., Some, treated...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>4</td>\n",
              "      <td>[The, resulting, 1, http://www.statmt.org/wmt10/, phrase, tables, range, from, 76, to, 48, million, entries, ,, with, an, average, of, 3.9, words, per, phrase, ., Paraphrase, tables, (, PPHT, ), contain, pairs, of, corresponding, phrases, in, the, same, language, ,, possibly, associated, with, probabilities, ., They, proved, to, be, useful, in, a, number, of, NLP, applications, such, as, natur...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>5</td>\n",
              "      <td>[Selection, of, learning, algorithm, and, its, algorithmspecific, parameters, were, done, as, follows, ., For, each, of, the, 7, classification, tasks, (, one, per, relationship, type, ), ,, for, each, of, the, 128, pattern, clustering, schemes, ,, we, prepared, a, list, of, most, of, the, compatible, algorithms, available, in, Weka, ,, and, we, automatically, selected, the, model, (, a, param...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>4</td>\n",
              "      <td>[ASO, is, a, recently, proposed, linear, multi-task, learning, algorithm, based, on, empirical, risk, minimization, ., The, method, requires, the, use, of, multiple, auxiliary, problems, ,, and, its, effectiveness, may, vary, depending, on, the, specific, auxiliary, problems, used, ., ASO, has, been, shown, to, be, effective, on, the, following, natural, language, processing, tasks, :, text, c...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, subordinate, clause, triggers, the, introduction, of, an, event, marker, ,, e, ,, with, its, event, time, marker, t., The, main, clause, triggers, the, introduction, of, an, event, marker, e, ~, ,, and, its, location, time, marker, t, ~, ,, with, the, DRS, -, condition, e', C, t, ~., The, assymetry, in, using, the, event, time, for, e, and, the, location, time, for, e, ~, arises, from, t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>4</td>\n",
              "      <td>[In, contrast, with, previous, results, ,, we, show, agreement, features, are, quite, helpful, in, both, gold, and, predicted, conditions, ., This, is, likely, a, result, of, MSA, having, a, rich, agreement, system, ,, covering, both, verb-, subject, and, noun, -, adjective, relations, ., The, result, holds, for, both, the, MaltParser, (, CITSEG, ), and, the, Easy, -, First, Parser, (, CITSEG,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>4</td>\n",
              "      <td>[Projective, Bilexical, Dependency, Grammars, (, PB, -, DGs, ), have, attracted, attention, recently, for, two, reasons, ., First, ,, because, they, capture, bilexical, head, -, tohead, dependencies, they, are, capable, of, producing, extremely, high, -, quality, parses, :, state, -, of, -, the, -, art, discriminatively, trained, PBDG, parsers, rival, the, accuracy, of, the, very, best, statis...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>1</td>\n",
              "      <td>[Sentence, 5, :, These, sequences, were, used, to, search, for, the, nearly, invariant, nucleotides, of, the, inverse, core, AAC, and, core, GTT, sites, separated, by, a, distance, typical, of, previously, identified, attC, sites, to, bp, ., In, some, cases, ,, the, context, in, which, the, method, terminologies, are, used, in, the, text, can, contain, valuable, information, about, the, method...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>1</td>\n",
              "      <td>[We, can, guarantee, this, by, requiring, the, lowered, node, to, dominate, the, last, word, to, be, attached, ., We, also, need, to, ensure, that, ,, to, avoid, crossing, branches, ,, the, lowered, node, does, not, dominate, any, unsaturated, attachment, sites, (, or, \", dangling, nodes, \", ), We, therefore, define, accessibility, for, tree, -, lowering, as, follows, :, It, will, be, noticed,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>1</td>\n",
              "      <td>[This, property, is, not, strictly, true, of, linguistic, data, ,, but, is, a, good, approximation, :, as, Lee, et, al., (, 2010, ), note, ,, assigning, each, word, type, to, its, most, frequent, part, of, speech, yields, an, upper, bound, accuracy, of, 93, %, or, more, for, most, languages, ., Since, this, is, much, better, than, the, performance, of, current, unsupervised, syntactic, class, ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, aims, of, this, paper, are, to, compare, implementations, of, pronoun, resolution, algorithms, automatically, on, a, common, corpus, and, to, see, if, results, from, psycholinguistic, experiments, can, be, used, to, improve, pronoun, resolution, ., Many, hand, -, tested, corpus, evaluations, have, been, done, in, the, past, (, e.g., ,, CITSEG, ), ,, but, these, have, the, drawback, of, b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>5</td>\n",
              "      <td>[Once, we, had, assembled, the, final, training, corpus, ,, we, annotated, it, with, statistical, word, alignments, and, constituent, parse, trees, on, both, sides, ., Unidirectional, word, alignments, were, provided, by, MGIZA, ++, (, CITSEG, ), ,, then, symmetrized, with, the, grow-, diag, -, final, -, and, heuristic, (, CITSEG, ), ., For, generating, parse, trees, ,, we, used, the, French, ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>5</td>\n",
              "      <td>[In, the, categorization, phase, ,, a, new, document, vector, leads, to, the, activation, of, a, single, category, ., For, details, we, refer, to, (, CITSEG, ), ., In, our, application, ,, we, tried, out, the, Learning, Vector, Quantization, (, LVQ, ), (, CITSEG, ), ., LVQ, has, been, used, in, its, default, configuration, only, ., No, adaptation, to, the, application, domain, has, been, made, .]</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>2</td>\n",
              "      <td>[PMG, reads, the, SL, phrasing, as, defined, by, PAM, and, generates, an, SL, phrasing, model, using, a, probabilistic, methodology, ., This, phrasing, model, is, then, applied, in, segmenting, any, arbitrary, SL, text, being, input, to, the, PRESEMT, system, for, translation, ., PMG, is, based, on, the, Conditional, Random, Fields, model, (, CITSEG, ), which, has, been, found, to, provide, th...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>5</td>\n",
              "      <td>[Our, experiments, are, on, Chinese, -, to, -, English, translation, ,, and, we, use, the, Chinese, parser, of, CITSEG, to, parse, the, source, side, of, the, bitext, ., Following, CITSEG, ,, we, modify, the, parser, to, output, a, packed, forest, for, each, sentence, ., Our, training, corpus, consists, of, 31,011, sentence, pairs, with, 0.8, M, Chinese, words, and, 0.9M, English, words, ., We...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>0</td>\n",
              "      <td>[3, ., S, indicates, to, everyone, in, P, that, @., The, situation, ~q, ,, used, above, in, the, mutual, belief, induction, schema, ,, is, the, context, of, what, has, been, said, ., This, schema, supports, a, weak, model, of, mutual, beliefs, ,, that, is, more, akin, to, mutual, assumptions, or, mutual, suppositions, [, CITSEG, ], ., Mutual, beliefs, can, be, inferred, based, on, some, eviden...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>4</td>\n",
              "      <td>[For, example, ,, modeling, CASE, in, Czech, improves, Czech, parsing, (, CITSEG, ), :, CASE, is, relevant, ,, not, redundant, ,, and, can, be, predicted, with, sufficient, accuracy, ., It, has, been, more, difficult, showing, that, agreement, morphology, helps, parsing, ,, however, ,, with, negative, results, for, dependency, parsing, in, several, languages, (, CITSEG, ), ., In, this, article...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>5</td>\n",
              "      <td>[For, each, internal, node, in, the, MCST, ,, an, SVM, is, trained, to, separate, all, the, samples, belonging, to, classes, in, its, left, subtree, from, those, in, its, right, subtree, ., We, use, linear, SVMs, ,, which, have, been, shown, to, be, effective, text, classifiers, (, CITSEG, ), ,, and, set, the, SVM, parameters, to, match, those, used, in, (, CITSEG, ), ., 1, Figure, 1, contrast...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>2</td>\n",
              "      <td>[The, current, account, makes, the, correct, predictions, ;, examples, (, 20, ), and, (, 21, ), ,, where, but, has, the, contrast, meaning, ,, appear, to, be, markedly, less, acceptable, than, examples, (, 22, ), and, 23, To, summarize, thus, far, ,, the, data, presented, in, the, earlier, account, as, well, as, examples, that, conflict, with, that, analysis, are, all, predicted, by, the, acco...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>4</td>\n",
              "      <td>[A, left-, corner, parsing, algorithm, with, top-down, filtering, has, been, reported, to, show, very, efficient, performance, for, unification, -, based, systems, (, CITSEG, ), ., In, particular, ,, top-down, filtering, seems, to, be, very, effective, in, increasing, parse, efficiency, (, CITSEG, ), ., Ideally, all, top, -, down, expectation, should, be, propagated, down, to, the, input, word...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>0</td>\n",
              "      <td>[We, shall, take, a•, a, l~sk, a, formalism, developed, by, the, second, author, in, previous, papers, [, CITSEG, ], ., The, idea, of, this, approach, is, to, separate, the, dynamic, programming, construct•, needed, for, efficient, chart, parsing, from, the, chosen, parsing, schema, ., Comparison, between, the, classifications, of, Kay, [, CITSEG, ], and, Gritfith, &amp;, Petrick, [, CITSEG, ], sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>0</td>\n",
              "      <td>[Standard, symbolic, machine, learning, techniques, have, been, successfully, applied, to, a, number, of, tasks, in, natural, language, processing, (, NLP, ), ., Examples, include, the, use, of, decision, trees, for, syntactic, analysis, (, CITSEG, ), ,, coreference, (, CITSEG, ), ,, and, cue, phrase, identification, (, CITSEG, ), ;, the, use, of, inductive, logic, programming, for, learning, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>1</td>\n",
              "      <td>[They, do, so, for, several, other, corpora, as, well, ., The, architecture, remains, applicable, to, a, large, variety, of, languages, ., According, to, current, tagger, comparisons, (, CITSEG, ), ,, and, according, to, a, comparsion, of, the, results, presented, here, with, those, in, (, CITSEG, ), ,, the, Maximum, Entropy, framework, seems, to, be, the, only, other, approach, yielding, comp...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>0</td>\n",
              "      <td>[These, 30, questions, are, determined, by, growing, a, classification, tree, on, the, word, vocabulary, as, described, in, (, CITSEG, ), ., The, 30, questions, represent, 30, different, binary, partitions, of, the, word, vocabulary, ,, and, these, questions, are, defined, such, that, it, is, possible, to, identify, each, word, by, asking, all, 30, questions, ., For, more, discussion, of, the,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>0</td>\n",
              "      <td>[First, ,, it, depends, on, the, amount, of, supervision, provided, ., CITSEG, ,, for, instance, ,, has, shown, that, a, grammar, can, be, easily, constructed, when, the, examples, are, fully, labeled, parse, trees, ., On, the, other, hand, ,, if, the, examples, consist, of, raw, sentences, with, no, extra, struc-tural, information, ,, grammar, induction, is, very, difficult, ,, even, theoreti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, most, closely, related, research, is, that, of, CITSEG, ,, who, merged, the, Brown, portion, of, the, Penn, Treebank, with, SemCor, (, similarly, to, our, approach, in, Section, 4.1, ), ,, and, used, this, as, the, basis, for, evaluation, of, a, generative, bilexical, model, for, joint, WSD, and, parsing, ., He, evaluated, his, proposed, model, in, a, parsing, context, both, with, and, w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>4</td>\n",
              "      <td>[As, opposed, to, closed, formats, ,, the, candidate, space, is, only, limited, by, the, provided, prefix, and, the, length, constraint, ., It, is, thus, harder, to, determine, the, difficulty, of, a, C-, test, because, it, is, influenced, by, a, combination, of, many, text, -, and, word, -, specific, factors, ., The, search, for, the, factors, that, determine, the, difficulty, of, C-tests, is...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>1</td>\n",
              "      <td>[Such, unbalanced, classes, create, problems, for, the, majority, of, inductive, learning, systems, ., A, distinctive, feature, of, our, work, is, the, fact, that, we, used, machine, learning, techniques, to, improve, an, existing, rule, -, based, natural, language, processor, from, the, inside, ., This, contrasts, with, approaches, where, there, are, essentially, no, explicit, rules, ,, such,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>0</td>\n",
              "      <td>[While, CITSEG, use, a, partial, parser, to, acquire, training, data, ,, such, machinery, appears, unnecessary, for, noun, compounds, ., CITSEG, has, proposed, the, use, of, simple, word, patterns, for, the, acquisition, of, verb, subcategorisation, information, ., An, analogous, approach, to, compounds, is, used, in, CITSEG, and, constitutes, one, scheme, evaluated, below, ., While, such, pat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>2</td>\n",
              "      <td>[Standard, numerical, methods, for, statistical, inference, of, log-linear, models, from, fully, annotated, data, so, -, called, complete, data, are, the, iterative, scaling, methods, of, CITSEG, and, Della, CITSEG, ., For, data, consisting, of, unannotated, sentences, so-called, incomplete, data, the, iterative, method, of, the, EM, algorithm, (, CITSEG, ), has, to, be, employed, ., However, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>5</td>\n",
              "      <td>[For, instance, ,, we, could, simply, generate, annotation, words, by, processing, the, document, alone, ., Our, results, are, summarized, in, Table, 1, ., We, compare, the, annotation, performance, of, the, model, proposed, in, this, paper, (, ExtModel, ), with, CITSEG, 's, original, continuous, relevance, model, (, Lavrenko03, ), and, two, other, simpler, models, which, do, not, take, the, i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>0</td>\n",
              "      <td>[In, (, CITSEG, ), a, system, for, the, automated, learning, of, morphological, word, -, formation, rules, is, described, ., This, system, divides, a, string, into, three, regions, and, from, training, examples, infers, their, correspondence, to, underlying, morphological, features, ., Brill, (, CITSEG, ), outlines, a, transformation, -, based, learner, which, learns, guessing, rules, from, a,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>2</td>\n",
              "      <td>[For, full, papers, ,, the, most, notable, work, has, focussed, on, argumentative, zoning, (, AZ, ), (, CITSEG, ), ., An, important, aspect, of, AZ, involves, capturing, the, attribution, of, knowledge, claims, and, citation, function, ,, and, the, scheme, has, been, tested, on, information, extraction, and, summarisation, tasks, with, Computational, Linguistics, papers, ., AZ, was, modified, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>0</td>\n",
              "      <td>[Our, previous, work, (, CITSEG, ), relied, on, the, intuition, that, in, a, coherent, text, ,, any, two, events, that, are, about, the, same, participants, are, likely, to, be, part, of, the, same, story, or, narrative, ., The, model, learned, simple, aspects, of, narrative, structure, (, ', narrative, chains, ', ), by, extracting, events, that, share, a, single, participant, ,, the, protagon...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, performed, an, analysis, of, our, classification, features, using, CITSEG, method, ., The, analysis, revealed, that, both, structural, and, syntactic, features, are, important, ., Among, the, syntactic, features, ,, the, dependency, path, is, the, most, important, ., Among, the, structural, features, ,, the, segment, feature, (, as, described, in, Table, 1, ), is, the, most, important, .]</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>2</td>\n",
              "      <td>[The, parser, supports, ambiguity, packing, ,, which, is, a, technique, for, merging, constituents, with, different, derivational, histories, but, identical, syntactic, properties, ., This, is, essential, for, parsing, long, and, ambiguous, sentences, ., Our, grammar, incorporates, many, ideas, from, existing, linguistic, work, ,, e.g., CITSEG, ., In, addition, ,, we, have, modeled, a, few, co...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>2</td>\n",
              "      <td>[Examples, of, formal, instantiations, of, this, idea, include, CCG, and, LTAG, ., The, lexical, entries, are, syntactic, constructs, (, graphs, ), that, specify, information, such, as, POS, tag, ,, subcategorization, /, dependency, information, and, other, syntactic, constraints, at, the, level, of, agreement, features, ., One, important, way, of, portraying, such, lexical, descriptions, is, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>5</td>\n",
              "      <td>[This, match, is, usually, computed, as, the, percentage, of, code, items, exercised, by, the, test, suite, ., Depending, on, the, de, nition, of, a, code, item, ,, various, measures, are, employed, ,, for, example, cf, ., CITSEG, and, CITSEG, ,, Appendix, The, measures, are, automatically, obtained, by, instrumentation, :, The, test, subject, is, extended, by, c, o, d, e, which, records, the,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>0</td>\n",
              "      <td>[Collins, et, al., (, CITSEG, ), proposed, an, efficient, method, to, calculate, Tree, Kernel, by, using, C, (n, 1, ,, n, 2, ), as, follows, ., •, If, the, productions, at, n, 1, and, n, 2, are, different, C, (, n, 1, ,, n, 2, ), =, 0, •, If, the, productions, at, n, 1, and, n, 2, are, the, same, ,, and, n, 1, and, n, 2, are, pre-terminals, ,, then, C, (, n, 1, ,, n, 2, ), =, 1, •, Else, if, t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>5</td>\n",
              "      <td>[100, sentences, were, selected, from, the, DUC, 2001, corpus, with, the, topics, \", illegal, alien, \", ,, \", term, limits, \", ,, \", gun, control, \", ,, and, \", NAFTA, \", ., Two, humans, annotated, the, 100, sentences, with, three, categories, (, positive, ,, negative, ,, and, N/A, ), ., To, measure, the, agreement, between, humans, ,, we, used, the, Kappa, statistic, (, CITSEG, ), ., The, Kap...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>0</td>\n",
              "      <td>[Previous, work, by, Manny, Rayner, and, the, author, ,, see, [, Samuelsson, &amp;~, CITSEG, ], attempts, to, tailor, an, existing, natural, -, language, system, to, a, specific, application, domain, by, extracting, a, specialized, grammar, from, the, original, one, using, a, large, set, of, training, examples, ., The, training, set, is, a, treebank, consisting, of, implicit, parse, trees, that, e...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>1</td>\n",
              "      <td>[We, further, optimized, string, recognition, and, plurality, detection, for, handling, citation, -strings, ., See, Table, 3, for, the, full, list, of, our, features, ., While, both, (, CITSEG, ), and, (, CITSEG, ), induced, decision, trees, (, C5, and, C4.5, ,, respectively, ), we, opted, for, using, an, SVM, -, based, approach, instead, (, CITSEG, ), ., SVMs, are, known, for, being, reliable...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, focus, of, this, discussion, is, on, the, linking, relation, used, to, extend, left, -, corner, parsers, ,, rather, than, on, the, prediction, step, of, the, Earley, algorithm, as, with, Shieber, ,, although, the, results, carry, over, ., Whereas, CITSEG, have, discussed, similar, techniques, in, the, context, of, semantichead, -, driven, generation, ,, we, are, concerned, here, with, pa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>1</td>\n",
              "      <td>[This, makes, the, task, of, expressing, the, output, of, some, application, system, in, a, context, -, dependent, way, quite, difficult, :, rather, than, being, related, to, an, RQLF, ,, this, output, has, to, be, related, to, a, QLF, that, is, sufficiently, instantiated, for, a, contextually, unambiguous, sentence, to, be, generated, from, it, ., The, resolution, mechanism, is, not, intended...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, former, stem, from, the, work, of, Halliday, and, Hasan, (, CITSEG, ), ., They, proposed, that, text, segments, with, similar, vocabulary, are, likely, to, be, part, of, a, coherent, topic, segment, ., hnplementations, of, this, idea, use, word, stem, repetition, (, CITSEG, ), ,, context, vectors, (, CITSEG, ), ,, entity, repetition, (, CITSEG, ), ,, semantic, similarity, (, CITSEG, ), ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>1</td>\n",
              "      <td>[These, should, be, distinguished, from, possibly, correct, parses, that, are, not, in, the, training, data, ., In, order, that, \", improbabilities, \", can, be, modelled, by, inhibitory, connections, (, CITSEG, ), show, how, a, Hidden, Markov, Model, can, be, implemented, by, a, neural, network, ., The, theoretical, ground, for, incorporating, negative, examples, in, a, language, learning, pro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, improved, system, combination, method, was, compared, to, a, simple, confusion, network, decoding, without, system, weights, and, the, method, proposed, in, (, CITSEG, ), on, the, Arabic, to, English, and, Chinese, to, English, NIST, MT05, tasks, ., Six, MT, systems, were, combined, :, three, (, A,C,E, ), were, phrasebased, similar, to, (, CITSEG, ), ,, two, (, B,D, ), were, hierarchical...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, interest, in, the, 80's, begun, to, turn, considering, grammar, checking, as, an, enterprise, of, its, own, right, (, CITSEG, ), ,, (, CITSEG, ), ,, (, CITSEG, ), ,, (, ., lensen, at, al., ,, 1983, ), ,, though, many, of, the, approaches, were, still, in, I, ;t1, (, :, NLU, tradition, (, (, ], harniak, ,, 198, a, ), ,, (, CITSEG, ), ,, (, CITSEG, ), ,, (, Weischedel, &amp;, Black, ,, ], 980,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>1</td>\n",
              "      <td>[Eq., (, 4, ), is, in, fact, the, n-gram, likelihood, of, the, token, pair, ,, i, i, t, s, 〈, 〉, sequence, and, Eq., (, 5, ), approximates, this, probability, using, a, bigram, language, model, ., This, model, is, conceptually, similar, to, the, joint, sourcechannel, model, (, CITSEG, ), where, the, target, token, i, t, depends, on, not, only, its, source, token, i, s, but, also, the, history,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>1</td>\n",
              "      <td>[Precision, Recall, F-Measure, Rule-based, 85.40, 91.89, Machine, Learning, 81.8, 75.00, 78.26, Table, 3, :, Precision, ,, Recall, ,, F-measure, of, the, Various, Methods, ., Our, work, can, be, compared, to, (, CITSEG, ), which, uses, CRF, for, automatic, keyword, extraction, from, documents, ;, they, reported, promising, results, (, F-score, of, 51.25, percent, ), on, a, Chinese, corpus, ., ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>0</td>\n",
              "      <td>[When, (, 2, ), is, applied, to, the, predicate, ,, (, 15, ), will, result, after, 13, -, reduction, ., However, ,, under, first, -, order, unification, ,, this, needs, to, simulated, by, having, the, variable, z, in, Az.run, (, z, ), unify, both, with, Bill, and, John, ,, and, this, is, not, possible, ., See, (, CITSEG, ), and, (, CITSEG, ), for, a, thorough, discussion, ., (, CITSEG, ), sugg...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>0</td>\n",
              "      <td>[For, finding, a, good, initial, parameter, set, ,, CITSEG, suggested, first, estimating, the, probabilities, with, a, set, of, regular, grammar, rules, ., Their, experiments, ,, however, ,, indicated, that, the, main, benefit, from, this, type, of, pretraining, is, one, of, run-time, efficiency, ;, the, improvement, in, the, quality, of, the, induced, grammar, was, minimal, ., CITSEG, argued,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>1</td>\n",
              "      <td>[Furthermore, ,, the, gradability, of, category, membership, is, clearly, influenced, by, context, :, in, a, corpus, describing, the, exploits, of, Vikings, ,, an, axe, will, most, likely, be, seen, as, a, kind, of, weapon, ,, but, in, a, corpus, dedicated, to, forestry, ,, it, will, likely, describe, a, tool, ., A, resource, like, WordNet, ,, in, which, is, -, a, links, are, reserved, for, ca...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, two, parsers, which, have, previously, reported, the, best, accuracies, on, the, Penn, Treebank, Wall, St., Journal, are, the, bigram, parser, described, in, (, CITSEG, ), and, the, SPATTER, parser, described, in, (, CITSEG, ), ., The, parser, presented, here, outperforms, both, the, bigram, parser, and, the, SPATTER, parser, ,, and, uses, different, modelling, technology, and, different...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, first, instantiation, of, this, para4igm, uses, predictors, to, decide, whether, each, word, belongs, to, the, in, -, terior, of, a, phrase, or, not, ,, and, then, groups, the, words, into, phrases, ., The, second, instantiation, finds, the, borders, of, phrases, (, beginning, and, end, ), and, then, pairs, !, them, in, an, \", optimal, \", way, into, different, phrases, ., These, problems...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>0</td>\n",
              "      <td>[(, In, some, cases, ,, an, additional, resource, ,, such, as, a, dictionary, or, a, thesaurus, ,, is, used, during, the, identication, process, ., ), The, work, reported, here, infers, specic, semantic, relationships, based, on, sets, of, examples, and, counterexamples, ., In, this, paper, ,, the, method, is, applied, to, a, French, corpus, on, computing, to, nd, noun-, verb, combinations, in...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>5</td>\n",
              "      <td>[Understanding, utterances, standing, in, a, Coherent, Situation, relation, requires, that, hearers, convince, themselves, that, the, utterances, describe, a, coherent, situation, given, their, knowledge, of, the, world, ., This, process, requires, that, a, path, of, inference, be, established, between, the, situations, (, i.e., ,, events, or, states, ), described, in, the, participating, utte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>5</td>\n",
              "      <td>[During, the, categorization, phase, ,, the, representation, is, used, to, assign, the, appropriate, class, to, a, new, document, vector, ., Several, pruning, or, specialization, heuristics, can, be, used, to, control, the, amount, of, generalization, ., We, used, ID3, (, CITSEG, ), ,, C4.5, (, CITSEG, ), and, C5.0, ,, RIPPER, (, CITSEG, ), ,, and, the, Naive, Bayes, inducer, (, CITSEG, ), con...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>0</td>\n",
              "      <td>[There, are, both, theoretical, and, practical, motivations, ., First, ,, we, wish, to, extend, formal, accounts, of, single, utterances, produced, by, single, speakers, to, explain, multi-participant, ,, multi-utterance, discourses, [, CITSEG, ], ., Previous, studies, of, the, discourse, structure, of, multiparticipant, dialogues, have, often, factored, out, the, role, of, MIXED, -, INITIATIV...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>5</td>\n",
              "      <td>[Frame-semantic, features, ., While, dependencybased, features, capture, the, syntactic, dependencies, ,, frame-, semantic, features, encode, the, semantic, representation, of, the, concepts, in, a, sentence, ., Following, our, previous, work, on, stance, classification, (, CITSEG, ), ,, we, employ, three, types, of, features, computed, based, on, the, frame, -, semantic, parse, of, each, sent...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>5</td>\n",
              "      <td>[In, the, remaining, experiments, ,, we, have, each, word, in, a, phrase, indexed, ., We, compare, the, results, for, the, 1911, and, 1987, Roget, 's, Thesauri, with, a, variety, of, WordNet, -, based, semantic, relatedness, measures, -, see, Table, 5, ., We, consider, 10, measures, ,, noted, in, the, table, as, J&amp;C, (, CITSEG, ), ,, Resnik, (, CITSEG, ), ,, Lin, (, CITSEG, ), ,, W&amp;P, (, CITSE...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>0</td>\n",
              "      <td>[Recording, some, dialogue, history, is, also, possible, ., Since, the, language, understanding, module, utilizes, unification, ,, a, wide, variety, of, linguistic, phenomena, can, be, covered, ., For, example, ,, speech, repairs, ,, particle, omission, ,, and, fillers, can, be, dealt, with, in, the, framework, of, unification, grammar, (, CITSEG, ), ., The, language, generation, module, featu...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, DRI, is, an, international, \", grassroots, \", effort, that, seeks, to, share, corpora, that, have, been, tagged, with, the, core, features, of, interest, to, the, discourse, community, ., In, order, to, use, the, core, scheme, ,, it, is, anticipated, that, each, group, will, need, to, refine, it, for, their, particular, purposes, ., A, usable, draft, core, scheme, is, now, available, for...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>0</td>\n",
              "      <td>[Recognition, of, punctuational, phenomena, does, not, imply, tha.t, they, can, be, successfully, encoded, into, a, NL, grammar, ,, or, whether, the, use, of, such, a, punctuated, grammar, will, result, in, arty, analytical, advantages, ., CITSEG, adw~cates, two, separate, grammars, ,, operatiug, at, different, levels, ., A, lexical, grammar, is, proposed, [, ', or, the, lexical, expressions, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>5</td>\n",
              "      <td>[Finding, the, oracle, alignment, amounts, to, solving, the, ILP, problems, introduced, above, ., Even, though, ILP, problems, are, NP-, hard, in, general, ,, there, exist, several, off, -, theshelf, ILP, solvers, able, to, efficiently, find, an, optimal, solution, or, decide, that, the, problem, is, infeasible, ., In, our, experiments, ,, we, used, the, free, solver, SCIP, (, CITSEG, ), ., An...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>5</td>\n",
              "      <td>[For, each, leaf, node, ,, it, looks, for, the, question, to, ask, of, the, context, such, that, splitting, the, node, into, two, leaf, nodes, results, in, the, biggest, decrease, in, impurity, ,, where, tile, impurity, measures, how, well, each, leaf, predicts, the, events, in, the, node, ., After, the, tree, is, grown, ,, a, heldout, dataset, is, used, to, smooth, the, probabilities, of, eac...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>1</td>\n",
              "      <td>[Recently, ,, a, number, of, data-driven, distortion, models, ,, based, on, lexical, features, and, relative, distance, ,, have, been, proposed, to, compensate, for, this, weakness, (, CITSEG, ), ., There, have, been, a, number, of, proposals, to, incorporate, syntactic, information, into, phrasal, decoding, ., Early, experiments, with, syntactically, -, informed, phrases, (, CITSEG, ), ,, and...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>4</td>\n",
              "      <td>[For, example, ,, in, information, retrieval, it, can, be, enough, to, find, only, simple, NPs, and, VPs, in, a, sentence, ,, for, information, extraction, we, might, also, want, to, find, relations, between, constituents, as, for, example, the, subject, and, object, of, a, verb, ., In, this, paper, we, discuss, some, Memory, -, Based, (, MB, ), shallow, parsing, techniques, to, find, labeled,...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>0</td>\n",
              "      <td>[However, ,, the, models, are, based, on, the, lexical, dependencies, of, elementary, trees, ,, which, is, a, simple, extension, of, the, LPCFG, ., That, is, ,, the, models, are, still, based, on, decomposition, into, primitive, lexical, dependencies, ., Derivation, trees, ,, the, structural, description, in, LTAG, (, CITSEG, ), ,, represent, the, association, of, lexical, items, i.e., ,, elem...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>1</td>\n",
              "      <td>[Sense, disambiguation, methods, require, a, decision, model, that, evaluates, the, relevant, statistics, ., Sense, disambiguation, thus, resembles, many, other, decision, tasks, ,, and, not, surprisingly, ,, several, common, decision, algorithms, were, employed, in, different, works, ., These, include, a, Bayesian, classifier, (, CITSEG, ), and, a, distance, metric, between, vectors, (, CITSE...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>3</td>\n",
              "      <td>[The, impact, of, the, existence, of, lazy, implementations, for, enrichment, operations, is, twofold, :, we, can, (, a, ), now, maintain, minimized, base, lexicons, for, storage, efficiency, and, add, enrichments, lazily, to, the, currently, pursued, string, hypothesis, only, ,, possibly, modulated, by, exception, diacritics, that, control, when, enrichment, should, or, should, not, happen, ....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>5</td>\n",
              "      <td>[1, ., A, tagger, ,, a, first, -, order, HMM, part, -of, -, speech, (, PoS, ), and, punctuation, tag, disambiguator, ,, is, used, to, assign, and, rank, tags, for, each, word, and, punctuation, token, in, sequences, of, sentences, (, CITSEG, ), ., 2, ., A, lemmatizer, is, used, to, replace, word, -, tag, pairs, with, lemma-tag, pairs, ,, where, a, lemma, is, the, morphological, base, or, dicti...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>4</td>\n",
              "      <td>[Standard, latent, semantic, analysis, (, LSA, ), and, its, probabilistic, variant, (, PLSA, ), have, been, applied, to, this, task, (, CITSEG, ), ., propose, a, hierarchical, latent, model, in, order, to, account, for, the, fact, that, some, words, are, more, general, than, others, ., More, sophisticated, graphical, models, have, also, been, employed, including, Gaussian, Mixture, Models, (, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>4</td>\n",
              "      <td>[Their, theoretical, I, finding, is, simply, stated, :, classification, error, rate, decreases, toward, the, noise, rate, exponentially, in, the, number, of, independent, ,, accurate, classifiers, ., The, theory, has, also, been, validated, empirically, ., Recently, ,, combination, techniques, have, been, investigated, for, part, of, speech, tagging, with, positive, results, (, CITSEG, ), ., I...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>2</td>\n",
              "      <td>[In, a, first, stage, ,, only, MEDLINE, abstracts, are, used, (, CITSEG, ), ,, later, other, -, anaphora, ,, a, very, specific, sub-task, ,, are, investigated, using, full, paper, content, (, CITSEG, ), ., CITSEG, presents, a, full, annotation, of, anaphora, and, coreference, in, biomedical, text, ,, but, only, noun, phrases, referring, to, biomedical, entities, are, considered, ., On, the, ba...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>4</td>\n",
              "      <td>[For, example, ,, the, name, recognition, module, can, make, use, of, the, considerable, research, that, exists, on, name, recognition, ,, e.g., (, CITSEG, ), ,, (, CITSEG, ), ., Secondly, ,, individual, components, can, be, replaced, when, improved, models, are, available, ,, without, affecting, other, parts, of, the, system, ., Thirdly, ,, this, approach, is, compatible, with, incorporating,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>4</td>\n",
              "      <td>[Activated, for, Treebank, Activated, for, TRAINS93, X, X, X, X, X, X, X, X, X, X, X, X, x, x, x, x, x, Table, 1, \", Pronoun, resolution, modules, used, in, our, experiments, can, run, in, isolation, or, with, the, addition, of, metamodules, that, combine, the, output, of, multiple, techniques, ., We, implemented, meta-modules, to, interface, to, the, genetic, algorithm, driver, and, to, combi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>1</td>\n",
              "      <td>[when, backup, compiler, appears, elsewhere, Since, this, is, proposed, merely, as, a, rough, heuristic, ,, it, is, not, stated, what, the, outcome, is, to, be, if, neither, or, both, subcomponents, appear, ., Nor, is, there, any, evaluation, of, the, algorithm, ., The, proposal, of, CITSEG, is, more, sophisticated, and, allows, for, the, frequency, of, the, words, in, the, compound, ., Their,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>1</td>\n",
              "      <td>[CITSEG, used, unambiguous, noun, compounds, from, the, parsed, Wall, Stree~, Journal, (, WSJ, ), corpus, to, estimate, the, association, ~alues, and, analysed, a, test, set, of, around, 160, compounds, ., After, some, tuning, ,, the, accuracy, was, about, 73, %, ,, as, compared, with, a, baseline, of, 64, %, achieved, by, always, bracketing, the, first, two, nouns, together, ., The, fourth, a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>5</td>\n",
              "      <td>[Even, though, their, genre, is, different, ,, we, plan, to, experiment, with, their, full, feature, set, for, improving, our, TLC, system, ., Turning, to, collective, classification, ,, there, have, been, various, collective, classification, frameworks, proposed, (, for, example, ,, CITSEG, ), ., In, this, paper, ,, we, use, an, approach, proposed, by, (, CITSEG, ), which, iteratively, predic...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>1</td>\n",
              "      <td>[One, could, consider, ,, for, instance, ,, to, extend, this, model, to, the, multi-document, setting, ,, where, one, would, need, to, explicitly, model, redundancy, across, documents, ., Alternatively, ,, one, could, include, user, models, to, account, for, novelty, or, user, preferences, along, the, lines, of, CITSEG, ., Our, model, is, similar, in, spirit, to, the, randomwalk, summarization...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, method, also, seem, to, work, well, for, [, CONFLICT, ], relations, ,, because, lexical, similarity, based, on, bag, -, of, -, words, (, BOW, ), can, narrow, the, range, of, candidates, with, this, relation, as, well, ., We, calculate, the, lexical, similarity, between, the, two, sentences, based, on, BOW, ., We, also, used, hyponym, and, synonym, dictionaries, (, CITSEG, ), and, a, data...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>0</td>\n",
              "      <td>[Note, that, the, one, -, line, summarization, system, (, CITSEG, ), ,, which, requires, a, given, topic, and, focuses, on, the, selection, of, key, phrases, most, related, to, the, topic, ,, works, on, a, setting, different, from, ours, ., In, general, ,, LexRank, is, a, graph, -, based, method, for, computing, relative, importance, of, textual, units, ., CITSEG, use, it, to, compute, the, se...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, evaluated, the, similarity, functions, introduced, in, the, previous, section, on, a, binary, decision, task, ,, using, the, same, experimental, framework, as, in, our, previous, preliminary, compari-, son, (, CITSEG, ), ., That, is, ,, the, data, consisted, of, the, verb-object, cooccurrence, pairs, in, the, 1988, Associated, Press, newswire, involving, the, 1000, most, frequent, nouns, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>0</td>\n",
              "      <td>[As, an, example, take, the, well, known, Ilead, Feature, Principle, of, IIPSG, (, Fig., 2, ), r., The, conditional, operator, ===, &gt;, is, translated, at, read, time, via, terra_expansion, /, 2, and, implements, the, delay, mechanism, by, coml, ), iling, l&gt;recon&lt;, lition, checks, into, the, principle, ., These, antecedent, checks, trigger, either, the, application, of, the, princiltle, ,, its,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>5</td>\n",
              "      <td>[Essentially, the, full, range, of, agreement, inside, the, noun, phrase, is, enforced, ., Agreement, between, the, nominative, NP, and, the, tensed, verb, (, e.g., in, number, ), is, not, enforced, by, the, grammar, ,, in, order, to, control, the, number, of, parameters, and, rules, ., For, noun, phrases, we, employ, Abney, 's, chunk, grammar, organization, (, CITSEG, ), ., The, noun, chunk, ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>1</td>\n",
              "      <td>[Such, unbalanced, classes, create, problems, for, the, majority, of, inductive, learning, systems, ., A, distinctive, feature, of, our, work, is, the, fact, that, we, used, machine, learning, techniques, to, improve, an, existing, rule, -, based, natural, language, processor, from, the, inside, ., This, contrasts, with, approaches, where, there, are, essentially, no, explicit, rules, ,, such,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>0</td>\n",
              "      <td>[However, ,, the, personalization, component, of, the, case, -, based, reasoning, approach, was, rule, -, based, (, e.g., ,, rules, were, applied, to, substitute, names, of, individuals, and, companies, in, texts, ), ., With, respect, to, these, systems, ,, the, contribution, of, our, work, lies, in, the, consideration, of, different, kinds, of, corpus, -, based, approaches, (, namely, ,, retr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, performance, of, the, RFF, -, based, similarity, measure, was, evaluated, for, a, sample, of, nouns, and, compared, with, that, of, Lin98, ., The, experiment, was, conducted, using, an, 18, million, tokens, subset, of, the, Reuters, RCV1, corpus, ,, parsed, by, Lin, 's, Minipar, dependency, parser, (, CITSEG, ), ., We, considered, first, an, evaluation, based, on, WordNet, data, as, a, g...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, definition, of, a, topic, segment, ranges, from, complete, stories, (, CITSEG, ), to, summaries, (, CITSEG, ), ., Given, the, quality, of, an, algorithm, is, task, dependent, ,, the, following, experiments, focus, on, the, relative, performance, ., Our, evaluation, strategy, is, a, variant, of, that, described, in, (, CITSEG, ,, 71, -, 73, ), and, the, TDT, segmentation, task, (, CITSEG,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, corpora, have, been, sentence, and, word, -, tokenized, using, regular, expression, -, based, sentence, boundary, detection, and, tokenization, tools, ., Sentences, have, been, part-of, -, speech, tagged, using, the, TnT, tagger, (, CITSEG, ), trained, on, the, Penn, Treebank, (, CITSEG, ), ., 3, Next, ,, domain, terms, were, identified, using, the, C-Value, approach, (, CITSEG, ), ., C-...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>1</td>\n",
              "      <td>[Table, 2, shows, the, system, 's, performance, for, pronouns, broken, down, by, two, parameters, ,, grammatical, person, and, inter, -, vs., intrasentential, antecedent, ., The, system, did, quite, well, (, 78, %, ), with, third, -, person, pronouns, with, intrasentential, antecedents, ,, the, largest, class, of, such, pronouns, ., Part, of, the, pronoun, resolution, performance, here, enable...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>0</td>\n",
              "      <td>[For, example, ,, in, (, 5, ), the, order, of, the, events, is, understood, to, be, the, reverse, of, that, in, (, 1, ), due, to, the, cue, word, because, which, signals, a, causal, relationship, between, the, events, :, (, 5, ), John, entered, the, room, because, Mary, stood, up, ., As, CITSEG, points, out, ,, if, forward, movement, of, time, is, considered, a, default, with, consecutive, eve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, maximum, number, of, words, in, Chinese, and, English, phrases, is, set, to, 8, and, 25, respectively, for, all, conditions, 2, ., We, perform, online, style, phrase, training, ,, i.e., ,, phrase, extraction, is, not, particular, for, any, evaluation, set, ., Two, different, word, alignment, models, are, trained, as, the, baseline, ,, one, is, symmetric, HMM, word, alignment, model, ,, t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>0</td>\n",
              "      <td>[If, uk, and, Vk, are, indeed, mutual, translations, ,, then, their, tendency, to, Z, The, co-occurrence, frequency, of, a, word, type, pair, is, simply, the, number, of, times, the, pair, co-occurs, in, the, corpus, ., However, ,, n, (, u, ), =, ~-~v, n, (, u.v, ), ,, which, is, not, the, same, as, the, frequency, of, u, ,, because, each, token, of, u, can, co-occur, with, several, differentv...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>5</td>\n",
              "      <td>[Top, -, down, propagation, can, be, precomputed, to, form, a, teachability, table, ., Each, entry, in, the, table, is, a, compiled, dag, which, represents, the, relation, between, a, non-terminal, category, and, a, rule, used, to, rewrite, the, constituents, in, the, teachability, relation, (, i.e., ,, reflexive, ,, transitive, closure, of, the, left, -, corner, path, ), ., For, example, ,, c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>1</td>\n",
              "      <td>[Thus, ,, for, instance, ,, we, do, not, expect, our, system, to, perform, well, on, single, -, cased, texts, (, e.g., ,, texts, written, in, all, capital, or, all, lower, -, cased, letters, ), or, on, optical, character, reader, -, generated, texts, ., We, noted, in, Section, 8, that, very, short, documents, of, one, to, three, sentences, also, present, a, difficulty, for, our, approach, ., T...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>2</td>\n",
              "      <td>[Furthermore, ,, we, also, build, MERS, models, for, lexicalized, and, unlexicalized, source, trees, ., Note, that, for, lexicalized, tree, ,, features, do, not, include, the, information, of, sub-trees, since, there, is, no, nonterminals, ., The, features, can, be, easily, obtained, by, modifying, the, TAT, extraction, algorithm, described, in, (, CITSEG, ), ., When, a, TAT, is, extracted, fr...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>4</td>\n",
              "      <td>[The, algorithm, is, again, described, by, Cutting, et, al., and, by, Sharman, ,, and, a, mathematical, justification, for, it, can, be, tbund, in, CITSEG, ., The, first, major, use, of, HMMs, for, part, of, speech, tagging, was, in, CLAWS, (, CITSEG, ), in, the, 1970s, ., With, the, availability, of, large, corpora, and, fast, computers, ,, there, has, been, a, recent, resurgence, of, interes...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5</td>\n",
              "      <td>[Our, analysis, was, carried, out, within, the, framework, of, Systemic-Functional, Linguistics, (, SFL, ), (, CITSEG, ), which, views, language, as, a, resource, for, the, creation, of, meaning, ., SFL, stratifies, meaning, into, context, and, language, ., The, strata, of, the, linguistic, resources, are, organised, into, networks, of, choices, ,, each, choice, resulting, in, a, different, me...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>1</td>\n",
              "      <td>[We, choose, an, adapted, LexRank, as, the, baseline, ,, considering, that, LexRank, outperforms, both, centroid, -, based, methods, and, other, systems, participating, in, Document, Understanding, Conferences, (, DUC, ), in, most, of, the, cases, ,, and, proves, quite, insensitive, to, the, noise, in, the, data, ., Note, that, the, one, -, line, summarization, system, (, CITSEG, ), ,, which, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>5</td>\n",
              "      <td>[Because, of, major, data, sparseness, problems, ,, smoothing, is, an, important, issue, ,, in, particular, for, the, stress, model, which, is, based, on, syllable, -, stress, -, tag, pairs, ., Performance, varied, by, up, to, 20, %, in, function, of, the, smoothing, algorithm, chosen, ., Best, results, were, obtained, when, using, a, variant, of, Modified, Kneser, -, Ney, Smoothing, 2, (, CIT...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>0</td>\n",
              "      <td>[When, (, 2, ), is, applied, to, the, predicate, ,, (, 15, ), will, result, after, 13, -, reduction, ., However, ,, under, first, -, order, unification, ,, this, needs, to, simulated, by, having, the, variable, z, in, Az.run, (, z, ), unify, both, with, Bill, and, John, ,, and, this, is, not, possible, ., See, (, CITSEG, ), and, (, CITSEG, ), for, a, thorough, discussion, ., (, CITSEG, ), sugg...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, syntactic, indicator, attributes, ,, predicative, and, infinitival, ,, were, applied, first, ., Afterward, ,, if, a, target, adjective, sense, was, not, resolved, ,, semantic, indicator, attributes, were, applied, ;, no, individual, indicator, nouns, were, used, ., The, semantic, attributes, that, were, applied, were, animate, ,, body, part, ,, color, ,, concrete, ,, human, ,, and, text,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, ability, to, deal, with, large, amomlts, of, possibly, ill-formed, text, is, one, of, the, principal, objectives, of, current, NLP, research, ., Recent, proposals, include, the, use, of, probabilistic, methods, (, see, e.g., CITSEG, ), and, large, robust, deterministic, systems, like, Hindle, 's, Fidditch, (, CITSEG, ), ., 4, Experience, so, far, suggests, that, systems, like, LIIIP, may...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, pronoun, model, 's, main, problem, is, that, ,, although, a, pronoun, may, have, been, displaced, from, its, original, position, ,, it, can, often, find, another, seemingly, acceptable, referent, nearby, ., Despite, this, issue, it, performs, significantly, better, than, chance, and, is, capable, of, slightly, improving, the, combined, model, ., Both, of, these, models, are, very, differ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, overall, success, rate, calculated, for, the, 422, pronouns, found, in, the, texts, was, 56.9, %, for, Mitkov, 's, method, ,, 49.72, %, for, Cogniac, and, 61.6, %, for, Kennedy, and, Boguraev, 's, method, ., Table, 2, presents, statistical, results, on, the, evaluation, corpus, ,, including, distribution, of, pronouns, ,, referential, distance, ,, average, number, of, candidates, for, an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>1</td>\n",
              "      <td>[(, CITSEG, ), introduced, the, idea, of, utilizing, a, belief, revision, mechanism, (, CITSEG, ), to, predict, whether, a, set, of, evidence, is, sufficient, to, change, a, user, 's, existing, belief, and, to, generate, responses, for, information, retrieval, dialogues, in, a, library, domain, ., They, argued, that, in, the, library, dialogues, they, analyzed, ,, \", in, no, cases, does, negot...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, word, in, focus, is, first, passed, through, a, twolevel, morphological, analysis, stage, ,, based, on, an, adaption, of, (, CITSEG, ), ., Two, purposes, are, served, here, :, checking, the, word, is, lexica, ], (, i.e., in, the, lexicon, or, a, permissible, inflection, of, a, word, in, the, lexicon, ), and, collecting, the, possible, categories, ,, which, are, represented, as, sets, of,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>1</td>\n",
              "      <td>[This, evaluation, method, is, much, harder, than, standard, word, accuracy, ,, but, it, appears, to, be, a, good, approximation, to, \", rule, accuracy, \", ., Using, this, strict, method, we, achieved, a, word, accuracy, of, 47, %, ,, which, is, quite, promising, ., Results, using, top, down, prediction, of, possible, word, hypotheses, by, the, parser, work, inspired, by, (, CITSEG, ), have, a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>5</td>\n",
              "      <td>[4, Given, two, thesaurus, categories, tl, and, t~, ,, there, is, a, parameter, which, represents, the, degree, of, acceptability, of, the, structure, [, nine, ], where, nl, is, a, noun, appearing, in, tl, and, n, 2, appears, in, t, 2, ., By, the, assumption, that, words, within, a, group, behave, similarly, ,, this, is, constant, given, the, two, categories, ., Following, CITSEG, we, can, for...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>0</td>\n",
              "      <td>[rule, (, s, ,, [, ], ), ., In, order, to, illustrate, how, ordinary, parsers, can, be, used, to, compute, the, intersection, of, a, FSA, and, a, CFG, consider, first, the, definite, -, clause, specification, of, a, top, -, down, parser, ., This, parser, runs, in, polynomial, time, if, implemented, using, Earle, ), ,, deduction, or, XOLDT, resolution, (, CITSEG, ), ., It, is, assumed, that, th...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>1</td>\n",
              "      <td>[This, paper, showed, that, the, named, -entity, recognition, ,, which, have, usually, been, solved, by, dynamicprogramming, -, based, sequence, -, labeling, techniques, with, local, features, ,, can, have, innegligible, performance, improvement, from, reranking, methods, ., Our, system, showed, clear, improvement, over, many, of, the, machine, -, learning, -, based, systems, reported, to, dat...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>1</td>\n",
              "      <td>[This, enables, both, re-use, of, those, resources, and, progressive, growth, as, new, applications, are, met, ., The, grammar, extraction, tool, then, makes, it, a, simple, task, to, extract, from, the, large, -, scale, resources, specially, tuned, subgrammars, for, particular, applications, ., Our, approach, shows, some, similarities, to, that, proposed, by, (, CITSEG, ), for, improving, par...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>4</td>\n",
              "      <td>[We, perform, opinion, piece, recognition, in, order, to, assess, the, usefulness, of, the, various, features, when, used, together, ., Other, previous, NLP, research, has, used, features, similar, to, ours, for, other, NLP, tasks, ., Low-, frequency, words, have, been, used, as, features, in, information, extraction, (, CITSEG, ), and, text, categorization, (, CITSEG, ), ., A, number, of, res...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>4</td>\n",
              "      <td>[A, machine, translation, system, needs, to, have, this, knowledge, codilied, in, some, way, ., As, generating, articles, and, number, is, only, important, when, the, rest, of, the, sentence, has, been, correctly, generated, ,, them, has, not, been, a, lot, of, research, devoted, to, it, ., Recently, ,, CITSEG, have, proposed, a, method, of, determining, the, referentiality, property, and, num...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, phrase, $, 366.50, an, ounce, is, a, noun, phrase, as, well, ., However, ,, it, is, not, a, base, NP, since, it, contains, two, other, noun, phrases, ., Two, base, NP, data, sets, have, been, put, forward, by, (, CITSEG, ), ., The, main, data, set, consist, of, four, sections, (, 15, -, 18, ), of, the, Wall, Street, Journal, (, WSJ, ), part, of, the, Penn, Treebank, (, CITSEG, ), as, tra...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>4</td>\n",
              "      <td>[In, contrast, to, these, earlier, studies, ,, our, work, focuses, on, a, different, goal, of, using, eye, gaze, for, automated, vocabulary, acquisition, and, interpretation, ., The, third, area, of, research, that, influenced, our, work, is, computational, modeling, of, language, acquisition, and, grounding, ., Recent, studies, have, shown, that, multisensory, information, (, e.g., ,, through...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>5</td>\n",
              "      <td>[p, c, (, β, ), denotes, the, probability, of, having, bunsetsu, β, in, compression, ,, calculated, analogously, to, Eq., 10, ,, 8, and, tfidf, (, β, ), obviously, denotes, the, tfidf, value, of, β, ., In, DPM, ,, a, compression, of, a, given, sentence, can, be, obtained, by, finding, arg, max, y, h, (, y, ), ,, where, y, ranges, over, possible, candidate, compressions, of, a, particular, leng...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>0</td>\n",
              "      <td>[Several, methods, are, known, that, can, parse, languages, generated, by, Tree, Adjoining, Grammars, (, TAGs, ), in, worst, case, time, O, (, n~, ), ,, where, n, is, the, length, of, the, input, string, (, see, (, CITSEG, ), and, references, therein, ), ., Although, asymptotically, faster, methods, can, be, constructed, ,, as, discussed, in, (, CITSEG, ), ,, these, methods, are, not, of, prac...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, task, of, word, sense, induction, (, WSI, ), is, to, find, the, different, senses, of, a, word, ., The, number, of, senses, is, not, known, in, advance, ,, therefore, has, to, be, determined, by, the, method, ., Similar, to, the, approach, as, presented, in, (, CITSEG, ), we, construct, a, word, graph, ., While, there, ,, edges, between, words, are, drawn, iff, words, co-occur, in, enume...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>1</td>\n",
              "      <td>[Every, conjunction, of, feature, templates, considered, contains, at, least, one, predicate, on, the, prediction, y, t, ,, and, up, to, two, predicates, on, the, context, ., The, feature, selection, algorithm, performs, a, greedy, forward, stepwise, feature, selection, on, the, feature, templates, so, as, to, maximize, development, set, accuracy, ., The, algorithm, is, similar, to, the, one, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, used, φ, 2, (, CITSEG, ), as, the, link, score, in, the, modified, competitive, linking, algorithm, ,, although, there, are, many, other, possible, choices, for, the, link, scores, ,, such, as, χ, 2, (, CITSEG, ), ,, log-likelihood, ratio, (, CITSEG, ), and, discriminatively, trained, weights, (, CITSEG, ), ., The, φ, 2, statistics, for, a, pair, of, words, e, i, and, f, j, is, computed, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>3</td>\n",
              "      <td>[In, case, of, ambiguity, ,, we, considered, only, the, first, (, arbitrary, ), analysis, for, Russian, ., For, Arabic, ,, we, apply, the, following, heuristic, :, use, the, most, frequent, analysis, estimated, from, the, gold, standard, labels, in, the, Arabic, Treebank, (, CITSEG, ), ;, if, a, word, does, not, appear, in, the, treebank, ,, we, choose, the, first, analysis, returned, by, the,...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>4</td>\n",
              "      <td>[Bidirectionality, of, grammar, is, a, research, topic, in, natural, language, processing, that, is, enjoying, increasing, attention, (, CITSEG, ), ., This, is, mainly, due, to, the, clear, theoretical, and, practical, advantages, of, bidirectional, grammar, use, (, see, ,, among, others, ,, CITSEG, ), ., We, address, this, topic, in, describing, a, novel, approach, to, HPSG, (, CITSEG, ), bas...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>4</td>\n",
              "      <td>[Free, (, CF, ), backbone, that, makes, a, first, sketch, of, the, structure, of, the, analyzed, sentence, ,, before, it, is, handed, to, a, more, elaborate, analyzer, (, possibly, a, coroutine, ), ,, that, takes, into, account, the, finer, grammatical, structure, to, filter, out, undesirable, parses, (, see, for, example, [, 24, ,, 28, ], ), ., In, [, 28, ], ,, Shieber, surveys, existing, var...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, evaluate, the, extractive, CoreSC, summaries, in, terms, of, how, well, they, enable, 12, chemistry, experts, /, evaluators, (, with, at, least, a, Masters, degree, in, chemistry, ), to, answer, complex, questions, about, the, papers, ., Our, test, corpus, consists, of, 28, papers, held, out, from, the, ART, /, CoreSC, corpus, ,, roughly, 1/9, ,, which, were, annotated, automatically, wit...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>0</td>\n",
              "      <td>[In, this, dialogue, ,, speaker, B, is, not, confident, that, he, will, be, able, to, identify, the, intersection, at, Lowell, Street, ,, and, so, suggests, that, the, intersection, might, be, marked, ., Speaker, A, replies, with, an, elaboration, of, the, initial, expression, ,, and, B, finds, that, he, is, now, confident, ,, and, so, accepts, the, reference, ., This, type, of, reference, is,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, first, directed, Applicative, CG, was, proposed, by, CITSEG, ., Functional, types, included, a, list, of, arguments, to, the, left, ,, and, a, list, of, arguments, to, the, right, ., Translating, Bar-Hillel, 's, notation, into, a, feature, based, notation, similar, to, that, in, HPSG, (, CITSEG, ), ,, we, obtain, the, following, category, for, a, ditransitive, verb, such, as, put, :, r, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>5</td>\n",
              "      <td>[Motivated, by, the, argument, structure, of, discourse, relations, used, in, Penn, Discourse, Treebank, (, CITSEG, ), ,, in, this, work, ,, we, adopt, the, clause, unit-based, definition, ., It, means, that, clauses, are, treated, as, the, basic, units, of, opinion, expressions, and, explanations, ., Let, d, =, {c, 1, ,, c, 2, ,, ...c, n, }, be, the, clauses, of, document, d., Directed, graph...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, first, adopted, the, full, feature, set, from, CITSEG, ,, a, state, -, of, -, the, -, art, feature, based, relation, extraction, system, ., For, space, reasons, ,, we, only, show, the, lexical, features, as, in, Table, 3, and, refer, the, reader, to, the, paper, for, the, rest, of, the, features, ., At, the, lexical, level, ,, a, relation, instance, can, be, seen, as, a, sequence, of, tok...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, third, column, adds, in, silence, information, ., Unlike, the, case, for, boundary, tones, ,, adding, silence, does, not, have, much, of, an, effect, ., 4, The, fourth, column, adds, in, speech, repair, correction, ,, and, shows, that, taking, into, account, the, correction, ,, gives, better, detection, rates, (, CITSEG, ), ., The, fifth, column, adds, in, boundary, tone, detection, ,, w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>5</td>\n",
              "      <td>[For, the, first, scenario, a, corpus, containing, 500, sentences, for, each, of, the, verbs, was, constructed, ., The, text, was, randomly, selected, from, corpora, of, different, domains, and, genres, ,, including, literary, fiction, ,, Bible, ,, computer, science, dissertation, abstracts, ,, operational, system, user, manuals, ,, newspapers, and, European, Parliament, proceedings, ., This, ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>0</td>\n",
              "      <td>[However, ,, it, is, still, an, open, question, which, kind, of, lexicalization, ,, e.g., ,, statistics, on, individual, words, or, statistics, based, upon, word, classes, ,, is, the, best, choice, ., Secondly, ,, these, approaches, have, in, common, the, fact, that, the, probability, models, are, trained, on, treebanks, ,, i.e., ,, corpora, of, manually, disambiguated, sentences, ,, and, not,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>5</td>\n",
              "      <td>[a, ., For, all, the, training, data, ,, the, pairs, of, pronunciations, are, aligned, using, standard, string, alignment, algorithm, based, on, CITSEG, ., The, substitution, /, insertion, /, deletion, cost, for, the, string, alignment, algorithm, is, based, on, the, baseline, cost, from, (, CITSEG, ), ., b, ., All, phonemes, in, the, pronunciations, are, decomposed, into, their, features, ., ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>1</td>\n",
              "      <td>[Regardless, of, the, criterion, for, success, ,, the, algorithm, does, need, further, evaluation, ., Immediate, plans, include, a, larger, scale, version, of, the, experiment, presented, here, ,, involving, thesaurus, classes, ,, as, well, as, a, similarly, designed, evaluation, of, how, the, algorithm, fares, when, presented, with, noun, groups, produced, by, distributional, clustering, ., I...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>4</td>\n",
              "      <td>[We, focus, on, topics, that, are, relatively, welldefined, in, scope, such, as, a, particular, event, or, a, single, news, event, that, does, not, evolve, over, time, ., This, can, eventually, be, extended, to, events, and, issues, that, are, evolving, either, in, time, or, scope, such, as, elections, ,, wars, ,, or, the, economy, ., In, social, sciences, and, the, study, of, complex, systems...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>1</td>\n",
              "      <td>[Since, data, can, be, represented, as, higher, -, order, tuples, ,, single, layer, networks, can, be, used, ., The, traditional, problems, of, training, times, do, not, arise, ., We, have, also, used, multi-layer, nets, on, this, data, :, they, have, no, advantages, ,, and, perform, slightly, less, well, (, CITSEG, ), ., The, supporting, role, of, the, grammatic, framework, and, the, prohibit...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, delicacy, of, testsuite, construction, is, acknowledged, in, EAGLES, ,, 1996, ,, p.37, ., Although, there, are, a, number, of, e, orts, to, construct, reusable, testsuites, ,, none, has, to, my, knowledge, explored, how, existing, grammars, can, be, exploited, ., CITSEG, ,, testsuites, have, been, drawn, up, from, a, linguistic, viewpoint, ,, informed, by, the, study, of, linguistics, an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>4</td>\n",
              "      <td>[The, method, is, a, form, of, multi-layered, artificial, neural, network, called, Simple, Synchrony, Networks, (, CITSEG, ), ., The, outputs, of, this, network, are, probability, estimates, computed, with, a, log-linear, model, (, also, known, as, a, maximum, entropy, model, ), ,, as, is, done, in, (, CITSEG, ), ., Log-linear, models, have, proved, successful, in, a, wide, variety, of, applic...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>0</td>\n",
              "      <td>[Standard, symbolic, machine, learning, techniques, have, been, successfully, applied, to, a, number, of, tasks, in, natural, language, processing, (, NLP, ), ., Examples, include, the, use, of, decision, trees, for, syntactic, analysis, (, CITSEG, ), ,, coreference, (, CITSEG, ), ,, and, cue, phrase, identification, (, CITSEG, ), ;, the, use, of, inductive, logic, programming, for, learning, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>2</td>\n",
              "      <td>[They, require, a, relatively, large, tagged, training, text, ., Transformation, -, based, tagging, as, introduced, by, CITSEG, also, requires, a, handtagged, text, for, training, ., No, pretagged, text, is, nec-essary, for, Hidden, Markov, Models, (, CITSEG, ), ., Still, ,, a, lexicon, is, needed, that, specifies, the, possible, parts, of, speech, for, every, word, ., CITSEG, have, shown, tha...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>2</td>\n",
              "      <td>[3, ), Collaborative, agents, are, interested, in, 1, The, notion, of, shared, plan, has, been, used, in, (, CITSEG, ), ., others, ', beliefs, in, order, to, decide, whether, to, revise, their, own, beliefs, so, as, to, come, to, agreement, (, CITSEG, ), ., Although, agents, involvedin, argumentation, and, non-collaborative, negotiation, take, other, agents, ', beliefs, into, consideration, ,,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>5</td>\n",
              "      <td>[To, evaluate, our, coreference, -, chain, extraction, method, we, compare, it, with, a, cue-phrases, technique, (, CITSEG, ), and, two, baselines, ., Baseline, 1, extracts, only, the, c-site, anchor, sentence, as, the, c-site, ;, baseline, 2, includes, sentences, before, /, after, the, c-site, anchor, sentence, as, part, of, the, c-site, with, a, 50/50, probability, -, it, tosses, a, coin, fo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>4</td>\n",
              "      <td>[From, this, perspective, then, ,, the, fundamental, problem, of, question, answering, is, that, of, finding, spaces, where, the, distance, between, questions, and, sentences, that, contain, correct, answers, is, small, and, where, the, distance, between, questions, and, sentences, that, contain, incorrect, answers, is, large, ., In, this, paper, ,, we, propose, a, new, space, and, a, new, met...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>2</td>\n",
              "      <td>[The, most, basic, feature, is, the, =x, licensor, feature, ,, which, cancels, out, a, corresponding, x, licensee, feature, and, projects, ., A, simple, example, is, a, determiner, selecting, a, noun, to, form, a, determiner, phrase, (, akin, to, the, context, free, rule, DP, →, det, noun, ), ., This, is, shown, below, (, underline, indicates, canceled, features, ,, and, the, node, label, &lt;, i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>1</td>\n",
              "      <td>[5, We, expect, that, using, the, same, setup, on, v2.0, will, allow, a, crosstreebank, comparison, ., 6, We, used, the, first, 500, sentences, as, our, dev, set, and, the, rest, 4500, for, training, and, report, our, main, results, on, this, split, ., To, facilitate, the, comparison, of, our, results, to, those, reported, by, (, CITSEG, ), we, use, their, data, set, in, which, 177, empty, and...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>0</td>\n",
              "      <td>[Both, software, and, grammar, development, are, similar, processes, :, They, result, in, a, system, transforming, some, input, into, some, output, ,, based, on, a, functional, specification, (, e.g., ,, cf., (, CITSEG, ), for, the, application, of, a, particular, software, design, methodology, to, linguistic, engineering, ), ., Although, Grammar, Engineering, usually, is, not, based, on, conc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>5</td>\n",
              "      <td>[For, example, ,, for, English, ,, the, sequences, *, +, ed, +ly, and, un, +*+, ing, are, among, those, produced, ,, the, asterisk, representing, the, unspecified, root, ., Then, ,, each, sequence, ,, together, with, any, associated, restrictions, on, orthographic, features, ,, undergoes, analysis, by, the, compiled, spelling, rules, (, Section, 2.1, ), ,, with, the, surface, sequence, and, th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>1</td>\n",
              "      <td>[Features, that, occur, rarely, in, the, training, set, are, problematic, because, the, statistics, extracted, for, these, features, are, not, reliable, ., They, may, still, contribute, positively, to, the, ME, model, because, we, use, Gaussian, smoothing, (, CITSEG, ), help, avoid, overfitting, ., Instead, of, including, every, possible, feature, ,, we, used, a, cutoff, to, remove, features, ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>4</td>\n",
              "      <td>[Word, sense, disambiguation, is, a, potentially, crucial, task, in, many, NLP, applications, ,, such, as, machine, translation, (, CITSEG, ), ,, parsing, (, CITSEG, ), and, text, retrieval, (, CITSEG, ), ., Various, corpus-, based, approaches, to, word, sense, disambiguation, have, been, proposed, (, CITSEG, ), ., The, use, of, corpus, -, based, approaches, has, grown, with, the, use, of, mac...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, relation, hierarchy, was, constructed, manually, ., A, rich, hierarchical, structure, between, the, set, of, relations, is, essential, to, the, graph, matching, operations, we, use, for, the, integration, phase, ., As, we, are, using, the, conceptual, graph, formalism, to, represent, our, definitions, ,, we, can, use, the, graph, matching, operations, defined, in, (, CITSEG, ), ., The, t...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>0</td>\n",
              "      <td>[Note, that, the, unfolding, of, the, magic_s, literal, leads, to, the, instantiation, of, the, argument, VFORM, to, finite, ., As, a, result, of, the, fact, that, there, are, no, other, magic_s, literals, in, the, remainder, of, the, magic, -, compiled, grammar, the, magic_s, rule, can, be, discarded, ., This, filter, optimization, is, reminiscent, of, computing, the, deterministic, closure, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>0</td>\n",
              "      <td>[4, There, are, other, ways, to, define, the, B, annotation, ,, e.g., ,, as, always, marking, the, beginning, of, a, phrase, ., The, indicating, that, the, NPs, are, I, ,, California, and, last, May, ., This, approach, has, been, studied, in, (, CITSEG, ), .]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, method, also, seem, to, work, well, for, [, CONFLICT, ], relations, ,, because, lexical, similarity, based, on, bag, -, of, -, words, (, BOW, ), can, narrow, the, range, of, candidates, with, this, relation, as, well, ., We, calculate, the, lexical, similarity, between, the, two, sentences, based, on, BOW, ., We, also, used, hyponym, and, synonym, dictionaries, (, CITSEG, ), and, a, data...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>1</td>\n",
              "      <td>[This, suggests, another, possible, objective, function, :, choose, ~, to, maximize, the, number, Co, (, ~, ), of, times, the, maximum, likelihood, parse, (, under, 0, ), is, in, fact, the, correct, parse, ,, in, the, training, corpus, ., Co, (, ~, ), is, a, highly, discontinuous, function, of, 0, ,, and, most, conventional, optimization, algorithms, perform, poorly, on, it, ., We, had, the, m...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>1</td>\n",
              "      <td>[(, III, ), The, way, in, which, spans, are, annotated, as, ar-guments, to, connectives, also, raises, a, challenge, ., First, ,, because, the, PDTB, annotates, both, structural, and, anaphoric, connectives, (, CITSEG, ), ,, a, span, can, serve, as, argument, to, &gt;1, connective, ., Secondly, ,, unlike, in, the, RST, corpus, (, CITSEG, ), or, the, Discourse, GraphBank, (, CITSEG, ), ,, discours...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, describe, the, revised, sere, ., antic, framework, in, Section, 3, ., and, work, through, several, examples, of, non-constituent, coordination, (, specifically, ,, rightnode, raising, ), in, Section, 4, ., We, discnss, examples, involving, intensioual, verbs, in, Section, 5, ,, 2, Previous, Work, CITSEG, ,, working, in, the, framework, of, Combinatory, Categorial, Grammar, (, CCG, ), ,, p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>2</td>\n",
              "      <td>[As, a, baseline, ,, we, adopt, the, entity, grid, ., This, model, outperforms, a, variety, of, word, overlap, and, semantic, similarity, models, ,, and, is, used, as, a, component, in, the, state, -, of, -, the, -, art, system, of, CITSEG, ., The, entity, grid, represents, each, entity, by, tracking, the, syntactic, roles, in, which, it, appears, throughout, the, document, ., The, internal, s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>0</td>\n",
              "      <td>[Earley, deduction, [, CITSEG, ], is, based, on, grammars, encoded, as, definite, clauses, ., The, instantiation, (, prediction, ), rule, of, top-down, Earley, deduction, is, not, needed, in, bottom, -, up, Earley, deduction, ,, because, there, is, no, prediction, ., There, is, only, one, inference, rule, ,, namely, the, reduction, rule, (, 1, ), 3, In, (, 1, ), ,, X, ,, G, and, G, t, are, lit...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>5</td>\n",
              "      <td>[Two, speech, samples, from, each, of, three, subjects, were, used, in, the, simulations, in, one, sample, a, mother, was, speaking, to, her, daughter, and, in, the, other, ,, the, same, mother, was, speaking, to, the, researcher, ., The, samples, were, taken, from, the, CHILDES, database, (, CITSEG, ), from, studies, reported, in, CITSEG, ., Each, sample, was, checked, for, consistent, word, ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>0</td>\n",
              "      <td>[3, ., Another, way, of, allowing, pragmatic, inferences, to, be, cancelled, is, to, assign, them, the, status, of, defeasible, information, ., CITSEG, formalizes, pre-suppositions, in, a, logical, framework, that, handles, defaults, (, CITSEG, ), ,, but, this, approach, is, not, tractable, and, it, treats, natural, disjunction, as, an, exclusiveor, and, implication, as, logical, equivalence, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>4</td>\n",
              "      <td>[C, U, T, V, X, W, ©, I, H, Y, is, the, negative, of, the, distance, between, and, the, value, predicted, for, H, by, the, fitted, hyperplane, function, ., CITSEG, used, SVM, regression, to, classify, clause, -, level, strength, of, opinion, ,, reporting, that, it, provided, lower, accuracy, than, other, methods, ., However, ,, independently, of, our, work, ,, CITSEG, found, that, applying, li...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>2</td>\n",
              "      <td>[The, child, learner, must, segment, a, continuous, stream, of, sounds, into, words, without, knowing, what, the, individual, words, are, until, the, stream, has, been, segmented, ., Computational, models, present, an, opportunity, to, test, the, potentially, innate, constraints, ,, structures, ,, and, algorithms, that, a, child, may, be, using, to, guide, her, acquisition, ., In, this, work, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>5</td>\n",
              "      <td>[Instances, are, stored, in, the, tree, as, paths, A, demo, of, the, NP, and, VP, chunker, is, available, at, http, :, www.sfb441.unituebingen.de, ~, dejean, chunker.h, tml, 3, Available, from, http, :, www.rulequest.com, of, connected, nodes, ending, in, leaves, which, contain, classi, cation, information, ., Nodes, are, connected, via, arcs, denoting, feature, values, ., Feature, information...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>5</td>\n",
              "      <td>[To, our, knowledge, ,, there, have, been, few, papers, about, identifying, sentence, boundaries, ., The, most, recent, work, will, be, described, in, (, Pa.lmer, and, Hearst, ,, To, appear, ), ., There, is, also, a, less, detailed, description, of, Pahner, and, Hearst, 's, system, ,, SATZ, ,, in, (, CITSEG, ), ., 1, The, SATZ, architecture, uses, either, a, decision, tree, or, a, neural, netw...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216</th>\n",
              "      <td>5</td>\n",
              "      <td>[In, the, second, experiment, ,, each, training, sentence, and, each, test, sentence, hypothesis, was, analysed, by, the, Core, Language, Engine, (, CITSEG, ), trained, on, the, ATIS, domain, (, CITSEG, ), ., Unanalysable, sentences, were, discarded, ,, as, were, sentences, of, over, 15, words, in, length, (, the, ATIS, adaptation, had, concentrated, on, sentences, of, 15, words, or, under, ,,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>0</td>\n",
              "      <td>[Several, types, of, research, have, involved, document, -, level, subjectivity, classification, ., Some, work, identifies, inflammatory, texts, (, e.g., ,, (, CITSEG, ), ), or, classifies, reviews, as, positive, or, negative, (, (, CITSEG, ), ), ., Tong, 's, system, (, CITSEG, ), generates, sentiment, timelines, ,, tracking, online, discussions, and, creating, graphs, of, positive, and, negat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, compared, using, the, DARPA, GALE, P2.5, Chinese, -, English, translation, test, set, ,, as, used, in, CITSEG, ., The, corpus, includes, the, Chinese, input, sentences, ,, each, accompanied, by, an, English, reference, translation, and, three, participating, state, -, of, -, the, -, art, MT, systems, ', output, ., We, computed, sentence, -, level, correlations, following, the, benchmark, ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>2</td>\n",
              "      <td>[There, are, two, particularly, appealing, cases, -, (, 1, ), when, the, extraction, component, has, failed, to, extract, a, description, and, (, 2, ), when, the, user, model, (, user, 's, interests, ,, knowledge, of, the, entity, and, personal, preferences, for, sources, of, information, and, for, either, conciseness, or, verbosity, ), dictates, that, a, description, should, be, used, even, w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, also, experimented, adding, #, as, a, delimiter, for, the, splitted, words, except, the, last, word, (, e.g., ,, Finanzkrisen, is, splitted, as, finanz#, krisen, ), (, CS2, ), ., On, top, of, the, compound, splitting, ,, we, applied, the, lexical, redundancy, normalization, (, CS, +, Norm1, ), ., We, lemmatized, German, articles, ,, adjectives, (, only, positive, form, ), ,, for, some, pr...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>2</td>\n",
              "      <td>[Note, that, all, the, information, encoded, into, our, constraints, is, also, encoded, in, the, features, and, is, thus, available, to, the, feature, -, based, model, ., This, enables, us, to, properly, evaluate, the, impact, of, our, modeling, decision, which, augments, a, feature, -, based, model, with, constraints, ., Baselines, We, compared, our, model, against, four, baselines, ,, two, w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>0</td>\n",
              "      <td>[This, process, continues, until, the, expression, ,, kept, in, the, participants, ', common, ground, ,, is, mutually, accepted, ., This, excerpt, from, Clark, and, Wilkes, -, Gibbs, 's, data, illustrates, rejection, (, line, 2, ), ,, replacement, (, line, 2, ), ,, and, acceptance, (, lines, 3, and, 4, ), :, An, agent, can, infer, a, plan, even, if, it, is, invalid, in, that, agent, 's, view, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>1</td>\n",
              "      <td>[Learning, in, phrase, alignment, models, generally, requires, computing, either, Viterbi, phrase, alignments, or, expectations, of, alignment, links, ., For, some, restricted, combinatorial, spaces, of, alignments, -, those, that, arise, in, ITG, -, based, phrase, models, (, CITSEG, ), or, local, distortion, models, (, CITSEG, ), -, inference, can, be, accomplished, using, polynomial, time, d...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>2</td>\n",
              "      <td>[Although, it, is, still, used, for, linguistic, description, (, e.g., CITSEG, ), ,, it, has, been, somewhat, overshadowed, in, recent, years, by, HPSG, (, CITSEG, ), ,, and, by, Lambek, Categorial, Grammars, (, CITSEG, ), ., It, is, therefore, worth, giving, some, brief, indications, of, how, it, fits, in, with, these, developments, ., The, first, directed, Applicative, CG, was, proposed, by,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>4</td>\n",
              "      <td>[Nevertheless, ,, the, efforts, in, this, direction, so, far, have, shown, very, insignificant, improvements, ,, if, any, (, CITSEG, ), ., We, believe, that, the, main, reason, for, that, is, that, incorporating, information, sources, in, NLP, needs, to, be, coupled, with, a, learning, approach, that, is, suitable, for, it, ., Studies, have, shown, that, both, machine, learning, and, probabili...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>5</td>\n",
              "      <td>[Since, Matxin, was, designed, to, be, open, source, ,, we, built, a, simple, compiler, that, converted, the, XFST, rules, into, regular, expressions, that, could, then, be, applied, without, FST, technology, ,, at, the, cost, of, execution, speed, ., This, verbal, chunk, transfer, module, read, and, applied, these, regular, expressions, at, a, speed, of, 50, verbal, chunks, per, second, ., In...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, functor, -, argument, distinction, in, CG, helps, to, model, prominence, relations, without, extra, levels, of, representation, ., CCG, schema, (, CITSEG, ;, is, summarized, in, (, 4, ), ., Combinator, notation, is, preferred, here, because, they, are, the, formal, primitives, operating, on, the, PAS, (, cf., (, CITSEG, ), for, Combinatory, Logic, ), ., Application, is, the, only, primit...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, obtained, frequencies, of, cooccurrence, were, weighted, by, the, 1+log, weight, function, ., The, distributional, similarity, was, measured, by, means, of, three, different, similarity, measures, :, the, Jaccard, 's, coefficient, ,, L1, distance, ,, and, the, skew, divergence, ., This, choice, of, similarity, measures, was, motivated, by, results, of, studies, by, (, CITSEG, ), and, (, ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>0</td>\n",
              "      <td>[Strong, empirical, evidence, has, been, presented, over, the, past, 15, years, indicating, that, the, human, sentence, processing, mechanism, makes, online, use, of, contextual, information, in, the, preceding, discourse, (, CITSEG, ), and, in, the, visual, environment, (, CITSEG, ), ., These, results, lend, support, to, Mark, Steedman, 's, (, 1989, ), \", intuition, \", that, sentence, interpr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>5</td>\n",
              "      <td>[As, a, baseline, classifier, we, use, the, substring, matching, technique, of, (, CITSEG, ), ,, which, labels, a, sentence, as, spec, if, it, contains, one, or, more, of, the, following, :, suggest, ,, potential, ,, likely, ,, may, ,, at, least, ,, in, part, ,, possibl, ,, further, investigation, ,, unlikely, ,, putative, ,, insights, ,, point, toward, ,, promise, and, propose, ., To, provide...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>0</td>\n",
              "      <td>[D., Lin, also, found, that, the, choice, of, similarity, function, can, affect, the, quality, of, automatically, -, constructed, thesauri, to, a, statistically, significant, degree, (, 1998, a, ), and, the, ability, to, determine, common, morphological, roots, by, as, much, as, 49, %, in, precision, (, 1998, b, ), ., These, empirical, results, indicate, that, investigating, different, similar...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>0</td>\n",
              "      <td>[If, one, agent, has, limited, working, memory, ,, then, the, (, ), thor, agenl, can, make, the, di~doguc, go, more, slnoothly, by, adopting, a, strategy, that, makes, deliberative, premises, salient, ., In, other, words, ,, slrategies, ~ue, cooperative, for, certain, conversational, p;u'tners, ,, in, /, der, particular, task, delinitions, ,, lor, p~uticul~u, communicalion, situations, ., Here...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, Penn, Treebank, (, PTB, ), (, CITSEG, ), has, been, used, for, a, rather, simple, approach, to, deriving, large, grammars, automatically, :, one, where, the, grammar, rules, are, simply, ', read, off, ', the, parse, trees, in, the, corpus, ,, with, each, local, subtree, providing, the, left, and, right, hand, sides, of, a, rule, ., Charniak, (, CITSEG, ), reports, precision, and, recall,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>4</td>\n",
              "      <td>[Alternatively, ,, we, can, take, a, regression, perspective, by, assuming, that, the, labels, come, from, a, discretization, of, a, continuous, function, feature, space, to, a, metric, space, ., 5, If, we, choose, R, from, a, family, of, sufficiently, \", gradual, \", functions, ,, then, similar, items, necessarily, receive, similar, labels, ., In, particular, ,, we, consider, linear, ,, S, -, ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>5</td>\n",
              "      <td>[Our, segmentation, algorithm, takes, a, list, of, tokenized, sentences, as, input, ., A, tokenizer, (, CITSEG, ), and, a, sentence, boundary, disambiguation, algorithm, (, CITSEG, ), or, EAGLE, ), may, be, used, to, convert, a, plain, text, document, into, the, acceptable, input, format, .]</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>5</td>\n",
              "      <td>[Both, of, these, considerations, suggest, the, relevance, of, inductive, and, experimental, approaches, to, the, construction, of, lexicons, with, semantic, information, ., This, paper, presents, a, method, for, automatic, induction, of, semantically, annotated, subcategorization, frames, from, unannotated, corpora, ., We, use, a, statistical, subcat-induction, system, which, estimates, proba...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>1</td>\n",
              "      <td>[Specifically, ,, to, account, for, the, forward, progression, of, time, induced, by, successive, simple, past, tenses, in, a, narrative, ,, they, treat, the, simple, past, as, referring, to, a, time, evoked, by, a, previous, past, tense, ., For, instance, ,, in, CITSEG, 's, proposal, ,, accomplishments, and, achievements, x, introduce, a, new, reference, point, that, is, temporally, ordered, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238</th>\n",
              "      <td>4</td>\n",
              "      <td>[CBC, (, Clustering, by, Committee, ), proposed, by, CITSEG, achieves, high, recall, and, precision, in, generating, similarity, lists, of, words, discriminated, by, their, meaning, and, senses, ., However, ,, such, clustering, algorithms, fail, to, name, their, classes, ., CITSEG, was, the, first, to, use, clustering, for, labeling, is, -, a, relations, using, conjunction, and, apposition, fe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>2</td>\n",
              "      <td>[We, developed, FiESTA, (, an, acronym, for, \", format, for, extensive, spatiotemporal, annotations, \", ), ,, which, takes, into, account, various, approaches, ,, among, them, ,, the, annotation, graph, approach, (, CITSEG, ), ,, the, NITE, object, model, (, CITSEG, ), ,, the, speech, transcription, facilities, of, the, TEI, P5, specification, (, TEI, CITSEG, ), ,, and, the, (, X), CES, standa...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, SVM, classification, model, is, built, from, lexical, and, syntactic, features, assigned, to, tokens, and, entity, pairs, prior, to, classification, ., We, use, features, developed, in, part, from, those, described, in, CITSEG, ., These, features, are, split, into, 11, sets, ,, as, described, in, Table, 3, ., The, tokN, features, are, POS, and, surface, string, taken, from, a, window, of...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>0</td>\n",
              "      <td>[We, allow, nonprojectivity, by, loosening, the, linking, between, dependency, tree, and, domain, structure, :, A, modifier, (, e.g., ,, \", Mann, \", ), may, not, only, be, inserted, into, a, domain, associated, with, its, direct, head, (, \", gesehen, \", ), ,, but, also, into, a, domain, of, a, transitive, head, (, \", hat, \", ), ,, which, we, will, call, the, positional, head, ., The, possibili...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>4</td>\n",
              "      <td>[Within, the, field, of, Machine, Translation, ,, by, far, the, most, dominant, paradigm, is, Phrase, -, based, Statistical, Machine, Translation, (, PBSMT, ), (, CITSEG, ), ., However, ,, unlike, in, rule, -, and, example, -, based, MT, ,, it, has, proven, difficult, to, date, to, incorporate, linguistic, ,, syntactic, knowledge, in, order, to, improve, translation, quality, ., Only, quite, r...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, use, a, decision, -, list, algorithm, to, learn, sets, of, words, and, extraction, patterns, for, the, classes, DENOTATIONAL, DISTINCTIONS, and, ATTITUDE, -, STYLE, DISTINCTIONS, ., These, are, split, further, for, each, leaf, class, ,, as, explained, in, Section, 2.3, ., The, algorithm, we, implemented, is, inspired, by, the, work, of, CITSEG, on, word, sense, disambiguation, ., He, clas...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>4</td>\n",
              "      <td>[To, resolve, the, opposition, between, surface, order, and, the, PAS, in, a, free, word, order, language, ,, one, can, let, the, type, shifted, categories, of, terms, proliferate, ,, or, reformulate, CCG, in, such, a, way, that, arguments, of, the, verbs, are, sets, ,, rather, than, lists, whose, arguments, are, made, available, one, at, a, time, ., The, former, alternative, makes, the, spuri...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, evaluation, is, summarized, in, Table, 3, ., The, results, demonstrate, that, either, leveraging, the, same, unlabeled, data, or, providing, a, much, larger, unlabeled, dataset, for, the, monolingual, semisupervised, methods, ,, the, SLBD, method, can, significantly, outperform, the, evaluated, monolingual, semi-supervised, methods, ,, which, indicates, that, the, segmenting, information...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>1</td>\n",
              "      <td>[As, CITSEG, observed, ,, \", the, fact, that, existing, systems, perform, extremely, well, on, mixed, -, case, English, newswire, corpora, is, certainly, related, to, the, years, of, research, and, organized, evaluations, on, this, specific, task, in, this, language, ., It, is, not, clear, what, resources, are, required, to, adapt, systems, to, new, languages, ., \", It, is, important, to, ment...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, combination, of, these, 3, ×, 3, design, choices, yielded, 9, different, dialogue, systems, ., Participants, were, asked, to, schedule, a, health, care, appointment, with, each, of, the, 9, systems, ,, yielding, a, total, of, 9, dialogues, per, participant, ., System, utterances, were, generated, using, a, simple, template, -, based, algorithm, and, synthesised, using, the, speech, synth...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>1</td>\n",
              "      <td>[\", Semantic, \", here, means, that, the, collocations, the, algorithm, discovers, are, not, collocations, among, words, in, the, sense, of, traditional, linguistics, but, collocations, that, reflect, ontological, relations, among, entities, in, given, subject, domains, ., We, expect, that, the, knowledge, to, be, extracted, will, not, only, be, useful, for, disambiguating, sentences, but, also...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, Wilcoxon, Signed, Ranks, (, Wilcoxon, ,, henceforth, ), test, is, a, non-parametric, test, for, statistical, significance, that, is, appropriate, when, there, is, one, data, sample, and, several, measures, ., For, example, ,, to, compare, the, accuracy, of, two, parsers, over, the, same, data, set, ., As, the, number, of, samples, (, sentences, ), is, large, we, use, the, normal, approxi...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>2</td>\n",
              "      <td>[We, prune, phrase, translation, entries, by, their, probabilities, ., The, maximum, number, of, tokens, in, Arabic, phrases, is, set, to, 5, for, all, conditions, ., Our, decoder, is, a, phrase, -, based, multi-stack, imple-mentation, of, the, log-linear, model, similar, to, Pharaoh, (, CITSEG, ), ., Like, other, log, -, linear, model, based, decoders, ,, active, features, in, our, translatio...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>5</td>\n",
              "      <td>[In, the, remaining, experiments, ,, we, have, each, word, in, a, phrase, indexed, ., We, compare, the, results, for, the, 1911, and, 1987, Roget, 's, Thesauri, with, a, variety, of, WordNet, -, based, semantic, relatedness, measures, -, see, Table, 5, ., We, consider, 10, measures, ,, noted, in, the, table, as, J&amp;C, (, CITSEG, ), ,, Resnik, (, CITSEG, ), ,, Lin, (, CITSEG, ), ,, W&amp;P, (, CITSE...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>4</td>\n",
              "      <td>[Backreferencing, has, been, implicit, in, previous, research, ,, such, as, in, the, \", batch, rules, \", of, CITSEG, ,, bracketing, transducers, for, finite, -, state, parsing, (, CITSEG, ), ,, and, the, \", LocalExtension, \", operation, of, CITSEG, ., The, explicit, use, of, backreferencing, leads, to, more, elegant, and, general, solutions, ., Backreferencing, is, widely, used, in, editors, ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>0</td>\n",
              "      <td>[After, that, ,, similarities, are, calculated, based, on, the, mapped, context, vectors, using, various, measures, :, city, -, block, metric, (, CITSEG, ), ,, cosine, similarity, (, CITSEG, ), ,, weighted, jaccard, index, (, CITSEG, ), ,, Jensen, -, Shannon, divergence, (, CITSEG, ), ,, the, number, of, overlapping, context, words, (, CITSEG, ), ,, Sim, -, Rank, (, CITSEG, ), ,, euclidean, di...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>1</td>\n",
              "      <td>[Table, 1, shows, precision, and, recall, figures, obtained, with, each, semantic, model, on, these, two, data, sets, ., A, baseline, ,, computed, using, the, most, frequent, sense, in, WordNet, ,, is, also, indicated, ., The, best, results, reported, on, these, data, sets, are, 69.0, %, on, SENSEVAL, -, 2, data, (, CITSEG, ), and, 65.2, %, on, SENSEVAL, -, 3, data, (, CITSEG, ), ., Note, howe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>0</td>\n",
              "      <td>[(, k, ), odall, 's, aeco, ,, mt, does, not, deal, with, examples, such, as, (, 171, ), ), ,, which, he, argues, to, I, ), e, examples, of, 'a, different, phenomcaon, ,, llowew, ;r, flmse, can, be, incorporated, into, a, ad, ), aeco, ,, nt, (, e.g., Moltmamh, 1992, ), ., There, are, various, technical, difliculties, with, Geedali, 's, account, (, see, e.g., CITSEG, ), ., There, is, also, a, f'...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>3</td>\n",
              "      <td>[We, w, ould, like, to, thank, our, colleagues, in, BLLIP, Brown, Laboratory, for, Linguistic, Information, Processing, and, Bob, Moore, for, their, helpful, comments, on, this, paper, ., Left-corner, transforms, are, particularly, useful, because, they, can, preserve, annotations, on, productions, more, on, this, below, and, are, therefore, applicable, to, more, complex, grammar, formalisms, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, speech, and, language, processing, architecture, is, based, on, that, of, the, SRI, Command, Talk, system, (, CITSEG, ), ., The, system, comprises, a, suite, of, about, 20, agents, ,, connected, together, using, the, SPd, Open, Agent, Architecture, (, OAA, ;, (, CITSEG, ), ), ., Speech, recognition, is, performed, using, a, version, of, the, Nuance, recognizer, (, CITSEG, ), ., Initial, ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>1</td>\n",
              "      <td>[It, focusses, on, extracting, linguistic, properties, ,, as, compared, to, e.g., general, concept, learning, (, CITSEG, ), ., Unlike, CITSEG, ,, however, ,, it, is, not, confined, to, simple, morpho-syntactic, information, but, can, also, handle, selectional, restrictions, ,, semantic, types, and, argument, structure, ., Finally, ,, while, statistical, approaches, like, CITSEG, can, gather, e...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>0</td>\n",
              "      <td>[Many, of, the, NLU, systems, developed, in, the, 70's, indu(, le, (l, a, kind, of, error, recovery, Inechanisln, ranging, flom, the, treatment, only, of, spelling, e.rrors, ,, PARRY, (, 1, ), arkinson, c, 't, al., ,, 1977, ), ,, to, tile, inclusion, also, of, incomplete, int, ), ut, containing, some, kind, of, ellipsis, ,, LAD, -, DEll, ,, /, LIFEll, (, CITSEG, ), ., The, interest, in, the, 8...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>0</td>\n",
              "      <td>[Hidden, Markov, models, (, HMMs, ), are, commonly, used, to, represent, a, wide, range, of, linguistic, phenomena, in, text, ,, including, morphology, ,, parts, -, ofspeech, (, POS, ), ,, named, entity, mentions, ,, and, even, topic, changes, in, discourse, ., An, HMM, consists, of, a, set, of, states, S, ,, a, set, of, observations, (, in, our, case, words, or, tokens, ), W, ,, a, transition...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>0</td>\n",
              "      <td>[Recent, theorizing, in, linguistics, brought, forth, a, level, of, representation, called, the, Predicate, -, Argument, Structure, (, PAS, ), ., PAS, acts, as, the, interface, between, lexical, semantics, and, d-structure, in, GB, (, CITSEG, ), ,, functional, structure, in, LFG, (, CITSEG, ), ,, and, complement, structure, in, HPSG, (, CITSEG, ), ., PAS, is, the, sole, level, of, representati...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>0</td>\n",
              "      <td>[For, example, ,, it, is, not, necessary, for, all, nine, steps, to, be, composed, ., They, can, also, be, cascaded, ., In, that, case, it, will, be, possible, to, implement, different, steps, by, different, strategies, ,, e.g., by, deterministic, or, non-deterministic, transducers, or, bimachines, (, CITSEG, ), ., The, range, of, possibilities, leaves, plenty, of, room, for, future, research, .]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>0</td>\n",
              "      <td>[What, sets, this, work, apart, from, them, ,, however, ,, is, a, novel, use, we, make, of, Conditional, Random, Fields, (, CRFs, ), to, select, among, possible, compressions, (, CITSEG, ), ., An, obvious, benefit, of, using, CRFs, for, sentence, compression, is, that, the, model, provides, a, general, (, and, principled, ), probabilistic, framework, which, permits, information, from, various,...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>3</td>\n",
              "      <td>[To, address, this, issue, ,, we, propose, to, add, a, peer-review, helpfulness, model, to, current, peer-review, systems, ,, to, automat-ically, predict, peer-review, helpfulness, based, on, features, mined, from, textual, reviews, using, Natural, Language, Processing, (, NLP, ), techniques, ., Such, an, intelligent, component, could, enable, peer-review, systems, to, 1, ), control, the, qual...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>0</td>\n",
              "      <td>[This, seems, intuitively, plausible, and, means, that, the, strength, of, belief, depends, on, the, strength, of, underlying, assumptions, ,, and, that, for, all, inference, rules, that, depend, on, multiple, premises, ,, the, strength, of, an, inferred, belief, is, the, weakest, of, the, supporting, beliefs, ., This, representation, of, mutual, belief, differs, from, the, common, representat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, approach, is, presented, as, a, knowledge, poor, anaphora, resolution, algorithm, (, CITSEG, ), ,, which, makes, use, of, POS, and, NP, chunking, ,, it, tries, to, individuate, pleonastic, \", it, \", occurrences, ,, and, assigns, animacy, ., The, weighting, algorithm, seems, to, contain, the, most, original, approach, ., It, is, organized, with, a, filtering, approach, by, a, series, of, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>5</td>\n",
              "      <td>[For, instance, ,, the, TAG, in, Figure, 3, is, represented, by, the, Datalog, program, in, Figure, 4, ., Moreover, ,, the, method, of, reduc, -, Figure, 3, :, A, TAG, with, one, initial, tree, (, left, ), and, one, auxiliary, tree, (, right, ), tion, extends, to, the, problem, of, tactical, generation, (, surface, realization, ), for, these, grammar, formalisms, coupled, with, Montague, seman...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, knowledge, -, based, method, of, Lappin, and, Leass, produces, better, results, ., Nevertheless, ,, RkPSTAT, ,, a, version, of, RAP, obtained, by, using, statistically, measured, preference, patterns, for, the, antecedents, ,, prodticed, a, slight, enhancement, of, performance, over, RAP, ., Other, pronominal, resolution, approaches, promote, knowledge, -, poor, methods, (, CITSEG, ), ,,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>5</td>\n",
              "      <td>[In, addition, to, converting, the, ATB, 's, constituent, parses, to, dependency, trees, ,, we, make, a, handful, of, other, changes, ., Following, CITSEG, and, others, ,, sentences, headed, by, X, nodes, are, deleted, because, the, treebank, annotators, considered, them, unbracketable, or, somehow, erroneous, ., Following, ,, Treebank, sentences, headed, by, TOP, elements, containing, multipl...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>2</td>\n",
              "      <td>[The, grammar, employed, is, a, partial, characterisation, of, Chomsky, 's, Government, -, Binding, theory, [, CITSEG, ], and, only, takes, account, of, very, local, constralnts, (, i.e., X, -bar, ,, Theta, and, Case, ), ;, a, way, of, encoding, all, constraints, in, the, proper, branch, formalism, (, e.g., [, Crocker, 1992, ], ), will, be, needed, before, a, grammar, of, sufficient, coverage,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>0</td>\n",
              "      <td>[It, is, widely, acknowledged, that, a, full, account, of, natural, language, utterances, can, not, be, given, in, terms, of, only, syntactic, or, semantic, phenomena, ., For, example, ,, CITSEG, has, shown, that, in, order, to, understand, a, scalar, implicature, ,, one, must, analyze, the, conversants, ', beliefs, and, intentions, ., To, recognize, normal, state, implicatures, one, must, con...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272</th>\n",
              "      <td>1</td>\n",
              "      <td>[These, proposed, methods, for, extracting, word, correspondences, from, bilingual, corpora, have, the, following, drawbacks, ., First, ,, most, of, theln, assume, that, the, input, corpora, m'e, aligned, sentence, by, sentence, ,, which, reduces, their, applicability, remarkably, ., Although, a, number, of, automatic, sentence, alignment, methods, have, been, proposed, (, CITSEG, b, ;, CITSEG...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>5</td>\n",
              "      <td>[CITSEG, use, some, combination, of, lexical, ,, phonological, ,, and, morphological, data, ., CITSEG, described, the, dialectal, distances, in, Acadian, villages, by, the, degree, to, which, their, fishing, terminology, varied, ., CITSEG, did, a, similar, analysis, based, on, the, varying, pronunciation, of, /, r/., CITSEG, grouped, the, Gaelic, dialects, on, the, basis, of, whether, the, voc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>2</td>\n",
              "      <td>[Ellipsis, interpretations, are, represented, as, simple, sets, of, substitutions, on, semantic, representations, of, the, antecedent, ., The, substitutions, can, be, built, up, in, an, order, -, independent, way, (, i.e., before, ,, after, or, during, scoping, ), ,, and, without, recourse, to, higherorder, unification, ., The, treatment, is, similar, to, the, discourse, copying, analysis, of,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>0</td>\n",
              "      <td>[These, axioms, are, based, on, the, lexieal, semantics, of, CoL, verbs, and, of, spatial, prepositions, ., They, also, take, into, account, the, syntactic, structure, of, the, sentence, (, we, have, supposed, an, X, -, bar, syntax, with, a, VP, internal, subject, ,, though, this, is, not, essential, ), and, the, links, which, exist, at, the, level, of, diseours, between, this, sentence, and, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, higher, -, order, unification, method, developed, by, CITSEG, could, be, used, for, this, purpose, ;, in, this, case, the, sentence, -, level, semantics, is, recovered, without, copying, any, syntactic, representations, ., Event, referential, forms, such, as, do, it, ,, do, tha~, ,, and, do, so, constitute, full, verb, phrases, in, the, syntax, ., It, has, been, often, noted, (, CITSEG, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, former, stem, from, the, work, of, Halliday, and, Hasan, (, CITSEG, ), ., They, proposed, that, text, segments, with, similar, vocabulary, are, likely, to, be, part, of, a, coherent, topic, segment, ., hnplementations, of, this, idea, use, word, stem, repetition, (, CITSEG, ), ,, context, vectors, (, CITSEG, ), ,, entity, repetition, (, CITSEG, ), ,, semantic, similarity, (, CITSEG, ), ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>1</td>\n",
              "      <td>[To, do, this, ,, we, search, for, association, rules, describing, the, appraisal, features, that, can, be, found, in, a, single, appraisal, expression, ., We, generally, look, for, rules, that, contain, attitude, type, ,, orientation, ,, thing, type, ,, and, a, product, name, ,, when, these, rules, occur, more, frequently, than, expected, ., The, idea, is, similar, to, CITSEG, 's, notion, of,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>0</td>\n",
              "      <td>[In, the, above, example, ,, this, would, result, in, two, lexical, rules, :, one, for, words, with, tl, as, their, c, value, and, one, for, those, with, t, 2, as, their, c, value, ., In, the, latter, case, ,, we, can, also, take, care, of, transferring, the, value, of, z, ., However, ,, as, discussed, by, CITSEG, ,, creating, several, instances, of, lexical, rules, can, be, avoided, ., Instea...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280</th>\n",
              "      <td>5</td>\n",
              "      <td>[(, 15, ), The, tire, flattened, ., v, δ, P, DP, tire, v, δ, -, en, v, BE, P, v, BE, √, flat, ARG, δ, (, tire, ,, e), ∧, BECOME, (, BE, (, [, state, flat, ], ), ,, e), In, (, CITSEG, ), ,, I, present, evidence, from, Mandarin, Chinese, that, this, analysis, is, on, the, right, track, ., The, rest, of, this, paper, ,, however, ,, will, be, concerned, with, the, computational, implementation, of...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>0</td>\n",
              "      <td>[For, example, ,, in, crosslanguage, information, retrieval, ,, glossing, a, document, often, provides, a, sufficient, translation, for, humans, to, comprehend, the, key, concepts, ., Furthermore, ,, a, glossing, algorithm, can, be, used, for, lexical, selection, in, a, full, -, fledged, machine, translation, (, MT, ), system, ., Many, corpus, -, based, MT, systems, require, parallel, corpora,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>4</td>\n",
              "      <td>[1, The, extraction, patterns, (, EPs, ), were, automatically, generated, using, the, Sundance, /, AutoSlog, software, package, (, CITSEG, ), ., AutoSlog, relies, on, the, Sundance, shallow, parser, and, can, be, applied, exhaustively, to, a, text, corpus, to, generate, IE, patterns, that, can, extract, every, noun, phrase, in, the, corpus, ., Au-to, Slog, has, been, used, to, learn, IE, patte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283</th>\n",
              "      <td>4</td>\n",
              "      <td>[In, most, recent, parsing, work, the, history, consists, of, a, small, number, of, manually, selected, features, (, CITSEG, ), ., Other, researchers, have, proposed, automatically, selecting, the, conditioning, information, for, various, states, of, the, model, ,, thus, potentially, increasing, greatly, the, space, of, possible, features, and, selectively, choosing, the, best, predictors, for...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>5</td>\n",
              "      <td>[To, validate, the, model, ,, we, test, unsupervised, learning, of, tags, conditioned, on, a, given, dependency, tree, structure, ., This, is, useful, ,, because, coarse-, grained, syntactic, categories, ,, such, as, those, used, in, the, Penn, Treebank, (, PTB, ), ,, make, insufficient, distinctions, to, be, the, basis, of, accurate, syntactic, parsing, (, CITSEG, ), ., Hence, ,, state, -, of...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>5</td>\n",
              "      <td>[During, the, categorization, phase, ,, the, representation, is, used, to, assign, the, appropriate, class, to, a, new, document, vector, ., Several, pruning, or, specialization, heuristics, can, be, used, to, control, the, amount, of, generalization, ., We, used, ID3, (, CITSEG, ), ,, C4.5, (, CITSEG, ), and, C5.0, ,, RIPPER, (, CITSEG, ), ,, and, the, Naive, Bayes, inducer, (, CITSEG, ), con...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>0</td>\n",
              "      <td>[For, both, applications, ,, a, tagger, with, the, highest, possible, accuracy, is, required, ., The, debate, about, which, paradigm, solves, the, part-of, -, speech, tagging, problem, best, is, not, finished, ., Recent, comparisons, of, approaches, that, can, be, trained, on, corpora, (, CITSEG, ), have, shown, that, in, most, cases, statistical, aproaches, (, CITSEG, ), yield, better, result...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>1</td>\n",
              "      <td>[Traditionally, ,, some, of, the, most, relevant, approaches, to, solve, anaphora, have, been, those, called, poor-knowledge, approaches, ., They, use, limited, knowledge, (, lexical, ,, morphological, and, syntactic, information, sources, ), for, the, detection, of, the, correct, antecedent, ., These, proposals, have, report, high, success, rates, for, English, (, 89.7, %, ), (, CITSEG, ), an...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, will, return, to, this, point, in, §, 5, ., By, inspecting, the, values, of, A4, in, terms, of, the, grammar, probabilities, indicates, that, ., h4, ij, contains, the, values, we, wanted, ,, i.e., expectation, of, obtaining, node, Aj, when, node, Ai, is, rewritten, by, adjunction, at, each, level, of, the, TAG, derivation, process, ., By, construction, we, have, ensured, that, the, follow...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>0</td>\n",
              "      <td>[H, :, No, rabies, cases, have, been, confirmed, ., Because, it, drops, important, qualifiers, in, a, negative, context, ,, the, hypothesis, does, not, follow, ;, yet, both, the, lexical, content, and, the, predicate, -, argument, structure, of, the, hypothesis, closely, match, the, premise, ., At, the, other, extreme, ,, textual, inference, can, be, approached, as, deduction, ,, building, on,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>0</td>\n",
              "      <td>[CITSEG, have, noted, the, importance, of, a, cooperative, system, providing, support, for, its, responses, ., They, identified, strategies, that, a, system, can, adopt, in, justifying, its, beliefs, ;, however, ,, they, did, not, specify, the, criteria, under, which, each, of, these, strategies, should, be, selected, ., CITSEG, described, a, method, of, determining, when, to, include, optiona...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>1</td>\n",
              "      <td>[To, measure, the, similarity, between, gesture, trajectories, ,, we, use, dynamic, time, warping, (, CITSEG, ), ,, which, gives, a, similarity, metric, for, temporal, data, that, is, invariant, to, speed, ., This, is, reported, in, the, DTW, -, DISTANCE, feature, ., All, features, are, computed, from, hand, and, body, pixel, coordinates, ,, which, are, obtained, via, computer, vision, ;, our,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>5</td>\n",
              "      <td>[By, implementing, our, own, version, of, the, publicly, available, Collins, parser, (, CITSEG, ), ,, we, also, learned, a, dependency, model, that, enables, the, mapping, of, parse, trees, into, sets, of, binary, relations, between, the, head, -, word, of, each, constituent, and, its, sibling, -, words, ., For, example, ,, the, parse, tree, of, TREC, -, 9, question, Q210, :, \", How, many, dog...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, hypothesized, that, IE, techniques, would, be, wellsuited, for, source, identification, because, an, opinion, statement, can, be, viewed, as, a, kind, of, speech, event, with, the, source, as, the, agent, ., We, investigate, two, very, different, learning, -, based, methods, from, information, extraction, for, the, problem, of, opinion, source, identification, :, graphical, models, and, e...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, topicalized, partial, vP, \", Anna, lichen, \", receives, its, restricting, semantic, information, from, the, auxiliary, verb, and, upon, its, evaluation, provides, essential, bindings, not, only, for, the, direct, object, ,, but, also, for, the, subject, that, stayed, behind, in, the, Mittelfeld, together, with, the, auxiliary, verb, ., These, mutual, dependencies, between, the, subconsti...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, B&amp;C, scheme, is, similar, to, the, original, DepBank, scheme, (, CITSEG, ), ,, but, overall, contains, less, grammatical, detail, ;, describes, the, differences, ., We, chose, this, resource, for, the, following, reasons, :, it, is, publicly, available, ,, allowing, other, researchers, to, compare, against, our, results, ;, the, GRs, making, up, the, annotation, share, some, similarities...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>1</td>\n",
              "      <td>[In, other, words, ,, a, smaller, distance, indicates, greater, similarity, ., The, reason, for, choosing, this, measure, is, that, it, can, be, used, to, compute, the, distance, between, any, two, co-occurrence, vectors, independent, of, any, information, about, other, words, ., This, is, in, contrast, to, many, other, measures, ,, e.g., ,, CITSEG, ,, which, use, the, co-occurrences, of, feat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>4</td>\n",
              "      <td>[For, a, node, v, i, ,, we, can, then, describe, the, pure, model, of, spreading, activation, as, follows, :, EQUATION, This, pure, model, of, SA, has, several, significant, problems, ,, the, most, notable, being, that, activation, can, saturate, the, entire, network, unless, certain, constraints, are, imposed, ,, namely, limiting, how, far, activation, can, spread, from, the, initially, activ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>1</td>\n",
              "      <td>[Second, ,, we, wished, to, investigate, how, well, our, approach, would, work, for, determining, prosodic, phrasing, in, a, text, -, to, -, speech, synthesizer, ., Existing, text, -, to, -, speech, systems, perform, well, on, word, pronunciation, and, short, sentences, ,, 12, but, when, it, comes, to, long, sentences, and, paragraphs, ,, synthetic, speech, tends, to, be, difficult, to, listen...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>4</td>\n",
              "      <td>[We, use, TiMBL, (, CITSEG, ), ,, a, memory, -, based, learner, (, MBL, ), ,, for, both, phases, ., We, use, TiMBL, because, MBL, has, been, shown, to, work, well, with, small, data, sets, (, CITSEG, ), ;, allows, for, the, use, of, both, text, -, based, and, numeric, features, ;, and, does, not, suffer, from, a, fragmented, class, space, ., We, mostly, use, the, default, settings, of, TiMBL, ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>0</td>\n",
              "      <td>[Several, types, of, research, have, involved, document, -, level, subjectivity, classification, ., Some, work, identifies, inflammatory, texts, (, e.g., ,, (, CITSEG, ), ), or, classifies, reviews, as, positive, or, negative, (, (, CITSEG, ), ), ., Tong, 's, system, (, CITSEG, ), generates, sentiment, timelines, ,, tracking, online, discussions, and, creating, graphs, of, positive, and, negat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>5</td>\n",
              "      <td>[Prior, work, has, reported, that, certain, grammatical, productions, are, repeated, in, adjacent, sentences, more, often, than, would, be, expected, by, chance, (, CITSEG, ), ., We, analyze, all, co-occurrence, patterns, rather, than, just, repetitions, ., We, use, the, gold, standard, parse, trees, from, the, Penn, Treebank, (, CITSEG, ), ., Our, unit, of, analysis, is, a, pair, of, adjacent...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, independence, assumption, can, also, be, made, in, the, case, of, a, class, -, based, model, or, a, slot, -based, model, ., For, slot, -, based, models, ,, with, tile, independence, assumption, ,, P.~, (, X, ,, ~, ,, ith, =, 1, ), and, Ps, ,, .l, (, Xwitfl, =, 1, ), are, to, be, compared, (, c.f., (, CITSEG, ), ), ., Assuming, that, random, variables, (, case, slots, ), are, mutually, in...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>5</td>\n",
              "      <td>[Three, papers, already, annotated, according, to, the, GENIA, event, annotation, scheme, (, CITSEG, ), ,, were, further, annotated, according, to, the, three, annotation, schemes, described, above, ., We, obtained, all, corresponding, CoreSCs, ,, events, and, segments, per, sentence, ., Each, sentence, has, a, single, CoreSC, annotation, and, one, or, more, segment, annotations, (, depending,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, committee, membership, information, that, we, used, in, the, experiments, is, from, Stewart, and, Woon, 's, committee, assignment, codebook, (, CITSEG, ), ., This, provided, us, with, a, roster, for, each, committee, and, rank, and, seniority, information, for, each, member, ., In, our, experiments, we, use, the, rank, within, party, and, committee, seniority, member, attributes, to, tes...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>1</td>\n",
              "      <td>[Table, 1, shows, our, results, for, each, of, our, selected, models, with, our, compositionality, evaluation, ., The, 2D, models, employing, feature, norms, and, association, norms, do, significantly, better, than, the, text, -, only, model, (, two-tailed, t-test, ), ., This, result, is, consistent, with, other, works, using, this, model, with, these, features, (, CITSEG, ), .]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>0</td>\n",
              "      <td>[This, highlights, a, problem, with, human-generated, ontologies, :, substantial, errors, of, omission, ., The, existing, approaches, to, ontology, induction, include, those, that, start, from, structured, data, ,, merging, ontologies, or, database, schemas, (, CITSEG, ), ., Other, approaches, use, natural, language, data, ,, sometimes, just, by, analyzing, the, corpus, (, CITSEG, ), ,, (, CIT...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307</th>\n",
              "      <td>5</td>\n",
              "      <td>[By, inspecting, the, values, of, A4, in, terms, of, the, grammar, probabilities, indicates, that, ., h4, ij, contains, the, values, we, wanted, ,, i.e., expectation, of, obtaining, node, Aj, when, node, Ai, is, rewritten, by, adjunction, at, each, level, of, the, TAG, derivation, process, ., By, construction, we, have, ensured, that, the, following, theorem, from, (, CITSEG, ), applies, to, p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>308</th>\n",
              "      <td>0</td>\n",
              "      <td>[One, widely, used, approach, to, evaluation, is, based, on, the, notion, of, a, reference, answer, (, CITSEG, ), ., An, agent, 's, responses, to, a, query, are, compared, with, a, predefined, key, of, minimum, and, maximum, reference, answers, ;, performance, is, the, proportion, of, responses, that, match, the, key, ., This, approach, has, many, widely, acknowledged, limitations, (, CITSEG, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309</th>\n",
              "      <td>0</td>\n",
              "      <td>[Following, the, work, of, ,, for, example, ,, CITSEG, ,, lust, and, CITSEG, and, Altma.nn, al, ]d, CITSEG, ,, it, has, heroine, widely, accepted, that, semantic, i11terpretation, in, hnman, sentence, processing, can, occur, beibre, sentence, boundaries, and, even, before, clausal, boundaries, ., It, is, less, widely, accepted, that, there, is, a, need, for, incremental, interpretation, in, co...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>310</th>\n",
              "      <td>5</td>\n",
              "      <td>[Our, approach, to, grammar, lexicalization, is, class, -, based, in, the, sense, that, we, use, classbased, estimated, frequencies, f, c, (, v, n, ), of, headverbs, v, and, argument, head, -, nouns, n, instead, of, pure, frequency, statistics, or, classbased, probabilities, of, head, word, dependencies, ., Class, -, based, estimated, frequencies, are, introduced, in, CITSEG, as, the, frequenc...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>5</td>\n",
              "      <td>[Two, speech, samples, from, each, of, three, subjects, were, used, in, the, simulations, in, one, sample, a, mother, was, speaking, to, her, daughter, and, in, the, other, ,, the, same, mother, was, speaking, to, the, researcher, ., The, samples, were, taken, from, the, CHILDES, database, (, CITSEG, ), from, studies, reported, in, CITSEG, ., Each, sample, was, checked, for, consistent, word, ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>312</th>\n",
              "      <td>3</td>\n",
              "      <td>[However, ,, inference, with, these, more, complex, models, will, probably, itself, become, more, complex, ., The, MCMC, sampler, of, CITSEG, used, here, is, satifactory, for, small, and, medium, -, sized, problems, ,, but, it, would, be, very, useful, to, have, more, efficient, inference, procedures, ., It, may, be, possible, to, adapt, efficient, split-merge, samplers, (, CITSEG, ), and, Var...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313</th>\n",
              "      <td>0</td>\n",
              "      <td>[Previous, simulations, in, word, segmentation, using, the, same, type, of, distributional, information, as, many, statistical, optimization, -, based, learners, but, without, an, optimization, model, suggest, that, statistics, alone, are, not, sufficient, for, learning, to, succeed, in, a, computationally, efficient, online, manner, ;, further, constraints, on, the, search, space, are, needed...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, improved, system, combination, method, was, compared, to, a, simple, confusion, network, decoding, without, system, weights, and, the, method, proposed, in, (, CITSEG, ), on, the, Arabic, to, English, and, Chinese, to, English, NIST, MT05, tasks, ., Six, MT, systems, were, combined, :, three, (, A,C,E, ), were, phrasebased, similar, to, (, CITSEG, ), ,, two, (, B,D, ), were, hierarchical...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315</th>\n",
              "      <td>0</td>\n",
              "      <td>[Order, -, independence, can, be, shown, to, hold, for, grammars, that, contain, no, unary, or, epsilon, (, 'empty, ', ), rules, ,, i.e., rules, whose, righthand, sides, have, one, or, zero, elements, ., The, grammar, that, we, have, extracted, from, PTB, II, ,, and, which, is, used, in, the, compaction, experiments, reported, in, the, next, section, ,, is, one, that, excludes, such, rules, .,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316</th>\n",
              "      <td>2</td>\n",
              "      <td>[This, seems, like, a, plausible, explanation, ,, since, it, implies, that, the, source, and, target, domains, may, not, be, that, different, ., If, the, domains, are, so, similar, that, a, large, amount, of, source, data, outperforms, a, small, amount, of, target, data, ,, then, it, is, unlikely, that, blow, -, ing, up, the, feature, space, will, help, ., We, additionally, ran, the, MEGAM, mo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317</th>\n",
              "      <td>1</td>\n",
              "      <td>[\", Semantic, \", here, means, that, the, collocations, the, algorithm, discovers, are, not, collocations, among, words, in, the, sense, of, traditional, linguistics, but, collocations, that, reflect, ontological, relations, among, entities, in, given, subject, domains, ., We, expect, that, the, knowledge, to, be, extracted, will, not, only, be, useful, for, disambiguating, sentences, but, also...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>1</td>\n",
              "      <td>[It, s, details, are, not, important, for, our, aim, of, giving, a, semantic, interpretation, of, paragraphs, ;, the, main, theses, of, our, theory, do, not, depend, on, a, logical, notation, ., So, we, will, use, a, very, simple, formalism, ,, like, the, one, above, ,, resembling, the, standard, first, order, language, ., But, ,, obviously, ,, there, are, other, possibilities, --, for, instan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>0</td>\n",
              "      <td>[CITSEG, notes, that, conceptual, spelling, correction, is, part, of, a, closely, related, class, of, problems, which, include, word, sense, disambiguation, ,, word, choice, selection, in, machine, translation, ,, and, accent, and, capitalization, restoration, ., This, class, of, problems, has, been, attacked, by, many, others, ., A, number, of, feature, -, based, methods, have, been, tried, ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>4</td>\n",
              "      <td>[19, Multiple, edges, from, j, to, k, are, summed, into, a, single, edge, ., (, CITSEG, ), ., Efficient, hardware, implementation, is, also, possible, via, chip-level, parallelism, (, CITSEG, ), .•, In, many, cases, of, interest, ,, T, i, is, an, acyclic, graph, ., 20, Then, Tarjan, 's, method, computes, w, 0, j, for, each, j, in, topologically, sorted, order, ,, thereby, finding, t, i, in, a,...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>2</td>\n",
              "      <td>[State, parameters, include, the, PSA, 's, current, position, ,, some, environmental, variables, such, as, local, temperature, ,, pressure, and, carbon, dioxide, levels, ,, and, the, status, of, the, Shuttle, 's, doors, (, open, /, closed, ), ., A, visual, display, gives, direct, feedback, on, some, of, these, parameters, ., The, speech, and, language, processing, architecture, is, based, on, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, summarisation, system, can, then, use, this, information, to, generate, template, -, like, abstracts, :, Main, goal, of, the, text, :..., ;, Builds, on, work, by, :..., ;, Contrasts, with, :..., ;, etc., Second, ,, the, question, of, what, constitutes, a, useful, gold, standard, has, not, yet, been, solved, satisfactorily, ., Researchers, developing, corpus, resources, for, summarisation...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>4</td>\n",
              "      <td>[Grammar, extraction, algorithm, Systemic, Functional, Grammar, (, SFG, ), (, CITSEG, ), is, based, on, the, assumption, that, the, differentiation, of, syntactic, phenomena, is, always, deter-mined, by, its, function, in, the, communicative, context, ., This, functional, orientation, has, lead, to, the, creation, of, detailed, linguistic, resources, that, are, characterized, by, an, integrate...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324</th>\n",
              "      <td>0</td>\n",
              "      <td>[This, ordering, reflects, the, relative, defeasibility, of, different, assumptions, ., Augmenting, the, strength, of, an, assumption, thus, decreases, its, relative, defensibility, ., A, claim, of, this, paper, i8, that, one, role, of, IRU, 's, is, to, ensure, that, these, assumptions, are, supported, by, evidence, ,, thus, decreasing, the, defensibility, of, the, mutual, beliefs, that, depen...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>5</td>\n",
              "      <td>[•, Simple, -, Voting, is, the, most, simple, majority, voting, with, word, -, level, polarity, (, Section, 3, ), ., •, Negation, Voting, proposed, by, CITSEG, is, the, majority, voting, that, takes, negations, into, account, ., As, negations, ,, we, employed, not, ,, no, ,, yet, ,, never, ,, none, ,, nobody, ,, nowhere, ,, nothing, ,, and, neither, ,, which, are, taken, from, (, CITSEG, ), (,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326</th>\n",
              "      <td>1</td>\n",
              "      <td>[However, ,, these, approaches, focused, on, the, studies, of, bilingual, corpus, synthesis, and, exploitation, while, ignoring, the, monolingual, corpora, ,, therefore, limiting, the, potential, of, further, translation, quality, improvement, ., In, this, paper, ,, we, propose, a, novel, adaptation, method, to, adapt, the, translation, model, for, domainspecific, translation, task, by, utiliz...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327</th>\n",
              "      <td>2</td>\n",
              "      <td>[While, user, session, segmentation, can, be, improved, with, more, sophisticated, algorithms, ,, this, simple, low-, cost, heuristic, performs, adequately, for, our, purposes, ., We, then, move, on, to, map, queries, to, Freebase, and, empirically, filter, sessions, that, are, less, entity, -, centric, ., We, use, an, annotation, tool, especially, for, short, text, (, CITSEG, ), called, Tagme...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>0</td>\n",
              "      <td>[Following, G&amp;G, ,, we, require, that, the, prosody, rules, build, a, binary, tree, whose, terminals, are, phonological, words, and, whose, node, labels, are, indices, that, mark, boundary, salience, ., An, alternative, representation, based, on, CITSEG, is, presented, in, CITSEG, ,, which, contends, that, prosody, ,, including, prosodic, phrasing, ,, is, more, properly, represented, as, a, gr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329</th>\n",
              "      <td>1</td>\n",
              "      <td>[To, the, best, of, our, knowledge, ,, there, are, only, a, few, works, that, try, to, study, the, expressive, power, of, phrase, -, based, machine, translation, systems, or, to, provide, tools, for, analyzing, potential, causes, of, failure, ., The, approach, described, in, (, CITSEG, ), is, very, similar, to, ours, :, in, this, study, ,, the, authors, propose, to, find, and, analyze, the, li...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>330</th>\n",
              "      <td>1</td>\n",
              "      <td>[While, current, models, focus, solely, on, efficient, decoding, ,, discriminative, models, must, also, allow, for, efficient, training, ., Past, work, on, discriminative, SMT, only, address, some, of, these, problems, ., To, our, knowledge, no, systems, directly, address, Problem, 1, ,, instead, choosing, to, ignore, the, problem, by, using, one, or, a, small, handful, of, reference, derivati...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>331</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, also, added, manually, -, developed, features, found, by, other, researchers, ., We, created, 14, feature, sets, representing, some, classes, from, (, CITSEG, ), ,, some, Framenet, lemmas, with, frame, element, experiencer, (, CITSEG, ), ,, adjectives, manually, annotated, for, polarity, (, CITSEG, ), ,, and, some, subjectivity, clues, listed, in, (, CITSEG, ), ., We, represented, each, s...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>332</th>\n",
              "      <td>2</td>\n",
              "      <td>[Speech, repairs, are, common, in, spontaneous, speech, -, one, study, found, 30, %, of, dialogue, turns, contained, repairs, (, CITSEG, ), and, another, study, found, one, repair, every, 4.8, seconds, (, CITSEG, ), ., Because, of, the, relatively, high, frequency, of, this, phenomenon, ,, spontaneous, speech, recognition, systems, will, need, to, be, able, to, deal, with, repairs, to, achieve...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>333</th>\n",
              "      <td>0</td>\n",
              "      <td>[Com-mand, Talk, (, CITSEG, ), ,, Circuit, Fix, -, It, Shop, (, CITSEG, ), and, (, CITSEG, ), are, spoken, language, systems, but, they, interface, to, simulation, or, help, facilities, rather, than, semi-autonomous, agents, ., Jack, 's, MOOse, Lodge, (, CITSEG, ), takes, text, rather, than, speech, as, natural, language, input, and, the, avatars, being, controlled, are, not, semi-autonomous, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334</th>\n",
              "      <td>0</td>\n",
              "      <td>[Finally, ,, our, procedure, induces, a, \", hard, \", part, -ofspeech, classification, of, occurrences, in, context, ,, i.e., ,, each, occurrence, is, assigned, to, only, one, category, ., It, is, by, no, means, generally, accepted, that, such, a, classification, is, linguistically, adequate, ., There, is, both, synchronic, (, CITSEG, ), and, diachronic, (, CITSEG, ), evidence, suggesting, that...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335</th>\n",
              "      <td>0</td>\n",
              "      <td>[Other, research, directed, towards, improving, the, throughput, of, unification, -, based, parsing, systems, has, been, concerned, with, the, unification, operation, itself, ,, which, can, consume, up, to, 90, %, of, parse, time, (, e.g., CITSEG, ), in, systems, using, lexicalist, grammar, formalisms, (, e.g., HPSG, ;, CITSEG, ), ., However, ,, parsing, algorithms, assume, more, importance, f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>336</th>\n",
              "      <td>1</td>\n",
              "      <td>[What, restrictions, apply, ?, which, cannot, be, felicitously, uttered, except, in, a, context, where, there, is, something, in, the, discourse, that, a, restriction, could, \", apply, \", to, ., Conventional, approaches, to, subcategorization, ,, such, as, Definite, Clause, Grammar, (, CITSEG, ), ,, Categorial, Grammar, (, CITSEG, ), ,, PATR, -, II, (, CITSEG, ), ,, and, lexicalized, TAG, (, C...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337</th>\n",
              "      <td>0</td>\n",
              "      <td>[Most, of, the, items, are, single, words, ,, some, are, N-grams, ,, but, none, involve, syntactic, generalizations, as, in, the, extraction, patterns, ., Any, data, used, to, develop, this, vocabulary, does, not, overlap, with, the, test, sets, or, the, unannotated, data, used, in, this, paper, ., Many, of, the, subjective, clues, are, from, manually, developed, resources, ,, including, entri...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, results, of, each, of, the, predictors, used, in, the, Inside, /, 0utside, method, are, presented, in, Table, 3, ., The, results, are, comparable, to, other, results, reported, using, the, Inside, /, Outside, method, (, CITSEG, ), (, see, Table, 7, ., We, have, observed, that, most, of, the, mistaken, predictions, of, base, NPs, involve, predictions, with, respect, to, conjunctions, ,, g...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>4</td>\n",
              "      <td>[Mention, detection, ., Many, ACE, participants, have, also, adopted, a, corpus, -, based, approach, to, SC, determination, that, is, investigated, as, part, of, the, mention, detection, (, MD, ), task, (, e.g., ,, CITSEG, ), ., Briefly, ,, the, goal, of, MD, is, to, identify, the, boundary, of, a, mention, ,, its, mention, type, (, e.g., ,, pronoun, ,, name, ), ,, and, its, semantic, type, (,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340</th>\n",
              "      <td>3</td>\n",
              "      <td>[Our, model, avoids, the, estimation, biases, associated, with, heuristic, frequency, count, approaches, and, uses, standard, regularisation, techniques, to, avoid, degenerate, maximum, likelihood, solutions, ., Having, demonstrated, the, efficacy, of, our, model, with, very, simple, features, ,, the, logical, next, step, is, to, investigate, more, expressive, features, ., Promising, features,...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, HMM, part-of-, speech, tagging, model, and, corresponding, Viterbi, algorithm, were, implemented, based, on, their, description, in, the, updated, version, ,, http://www.cs.colorado.edu/˜martin/, SLP/updated.html, ,, of, chapter, 8, of, (, CITSEG, ), ., A, model, was, trained, using, Maximum, Likelihood, from, the, UPenn, Treebank, (, CITSEG, ), ., The, input, model, file, is, encoded, u...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>5</td>\n",
              "      <td>[Table, 1, shows, the, text, format, for, LM, training, data, after, segmentation, with, each, model, ., As, can, be, seen, ,, the, wordbased, approach, does, n't, use, word, boundary, tokens, ., (, CITSEG, ), were, used, with, no, limits, as, to, the, order, of, n-grams, ,, but, limiting, the, number, of, counts, to, 4.8, and, 5, million, counts, ., In, some, models, this, growing, method, re...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>0</td>\n",
              "      <td>[•, UTTERANCE, TYPES, 4, The, theory, of, centering, ,, which, is, part, of, attentional, state, ,, depends, on, discourse, participants, ', recognizing, the, beginning, and, end, of, a, discourse, segment, [, CITSEG, ], ., 5, The, relationship, between, utterance, level, meaning, and, discourse, intentions, rests, on, a, theory, of, joint, commitment, or, shared, plans, [, CITSEG, ], Note, th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>0</td>\n",
              "      <td>[In, the, literature, of, norl-incremental, generation, ,, the, need, for, defaults, is, hardly, ever, taken, into, account, ., The, conunon, point, of, view, restricts, the, iulmt, to, be, sulIicient, for, generation, (, see, ,, e.g., ,, the, Te:ct, Slructure, by, (, CITSEG, ), for, a, syntactic, generator, ), ., In, incremental, gm, ,, eration, ,, most, authors, agree, on, the, necessity, of...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>0</td>\n",
              "      <td>[In, other, words, ,, the, derivations, by, the, parser, must, saturate, the, combinators, in, order, to, reveal, the, PAS, ,, which, should, contain, no, combinators, ., PAS, is, the, semantic, normal, form, of, a, derivation, ., The, sequence, of, evaluation, is, the, normal, order, ,, which, corresponds, to, reducing, the, leftmostoutermost, redex, first, (, CITSEG, ), ., In, treetheoretic,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>1</td>\n",
              "      <td>[Although, much, faster, than, full, -, integration, ,, cube, pruning, still, computes, a, fixed, amount, of, +, LM, items, at, each, node, ,, many, of, which, will, not, be, useful, for, arriving, at, the, 1, -, best, hypothesis, at, the, root, ., It, would, be, more, efficient, to, compute, as, few, +, LM, items, at, each, node, as, are, needed, to, obtain, the, 1, -, best, hypothesis, at, t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>4</td>\n",
              "      <td>[We, use, the, usual, m-gram, approximation, to, model, the, joint, probability, of, a, transformation, :, p, (, S, ,, T, ), =, M, i, =1, p, (, s, i, ,, τ, i, |s, i, −, m, +, 1, ,, τ, i, −, m+, 1, ,, ., ., ., s, i−, 1, ,, τ, i−1, ), (, 2, ), The, work, of, CITSEG, is, similar, in, spirit, to, this, method, ,, but, uses, a, factored, sourcechannel, model, ., Note, that, the, decision, rule, (, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, former, stem, from, the, work, of, Halliday, and, Hasan, (, CITSEG, ), ., They, proposed, that, text, segments, with, similar, vocabulary, are, likely, to, be, part, of, a, coherent, topic, segment, ., hnplementations, of, this, idea, use, word, stem, repetition, (, CITSEG, ), ,, context, vectors, (, CITSEG, ), ,, entity, repetition, (, CITSEG, ), ,, semantic, similarity, (, CITSEG, ), ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>5</td>\n",
              "      <td>[It, contains, 15, fields, to, be, extracted, :, title, ,, author, ,, affiliation, ,, address, ,, note, ,, email, ,, date, ,, abstract, ,, introduction, ,, phone, ,, keywords, ,, web, ,, degree, ,, publication, number, ,, and, page, (, CITSEG, ), ., The, header, dataset, contains, 935, headers, ., Following, previous, research, (, CITSEG, ), ,, for, each, trial, we, randomly, select, 500, for,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>1</td>\n",
              "      <td>[These, results, are, achieved, using, most, frequent, sense, information, ,, which, surprisingly, outperforms, both, goldstandard, senses, and, automatic, WSD, ., The, results, are, notable, in, demonstrating, that, very, simple, preprocessing, of, the, parser, input, facilitates, significant, improvements, in, parser, performance, ., We, provide, the, first, definitive, results, that, word, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351</th>\n",
              "      <td>1</td>\n",
              "      <td>[On, the, other, hand, ,, our, data, takes, into, account, syntactic, information, ,, while, the, target, classification, is, not, only, based, on, syntax, ,, but, also, on, other, aspects, of, the, properties, of, the, verbs, ., These, results, compare, poorly, to, the, performance, achieved, by, (, CITSEG, ), ,, who, obtains, an, Adjusted, Rand, measure, of, 0.15, in, a, similar, task, ,, in...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, first, supplies, each, edge, in, the, chart, with, two, indices, ,, a, backward, index, pointing, to, the, state, in, the, chart, that, the, edge, is, predicted, from, ,, and, a, forward, index, poinfing, to, the, states, that, are, predicted, from, the, edge, ., By, matching, forward, and, backward, indices, ,, the, edges, that, must, be, combined, for, completion, can, be, located, fas...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>2</td>\n",
              "      <td>[Other, related, work, includes, a, bilingual, capitalization, model, for, capitalizing, machine, translation, (, MT, ), outputs, ,, using, conditional, random, fields, (, CRFs, ), reported, by, (, CITSEG, ), ., This, work, exploits, case, information, both, from, source, and, target, sentences, of, the, MT, system, ,, producing, better, performance, than, a, baseline, capitalizer, using, a, t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354</th>\n",
              "      <td>0</td>\n",
              "      <td>[Glossaries, find, obvious, use, as, sources, of, reference, ., A, survey, on, the, use, of, lexicographical, aids, in, specialized, translation, showed, that, glossaries, are, among, the, top, five, resources, used, (, CITSEG, ), ., Glossaries, have, also, been, shown, to, facilitate, reception, of, texts, and, acquisition, of, knowledge, during, study, (, CITSEG, ), ,, while, selfexplanation...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>2</td>\n",
              "      <td>[The, top, feature, structure, encodes, information, that, needs, to, be, percolated, up, the, tree, should, an, adjunction, take, place, ., In, contrast, ,, the, bottom, feature, structure, encodes, information, that, remains, local, to, the, node, at, which, adjunction, takes, place, ., The, language, chosen, for, semantic, representation, is, a, flat, semantics, along, the, line, of, (, CIT...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, first, trial, application, of, the, automatic, subgrammar, extraction, tool, has, been, carried, out, for, an, information, system, with, an, output, component, that, generates, integrated, text, and, graphics, ., This, information, system, has, been, developed, for, the, domain, of, art, history, and, is, capable, of, providing, short, biography, articles, for, around, l, 0, 000, artist...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357</th>\n",
              "      <td>2</td>\n",
              "      <td>[The, best, performance, on, the, WSJ, corpus, was, achieved, by, a, combination, of, the, SATZ, system, (, CITSEG, ), with, the, Alembic, system, (, CITSEG, ), :, a, 0.5, %, error, rate, ., The, best, performance, on, the, Brown, corpus, ,, a, 0.2, %, error, rate, ,, was, reported, by, CITSEG, ,, who, trained, a, decision, tree, classifier, on, a, 25, -, million, -, word, corpus, ., In, the, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>358</th>\n",
              "      <td>4</td>\n",
              "      <td>[Tense, interpretation, has, received, much, attention, in, linguistics, (, CITSEG, ), and, natural, language, processing, (, CITSEG, ), ., Several, researchers, (, CITSEG, ), have, sought, to, explain, the, temporal, relations, induced, by, tense, by, treating, it, as, anaphoric, ,, drawing, on, Reichenbach, 's, separation, between, event, ,, speech, ,, and, reference, times, (, CITSEG, ), .,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359</th>\n",
              "      <td>0</td>\n",
              "      <td>[Our, goal, is, to, learn, a, representation, for, each, word, of, interest, ., Most, efficient, learning, methods, known, today, and, ,, in, particular, ,, those, used, in, NLP, ,, make, use, of, a, linear, decision, surface, over, their, feature, space, (, CITSEG, ), ., Therefore, ,, in, order, to, learn, expressive, representations, one, needs, to, compose, complex, features, as, a, functio...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>360</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, Penn, Treebank, (, PTB, ), (, CITSEG, ), has, been, used, for, a, rather, simple, approach, to, deriving, large, grammars, automatically, :, one, where, the, grammar, rules, are, simply, ', read, off, ', the, parse, trees, in, the, corpus, ,, with, each, local, subtree, providing, the, left, and, right, hand, sides, of, a, rule, ., Charniak, (, CITSEG, ), reports, precision, and, recall,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>0</td>\n",
              "      <td>[CITSEG, describes, a, cascade, of, finite, -, state, transducers, ,, which, first, finds, noun, and, verb, groups, ,, then, their, heads, ,, and, finally, syntactic, functions, ., Brants, and, Skut, (, 1998, ), describe, a, partially, automated, annotation, tool, which, constructs, a, complete, parse, of, a, sentence, by, recursively, adding, levels, to, the, tree, ., (, CITSEG, ), use, casca...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362</th>\n",
              "      <td>5</td>\n",
              "      <td>[Following, CITSEG, ,, we, use, factored, trigram, models, over, words, ,, part, -of, -, speech, tags, and, supertags, to, score, partial, and, complete, realizations, ., The, language, models, were, created, using, the, SRILM, toolkit, (, CITSEG, ), on, the, standard, training, sections, (, 2, -, 21, ), of, the, CCGbank, ,, with, sentenceinitial, words, (, other, than, proper, names, ), uncap...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363</th>\n",
              "      <td>4</td>\n",
              "      <td>[In, order, to, measure, the, contribution, of, syntactic, relations, ,, we, wanted, to, test, them, on, several, ML, algorithms, ., At, present, we, have, chosen, one, algorithm, which, does, not, combine, features, (, Decision, Lists, ), and, another, which, does, combine, features, (, AdaBoost, ), ., Despite, their, simplicity, ,, Decision, Lists, (, Dlist, for, short, ), as, defined, in, C...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>364</th>\n",
              "      <td>5</td>\n",
              "      <td>[To, assess, the, practical, performance, of, the, three, unification, -, based, parsers, described, above, ,, a, series, of, experiments, were, conducted, using, the, ANLT, grammar, (, CITSEG, ), ,, a, wide, -, coverage, grammar, of, English, ., The, grammar, is, defined, in, metagrammatical, formalism, which, is, compiled, into, a, unification, -, based, ', object, gran~mar, ', --a, syntacti...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365</th>\n",
              "      <td>4</td>\n",
              "      <td>[This, need, motivates, research, on, fully, automatic, text, processing, that, may, rely, on, general, principles, of, linguistics, and, computation, ,, but, does, not, depend, on, knowledge, about, individual, words, ., In, this, paper, ,, we, describe, an, experiment, on, fully, automatic, derivation, of, the, knowledge, necessary, for, part-of-, speech, tagging, ., Part-of, -, speech, tagg...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>0</td>\n",
              "      <td>[For, N-rule, modeling, ,, clustering, increases, the, success, rate, for, both, N, =, 1, and, N, =, 2, ,, although, only, by, about, half, as, much, as, for, N-grams, ., This, suggests, that, conditioning, the, occurrence, of, a, grammar, rule, on, the, identity, of, its, mother, (, as, in, the, 2, -, rule, case, ), accounts, for, some, ,, but, not, all, ,, of, the, contextual, influences, th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367</th>\n",
              "      <td>5</td>\n",
              "      <td>[Reproducibility, is, the, extent, to, which, different, annotators, will, produce, the, same, classification, ., We, use, the, Kappa, coefficient, (, CITSEG, ), to, measure, stability, and, reproducibility, ., The, rationale, for, using, Kappa, is, explained, in, (, CITSEG, ), ., The, studies, used, to, evaluate, stability, and, reproducibility, we, describe, in, more, detail, in, (, CITSEG, ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>1</td>\n",
              "      <td>[Of, the, neural, embedding, models, ,, SENNA, gets, the, best, performance, ,, which, we, attribute, to, its, preservation, of, sequential, order, in, handling, context, ., Surprisingly, ,, the, Skip-gram, model, retrained, on, biomedical, data, (, SG, -, bio, ), fared, worse, than, the, original, (, SG, -, news, ), ,, due, probably, in, large, part, to, the, fact, that, the, original, traini...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, generate, a, sample, of, 160, random, utterances, by, varying, the, parameters, in, Table, 2, with, a, uniform, distribution, ., This, sample, is, intended, to, provide, enough, training, material, for, estimating, all, 67, parameters, for, each, personality, dimension, ., Following, ,, two, expert, judges, (, not, the, authors, ), familiar, with, the, Big, Five, adjectives, (, Table, 1, ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>4</td>\n",
              "      <td>[We, present, a, new, method, for, generating, linguistic, variation, projecting, multiple, personality, traits, continuously, ,, by, combining, and, extending, previous, research, in, statistical, natural, language, generation, (, CITSEG, ), ., While, handcrafted, rule, -, based, approaches, are, limited, to, variation, along, a, small, number, of, discrete, points, (, CITSEG, ), ,, we, learn...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371</th>\n",
              "      <td>0</td>\n",
              "      <td>[In, (, 2, ), sense_organ, as, the, semantic, type, of, the, first, argument, ofperzipiert, is, only, acquired, because, the, simplified, hierarchy, in, fig, ., 1, has, nose, and, ear, as, its, only, subtypes, ., Here, the, work, of, CITSEG, who, use, the, MDL, principle, to, generalize, over, the, slots, of, observed, case, frames, might, prove, fruitful, ., An, important, question, is, how, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372</th>\n",
              "      <td>1</td>\n",
              "      <td>[These, methods, have, a, tendency, to, underestimate, the, significance, of, the, results, ,, which, tends, to, make, one, believe, that, some, new, technique, is, no, better, than, the, current, technique, even, when, it, is, ., This, underestimate, comes, from, these, methods, assuming, that, the, techniques, being, compared, produce, independent, results, when, in, our, experiments, ,, the...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, bulk, of, LFG, involves, stating, constraints, about, a, single, model, ,, and, /, :, is, well, equipped, for, this, task, ,, but, constraining, equations, involve, looking, at, the, structure, of, other, possible, parse, trees, ., (, In, this, respect, they, are, reminiscent, of, the, feature, specification, defaults, of, GPSG, ., ), The, approach, of, the, present, paper, has, been, dr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>0</td>\n",
              "      <td>[Starting, with, (, CITSEG, ), ,, testsuites, have, been, drawn, up, from, a, linguistic, viewpoint, ,, \", in, -, ], ormed, by, [, the, ], study, of, linguistics, and, [, reflecting, ], the, grammatical, issues, that, linguists, have, concerned, themselves, with, \", (, CITSEG, ,, ,, p.4, ), ., Although, the, question, is, not, explicitly, addressed, in, (, CITSEG, ), ,, all, the, testsuites, r...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375</th>\n",
              "      <td>0</td>\n",
              "      <td>[It, has, also, been, the, subject, of, a, number, of, psycholinguistic, studies, on, a, more, theoretical, level, (, CITSEG, ), ., The, implementation, described, in, this, paper, is, based, on, the, most, recent, model, ,, that, of, (, CITSEG, ), ., This, model, is, interesting, in, that, it, does, not, allow, the, parser, to, employ, delay, tactics, ,, such, as, using, a, lookahead, buffer,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376</th>\n",
              "      <td>4</td>\n",
              "      <td>[Figure, 2, :, Example, of, \", relaxed, \", maximal, common, sui, ), graph, and, maximal, join, algorithms, Semantic, distance, between, concepts, ., In, the, maximal, common, subgraph, algorithm, proposed, by, (, Sow, %, :, 1984, ), ,, two, concepts, (, C1, ,, CY, ), could, be, matched, if, one, snbsumed, the, other, in, the, concept, hierarchy, ., We, can, relax, that, criteria, to, match, tw...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>5</td>\n",
              "      <td>[An, experiment, was, conducted, with, several, corpora, as, detailed, in, Table, 2, ., There, was, some, e, ort, to, cover, the, corpus, HC, -, DE, ,, but, no, grammar, development, based, on, the, other, corpora, ., The, NEWS, -SC, corpus, is, part, the, corpus, of, verb-nal, sentences, used, by, CITSEG, ., A, training, set, of, 1000, sentences, from, each, corpus, was, parsed, with, an, ins...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>378</th>\n",
              "      <td>1</td>\n",
              "      <td>[Although, we, have, not, been, successful, in, Figure, 6, :, Learning, curve, for, Super, GREC, Figure, 7, :, Learning, curve, for, EPI, proving, our, initial, hypothesis, we, argue, that, our, results, calls, for, further, study, due, to, several, concerns, raised, by, the, results, remaining, unanswered, ., It, may, be, that, our, notion, of, distance, to, lexical, resource, entries, is, to...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379</th>\n",
              "      <td>1</td>\n",
              "      <td>[Using, additional, source, side, information, beyond, the, markup, did, not, produce, a, gain, in, performance, ., For, compound, splitting, ,, we, follow, Fritzinger, and, Fraser, (, 2010, ), ,, using, linguistic, knowledge, en-coded, in, a, rule, -, based, morphological, analyser, and, then, selecting, the, best, analysis, based, on, the, geometric, mean, of, word, part, frequencies, ., Oth...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>1</td>\n",
              "      <td>[Table, 6, shows, the, performance, of, the, NatLog, system, on, RTE3, data, ., Relative, to, the, Stanford, RTE, system, ,, NatLog, achieves, high, precision, on, its, yes, predictions, -, about, 76, %, on, the, development, set, ,, and, 68, %, on, the, test, set-suggesting, that, hybridizing, may, be, effective, ., For, comparison, ,, the, FOL, -, based, system, reported, in, (, CITSEG, ), a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>381</th>\n",
              "      <td>1</td>\n",
              "      <td>[Various, statistics, for, this, extraction, are, shown, in, Table, 1, ., The, number, of, distinct, hypernyms, in, the, gazetteer, was, 12,786, ., Although, this, Wikipedia, gazetteer, is, much, smaller, than, the, English, version, used, by, CITSEG, that, has, over, 2,000,000, entries, ,, it, is, the, largest, gazetteer, that, can, be, freely, used, for, Japanese, NER, ., Our, experimental, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>1</td>\n",
              "      <td>[Games, provide, a, better, explanation, of, coherence, ,, but, still, require, the, agent, 's, to, recognize, each, other, 's, intentions, to, perform, the, dialogue, game, ., As, a, result, ,, this, work, can, be, viewed, as, a, special, case, of, the, intentional, view, ., An, interesting, model, is, described, by, [, CITSEG, ], ,, which, separates, out, the, conversational, games, from, th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, rest, of, the, sentences, were, marked, either, positive, (, p, ), ,, negative, (, n, ), or, objective, /, neutral, (, o, ), ., A, total, of, 1,741, citations, were, annotated, ., Although, this, annotation, was, performed, by, the, first, author, only, ,, we, know, from, previous, work, that, similar, styles, of, annotation, can, achieve, acceptable, interannotator, agreement, (, CITSEG...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>5</td>\n",
              "      <td>[Source, :, Encodes, the, source, of, the, knowledge, being, expressed, by, the, event, as, Current, (, the, current, study, ), or, Other, (, any, other, source, ), ., Of, these, five, dimensions, ,, only, KT, ,, CL, and, Source, were, considered, during, the, comparison, with, the, other, two, schemes, ,, since, they, are, directly, related, to, discourse, analysis, ., The, GENIA, event, corp...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>385</th>\n",
              "      <td>0</td>\n",
              "      <td>[F, ,, flbrt, in, findlug, cormections, between, words, is, seen, in, work, on, automatic, extraction, of, sem~mtic, relations, Dora, MRI, ), s, (, CITSEG!32, ), ., Additionally, ,, effort, in, finding, words, that, are, close, semantically, is, seen, by, the, current, interest, in, statistical, techniques, for, word, clustering, ,, looking, at, (, -, ooccurrences, of, words, in, text, corpora...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386</th>\n",
              "      <td>0</td>\n",
              "      <td>[Systemic, grammar, assumes, multifunctional, constituent, structuresrepresentable, as, feature, structures, with, coreferences, ., As, shown, in, the, following, function, structure, example, for, the, sentence, \", The, people, that, buy, silver, love, it, ., \", ,, different, functions, can, be, filled, by, one, and, the, same, constituent, :, Given, the, notational, equivalence, of, HPSG, an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>387</th>\n",
              "      <td>0</td>\n",
              "      <td>[BFP, can, add, the, VP, and, the, S, onto, the, end, of, the, forward, centers, list, ,, as, Sidner, does, in, her, algorithm, for, local, focusing, [, CITSEG, ], ., This, lets, BFP, get, the, two, examples, of, event, anaphora, ., Hobbs, discusses, the, fact, that, his, algorithm, can, not, be, modified, to, get, event, anaphora, in, [, CITSEG, ], ., Another, interesting, fact, is, that, in,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388</th>\n",
              "      <td>5</td>\n",
              "      <td>[This, consists, of, approximately, 50,000, aligned, sentences, and, 448, wordaligned, sentences, ,, which, are, split, into, a, 248, sentence, trial, set, and, a, 200, sentence, test, set, ., We, used, these, as, our, training, and, test, sets, ,, respectively, ., For, parameter, tuning, ,, we, used, the, 17, sentence, trial, set, from, the, Romanian, -, English, corpus, in, the, 2003, NAACL,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>389</th>\n",
              "      <td>2</td>\n",
              "      <td>[The, AdaBoost, algorithm, was, presented, by, Freund, and, Schapire, in, 1996, (, CITSEG, ), and, has, become, a, widely, -, known, successful, method, in, machine, learning, ., The, AdaBoost, algorithm, imposes, one, constraint, on, its, underlying, learner, :, it, may, abstain, from, making, predictions, about, labels, of, some, samples, ,, 1, This, is, the, balanced, version, of, F-measure...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, model, is, highly, general, and, can, be, optimised, for, different, tasks, ., It, extends, prior, work, on, syntax, -, based, models, (, CITSEG, ), ,, by, providing, a, general, framework, for, defining, context, so, that, a, large, number, of, syntactic, relations, can, be, used, in, the, construction, of, the, semantic, space, ., Our, approach, differs, from, CITSEG, in, three, import...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391</th>\n",
              "      <td>5</td>\n",
              "      <td>[Previous, work, has, made, use, of, various, restrictions, or, approximations, that, allow, efficient, training, of, GLMs, for, parsing, ., This, section, describes, the, relationship, between, our, work, and, this, previous, work, ., In, reranking, approaches, ,, a, first, -, pass, parser, is, used, to, enumerate, a, small, set, of, candidate, parses, for, an, input, sentence, ;, the, rerank...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392</th>\n",
              "      <td>5</td>\n",
              "      <td>[There, was, a, reduction, of, over, half, the, transitions, on, the, trie, formed, from, the, Alvey, lexicon, ., If, the, word, is, unknown, ,, the, system, reconsiders, analysis, from, the, point, where, it, broke, down, with, the, added, possibility, of, an, error, rule, ., There, are, currently, four, error, rules, ,, corresponding, to, the, four, Damerau, transformations, :, omission, ,, ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>1</td>\n",
              "      <td>[This, is, caused, by, the, \", DE, \", construction, ,, in, which, a, clause, is, used, as, a, modifier, of, an, NP, ., For, instance, ,, in, the, example, indicated, in, Figure, 1, ,, for, the, last, NP, ,, \", \", (, \", international, Olympic, conference, \", ), the, parent, node, is, NP, ,, from, where, it, goes, down, to, the, target, verb, \", \", (, \", taking, place, \", ), ., Since, the, gover...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>0</td>\n",
              "      <td>[Hellinger, distance, In, Section, 2.2, we, have, seen, how, to, derive, psd, kernels, (, similarities, ), from, nsd, kernels, (, distances, ), ., It, seems, likely, that, distance, measures, that, are, known, to, work, well, for, comparing, co-occurrence, distributions, will, also, give, us, suitable, psd, similarity, measures, ., Negative, semi-definite, kernels, are, by, definition, symmetr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>3</td>\n",
              "      <td>[The, true, utility, of, content, models, is, to, structure, abstracts, that, have, no, structure, to, begin, with, ., Thus, ,, our, exploratory, experiments, in, applying, content, models, trained, with, structured, RCTs, on, unstructured, RCTs, is, a, closer, approximation, of, an, extrinsically, -, valid, measure, of, performance, ., Such, a, component, would, serve, as, the, first, stage, ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>1</td>\n",
              "      <td>[Despite, its, simplicity, ,, the, performance, of, our, approach, was, on, the, level, with, the, previously, highest, reported, results, on, the, same, test, collections, ., The, error, rate, on, sentence, boundaries, in, the, Brown, corpus, was, not, significantly, worse, than, the, lowest, quoted, before, (, CITSEG, :, 0.28, %, vs., 0.20, %, error, rate, ), ., On, the, WSJ, corpus, our, sy...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>0</td>\n",
              "      <td>[CITSEG, is, one, of, the, first, who, proposed, to, split, up, parsing, into, several, cascades, ., He, suggests, to, first, find, the, chunks, and, then, the, dependecies, between, these, chunks, ., CITSEG, describes, a, cascade, of, finite, -, state, transducers, ,, which, first, finds, noun, and, verb, groups, ,, then, their, heads, ,, and, finally, syntactic, functions, ., Brants, and, Sk...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>2</td>\n",
              "      <td>[We, have, presented, what, is, to, our, knowledge, the, first, formalization, and, implementation, of, a, type, of, rule, and, control, regime, intended, for, use, in, situations, where, it, is, desired, to, produce, the, effect, of, transforming, one, feature, structure, into, another, ., 9, The, formalism, described, above, has, been, implemented, as, part, of, ISSCO, 's, ELU, l°, ,, an, en...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>4</td>\n",
              "      <td>[The, former, alternative, makes, the, spurious, ambiguity, problem, of, CG, parsing, (, CITSEG, ), even, more, severe, ., Multiset, CCG, (, CITSEG, ), is, an, example, of, the, setoriented, approach, ., It, is, known, to, be, computationally, tractable, but, less, efficient, than, the, polynomial, time, CCG, algorithm, of, CITSEG, ., I, try, to, show, in, this, paper, that, the, traditional, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400</th>\n",
              "      <td>5</td>\n",
              "      <td>[Experiments, used, a, model, with, 35, classes, ., From, maximal, probability, parses, for, the, British, National, Corpus, derived, with, a, statistical, parser, (, CITSEG, ), ,, we, extracted, frequency, tables, for, intransitve, verb, /, subject, pairs, and, transitive, verb, /, subject, /, object, triples, ., The, 500, most, frequent, verbs, were, selected, for, slot, labeling, ., Fig., 6...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401</th>\n",
              "      <td>0</td>\n",
              "      <td>[In, linguistic, theory, ,, the, interest, has, shifted, from, phrase, structure, rules, that, combine, adjacent, and, contiguous, constituents, to, •, principle, -, based, approaches, to, grammar, that, state, general, well, -, formedness, conditions, instead, of, describing, particular, constructions, (, e.g., IIPSG, ), •, operations, on, strings, that, go, beyond, concatenation, (, head, wr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>5</td>\n",
              "      <td>[To, sum, up, ,, this, work, has, been, carried, out, to, automatically, classify, Arabic, documents, using, the, NB, algorithm, ,, with, the, use, of, a, different, data, set, ,, a, different, number, of, categories, ,, and, a, different, root, extraction, algorithm, from, those, used, in, (, CITSEG, ), ., In, this, work, ,, the, average, accuracy, over, all, categories, is, :, 68.78, %, in, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>403</th>\n",
              "      <td>4</td>\n",
              "      <td>[To, avoid, predicting, certain, features, ,, we, use, a, weak, prediction, dr, (, i, ,, k, ), that, the, ideal, prediction, table, would, remove, ,, but, it, may, also, cost, less, to, use, ., CITSEG, proposed, to, analyze, the, behavior, of, Prolog, programs, ,, including, parsers, ,, by, using, something, much, like, a, weak, prediction, table, ., To, guarantee, that, the, table, was, finit...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404</th>\n",
              "      <td>0</td>\n",
              "      <td>[In, this, paper, ,, we, address, both, of, these, shortcomings, by, proposing, regular, tree, grammars, (, RTGs, ), as, a, novel, underspecification, formalism, ., Regular, tree, grammars, (, CITSEG, ), are, a, standard, approach, for, specifying, sets, of, trees, in, theoretical, computer, science, ,, and, are, closely, related, to, regular, tree, transducers, as, used, e.g., in, recent, wor...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>4</td>\n",
              "      <td>[n, have, yet, to, beapplied, ., Clearly, ,, this, argument, applies, to, both, complete, -, data, and, incomplete, -, data, estimation, ., Note, that, for, a, uniformly, distributed, reference, model, p, 0, ,, the, minimum, divergence, model, is, a, maximum, entropy, model, (, CITSEG, ), ., In, Sec., 4, ,, we, will, demonstrate, that, a, uniform, initialization, of, the, IM, algorithm, shows,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>406</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, essential, contribution, of, our, study, is, that, we, treat, preverbal, and, postverbal, parts, of, the, sentence, differently, ., The, sentence, -, initial, position, ,, which, in, German, is, the, VF, ,, has, been, shown, to, be, cognitively, more, prominent, than, other, positions, (, CITSEG, ), ., Motivated, by, the, theoretical, work, by, CITSEG, ,, we, view, the, VF, as, the, plac...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>407</th>\n",
              "      <td>0</td>\n",
              "      <td>[Recent, work, in, video, surveillance, has, demonstrated, the, benefit, of, representing, complex, events, as, temporal, relations, between, lower, level, subevents, (, CITSEG, ), ., Thus, ,, to, represent, events, in, the, sports, domain, ,, we, would, ideally, first, represent, the, basic, sub, events, that, occur, in, sports, video, (, e.g., ,, hitting, ,, throwing, ,, catching, ,, running...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408</th>\n",
              "      <td>2</td>\n",
              "      <td>[Let, us, take, a, second, example, out, of, the, literature, to, illustrate, our, method, ., Consider, the, following, paragraph, containing, a, citation, :, \", Comprehension, -, based, summarization, ,, e.g., CITSEG, ,, is, the, most, ambitious, model, of, automatic, summarization, ,, requiring, a, complete, understanding, of, the, text, ., Due, to, the, failure, of, rule, -, based, NLP, and...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>409</th>\n",
              "      <td>1</td>\n",
              "      <td>[They, obtained, a, relatively, small, improvement, ,, and, no, statistical, significance, test, was, reported, to, determine, if, the, improvement, was, statistically, significant, ., Note, that, the, experiments, in, (, CITSEG, ), did, not, use, a, state, -, of, -, the, -, art, MT, system, ,, while, the, experiments, in, (, CITSEG, ), were, not, done, using, a, full, -, fledged, MT, system, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>4</td>\n",
              "      <td>[(, 1, ), a., It, was, not, the, sales, manager, who, hit, the, bottle, that, day, ,, but, the, office, worker, with, the, serious, drinking, problem, ., b., That, day, the, office, manager, ,, who, was, drinking, ,, hit, the, problem, sales, worker, with, a, bottle, ,, but, it, was, not, serious, ., While, vector, addition, has, been, effective, in, some, applications, such, as, essay, gradin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>2</td>\n",
              "      <td>[Negation, lies, at, the, heart, of, deductive, inference, ,, of, which, consistency, checking, (, searching, for, contradictions, in, texts, ), is, a, prime, example, in, natural, language, understanding, ., It, should, n't, therefore, come, as, a, surprise, that, detecting, negation, and, adequately, representing, its, scope, is, of, utmost, importance, in, computational, semantics, ., In, t...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>412</th>\n",
              "      <td>1</td>\n",
              "      <td>[In, languages, like, Chinese, ,, where, no, word, boundary, exists, in, written, texts, ,, this, is, by, no, means, an, easy, job, ., In, many, cases, the, machine, will, not, even, realize, that, there, is, an, unfound, word, in, the, sentence, since, most, single, Chinese, characters, can, be, words, by, themselves, ., Purely, statistical, methods, of, word, segmentation, (, e.g., CITSEG, ,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>0</td>\n",
              "      <td>[For, example, ,, cutting, up, the, first, parse, tree, of, Figure, 1, at, the, NP, of, the, rule, vp_v_np, yields, rules, 2, and, 3, of, Figure, 3, ., The, idea, behind, this, is, to, create, a, specialized, grammar, that, retains, a, high, coverage, but, allows, very, much, faster, parsing, ., This, has, turned, out, to, be, possible, -, speedups, compared, to, using, the, original, grammar,...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, classification, results, show, that, our, method, is, powerful, ,, and, suited, to, the, classification, of, unknown, verbs, ., However, ,, we, have, not, yet, addressed, the, problem, of, verbs, that, can, have, multiple, classifications, ., We, think, that, many, cases, of, ambiguous, classification, of, the, lexical, entry, for, a, verb, can, be, addressed, with, the, notion, of, inte...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>5</td>\n",
              "      <td>[In, the, initial, annotation, phase, ,, 13, %, of, our, corpus, was, annotated, twice, by, different, annotators, in, order, to, measure, inter-annotator, agreement, ., We, did, this, measurement, as, it, was, done, for, MUC, (, CITSEG, ), and, in, the, same, way, as, a, coreference, resolution, system, is, evaluated, against, some, gold, standard, :, one, annotation, was, set, to, be, the, g...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>0</td>\n",
              "      <td>[3, Santamaría, et, al., ,, in, this, issue, ,, discuss, how, to, link, word, senses, to, Web, directory, nodes, ,, and, thence, to, Web, pages, ., The, Web, is, being, used, to, address, data, sparseness, for, language, modeling, ., In, addition, to, CITSEG, and, references, therein, ,, CITSEG, gathers, lexical, statistics, for, resolving, prepositional, phrase, attachments, ,, and, CITSEG, \"...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>0</td>\n",
              "      <td>[Vector-, based, models, of, word, meaning, (, CITSEG, ), have, become, increasingly, popular, in, natural, language, processing, (, NLP, ), and, cognitive, science, ., The, appeal, of, these, models, lies, in, their, ability, to, represent, meaning, simply, by, using, distributional, information, under, the, assumption, that, words, occurring, within, similar, contexts, are, semantically, sim...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418</th>\n",
              "      <td>1</td>\n",
              "      <td>[3.1, Ontology, Various, authors, (, including, CITSEG, have, proposed, modeltheoretic, treatments, in, which, a, parallel, ontological, distinction, is, made, between, substances, and, things, ,, processes, and, events, ,, etc., A, similarly, parallel, distinction, is, employed, here, ,, but, in, a, rather, different, way, :, unlike, the, above, treatments, ,, the, present, account, models, s...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419</th>\n",
              "      <td>1</td>\n",
              "      <td>[PLUM, was, employed, in, both, MUC, -, 6, template, tasks, (, TE, and, ST, ), ., Two, new, heavyweight, algorithms, were, developed, in, the, last, year, ., One, is, a, full, parser, of, English, ,, using, a, statistically, learned, decision, procedure, ;, SPATTER, has, achieved, the, highest, scores, yet, reported, on, parsing, English, text, (, CITSEG, ), ., Because, the, measurable, improv...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420</th>\n",
              "      <td>3</td>\n",
              "      <td>[While, we, use, supervised, methods, to, annotate, papers, with, a, fixed, set, of, topics, (, CoreSCs, ), in, scientific, papers, ,, our, summary, content, model, for, extracts, shares, similar, principles, such, as, global, ordering, of, sentences, and, non-recurrence, ., However, ,, their, evaluation, involved, newspaper, articles, and, extracts, which, are, a, lot, shorter, (, 15, and, 6,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>0</td>\n",
              "      <td>[If, a, QLF, expression, contains, uninstantiated, recta-variables, ,, the, valuation, relation, can, associate, more, than, one, value, with, the, expression, ., In, the, case, of, formulas, ,, they, may, be, given, both, the, values, true, and, false, ,, corresponding, to, the, formula, being, true, under, one, possible, resolution, and, false, under, another, ., A, subsumption, ordering, ov...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>3</td>\n",
              "      <td>[Before, explaining, our, CLIR, system, ,, we, classify, existing, CLIR, into, three, approaches, in, terms, of, the, implementation, of, the, translation, phase, ., The, first, approach, translates, queries, into, the, document, language, (, CITSEG, ), ,, while, the, second, approach, translates, documents, into, the, query, language, (, CITSEG, ), ., The, third, approach, transfers, both, qu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>0</td>\n",
              "      <td>[Slightly, more, generally, ,, PI_IG, can, generate, the, language, {, w~, ], we, R}, for, any, k, &gt;, 1, and, regular, language, R, ., We, believe, that, the, language, involving, copies, of, strings, of, matching, brackets, described, in, Example, 5, cannot, be, generated, by, PI_IG, but, ,, as, shown, in, Exampie, 5, ,, it, can, be, generated, by, P/T, (, :, ;, and, therefore, PLPATR, ., Sli...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>424</th>\n",
              "      <td>4</td>\n",
              "      <td>[While, self-, training, has, worked, in, several, domains, ,, the, early, results, on, self, -, training, for, parsing, were, negative, (, CITSEG, ), ., However, more, recent, results, have, shown, that, it, can, indeed, improve, parser, performance, (, CITSEG, ), ., One, possible, use, for, this, technique, is, for, parser, adaptation, -, initially, training, the, parser, on, one, type, of, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>425</th>\n",
              "      <td>2</td>\n",
              "      <td>[The, lexical, -, semantic, structure, adopted, for, UNITRAN, is, an, augmented, form, of, Jackendoff, 's, representation, in, which, events, are, distinguished, from, states, (, as, before, ), ,, but, events, are, further, subdivided, into, activities, ,, achievements, ,, and, accomplishments, ., The, subdivision, is, achieved, by, means, of, three, features, proposed, by, Bennett, etal, ., (...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426</th>\n",
              "      <td>1</td>\n",
              "      <td>[As, a, consequence, ,, relationships, considered, have, been, mostly, synonymic, or, taxonomic, ,, or, dened, as, term, variations, ., On, the, other, hand, ,, other, work, has, been, carried, out, in, order, to, acquire, collocations, ., Most, of, these, endeavours, have, focused, on, purely, statistical, acquisition, techniques, (, CITSEG, ), ,, on, linguisitic, acquisition, (, by, the, use...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>427</th>\n",
              "      <td>3</td>\n",
              "      <td>[We, conjecture, that, this, trend, may, continue, by, incorporating, additional, information, ,, e.g., ,, three, -, dimensional, models, as, proposed, by, CITSEG, ., In, the, current, work, morphological, analyses, and, lexical, probabilities, are, derived, from, a, small, Treebank, ,, which, is, by, no, means, the, best, way, to, go, ., Using, a, wide, -, coverage, morphological, analyzer, b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428</th>\n",
              "      <td>5</td>\n",
              "      <td>[These, rules, were, learned, using, a, word, -, aligned, parallel, corpus, ., The, POS, tags, for, the, reordering, models, are, generated, using, the, TreeTagger, (, CITSEG, ), for, all, languages, ., Translation, is, performed, by, the, STTK, Decoder, (, CITSEG, ), and, all, systems, are, optimized, towards, BLEU, using, Minimum, Error, Rate, Training, as, proposed, in, CITSEG, .]</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>429</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, evaluation, is, summarized, in, Table, 3, ., The, results, demonstrate, that, either, leveraging, the, same, unlabeled, data, or, providing, a, much, larger, unlabeled, dataset, for, the, monolingual, semisupervised, methods, ,, the, SLBD, method, can, significantly, outperform, the, evaluated, monolingual, semi-supervised, methods, ,, which, indicates, that, the, segmenting, information...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>430</th>\n",
              "      <td>5</td>\n",
              "      <td>[Even, assuming, perfect, word, recognition, ,, the, problem, of, determining, the, intended, words, is, complicated, due, to, the, occurrence, of, speech, repairs, ,, which, occur, where, the, speaker, goes, back, and, changes, (, or, repeats, ), something, she, just, said, ., The, words, that, are, replaced, or, repeated, are, no, longer, part, of, the, intended, utterance, ,, and, so, need,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>0</td>\n",
              "      <td>[By, extending, the, analysis, of, temporal, subordinate, clauses, in, (, CITSEG, ), ,, to, sentences, which, include, quantification, over, eventualities, ,, we, can, propose, an, alternative, DRT, solution, to, Partee, 's, quantification, problem, ., As, in, (, CITSEG, ), ,, such, sentences, trigger, box-splitting, ., But, now, ,, the, location, time, of, the, eventuality, in, the, subordina...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>432</th>\n",
              "      <td>4</td>\n",
              "      <td>[In, (, CITSEG, ), sequence, of, words, features, are, utilized, using, a, sub-sequence, kernel, ., In, (, CITSEG, ), dependency, graph, features, are, exploited, ,, and, in, (, CITSEG, ), syntactic, features, are, employed, for, relation, extraction, ., Although, in, order, to, achieve, the, best, performance, ,, it, is, necessary, to, use, a, proper, combination, of, these, features, (, CITS...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>433</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, tiles, may, b, e, of, any, length, ,, up, to, the, maximal, length, of, a, phrase, in, the, training, data, ,, which, gives, MBSL, a, generalization, power, that, compensates, for, the, setup, of, using, only, POS, tags, ., The, results, presented, here, were, obtained, by, optimizing, MBSL, parameters, based, on, 5, -, fold, CV, on, the, training, data, ., SNoW, uses, the, Open, Close, ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>434</th>\n",
              "      <td>0</td>\n",
              "      <td>[Recently, ,, the, concept, of, valency, has, gained, considerable, attention, ., Not, only, do, all, linguistic, theories, refer, to, some, reformulation, of, the, traditional, notion, of, valency, (, in, the, form, of, 0grid, ,, subcategorization, list, ,, argument, list, ,, or, extended, domain, of, locality, ), ;, there, is, a, growing, number, of, parsers, based, on, binary, relations, be...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>5</td>\n",
              "      <td>[For, the, evaluation, of, the, results, we, use, the, BLEU, score, (, CITSEG, ), ., Section, 8, compares, translations, generated, from, automatically, built, and, manually, annotated, tectogrammatical, representations, ., We, also, compare, the, results, with, the, output, generated, by, the, statistical, translation, system, GIZA, ++/, ISI, ReWrite, Decoder, (, CITSEG, ), ,, trained, on, th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, answer, seems, to, lie, in, addressing, the, concept, which, underlies, the, union, of, adjective, and, noun, in, these, three, cases, ,, i.e., ,, intensification, ,, and, hence, establish, a, single, meaning, representation, tbr, the, adjectives, which, can, be, viewed, as, an, interlingual, pivot, for, translation, ., Collocations, have, been, studied, by, computational, linguists, in,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>5</td>\n",
              "      <td>[It, consists, of, 447, source, sentences, that, were, translated, by, four, human, translators, as, well, as, ten, MT, systems, ., Each, machine, translated, sentence, was, evaluated, by, two, human, judges, for, their, fluency, and, adequacy, on, a, 5, -, poi, nt, scale, 2, ., To, remove, the, bias, in, the, distributions, of, scores, between, different, judges, ,, we, follow, the, normaliza...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, semantic, contribution, of, each, lexical, entry, ,, which, we, will, refer, to, as, a, meaning, constructor, ,, is, a, linear-, logic, formula, consisting, of, instructions, in, the, glue, language, for, combining, the, meanings, of, the, lexical, entry, 's, syntactic, arguments, to, obtain, the, meaning, of, the, f-structure, headed, by, the, entry, ., For, instance, ,, the, meaning, c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>4</td>\n",
              "      <td>[The, degree, of, convergence, can, be, measured, using, a, perplexity, measure, ,, the, sum, of, plog2, p, for, hypothesis, probabilities, p, ,, which, gives, an, estimate, of, the, degree, of, disorder, in, the, model, ., The, algorithm, is, again, described, by, Cutting, et, al., and, by, Sharman, ,, and, a, mathematical, justification, for, it, can, be, tbund, in, CITSEG, ., The, first, ma...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>0</td>\n",
              "      <td>[1, Introduction, \", Unification, -, based, \", Grammars, (, UBGs, ), can, capture, a, wide, variety, of, linguistically, important, syntactic, and, semantic, constraints, ., However, ,, because, these, constraints, can, be, non-local, or, context-sensitive, ,, developing, stochastic, versions, of, UBGs, and, associated, estimation, procedures, is, not, as, straight, -, forward, as, it, is, for...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>0</td>\n",
              "      <td>[9, Not, all, VP, ellipses, have, VP, antecedents, ., this, is, so, ,, the, antecedent, and, ellipsis, categories, are, both, used, to, determine, what, fozm, should, be, substituted, for, the, antecedent, form, ., This, comprises, the, restriction, of, the, antecedent, form, and, a, new, category, constructed, by, taking, the, features, of, the, antecedent, category, ,, unless, overridden, by...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>442</th>\n",
              "      <td>2</td>\n",
              "      <td>[Both, rules, produce, a, magic, fact, with, which, a, subject, np, can, be, built, ., A, possible, solution, to, this, problem, is, to, couple, magic, rules, with, the, modified, version, of, the, original, grammar, rule, that, instigated, it, ., To, accomplish, this, I, propose, a, technique, that, can, be, considered, the, off, -, line, variant, of, an, index, -, ing, technique, described, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>443</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, WARRANT, in, lb, can, be, used, by, the, he~uer, in, deliberating, whether, lo, ACCEPT, or, REJIi, (, ?, T, tile, speakef, 's, I'ROPOSAI, ,, in, la., 1, An, amdysis, of, proposals, in, a, corpus, of, 55, problemsolving, dialogues, SllOWS, lhat, communicating, agents, do, n't, always, include, warrants, in, a, prol, ), osal, ,, and, suggest, a, number, of, hypolheses, abotlt, which, facto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>444</th>\n",
              "      <td>5</td>\n",
              "      <td>[However, ,, it, is, not, a, base, NP, since, it, contains, two, other, noun, phrases, ., Two, base, NP, data, sets, have, been, put, forward, by, (, CITSEG, ), ., The, main, data, set, consist, of, four, sections, (, 15, -, 18, ), of, the, Wall, Street, Journal, (, WSJ, ), part, of, the, Penn, Treebank, (, CITSEG, ), as, training, material, and, one, section, (, 20, ), as, test, material, 1.,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>445</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, lexicon, contains, stem, forms, and, has, a, detailed, word, class, type, hierarchy, at, its, top, ., Morphology, is, also, organized, as, a, monotonic, type, hierarchy, ., Currently, used, implementations, of, SFG, are, the, PENMAN, system, (, CITSEG, ), ,, the, KPML, system, (, CITSEG, ), and, WAG, -, KRL, (, CITSEG, ), ., Our, subgrammar, extraction, has, been, applied, and, tested, i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446</th>\n",
              "      <td>0</td>\n",
              "      <td>[Lexical, ambiguity, resolution, is, an, important, research, problem, for, the, fields, of, information, retrieval, and, machine, translation, (, CITSEG, ), ., However, ,, making, fine, -, grained, sense, distinctions, for, words, with, multiple, closelyrelated, meanings, is, a, subjective, task, (, CITSEG, ), ,, which, makes, it, difficult, and, error-prone, ., Fine-grained, sense, distincti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>5</td>\n",
              "      <td>[d), the, opinions, associated, with, each, feature, f, are, ranked, based, on, their, strength, ., Solution, The, steps, of, our, solution, are, outlined, in, Figure, 1, above, ., OPINE, parses, the, reviews, using, MINI, -, PAR, (, CITSEG, ), and, applies, a, simple, pronoun-resolution, module, to, parsed, review, data, ., OPINE, then, uses, the, data, to, find, explicit, product, features, ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>4</td>\n",
              "      <td>[The, Naive, Bayesian, classifier, has, emerged, as, a, consistently, strong, performer, in, a, wide, range, of, comparative, studies, of, machine, learning, methodologies, ., A, recent, survey, of, such, results, ,, as, well, as, possible, explanations, for, its, success, ,, is, presented, in, (, CITSEG, ), ., A, similar, finding, has, emerged, in, word, sense, disambiguation, ,, where, a, nu...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>5</td>\n",
              "      <td>[In, order, to, integrate, domain, knowledge, with, a, features, -, based, model, ,, we, develop, a, simple, taxonomy, of, constraints, (, i.e., desired, class, distributions, ), and, employ, a, top-down, classification, algorithm, on, top, of, a, Maximum, Entropy, Model, augmented, with, GE, constraints, ., This, algorithm, enables, us, to, break, the, multi-class, prediction, into, a, pipeli...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>5</td>\n",
              "      <td>[Each, piece, of, evidence, contains, a, belief, _beli, ,, and, an, evidential, relationship, supports, (, ., beli, ,, -, bel, ), ., Following, Walker, 's, weakest, link, assumption, (, CITSEG, ), the, strength, of, the, evidence, is, the, weaker, of, the, strength, of, the, belief, and, the, strength, of, the, evidential, relationship, ., The, evaluator, then, employs, a, simplified, version,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>3</td>\n",
              "      <td>[In, order, to, gain, the, benefits, of, probabilistic, modeling, ,, we, replace, the, task, of, developing, large, rule, sets, with, the, task, of, estimating, large, numbers, of, statistical, parameters, for, the, monolingual, and, translation, models, ., This, gives, rise, to, a, new, cost, trade, -, off, in, human, annotation, /, judgement, versus, barely, tractable, fully, automatic, trai...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>452</th>\n",
              "      <td>1</td>\n",
              "      <td>[Then, we, integrated, the, idea, of, exploiting, argument, interdependence, to, further, improve, the, performance, of, our, system, and, explained, linguistically, why, the, results, of, our, system, were, different, from, the, ones, in, previous, research, ., Although, we, make, discriminations, of, arguments, and, adjuncts, ,, the, analysis, is, still, coarse-grained, ., CITSEG, has, made,...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>453</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, grammar, is, a, manually, developed, headed, context, -, free, phrase, structure, grammar, for, German, subordinate, clauses, with, 5508, rules, and, The, formalism, is, that, of, CITSEG, ,, henceforth, C+R:, mother, -&gt;, non, -, heads, head, ', non-heads, (, freq, ), The, rules, are, head, marked, with, a, prime, ., The, non, -, head, sequences, may, be, empty, ,, freq, is, a, rule, freq...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454</th>\n",
              "      <td>0</td>\n",
              "      <td>[It, is, the, smallest, linguistic, representation, of, what, ,, in, logic, ,, is, called, a, \", model, ,, \", and, it, is, the, first, reasonable, domain, of, anaphora, resolution, ,, and, of, coherent, thought, about, a, central, topic, ., A, paragraph, can, be, thought, of, as, a, grammatical, unit, in, the, following, sense, :, it, is, the, discourse, unit, in, which, a, functional, (, or, ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455</th>\n",
              "      <td>5</td>\n",
              "      <td>[A, test, set, of, syntactically, ambiguous, noun, compounds, was, extracted, from, our, 8, million, word, Grolier, 's, encyclopedia, corpus, in, the, following, way, ., 2, Because, the, corpus, is, not, tagged, or, parsed, ,, a, somewhat, conservative, strategy, of, looking, for, unambiguous, sequences, of, nouns, was, used, ., To, distinguish, nouns, from, other, words, ,, the, University, o...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>5</td>\n",
              "      <td>[Our, raw, knowledge, about, the, relation, consists, of, the, frequencies, f~n, of, occurrence, of, particular, pairs, (, v, ,, n, ), in, the, required, configuration, in, a, training, corpus, ., Some, form, of, text, analysis, is, required, to, collect, such, a, collection, of, pairs, ., The, corpus, used, in, our, first, experiment, was, derived, from, newswire, text, automatically, parsed,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, sequent, marked, with, *, is, easily, seen, to, be, derivable, without, abstractions, ., A, remarkable, point, about, SDL, 's, ability, to, cover, this, language, is, that, neither, L, nor, LP, can, generate, it, ., Hence, ,, this, example, substantiates, the, claim, made, in, (, CITSEG, ), that, the, inferential, capacity, of, mixed, Lambek, systems, may, be, greater, than, the, sum, of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>4</td>\n",
              "      <td>[The, correspondence, between, discourse, segments, and, more, abstract, units, of, meaning, is, poorly, understood, (, see, (, CITSEG, ), ), ., A, number, of, alternative, proposals, have, been, presented, which, directly, or, indirectly, relate, segments, to, intentions, (, CITSEG, ), ,, RST, relations, (, CITSEG, ), or, other, semantic, relations, (, CITSEG, ), ., We, present, initial, resu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>0</td>\n",
              "      <td>[For, example, ,, a, fragment, missing, a, noun, phrase, such, as, John, likes, can, be, associated, with, a, seman, -, I, ,, ies, which, is, a, function, from, entities, to, truth, values, ., Ilence, ,, tam, partial, syntax, tree, given, in, Fig., 14, The, problem, of, there, being, an, arbitrary, mmg, )er, of, different, partial, trees, for, a, particular, fragment, is, refleeted, in, most, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>5</td>\n",
              "      <td>[To, avoid, bias, ,, the, competing, systems, were, presented, anonymously, and, in, random, order, ., Following, (, CITSEG, ), ,, we, provide, the, annotators, with, only, short, sentences, :, those, with, source, sentences, between, 10, and, 25, tokens, long, ., Following, (, CITSEG, ), ,, we, conduct, a, targeted, evaluation, ;, we, only, draw, our, evaluation, pairs, from, the, uncohesive,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>2</td>\n",
              "      <td>[We, give, an, intuitive, description, of, the, mathematical, background, of, Adaptor, Grammars, in, 3.1, ,, referring, the, reader, to, CITSEG, for, technical, details, ., The, models, we, examine, are, derived, from, the, collocational, model, of, by, varying, three, parameters, ,, resulting, in, 6, models, :, two, baselines, that, do, not, take, advantage, of, stress, cues, and, either, do,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, evaluate, the, following, two, search, algorithms, :, •, beam, search, algorithm, (, BS, ), :, (, CITSEG, ), In, this, algorithm, the, search, space, is, explored, in, a, breadth-, first, manner, ., The, search, algorithm, is, based, on, a, dynamic, programming, approach, and, applies, various, pruning, techniques, in, order, to, restrict, the, number, of, considered, hypotheses, ., For, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>1</td>\n",
              "      <td>[Our, results, agree, with, previous, work, on, Arabic, and, Hebrew, in, that, marking, the, definite, article, is, helpful, for, parsing, ., We, go, beyond, previous, work, ,, however, ,, and, explore, additional, lexical, and, inflectional, features, ., Previous, work, with, MaltParser, in, Russian, ,, Turkish, ,, and, Hindi, showed, gains, with, CASE, but, not, with, agreement, features, (,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>3</td>\n",
              "      <td>[While, it, may, be, worth, basing, such, a, model, on, preexisting, sense, classes, (, CITSEG, ), ,, in, the, work, described, here, we, look, at, how, to, derive, the, classes, directly, from, distributional, data, ., More, specifically, ,, we, model, senses, as, probabilistic, concepts, or, clusters, c, with, corresponding, cluster, membership, probabilities, p, (, clw, ), for, each, word, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>465</th>\n",
              "      <td>0</td>\n",
              "      <td>[Some, aspectual, auxiliaries, also, perform, an, aspectual, transformation, of, the, clause, they, modify, ,, e.g., ,, I, finished, staring, at, it, (, culminated, process, ), ., Aspectual, coercion, ,, a, second, type, of, aspectual, transformation, ,, can, take, place, when, a, clause, is, modified, by, an, aspectual, marker, that, violates, an, aspectual, constraint, (, CITSEG, ), ., In, t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>466</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, estimate, P, (, noun2, I, verb, ,, prep, ), and, P, (, noun2, I, nount, ,, prep, ), from, training, data, consisting, of, triples, ,, and, compare, them, :, If, the, former, exceeds, the, latter, (, by, a, certain, margin, ), we, attach, it, to, verb, ,, else, if, the, latter, exceeds, the, former, (, by, the, same, margin, ), we, attach, it, to, noun1, ., In, our, experiments, ,, describ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467</th>\n",
              "      <td>1</td>\n",
              "      <td>[In, their, models, ,, syntactic, and, lexical, /, semantic, features, are, dependent, on, each, other, and, are, combined, together, ., This, paper, also, proposes, a, method, of, utilizing, lexical, /, semantic, features, for, the, purpose, of, applying, them, to, ranking, parses, in, syntactic, analysis, ., However, ,, unlike, the, models, of, CITSEG, ,, and, Charniak, (, 1997, ), ,, we, as...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>468</th>\n",
              "      <td>0</td>\n",
              "      <td>[Despite, their, large, length, difference, ,, the, two, 0002, sentences, are, still, aligned, as, a, 1, -, 1, pair, ,, because, the, sentences, in, the, following, 4, alignments, (, 0003, -, 0003, ;, 0004, -, 0004, ,, 0005, ;, 0005, -, 0006, ;, 0006, -, 0007, ), have, rather, similar, HTML, markups, and, are, taken, by, the, program, to, be, the, most, likely, alignments, ., Beside, HTML, mar...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>469</th>\n",
              "      <td>5</td>\n",
              "      <td>[In, a, debate, with, many, people, arguing, about, many, different, things, ,, we, could, imagine, a, large, network, of, speeches, interacting, with, each, other, in, the, same, way, ., If, we, associate, each, speech, in, the, network, with, its, speaker, ,, we, can, try, to, identify, the, most, important, people, in, the, debate, based, on, how, central, their, speeches, are, in, the, net...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>470</th>\n",
              "      <td>0</td>\n",
              "      <td>[This, paper, presents, a, corpus, -, based, approach, that, results, in, high, accuracy, by, combining, a, number, of, very, simple, classifiers, into, an, ensemble, that, performs, disambiguation, via, a, majority, vote, ., This, is, motivated, by, the, observation, that, enhancing, the, feature, set, or, learning, algorithm, used, in, a, corpus, -, based, approach, does, not, usually, impro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>471</th>\n",
              "      <td>5</td>\n",
              "      <td>[In, total, ,, we, have, 208, topics, annotated, with, keywords, ., The, average, length, of, the, topics, (, measured, using, the, number, of, dialog, acts, ), among, all, the, meetings, is, 172.5, ,, with, a, high, standard, deviation, of, 236.8, ., We, used, six, meetings, as, our, development, set, (, the, same, six, meetings, as, the, test, set, in, (, CITSEG, ), ), to, optimize, our, key...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>472</th>\n",
              "      <td>5</td>\n",
              "      <td>[To, compare, with, it, ,, we, also, reimplement, their, method, without, any, hand, designed, lexicon, ., •, PDTB, -, Rel, :, For, discourse, relation, extraction, ,, we, use, \", PDTB, -, Styled, End, -to, -, End, Discourse, Parser, \", (, CITSEG, ), to, extract, discourse, level, relations, as, baseline, ., Since, it, is, a, general, discourse, relations, identification, algorithms, ,, \", Cau...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>473</th>\n",
              "      <td>3</td>\n",
              "      <td>[However, ,, there, are, many, possible, extensions, that, could, be, examined, in, the, future, and, added, to, the, implementation, if, the, investigation, indicates, that, it, would, create, a, yet, more, usable, system, ., These, include, the, following, :, •, use, of, low, level, knowledge, from, the, speech, recognition, phase, ,, •, use, of, high, level, knowledge, about, the, domain, i...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>474</th>\n",
              "      <td>3</td>\n",
              "      <td>[On, the, other, hand, ,, there, are, valid, translation, pairs, in, the, training, corpus, that, are, not, learned, due, to, word, alignment, errors, as, shown, in, CITSEG, ., We, would, like, to, improve, phrase, translation, accuracy, and, at, the, same, time, extract, as, many, as, possible, valid, phrase, pairs, that, are, missed, due, to, incorrect, word, alignments, ., One, approach, is...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>475</th>\n",
              "      <td>1</td>\n",
              "      <td>[An, objective, and, fair, evaluation, of, the, impact, of, published, research, requires, both, quantitative, and, qualitative, assessment, ., Existing, bibliometric, measures, such, as, H-Index, (, CITSEG, ), ,, G-index, (, CITSEG, ), ,, and, Impact, Factor, (, CITSEG, ), focus, on, the, quantitative, aspect, of, this, evaluation, which, dose, not, always, correlate, with, the, qualitative, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>476</th>\n",
              "      <td>1</td>\n",
              "      <td>[Also, ,, since, none, of, these, studies, relate, observed, performance, to, that, of, other, comparable, parsing, systems, ,, implementational, oversights, may, not, be, apparent, and, so, be, a, confounding, factor, in, any, general, conclusions, made, ., Other, research, directed, towards, improving, the, throughput, of, unification, -, based, parsing, systems, has, been, concerned, with, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>477</th>\n",
              "      <td>4</td>\n",
              "      <td>[One, consists, of, the, headers, of, research, papers, ., The, other, consists, of, pre-segmented, citations, from, the, reference, sections, of, research, papers, ., These, data, sets, have, been, used, as, standard, benchmarks, in, several, previous, studies, (, CITSEG, ), .]</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>478</th>\n",
              "      <td>0</td>\n",
              "      <td>[It, seems, a, perfectly, valid, rule, of, conversation, not, to, tell, people, what, they, already, know, ., Indeed, ,, Grice, 's, QUANTITY, lllaxim, has, often, been, interpreted, this, way, :, Do, not, make, your, contribution, more, informative, than, is, required, [, CITSEG, ], ., Stalnaker, ,, as, well, ,, suggests, that, to, assert, something, that, is, already, presupposed, is, to, att...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>479</th>\n",
              "      <td>0</td>\n",
              "      <td>[Re-estimation, on, any, of, the, words, in, a, class, therefore, counts, towards, re-estimation, for, all, of, them, 1., The, results, of, the, Xerox, experiment, appear, very, encouraging, ., Preparing, tagged, corpora, either, by, hand, is, labour-, intensive, and, potentially, error-prone, ,, and, although, a, semi-automatic, approach, can, be, used, (, CITSEG, ), ,, it, is, a, good, thing...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>5</td>\n",
              "      <td>[Given, a, training, sample, ,, the, SVM, finds, a, hyperplane, with, the, maximal, margin, of, separation, between, the, two, classes, ., The, classification, is, then, just, to, determine, which, side, of, the, hyperplane, the, test, sample, lies, in, ., We, used, the, SVM, light, package, (, CITSEG, ), in, our, experiment, .]</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481</th>\n",
              "      <td>4</td>\n",
              "      <td>[Lexical, selection, is, the, task, of, choosing, target, language, words, that, accurately, reflect, the, meaning, of, the, corresponding, source, language, words, ., It, plays, an, important, role, in, machine, translation, (, (, CITSEG, ), or, interlingua, (, CITSEG, ), ., This, engineering, approach, requires, great, effort, in, designing, the, representation, and, the, mapping, rules, ., ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>482</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, degree, of, difficulty, in, this, task, depends, on, three, factors, ., First, ,, it, depends, on, the, amount, of, supervision, provided, ., CITSEG, ,, for, instance, ,, has, shown, that, a, grammar, can, be, easily, constructed, when, the, examples, are, fully, labeled, parse, trees, ., On, the, other, hand, ,, if, the, examples, consist, of, raw, sentences, with, no, extra, struc-tura...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>483</th>\n",
              "      <td>5</td>\n",
              "      <td>[For, the, 0.16, %, arguments, with, multiple, labels, in, the, training, A, diverse, set, of, 28, features, is, used, in, (, CITSEG, ), for, argument, classification, ., In, this, work, ,, the, number, of, features, is, pruned, to, 11, ,, so, that, we, can, work, with, reasonably, many, auxiliary, problems, in, later, experiments, with, ASO, ., To, find, a, smaller, set, of, effective, featur...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>484</th>\n",
              "      <td>0</td>\n",
              "      <td>[(, CITSEG, ), have, build, a, chunker, by, applying, transformation, -, based, learning, to, sections, of, the, Penn, Treebank, ., Rather, than, working, with, bracket, structures, ,, they, have, represented, the, chunking, task, as, a, tagging, problem, ., POS, -, like, tags, were, used, to, account, for, the, fact, that, words, were, inside, or, outside, chunks, ., They, have, applied, thei...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>5</td>\n",
              "      <td>[During, the, categorization, phase, ,, the, representation, is, used, to, assign, the, appropriate, class, to, a, new, document, vector, ., Several, pruning, or, specialization, heuristics, can, be, used, to, control, the, amount, of, generalization, ., We, used, ID3, (, CITSEG, ), ,, C4.5, (, CITSEG, ), and, C5.0, ,, RIPPER, (, CITSEG, ), ,, and, the, Naive, Bayes, inducer, (, CITSEG, ), con...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>4</td>\n",
              "      <td>[We, represent, each, citation, as, a, feature, set, in, a, Support, Vector, Machine, (, SVM, ), (, CITSEG, ), framework, and, use, n-grams, of, length, 1, to, 3, as, well, as, dependency, triplets, as, features, ., The, dependency, triplets, are, constructed, by, merging, the, relation, ,, governor, and, dependent, in, a, single, string, ,, for, instance, ,, the, relation, nsubj, (, failed, ,...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>487</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, delicacy, of, testsuite, construction, is, acknowledged, in, CITSEG, ,, p.37, ., Although, there, are, a, number, of, e, orts, to, construct, reusable, testsuites, ,, none, has, to, my, knowledge, explored, how, existing, grammars, can, be, exploited, ., CITSEG, ,, testsuites, have, been, drawn, up, from, a, linguistic, viewpoint, ,, informed, by, the, study, of, linguistics, and, re, ec...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>488</th>\n",
              "      <td>0</td>\n",
              "      <td>[While, at, first, sight, it, appears, left-recursive, ,, inspection, of, its, converted, form, shows, its, true, leftmost, subrule, to, be, ', conjunction, ', ., Naturally, ,, compilation, may, induce, left-recursion, as, well, as, eliminating, it, ,, in, which, case, LIIIP, will, suffer, from, the, same, termination, problems, as, an, ordinary, DCG, formalism, interpreted, in, this, way, ., ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489</th>\n",
              "      <td>4</td>\n",
              "      <td>[The, second, technique, is, based, on, discriminatively, -, trained, SVM, classifiers, (, CITSEG, ), ., These, SVM, classifiers, can, handle, many, nonindependent, features, ., However, ,, for, this, sequence, labeling, problem, ,, CITSEG, work, in, a, two, stages, process, :, first, classifying, each, line, independently, to, assign, it, label, ,, then, adjusting, these, labels, based, on, a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>1</td>\n",
              "      <td>[Instead, ,, the, aim, is, to, produce, bilingual, (, i.e., ,, synchronized, ,, see, below, ), dependency, representations, that, are, appropriate, to, performing, the, translation, task, for, a, specific, language, pair, or, specific, bilingual, corpus, ., For, example, ,, headwords, in, both, languages, are, chosen, to, force, a, synchronized, alignment, (, for, better, or, worse, ), in, ord...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491</th>\n",
              "      <td>0</td>\n",
              "      <td>[Additionally, ,, we, present, results, of, the, tagger, on, the, NEGRA, corpus, (, CITSEG, ), and, the, Penn, Treebank, (, CITSEG, ), ., The, Penn, Treebank, results, reported, here, for, the, Markov, model, approach, are, at, least, equivalent, to, those, reported, for, the, Maximum, Entropy, approach, in, (, CITSEG, ), ., For, a, comparison, to, other, taggers, ,, the, reader, is, referred,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, obtained, frequencies, of, cooccurrence, were, weighted, by, the, 1+log, weight, function, ., The, distributional, similarity, was, measured, by, means, of, three, different, similarity, measures, :, the, Jaccard, 's, coefficient, ,, L1, distance, ,, and, the, skew, divergence, ., This, choice, of, similarity, measures, was, motivated, by, results, of, studies, by, (, CITSEG, ), and, (, ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>2</td>\n",
              "      <td>[Secondly, ,, the, later, IBM, models, ,, such, as, Model, 4, ,, have, to, resort, to, heuristic, search, techniques, to, approximate, forward, -, backward, and, Viterbi, inference, ,, which, sacrifice, optimality, for, tractability, ., This, paper, presents, an, alternative, discriminative, method, for, word, alignment, ., We, use, a, conditional, random, field, (, CRF, ), sequence, model, ,,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>4</td>\n",
              "      <td>[These, studies, represent, the, context, in, which, an, ambiguous, word, occurs, with, a, wide, variety, of, features, ., However, ,, when, the, con-tribution, of, each, type, of, feature, to, overall, accuracy, is, analyzed, (, eg., (, CITSEG, ), ), ,, shallow, lexical, features, such, as, co-occurrences, and, collocations, prove, to, be, stronger, contributors, to, accuracy, than, do, deepe...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>0</td>\n",
              "      <td>[It, has, already, made, five, appearances, in, this, paragraph, and, at, least, one, diachronic, study, shows, a, veritable, population, explosion, (, CITSEG, ), ., While, substantial, work, on, noun, compounds, exists, in, both, linguistics, (, e.g., CITSEG, ), and, computational, linguistics, (, CITSEG, ), ,, techniques, suitable, for, broad, coverage, parsing, remain, unavailable, ., This,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>5</td>\n",
              "      <td>[EQUATION, Here, Y(, x, ), denotes, the, set, of, possible, dependency, trees, for, sentence, x., In, this, paper, ,, we, adopt, the, second, -, order, sibling, factorization, (, CITSEG, ), ,, in, which, each, sibling, part, consists, of, a, tuple, of, indices, (, h, ,, m, ,, c, ), where, (, h, ,, m, ), and, (, h, ,, c, ), are, a, pair, of, adjacent, edges, to, the, same, side, of, the, head, ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>0</td>\n",
              "      <td>[Lexical, cohesion, methods, are, typically, used, for, segmenting, written, text, in, a, collection, to, improve, information, retrieval, (, CITSEG, ), ., Multi-source, methods, combine, lexical, cohesion, with, other, indicators, of, topic, shift, such, as, cue, phrases, ,, prosodic, features, ,, reference, ,, syntax, and, lexical, attraction, (, CITSEG, ), using, decision, trees, (, CITSEG,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>5</td>\n",
              "      <td>[P, r(, E, n, ,, A, |E, m, ), =, P, r(, A|E, m, ), •, P, r(, E, n, |, A, ,, E, m, ), As, in, statistical, machine, translation, ,, we, make, modelling, assumptions, ., We, use, the, IBM, Model, 1, (, CITSEG, ), (, uniform, distribution, ), and, the, Hidden, Markov, Model, (, HMM, ,, first, -, order, dependency, ,, (, CITSEG, ), ), to, estimate, the, alignment, model, ., The, lexicon, probabili...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>0</td>\n",
              "      <td>[In, th.e, Japanese, language, ,, the, causative, ~nd, the, change, of, voice, a.re, realized, by, agglutinations, of, those, auxiliary, verbs, at, the, tail, of, current, verbs, ., These, auxiliary, verbs, as, well, a.s, ordinary, verbs, can, dominate, some, cases, so, that, these, agglutinations, may, change, the, whole, syntax, [, CITSEG, ], ., Namely, the, scope, of, the, operation, of, th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>0</td>\n",
              "      <td>[These, PCFGs, encode, a, maximum-likelihood, estimate, of, the, state, transition, probabilities, for, various, stochastic, generalized, left, -, corner, parsers, ,, since, a, top-down, parser, using, these, grammars, simulates, a, generalized, left-corner, parser, ., The, fact, that, LC, P, G, is, 17, times, larger, than, the, PCFG, inferred, after, applying, T, P, to, the, tree, -, bank, me...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>0</td>\n",
              "      <td>[Now, if, we, choose, f, to, be, the, labelling, function, of, D, (, which, maps, node, names, to, node, labels, ), and, G, is, the, chart, of, D, ,, then, L, (, f, (, G, ), ), will, be, the, set, of, configurations, of, D, ., The, grammar, in, Section, 3.2, is, simply, f, (, G, ), for, the, chart, above, (, up, to, consistent, renaming, of, nonterminals, ), ., In, the, worst, case, ,, the, do...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>0</td>\n",
              "      <td>[Recently, ,, the, concept, of, valency, has, gained, considerable, attention, ., Not, only, do, all, linguistic, theories, refer, to, some, reformulation, of, the, traditional, notion, of, valency, (, in, the, form, of, 0grid, ,, subcategorization, list, ,, argument, list, ,, or, extended, domain, of, locality, ), ;, there, is, a, growing, number, of, parsers, based, on, binary, relations, be...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>2</td>\n",
              "      <td>[For, example, ,, fragmentary, utterances, may, be, interpreted, with, respect, to, the, previous, user, input, ,, but, what, users, say, is, often, in, reaction, to, the, system, 's, previous, response, [, CITSEG, ], ., In, this, paper, we, focus, on, interactive, discourse, ., We, model, mixed, -, initiative, using, an, utterance, type, classification, and, a, set, of, rules, for, transfer, ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, word, in, focus, is, first, passed, through, a, twolevel, morphological, analysis, stage, ,, based, on, an, adaption, of, (, CITSEG, ), ., Two, purposes, are, served, here, :, checking, the, word, is, lexica, ], (, i.e., in, the, lexicon, or, a, permissible, inflection, of, a, word, in, the, lexicon, ), and, collecting, the, possible, categories, ,, which, are, represented, as, sets, of,...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>4</td>\n",
              "      <td>[The, hidden, states, represent, word, categories, (, \", tags, \", ), ,, the, observations, they, generate, represent, the, words, themselves, ,, and, the, tree, structure, represents, syntactic, dependencies, between, pairs, of, tags, ., To, validate, the, model, ,, we, test, unsupervised, learning, of, tags, conditioned, on, a, given, dependency, tree, structure, ., This, is, useful, ,, becau...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>506</th>\n",
              "      <td>1</td>\n",
              "      <td>[Another, common, approach, to, lexical, rules, is, to, encode, them, as, unary, phrase, structure, rules, ., This, approach, is, taken, ,, for, example, ,, in, LKB, (, CITSEG, ), where, lexical, rules, are, introduced, on, a, par, with, phrase, structure, rules, and, the, parser, makes, no, distinction, between, lexical, and, nonlexical, rules, (, CITSEG, ,, 31, ), ., A, similar, method, is, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>507</th>\n",
              "      <td>0</td>\n",
              "      <td>[Such, functions, have, been, used, in, tandem, with, statistical, functions, in, experiments, on, disambiguation, (, for, instance, CITSEG, ), ., Another, example, is, connection, strengths, i, ,, m~ural, network, approaches, to, language, processing, ,, th, ,, mgh, it, ., has, been, shown, that, certain, networks, are, ~, ,, tfectively, computing, probabilities, (, CITSEG, ), ., Nevertheless...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>508</th>\n",
              "      <td>1</td>\n",
              "      <td>[Our, approach, follows, CITSEG, in, aiming, to, leverage, the, Penn, Treebank, to, develop, a, broad, -, coverage, surface, realizer, for, English, ., However, ,, while, these, earlier, ,, generation, -, only, approaches, made, use, of, converters, for, transforming, the, outputs, of, Treebank, parsers, to, inputs, for, realization, ,, our, approach, instead, employs, a, shared, bidirectional...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>509</th>\n",
              "      <td>0</td>\n",
              "      <td>[In, (, CITSEG, ), ,, Riley, describes, a, decision, -, tree, based, approach, to, the, problem, ., His, performance, on, /, he, Brown, corpus, is, 99.8, %, ,, using, a, model, learned, t'rom, a, corpus, of, 25, million, words, ., Liberman, and, Church, suggest, in, (, CITSEG, ), that, ., a, system, could, be, quickly, built, to, divide, newswire, text, into, sentences, with, a, nearly, neglig...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>510</th>\n",
              "      <td>4</td>\n",
              "      <td>[The, study, and, the, first, results, we, have, here, presented, cover, from, lexical, semantics, to, discourse, structures, ,, with, strong, interactions, between, these, two, ends, ., Indeed, ,, lexical, informations, can, be, used, to, disambiguate, the, structure, of, the, discours, ,, as, well, as, discourse, relations, can, be, used, to, disambiguate, lexical, entries, ,, as, shown, in,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>511</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, parameterization, is, as, in, C+R, ,, with, one, significant, modification, ., Parameters, consist, of, (, i, ), rule, parameters, ,, corresponding, to, right, hand, sides, conditioned, by, parent, category, and, parent, head, ;, (, ii, ), lexical, choice, parameters, for, nonhead, children, ,, corresponding, to, child, lemma, conditioned, by, child, category, ,, parent, category, ,, and...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>0</td>\n",
              "      <td>[LFG, posits, several, different, representation, levels, ,, called, projections, ., Within, a, projection, ,, a, certain, type, of, linguistic, knowledge, is, represented, ,, which, explains, differences, in, the, formal, setup, (, data, types, and, operations, ), of, the, projections, ., The, two, standard, projections, ,, and, those, used, here, ,, are, the, constituent, (, c, -, ), structu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, former, stem, from, the, work, of, Halliday, and, Hasan, (, CITSEG, ), ., They, proposed, that, text, segments, with, similar, vocabulary, are, likely, to, be, part, of, a, coherent, topic, segment, ., hnplementations, of, this, idea, use, word, stem, repetition, (, CITSEG, ), ,, context, vectors, (, CITSEG, ), ,, entity, repetition, (, CITSEG, ), ,, semantic, similarity, (, CITSEG, ), ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>1</td>\n",
              "      <td>[Results, are, better, using, the, AA, (, ρ, max, =, 0.70, for, AA, -, cos, ), than, using, the, TAA, (, ρ, max, =, 0.56, ), ., Secondly, ,, the, AA, -, cos, spreading, strategy, significantly, outperforms, the, AA, -, wlm, strategy, over, this, sample, set, (, ρ, max, ,, wlm, =, 0.60, vs, ρ, max, ,, cos, =, 0.70, ), ., These, results, compare, favourably, to, similar, inter-concept, results, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>0</td>\n",
              "      <td>[2, ), Agents, involved, in, collaborative, negotiation, are, open, and, honest, with, one, another, ;, they, will, not, deliberately, present, false, information, to, other, agents, ,, present, information, in, such, a, way, as, to, mislead, the, other, agents, ,, or, strategically, hold, back, information, from, other, agents, for, later, use, ., This, distinguishes, collaborative, negotiati...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>4</td>\n",
              "      <td>[3, This, parluneter, lets, us, distinguish, between, an, agent, 's, ability, to, access, all, the, inlimnation, stored, in, its, memory, ,, lind, the, effort, involved, in, doing, so, ., The, advantages, of, the, AWM, model, is, that, it, was, shown, to, reproduce, ,, in, simulation, ,, mlmy, results, on, human, memory, ~md, lem'ning, ., Because, search, st~n'ts, from, the, current, pointer, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>5</td>\n",
              "      <td>[In, most, phrase, -, based, SMT, systems, the, heuristic, grow-, diag, -, final, -, and, is, used, to, combine, the, alignments, generated, by, GIZA, ++, from, both, directions, ., Then, these, alignments, are, used, to, extract, the, phrase, pairs, ., We, used, a, discriminative, word, alignment, model, (, DWA, ), to, generate, the, alignments, as, described, in, CITSEG, instead, ., This, mo...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, substitutions, we, considered, include, cases, we, deemed, harder, than, usual, to, notice, as, spelling, errors, :, common, letter, shape, alternations, (, e.g., ,, È, r, and, ©, È, z, ), ,, phonological, alternations, (, e.g., ,, à, S, and, s, ), and, dialectal, variations, (, e.g., ,, q, and, ³ŷ, ), ., We, do, not, handle, misspellings, involving, two, words, attached, to, each, other...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519</th>\n",
              "      <td>1</td>\n",
              "      <td>[In, addition, ,, hierarchical, relations, based, on, various, data, may, be, needed, depending, on, each, user, ., Accordingly, ,, we, try, to, extract, a, hierarchical, relation, of, words, automatically, and, statistically, ., In, previous, research, ,, ways, of, extracting, from, definition, sentences, in, dictionaries, (, CITSEG, ), or, from, a, corpus, by, using, patterns, such, as, \", a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520</th>\n",
              "      <td>5</td>\n",
              "      <td>[Our, task, is, to, order, the, target, dependency, tree, ., We, train, a, statistical, model, to, select, the, best, order, of, the, unordered, target, dependency, tree, ., An, important, advantage, of, our, model, is, that, it, is, global, ,, and, does, not, decompose, the, task, of, ordering, a, target, sentence, into, a, series, of, local, decisions, ,, as, in, the, recently, proposed, ord...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>521</th>\n",
              "      <td>5</td>\n",
              "      <td>[To, create, and, train, our, coreference, resolver, ,, we, used, a, combination, of, techniques, as, outlined, originally, by, (, CITSEG, ), and, subsequently, extended, by, (, CITSEG, ), ., Mimicking, their, approaches, ,, we, used, the, corpora, provided, for, the, MUC, -, 7, coreference, resolution, task, (, LDC2001, T02, ,, 2001, ), ,, which, includes, sets, of, newspaper, articles, ,, an...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>522</th>\n",
              "      <td>4</td>\n",
              "      <td>[Applicative, Categorial, Grammar, is, the, most, basic, form, of, Categorial, Grammar, ,, with, just, a, single, combination, rule, corresponding, to, function, application, ., It, was, first, applied, to, linguistic, description, by, Adjukiewicz, and, Bar-Hillel, in, the, 1950s, ., Although, it, is, still, used, for, linguistic, description, (, e.g., CITSEG, ), ,, it, has, been, somewhat, ov...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>2</td>\n",
              "      <td>[The, filtering, function, p, is, similar, to, (, CITSEG, ), :, p(, D, ), returns, a, copy, of, D, in, which, some, features, may, be, removed, ., Note, that, in, this, paper, ., restrictor, ., specifies, the, features, to, be, removed, by, p, ,, whereas, in, (, CITSEG, ), restrictor, specifies, the, features, to, be, retained, by, restriction, which, is, equivalent, to, p.]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>1</td>\n",
              "      <td>[We, now, give, a, more, detailed, comparison, of, the, models, in, this, article, to, the, parser, of, CITSEG, ., The, model, described, in, CITSEG, has, two, types, of, parameters, :]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>0</td>\n",
              "      <td>[This, dimension, characterizes, the, potential, effect, that, an, utterance, Ui, has, on, the, subsequent, dialogue, ,, and, roughly, corresponds, to, the, classical, notion, of, an, illocutionary, act, (, CITSEG, ), ., As, each, Ui, may, simultaneously, achieve, multiple, effects, ,, it, can, be, coded, for, three, different, aspects, :, Statement, ,, Influence, -, on, -, Hearer, ,, Influenc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, evaluation, is, summarized, in, Table, 3, ., The, results, demonstrate, that, either, leveraging, the, same, unlabeled, data, or, providing, a, much, larger, unlabeled, dataset, for, the, monolingual, semisupervised, methods, ,, the, SLBD, method, can, significantly, outperform, the, evaluated, monolingual, semi-supervised, methods, ,, which, indicates, that, the, segmenting, information...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>527</th>\n",
              "      <td>0</td>\n",
              "      <td>[Several, measures, of, distributional, similarity, have, been, proposed, in, the, literature, (, CITSEG, ), ., We, used, two, measures, ,, the, Jensen, -, Shannon, divergence, and, the, confusion, probability, ., Those, two, measures, have, been, previously, shown, to, give, promising, performance, for, the, task, of, estimating, the, frequencies, of, unseen, verb-argument, pairs, (, CITSEG, ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>528</th>\n",
              "      <td>1</td>\n",
              "      <td>[Focusing, solely, on, word, sense, discrimination, also, liberates, us, of, a, serious, constraint, common, to, other, work, on, word, sense, disambiguation, ., If, sense, labeling, is, part, of, the, task, ,, an, outside, source, of, knowledge, is, necessary, to, define, the, senses, ., Regardless, of, whether, it, takes, the, form, of, dictionaries, (, CITSEG, ), ,, thesauri, (, CITSEG, ), ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>529</th>\n",
              "      <td>1</td>\n",
              "      <td>[By, comparison, to, previous, work, in, unification, -, based, parsing, we, have, demonstrated, that, pro-and, retroactive, packing, are, well, -, suited, to, achieve, optimal, packing, ;, furthermore, ,, experimental, results, obtained, with, a, publicly, -, available, HPSG, processing, platform, confirm, that, ambiguity, packing, can, greatly, reduce, average, parse, complexity, for, this, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>530</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, used, two, datasets, ,, customer, reviews, (, CITSEG, ), and, movie, reviews, (, CITSEG, ), to, evaluate, sentiment, classification, of, sentences, ., Both, of, these, two, datasets, are, often, used, for, evaluation, in, sentiment, analysis, researches, ., The, number, of, examples, and, other, statistics, of, the, datasets, are, shown, in, Table, 1, ., Our, method, cannot, be, applied, ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>0</td>\n",
              "      <td>[However, ,, the, following, problems, arise, from, the, semantic, differential, procedure, as, measurement, of, meaning, ., The, procedure, is, not, based, on, the, denotative, meaning, of, a, word, ,, but, only, on, the, connotative, emotions, attached, to, the, word, ;, it, is, difficult, to, choose, the, relevant, dimensions, ,, i.e., the, dimensions, required, for, the, sufficient, semant...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, latter, could, be, just, a, useful, indication, to, the, translator, using, the, EBMT, system, ,, or, a, crucial, functional, factor, of, the, system, as, will, be, later, explained, ., The, similarity, metrics, reported, in, the, literature, can, be, characterised, depending, on, the, text, patterns, they, are, applied, on, ., So, ,, the, word, -, based, metrics, compare, individual, wo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>533</th>\n",
              "      <td>1</td>\n",
              "      <td>[In, this, paper, ,, we, compared, several, approaches, to, resolve, cases, of, coreferent, bridging, in, open-domain, newspaper, text, ., While, none, of, the, information, sources, can, match, the, precision, of, the, hypernymy, information, encoded, in, GermaNet, ,, or, that, of, using, a, combination, of, high, -, precision, patterns, with, the, World, Wide, Web, as, a, very, large, corpus...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534</th>\n",
              "      <td>2</td>\n",
              "      <td>[Now, we, are, ready, to, encode, the, problem, of, generating, grammatical, LTAG, derivation, trees, into, PDDL, ., PDDL, (, CITSEG, ), is, the, standard, input, language, for, modern, planning, systems, ., It, is, based, on, the, well, -, known, STRIPS, language, (, CITSEG, ), ., In, this, paradigm, ,, a, planning, state, is, defined, as, a, finite, set, of, ground, atoms, of, predicate, log...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>535</th>\n",
              "      <td>4</td>\n",
              "      <td>[This, algorithm, was, first, implemented, for, the, MUC, -6, FASTUS, system, (, CITSEG, ), ,, and, produced, one, of, the, top, scores, (, a, recall, of, 59, %, and, precision, of, 72, %, ), in, the, MUC, -, 6, Coreference, Task, ,, which, evaluated, systems, ', ability, to, recog-nize, coreference, among, noun, phrases, (, CITSEG, ), ., Note, that, only, identity, of, reference, was, evaluat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>536</th>\n",
              "      <td>0</td>\n",
              "      <td>[It, is, by, now, commonplace, knowledge, that, accurate, syntactic, parsing, is, not, possible, given, only, a, context, -, free, grammar, with, standard, Penn, Treebank, (, CITSEG, ), labels, (, e.g., ,, S, ,, N, P, ,, etc., ), (, CITSEG, ), ., Instead, researchers, condition, parsing, decisions, on, many, other, features, ,, such, as, parent, phrase, -, marker, ,, and, ,, famously, ,, the, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>537</th>\n",
              "      <td>4</td>\n",
              "      <td>[This, may, be, explained, by, the, fact, that, there, are, many, more, tree, structures, possible, for, the, four-, class, case, than, the, three, -, class, case, ,, thereby, increasing, the, impact, of, the, inter-class, similarity, measure, for, the, four-class, case, ., However, ,, this, impact, is, significant, only, in, conjunction, with, feature, culling, ., CITSEG, Figure, 2, compares,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>538</th>\n",
              "      <td>2</td>\n",
              "      <td>[For, this, system, ,, the, main, goals, are, that, an, executable, plan, which, meets, the, user, 's, goals, is, constructed, and, agreed, upon, by, both, the, system, and, the, user, and, then, that, the, plan, is, executed, ., The, dialogue, manager, must, keep, track, of, the, current, state, of, the, dialogue, ,, determine, the, effects, of, observed, conversation, acts, ,, generate, utte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>539</th>\n",
              "      <td>3</td>\n",
              "      <td>[Our, basic, parsing, and, interactive, training, paradigm, is, based, on, (, CITSEG, ), ., We, have, extended, their, work, by, significantly, increasing, the, expressiveness, of, the, parse, action, and, feature, languages, ,, in, particular, by, moving, far, beyond, the, few, simple, features, that, were, limited, to, syntax, only, ,, by, adding, more, background, knowledge, and, by, introd...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, gold, -, standard, sense, annotations, allow, us, to, perform, upper, bound, evaluation, of, the, relative, impact, of, a, given, semantic, representation, on, parsing, and, PP, attachment, performance, ,, to, contrast, with, the, performance, in, more, realistic, semantic, disambiguation, settings, ., The, gold, -, standard, parse, tree, annotations, are, required, in, order, to, carry,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>541</th>\n",
              "      <td>2</td>\n",
              "      <td>[Let, At, =, {, Q, ,, ..., ,, i, ,, ~}, be, the, set, of, features, that, are, active, in, an, example, and, are, linked, to, the, target, node, t., Then, the, linear, unit, corresponding, to, t, is, active, iff, t, E, w, i, &gt;, Ot, ,, iEAt, where, w~, is, the, weight, on, the, edge, connecting, the, ith, feature, to, the, target, node, t, ,, and, Ot, is, the, threshold, A, given, example, is, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>542</th>\n",
              "      <td>0</td>\n",
              "      <td>[Design, -, World, agents, can, be, parametrized, as, to, discourse, strategy, ,, and, tilt, elfecls, of, this, strategy, can, he, me, ~, Lsured, against, a, |, 'imge, of, cognitive, and, task, p~u'ameters, ., This, paper, compares, [, l~e, Explicit, -, Winrant, strategy, to, the, All-lmplicil, strategy, as, strategies, lot, supporting, deliberation, ., Other, strategies, tested, in, Design, -...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>543</th>\n",
              "      <td>0</td>\n",
              "      <td>[Mainstream, approaches, in, statistical, parsing, are, based, on, nondeterministic, parsing, techniques, ,, usually, employing, some, kind, of, dynamic, programming, ,, in, combination, with, generative, probabilistic, models, that, provide, an, n-best, ranking, of, the, set, of, candidate, analyses, derived, by, the, parser, (, CITSEG, ), ., These, parsers, can, be, enhanced, by, using, a, d...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>544</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, can, now, detect, and, correct, a, repair, ,, given, a, sentence, annotated, with, POS, tags, and, semantic, classes, ., But, how, can, we, construct, such, a, sequence, from, a, word, lattice, ?, Integrating, the, model, in, a, lattice, algorithm, requires, three, steps, :, mapping, the, word, lattice, to, a, tag, lattice, triggering, IPs, and, extracting, the, possible, reparandum, repa...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>545</th>\n",
              "      <td>4</td>\n",
              "      <td>[Among, the, n-best, sequences, output, by, the, MEMM, tagger, ,, the, sequence, with, the, highest, F-score, is, used, as, the, ', correct, ', sequence, for, training, the, reranker, ., The, two, log-linear, models, for, the, MEMM, tagger, and, reranker, are, estimated, using, a, limited, -, memory, BFGS, algorithm, implemented, in, an, open-source, software, Amis, 3, ., In, both, models, ,, ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546</th>\n",
              "      <td>0</td>\n",
              "      <td>[Variants, of, the, composition, rule, were, proposed, in, order, to, deal, with, non-peripheral, extraction, ,, 4, The, reformulation, is, not, entirely, faithful, here, to, Bar-Hillel, ,, who, used, a, slightly, problematic, ', double, slash, ', notation, for, functions, of, functions, ., 5, Lambek, notation, (, CITSEG, ), ., but, this, led, to, unwanted, effects, elsewhere, in, the, grammar...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>547</th>\n",
              "      <td>5</td>\n",
              "      <td>[In, order, to, facilitate, learning, of, cues, for, the, less, frequent, classes, ,, the, data, was, upsampled, (, duplicated, ), so, that, there, were, the, same, number, of, training, points, per, class, ., The, decision, tree, size, was, determined, using, error-, based, cost-, complexity, pruning, with, 4, -, fold, cross, validation, ., To, reduce, our, initial, candidate, feature, set, ,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>548</th>\n",
              "      <td>0</td>\n",
              "      <td>[therefore, show, that, phonotactics, can, indeed, he, learned, without, access, to, a, lexicon, --, without, such, a, tlemonsl, ., raliion, ,, we, are, trapped, in, circular, rc, ;, Lsoning, ., Gafos, :, and, CITSEG, demonstrate, that, phonotacties, can, be, learned, with, high, accuracy, from, the, same, unsegmented, utterances, we, used, in, our, simulations, ., In, general, ,, two, meth, -...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>549</th>\n",
              "      <td>4</td>\n",
              "      <td>[To, compare, our, work, with, Athar, (, 2011, ), ,, we, also, applied, a, three, -, class, annotation, scheme, ., In, this, method, of, annotation, ,, we, merge, the, citation, context, into, a, single, sentence, ., Since, the, context, introduces, more, than, one, sentiment, per, citation, ,, we, marked, the, citation, sentiment, with, the, last, sentiment, mentioned, in, the, context, windo...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>550</th>\n",
              "      <td>0</td>\n",
              "      <td>[CITSEG, --, without, actually, building, a, parsing, system, --, address, the, issue, of, how, frequency, information, can, be, associated, with, lexicalised, grammar, formalisms, ,, using, Lexicalized, Tree, Adjoining, Grammar, (, CITSEG, ), as, a, unifying, framework, ., They, consider, systematically, a, number, of, alternative, probao, bilistic, formulations, ,, including, those, of, CITS...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>551</th>\n",
              "      <td>1</td>\n",
              "      <td>[While, different, schemes, have, been, proposed, for, annotating, citations, according, to, their, function, (, CITSEG, ), ,, the, only, recent, work, on, citation, sentiment, detection, using, a, relatively, large, corpus, is, by, CITSEG, ., However, ,, this, work, does, not, handle, citation, context, ., CITSEG, proposed, a, system, to, attach, sentiment, information, to, the, citation, lin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552</th>\n",
              "      <td>2</td>\n",
              "      <td>[Discrepancies, in, length, throw, constituents, off, balance, ,, and, so, prosodic, phrasing, will, cross, constituent, boundaries, in, order, to, give, the, phrases, similar, lengths, ;, this, is, the, case, in, Chickens, were, eating, I, [, the, remaining, green, vegetables, ,, where, the, subject, -, predicate, boundary, finds, no, prosodic, correspondent, ., 4, The, most, explicit, versio...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553</th>\n",
              "      <td>0</td>\n",
              "      <td>[In, this, view, ,, the, semantic, space, is, constructed, from, words, that, bear, a, syntactic, relationship, to, the, target, word, of, interest, ., This, makes, semantic, spaces, more, flexible, ,, different, types, of, contexts, can, be, selected, and, words, do, not, have, to, physically, co-occur, to, be, considered, contextually, relevant, ., However, ,, existing, models, either, conce...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>5</td>\n",
              "      <td>[Summarization, system, is, then, an, ideal, pre-processing, component, in, the, sense, that, it, helps, to, reduce, the, number, of, tweets, for, processing, without, much, lose, of, information, ., Multi-document, summarization, has, been, well, studied, ,, and, a, couple, of, systems, have, been, developed, ., We, test, LexRank, (, CITSEG, ), ,, a, state, -, of, -, the, -, art, summarizatio...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, Direct, Inversion, Approach, (, DI, ,, ~, ), of, CITSEG, overcomes, these, problems, by, making, the, reordering, process, more, goal, -, directed, and, developing, a, reformulation, technique, that, allows, the, successful, treatment, of, rules, which, exhibit, head, -, recursion, ., Both, the, EAA, and, the, DIA, were, presented, as, approaches, to, the, inversion, of, parseroriented, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>2</td>\n",
              "      <td>[The, desired, result, is, that, (, once, an, overall, match, is, established, ), the, first, set, of, parentheses, should, capture, the, longest, string, possible, (, top, ), ;, the, second, set, should, then, match, the, longest, string, possible, from, what, 's, left, (, o, ), ,, and, so, on, ., Such, a, left, -, most, longest, match, concatenation, operation, is, described, in, §, 3., In, ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, implemented, Cubit, ,, a, Python, clone, of, the, Pharaoh, decoder, (, CITSEG, ), ,, and, adapted, cube, pruning, to, it, as, follows, ., As, in, Pharaoh, ,, each, bin, i, contains, hypotheses, (, i.e., ,, +, LM, items, ), covering, i, words, on, the, source, -, side, ., But, at, each, bin, (, see, Figure, 5, ), ,, all, +, LM, items, from, previous, bins, are, first, partitioned, into, −,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558</th>\n",
              "      <td>4</td>\n",
              "      <td>[We, merge, the, text, of, the, sentences, in, the, context, windows, as, well, as, their, dependency, triplets, to, obtain, the, features, ., The, results, are, reported, in, Table, 3, with, best, results, in, bold, ., Although, these, results, are, not, better, than, the, context, -, less, baseline, ,, the, reason, might, be, data, sparsity, since, existing, work, on, citation, sentiment, an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559</th>\n",
              "      <td>0</td>\n",
              "      <td>[Jaccard, 's, coefficient, (, CITSEG, ), calculates, the, proportion, of, features, belonging, to, either, word, that, are, shared, by, both, words, ., In, the, simplest, case, ,, the, features, of, a, word, are, defined, as, the, contexts, in, which, it, has, been, seen, to, occur, ., sim, ja+mi, is, a, variant, (, CITSEG, ), in, which, the, features, of, a, word, are, those, contexts, for, w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>560</th>\n",
              "      <td>0</td>\n",
              "      <td>[Our, system, maintains, a, set, of, beliefs, about, the, domain, and, about, the, user, 's, beliefs, ., Associated, with, each, belief, is, a, strength, that, represents, the, agent, 's, confidence, in, holding, that, belief, ., We, model, the, strength, of, a, belief, using, endorsements, ,, which, are, explicit, records, of, factors, that, affect, one, 's, certainty, in, a, hypothesis, (, C...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>561</th>\n",
              "      <td>0</td>\n",
              "      <td>[Following, CITSEG, ,, Jackendoff, (, 1976, ), ,, CITSEG, ,, we, approach, motion, verbs, in, terms, of, some, \", localist, semantical, \", role, labels, ., The, linguistic, study, of, French, intransitive, motion, verbs, (, see, eg, ., (, CITSEG, ), ), we, have, realized, has, allowed, the, definition, of, an, ontology, for, \", location, \", in, three, basic, concepts, :, •, locations, which, a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562</th>\n",
              "      <td>2</td>\n",
              "      <td>[For, the, 2011, Workshop, on, Machine, Translation, ,, we, built, a, hybrid, MT, system, ,, including, both, syntactic, and, non-syntactic, rules, ,, and, submitted, it, as, a, constrained, entry, to, the, French, -, English, translation, task, ., This, is, our, fourth, yearly, submission, to, the, WMT, shared, translation, task, ., In, design, and, construction, ,, the, system, is, similar, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>563</th>\n",
              "      <td>0</td>\n",
              "      <td>[Even, moderately, long, documents, typically, address, sew~ral, topics, or, different, aspects, of, the, same, topic, ., The, aim, of, linear, text, segmentation, is, to, discover, the, topic, boundaries, ., The, uses, of, this, procedure, include, information, retrieval, (, CITSEG, ), ,, summarization, (, CITSEG, ), ,, text, understanding, ,, anaphora, resolution, (, CITSEG, ), ,, language, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>0</td>\n",
              "      <td>[Thus, ,, it, is, important, to, maintain, the, possibility, of, flexible, distinction, of, the, different, senses, ,, e.g., ,, by, letting, this, distinction, be, determined, by, an, external, knowledge, source, such, as, a, thesaurus, or, a, dictionary, ., Although, this, requirement, may, seem, trivial, ,, most, corpus, -, based, methods, do, not, ,, in, fact, ,, allow, such, flexibility, ....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>0</td>\n",
              "      <td>[To, realize, a, domain-, independent, abstract, generation, system, ,, a, computational, theory, for, analyzing, linguistic, discourse, structure, and, its, practical, procedure, must, be, established, ., ltobbs, developed, a, theory, in, which, lie, arranged, three, kinds, of, relationships, between, sentences, from, the, text, coherency, viewpoint, [, CITSEG, ], ., Grosz, and, Sidner, propo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>0</td>\n",
              "      <td>[tions, which, show, that, people~, start, speaklug, 1, ), e, [, bre, all, necessary, linguistic, material, has, been, chosen, (, e.g., ,, articulating, a, noun, phrase, be, [, 'ore, ,, the, dominating, w', .rb, is, selected, ), ., As, a, consequence, of, undersl, ), ecification, ,, incremental, generation, is, essentially, based, on, working, with, defaults, ,, l'~lements, are, uttered, befor...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, number, of, candidates, 5, ), Node, activation, scores, were, calculated, for, each, pair, in, the, test, data, ,, and, the, candidates, were, ranked, by, their, score, ., The, candidate, with, the, highest, node, activation, score, was, selected, as, the, transliteration, of, the, given, English, name, ., Some, examples, of, English, words, and, the, top, three, ranking, candidates, amo...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>0</td>\n",
              "      <td>[DCGs, are, represented, using, the, same, notation, we, used, for, context, -, free, grammars, ,, but, now, of, course, the, category, symbols, can, be, first, -, order, terms, of, arbitrary, complexity, (, note, that, without, loss, of, generality, we, do, n't, take, into, account, DCGs, having, exter, -, ], In, fact, ,, the, standard, compilation, of, DCG, into, Prolog, clauses, does, somet...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>569</th>\n",
              "      <td>2</td>\n",
              "      <td>[0362-613X/87/030203-218503.00, on, developing, dictionary, servers, for, office, automation, systems, (, CITSEG, ), ., Few, established, parsing, systems, have, substantial, lexicons, and, even, those, which, employ, very, comprehensive, grammars, (, eg., CITSEG, ), consult, relatively, small, lexicons, ,, typically, generated, by, hand, ., Two, exceptions, to, this, generalisation, are, the,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570</th>\n",
              "      <td>0</td>\n",
              "      <td>[What, is, the, role, of, citation, contexts, in, the, overall, structure, of, scientific, context, ?, We, assume, a, hierarchical, ,, rhetorical, structure, not, unlike, RST, (, CITSEG, ), ,, but, much, flatter, ,, where, the, atomic, units, are, textual, blocks, which, carry, a, certain, functional, role, in, the, overall, scientific, argument, for, publication, (, CITSEG, ), ., Under, such,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>571</th>\n",
              "      <td>4</td>\n",
              "      <td>[An, analysis, of, the, mechanism, of, temporal, anaphoric, reference, hinges, upon, an, understanding, of, the, ontological, and, logical, foundations, of, temporal, reference, ., Different, concepts, have, been, used, in, the, literature, as, primitives, ., These, range, from, temporal, instants, in, Tense, logic, (, CITSEG, ), ,, through, intervals, of, time, (, CITSEG, (, 1972, ), ), as, i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>572</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, generalization, bound, tells, us, how, far, the, expected, average, regret, E[, REG, T, ], (, or, average, risk, ,, in, terms, of, CITSEG, ), is, from, the, average, regret, that, we, actually, observe, in, a, specific, instantiation, of, the, algorithm, ., Generalization, for, Online-to-, Batch, Conversion, ., In, practice, ,, perceptron, -, type, algorithms, are, often, applied, in, a,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>573</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, used, the, direct, output, of, the, 42-, topic, model, of, the, 105th, -, 108th, Senates, from, (, CITSEG, ), to, further, divide, the, speech, documents, into, topic, clusters, ., In, their, paper, ,, they, use, a, model, where, the, probabilities, of, a, document, belonging, to, a, certain, topic, varies, smoothly, over, time, and, the, words, within, a, given, document, have, exactly, ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>574</th>\n",
              "      <td>0</td>\n",
              "      <td>[In, other, words, ,, our, meta, -, level, process, learns, to, predict, the, performance, of, the, different, methods, from, their, confidence, levels, on, the, basis, of, previous, experience, ., These, predictions, enable, our, system, to, recommend, a, particular, method, for, handling, a, new, (, unseen, ), request, (, CITSEG, ), ., Following, CITSEG, ,, one, approach, for, achieving, thi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, build, a, lexical, co-occurrence, network, as, follows, :, Given, a, root, word, ,, connect, it, to, all, the, words, that, significantly, co-occur, with, it, in, the, training, corpus, ;, 1, then, ,, recursively, connect, these, words, to, their, significant, cooccurring, words, up, to, some, specified, depth, ., We, use, the, intersection, of, two, well, -, known, measures, of, signific...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>576</th>\n",
              "      <td>5</td>\n",
              "      <td>[Concept, annotated, datasets, can, be, used, to, test, the, ability, of, a, measure, to, differentiate, between, senses, when, determining, the, relatedness, of, polysemous, words, ., To, our, knowledge, ,, this, study, is, the, first, to, include, concept, pairs, and, to, automatically, generate, the, test, dataset, ., In, our, experiment, ,, we, annotated, a, high, number, of, pairs, simila...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577</th>\n",
              "      <td>0</td>\n",
              "      <td>[EBMT, is, based, on, the, idea, of, performing, translation, by, imitating, translation, examples, of, similar, sentences, [, CITSEG, ], ., In, this, type, of, translation, system, ,, a, large, amount, of, bi, /, multi-lingual, translation, examples, has, been, stored, in, a, textual, database, and, input, expressions, are, rendered, in, the, target, language, by, retrieving, from, the, datab...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>578</th>\n",
              "      <td>5</td>\n",
              "      <td>[Indeed, ,, when, developing, a, grammar, ,, it, is, necessary, to, have, some, means, of, assessing, both, the, coverage, of, the, grammar, (, does, it, generate, all, the, sentences, of, the, described, language, ?, ), and, its, degree, of, overgeneration, (, does, it, generate, only, the, sentences, of, the, described, language, ?, ), While, corpus, driven, efforts, along, the, PAR, -, SEVA...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>579</th>\n",
              "      <td>0</td>\n",
              "      <td>[This, paper, presents, Genpex, ,, a, system, for, generating, narrative, exercises, expressing, probability, problems, ., Genpex, was, created, in, the, context, of, an, inter-national, project, on, item, generation, for, testing, student, competencies, in, solving, probability, problems, ., Automatic, item, generation, is, an, effective, way, of, constructing, many, items, with, controlled, ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>580</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, data, was, preprocessed, using, regular, expressions, for, phone, numbers, ,, email, addresses, and, URLs, ., The, list, of, the, constraints, for, this, domain, is, given, in, Table, 1, ., We, implement, some, global, constraints, and, include, unary, constraints, which, were, largely, imported, from, the, list, of, seed, words, used, in, (, CITSEG, ), ., We, slightly, modified, the, se...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581</th>\n",
              "      <td>5</td>\n",
              "      <td>[To, evaluate, iterative, training, ,, we, extracted, maximum, probability, (, Viterbi, ), trees, for, the, 600, clause, test, set, in, each, iteration, of, parsing, ., For, extraction, of, a, maximal, probability, parse, in, unlexicalized, training, ,, we, used, Schmid, 's, lopar, parser, (, CITSEG, ), ., Trees, were, mapped, to, a, database, of, parser, generated, markup, guesses, ,, and, we...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>582</th>\n",
              "      <td>0</td>\n",
              "      <td>[By, indicating, that, the, speaker, does, not, want, the, floor, ,, prompts, function, on, a, number, of, levels, ,, including, the, expression, of, understanding, or, agreement, [, CITSEG, ], ., The, rules, for, the, allocation, of, control, are, based, on, the, utterance, type, classification, and, allow, a, dialogue, to, be, divided, into, segments, that, correspond, to, which, speaker, is...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>583</th>\n",
              "      <td>0</td>\n",
              "      <td>[If, the, system, can, recognize, that, the, second, \", OJIISAN, (, old, man, ), \", has, the, referential, property, of, the, definite, noun, phrase, ,, indicating, that, the, noun, phrase, refers, to, the, contextually, non-ambiguous, entity, ,, it, will, be, able, to, judge, that, the, second, \", OJIISAN, (, old, man, ), \", refers, to, the, entity, denoted, by, the, first, \", OJIISAN, (, old...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>584</th>\n",
              "      <td>1</td>\n",
              "      <td>[Tong, 's, system, (, CITSEG, ), generates, sentiment, timelines, ,, tracking, online, discussions, and, creating, graphs, of, positive, and, negative, opinion, messages, over, time, ., Research, in, genre, classification, may, include, recognition, of, subjective, genres, such, as, editorials, (, e.g., ,, (, CITSEG, ), ), ., In, contrast, ,, our, work, classifies, individual, sentences, ,, as...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>585</th>\n",
              "      <td>4</td>\n",
              "      <td>[The, support, /, oppose, classification, problem, can, be, approached, through, the, use, of, standard, classifiers, such, as, support, vector, machines, (, SVMs, ), ,, which, consider, each, text, unit, in, isolation, ., As, discussed, in, Section, 1, ,, however, ,, the, conversational, nature, of, our, data, implies, the, existence, of, various, relationships, that, can, be, exploited, to, ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>586</th>\n",
              "      <td>1</td>\n",
              "      <td>[Table, 2, shows, the, system, 's, performance, for, pronouns, broken, down, by, two, parameters, ,, grammatical, person, and, inter, -, vs., intrasentential, antecedent, ., The, system, did, quite, well, (, 78, %, ), with, third, -, person, pronouns, with, intrasentential, antecedents, ,, the, largest, class, of, such, pronouns, ., Part, of, the, pronoun, resolution, performance, here, enable...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>587</th>\n",
              "      <td>0</td>\n",
              "      <td>[Pronominalization, in, particular, serves, to, focus, attention, on, what, is, being, talked, about, ;, inappropriate, use, or, failure, to, use, pronouns, causes, communication, to, be, less, fluent, ., For, instance, ,, it, takes, longer, for, hearers, to, process, a, pronominalized, noun, phrase, that, is, no, ~, in, focus, than, one, that, is, ,, while, it, takes, longer, to, process, a, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>588</th>\n",
              "      <td>4</td>\n",
              "      <td>[They, found, out, that, different, features, suited, for, different, sub, tasks, of, SRL, ,, i.e., semantic, role, identification, and, classification, ., For, semantic, analysis, ,, developing, features, that, capture, the, right, kind, of, information, is, crucial, ., Experiments, on, Chinese, SRL, (, CITSEG, ), reassured, these, findings, ., In, this, paper, ,, we, mainly, focus, on, the, ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>589</th>\n",
              "      <td>0</td>\n",
              "      <td>[Unsupervised, methods, have, seen, substantial, reductions, in, alignment, error, (, CITSEG, ), as, measured, by, the, now, much, -, maligned, AER, metric, ., A, host, of, discriminative, methods, have, been, introduced, (, CITSEG, ), ., However, ,, few, of, these, methods, have, explicitly, addressed, the, tension, between, word, alignments, and, the, syntactic, processes, that, employ, them...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>590</th>\n",
              "      <td>4</td>\n",
              "      <td>[Attempts, to, segment, transcriptions, without, pauses, ,, e.g., (, CITSEG, ), ,, have, worked, poorly, ., Claims, that, humans, can, extract, words, without, pauses, seem, to, be, based, on, psychological, experiments, such, as, (, CITSEG, ), which, conflate, words, and, morphemes, ., Even, then, ,, explicit, boundaries, seem, to, improve, performance, (, CITSEG, ), ., Another, significant, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>591</th>\n",
              "      <td>5</td>\n",
              "      <td>[5, ., Cut, up, the, training, examples, by, matching, them, against, the, and, -, or, tree, and, cutting, at, the, determined, cutnodes, ., It, is, interesting, to, note, that, a, textbook, method, for, conslructing, decision, trees, for, classification, from, attribute, -, value, pairs, is, to, minimize, the, (, weighted, average, of, the, ), remaining, entropy, 5, over, all, possible, choic...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>592</th>\n",
              "      <td>0</td>\n",
              "      <td>[CITSEG, observe, that, for, two, potential, mutual, translations, X, and, Y, ,, the, fact, that, X, occurs, with, translation, Y, indicates, association, ;, X, 's, occurring, with, a, translation, other, than, Y, decreases, one, 's, belief, in, their, association, ;, but, the, absence, of, both, X, and, Y, yields, no, information, ., In, essence, ,, Smadja, et, al., argue, that, information, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>593</th>\n",
              "      <td>5</td>\n",
              "      <td>[As, our, baseline, parsers, ,, we, use, two, state, -, of, -, theart, lexicalised, parsing, models, ,, namely, the, Bikel, parser, (, CITSEG, ), and, Charniak, parser, (, CITSEG, ), ., While, a, detailed, description, of, the, respective, parsing, models, is, beyond, the, scope, of, this, paper, ,, it, is, worth, noting, that, both, parsers, induce, a, context, free, grammar, as, well, as, a,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>594</th>\n",
              "      <td>0</td>\n",
              "      <td>[1, Introduction, \", Unification, -, based, \", Grammars, (, UBGs, ), can, capture, a, wide, variety, of, linguistically, important, syntactic, and, semantic, constraints, ., However, ,, because, these, constraints, can, be, non-local, or, context-sensitive, ,, developing, stochastic, versions, of, UBGs, and, associated, estimation, procedures, is, not, as, straight, -, forward, as, it, is, for...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>595</th>\n",
              "      <td>0</td>\n",
              "      <td>[This, approach, is, exemplified, by, Combinatory, Categorial, Grammar, ,, CCG, (, CITSEG, ), ,, which, takes, a, basic, CG, with, just, application, ,, and, adds, various, new, ways, of, combining, elements, together, 2., Incremental, interpretation, can, then, be, achieved, using, a, standard, bottom, -, up, shift, reduce, parser, ,, working, from, left, to, right, along, the, sentence, ., T...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>3</td>\n",
              "      <td>[Our, work, contributes, a, new, principled, method, for, building, annotated, corpora, for, online, interactions, ., The, corpus, and, guidelines, will, also, be, shared, with, the, research, community, ., Another, line, of, research, that, is, correlated, with, ours, is, recognition, of, agreement, /, disagreement, (, CITSEG, ), and, classification, of, stances, (, CITSEG, ), in, online, for...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>5</td>\n",
              "      <td>[Given, that, the, transition, is, a, shift, ,, there, seem, to, be, more, and, less, coherent, ways, to, shi~, ., Note, that, the, three, items, being, examined, in, order, to, characterize, the, transition, between, each, pair, of, anchors, 4, are, the, =, See, [, BP80, ], and, [, Cho80, ], for, conditions, on, coreference, 3, See, [, Sid83, ], for, definition, and, discussion, of, co-specif...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, PAR, for, an, action, includes, the, action, 's, participants, (, its, agent, and, objects, ), ,, 1, as, well, as, kinematic, properties, such, a, s, i, t, s, path, ,, manner, and, duration, ,, and, dynamic, properties, ,, such, as, its, speed, and, force, (, see, Fig., 1, ), ., The, representation, also, allows, for, traditional, statespace, properties, of, actions, ,, such, a, s, appli...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, many, opinions, on, opinions, are, reflected, in, a, considerable, literature, (, CITSEG, ), ., Recent, computational, work, either, focuses, on, sentence, ', subjectivity, ', (, CITSEG, ), ,, concentrates, just, on, explicit, statements, of, evaluation, ,, such, as, of, films, (, CITSEG, ), ,, or, focuses, on, just, one, aspect, of, opinion, ,, e.g., ,, (, CITSEG, ), on, adjectives, ., ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600</th>\n",
              "      <td>5</td>\n",
              "      <td>[4, SPATTER, returns, a, complete, parse, for, all, sentences, of, fewer, then, 50, words, in, the, test, set, ,, but, the, sentences, of, 41, -, 50, words, required, much, more, computation, than, the, shorter, sentences, ,, and, so, they, have, been, excluded, ., seconds, per, sentence, on, an, SGI, R4400, with, 160, megabytes, of, RAM, ., To, evaluate, SPATTER, 's, performance, on, this, do...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>601</th>\n",
              "      <td>5</td>\n",
              "      <td>[Our, procedure, started, with, 50, instances, for, task, 1.1, and, 20, instances, for, task, 1.3, ,, given, its, reduced, training, set, size, ., We, optimised, the, Gaussian, Process, hyperparameters, every, 20, new, instances, ,, for, both, tasks, ., As, a, measure, of, informativeness, we, used, Information, Density, (, ID, ), (, CITSEG, ), ., This, measure, leverages, between, the, varian...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>602</th>\n",
              "      <td>5</td>\n",
              "      <td>[WIT, has, been, implemented, in, Common, Lisp, and, C, on, UNIX, ,, and, we, have, built, several, experimental, and, demonstration, dialogue, systems, using, it, ,, including, a, meeting, room, reservation, system, (, CITSEG, ), ,, a, video, -, recording, programming, system, ,, a, schedule, management, system, (, CITSEG, ), ,, and, a, weather, information, system, (, CITSEG, ), ., The, meet...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>603</th>\n",
              "      <td>4</td>\n",
              "      <td>[A, common, approach, for, sentiment, detection, is, to, use, a, labelled, lexicon, to, score, sentences, (, CITSEG, ), ., However, ,, such, approaches, have, been, found, to, be, highly, topic, dependent, (, CITSEG, ), ,, which, makes, the, creation, of, a, general, sentiment, classifier, a, difficult, task, ., CITSEG, worked, on, a, 2,829, sentence, citation, corpus, using, a, 12, -, class, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>604</th>\n",
              "      <td>0</td>\n",
              "      <td>[In, our, analysis, we, argued, for, hierarchical, organization, of, the, control, segments, on, the, basis, of, specific, examples, of, interruptions, ., We, also, believe, that, there, are, other, levels, of, structure, in, discourse, that, are, not, captured, by, the, control, rules, ,, e.g., control, shifts, do, not, always, correspond, with, task, boundaries, ., There, can, be, topic, shi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>605</th>\n",
              "      <td>0</td>\n",
              "      <td>[But, ,, (, unrestricted, ), ', before, ', is, analyzed, as, ', some, time, before, ', ,, and, thus, the, problem, arises, ., We, will, henceforth, informally, refer, to, this, problem, as, Partee, 's, quantification, problem, ., CITSEG, suggests, that, in, these, cases, we, somehow, have, to, insure, that, the, reference, time, ,, rz, ,, appears, in, the, universe, of, the, consequent, DRS, ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>606</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, work, of, CITSEG, enabled, Breiman, 's, refinement, and, application, of, their, techniques, for, machine, learning, (, CITSEG, ), ., His, technique, is, called, bagging, ,, short, for, \", bootstrap, aggregating, \", ., In, brief, ,, bootstrap, techniques, and, bag-ging, in, particular, reduce, the, systematic, biases, many, estimation, techniques, introduce, by, aggregating, estimates, m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>607</th>\n",
              "      <td>0</td>\n",
              "      <td>[Given, the, great, deal, of, similar, work, in, information, extraction, and, ontology, learning, ,, we, focus, here, only, on, techniques, for, weakly, supervised, or, unsupervised, semantic, class, (, i.e., ,, supertype, -, based, ), learning, ,, since, that, is, most, related, to, the, work, in, this, paper, ., Fully, unsupervised, semantic, clustering, (, e.g., ,, (, CITSEG, ), ), has, th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>608</th>\n",
              "      <td>1</td>\n",
              "      <td>[Translation, Parameters, ', 1, 'o, bc, practical, ,, a, model, for, P, (, CtIC, ,, ), needs, to, decompose, the, source, and, target, graphs, C~, and, Ct, into, subgraphs, small, enough, that, subgraph, translation, parameters, can, be, estimated, ., We, do, this, with, the, help, of, ', node, a.lignment, relations, ', between, the, nodes, of, these, graphs, ., 'l'lmse, alignment, relations, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>609</th>\n",
              "      <td>1</td>\n",
              "      <td>[Text, simplification, is, most, often, performed, on, the, sentence, level, ., Simplifying, texts, to, provide, more, comprehensible, input, to, a, targeted, audience, the, developers, generally, work, within, two, approaches, :, an, intuitive, approach, and, a, structural, approach, ., An, intuitive, approach, relies, mainly, on, the, developers, ', intuition, and, experience, (, CITSEG, ), ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>610</th>\n",
              "      <td>1</td>\n",
              "      <td>[been, used, in, previous, studies, ., To, deal, with, these, robustness, issues, ,, Church, (, 1993, ), developed, a, character, -, based, alignment, method, called, char_align, ., The, method, was, intended, as, a, replacement, for, sentence, -, based, methods, (, e.g., ,, (, CITSEG, ), ), ,, which, are, very, sensitive, to, noise, ., This, paper, describes, a, new, program, ,, called, word_...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611</th>\n",
              "      <td>4</td>\n",
              "      <td>[The, two, senses, of, well, also, differ, in, their, word, class, ., The, word, class, has, been, studied, as, a, difficulty, indicator, by, several, researchers, but, with, mixed, results, ., CITSEG, finds, that, function, words, are, easier, to, solve, ,, while, CITSEG, claims, that, prepositions, are, often, harder, for, learners, ., Sigott, (, 1995, ), could, not, confirm, any, effect, of...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>612</th>\n",
              "      <td>2</td>\n",
              "      <td>[We, believe, our, semantic, forms, are, fine, -, grained, ,, and, by, choosing, to, evaluate, against, COMLEX, ,, we, set, our, sights, high, :, COMLEX, is, considerably, more, detailed, than, the, OALD, or, LDOCE, used, for, other, earlier, evaluations, ., Our, error, analysis, also, revealed, some, interesting, issues, associated, with, using, an, external, standard, such, as, COMLEX, ., In...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>613</th>\n",
              "      <td>2</td>\n",
              "      <td>[As, a, result, of, characterizing, filtering, by, a, definite, clause, representation, Magic, brings, filtering, inside, of, the, logic, underlying, the, grammar, ., This, allows, it, to, be, optimized, in, a, processor, independent, and, logically, clean, fashion, ., I, discuss, two, possible, filter, optimizations, based, on, a, program, transformation, technique, called, unfolding, ), also...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614</th>\n",
              "      <td>0</td>\n",
              "      <td>[Thus, achieving, mutual, belief, of, understanding, is, an, instance, of, the, type, of, activity, that, agents, must, perform, as, they, collaborate, to, achieve, the, purposes, of, the, dialogue, ., I, claim, that, a, model, of, the, achievement, of, mutual, belief, of, understanding, can, he, extended, to, the, achievement, of, other, goals, in, dialogue, ., Achieving, understanding, is, n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>615</th>\n",
              "      <td>1</td>\n",
              "      <td>[This, evaluation, method, is, much, harder, than, standard, word, accuracy, ,, but, it, appears, to, be, a, good, approximation, to, \", rule, accuracy, \", ., Using, this, strict, method, we, achieved, a, word, accuracy, of, 47, %, ,, which, is, quite, promising, ., Results, using, top, down, prediction, of, possible, word, hypotheses, by, the, parser, work, inspired, by, (, CITSEG, ), have, a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>616</th>\n",
              "      <td>5</td>\n",
              "      <td>[For, the, reasons, explained, in, CITSEG, we, actually, estimate, ), ~, by, maximizing, a, regularized, version, of, the, log, pseudo-likelihood, (, 5, ), ,, where, aj, is, 7, times, the, maximum, value, of, fj, found, in, the, training, corpus, :, m, ~, 2, logPL, ~, (, ~, ), -~, 2, \", ~, 2, (, 5, ), j=l, vj, See, CITSEG, for, details, of, the, calculation, of, this, quantity, and, its, deriv...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>617</th>\n",
              "      <td>4</td>\n",
              "      <td>[We, then, present, the, results, of, this, model, on, the, Trains, corpus, and, show, that, it, can, better, account, for, these, discourse, events, than, can, be, achieved, by, modeling, them, individually, ., We, also, show, that, by, modeling, these, two, phenomena, that, we, can, increase, our, POS, tagging, performance, by, 8.6, %, ,, and, improve, our, ability, to, predict, the, next, w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>618</th>\n",
              "      <td>5</td>\n",
              "      <td>[One, problem, with, the, evaluation, in, the, previous, section, ,, is, that, the, original, CCGbank, is, not, expected, to, recover, internal, NP, structure, ,, making, its, task, easier, and, inflating, its, performance, ., To, remove, this, variable, ,, we, carry, out, a, second, evaluation, against, the, CITSEG, reannotation, of, Dep-Bank, (, CITSEG, ), ,, as, described, in, CITSEG, ., Pa...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>619</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, summarisation, system, can, then, use, this, information, to, generate, template, -, like, abstracts, :, Main, goal, of, the, text, :..., ;, Builds, on, work, by, :..., ;, Contrasts, with, :..., ;, etc., Second, ,, the, question, of, what, constitutes, a, useful, gold, standard, has, not, yet, been, solved, satisfactorily, ., Researchers, developing, corpus, resources, for, summarisation...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>620</th>\n",
              "      <td>0</td>\n",
              "      <td>[By, combining, Pierrehumbert, and, Hirschberg, 's, (, 1990, ), analysis, of, intonational, meaning, with, CITSEG, 's, theory, of, centering, in, discourse, ,, the, attentional, affect, of, pitch, accents, becomes, evident, ,, and, the, paradox, of, pitch, accented, pronominals, unravels, ., My, goal, here, is, to, develop, an, analysis, and, a, line, of, inquiry, and, to, suggest, that, my, d...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>621</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, use, the, CLASSIFIEDS, data, provided, by, CITSEG, and, compare, with, results, reported, by, HK06, (, CITSEG, ), and, CRR07, (, CITSEG, ), ., HK06, introduced, a, set, of, 33, features, along, with, their, majority, labels, ,, these, are, the, primary, set, of, additional, constraints, (, Table, 1, ), ., As, HK06, notes, ,, these, features, are, selected, using, statistics, of, the, labe...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>622</th>\n",
              "      <td>1</td>\n",
              "      <td>[It, was, based, on, the, idea, that, words, which, are, translations, of, each, other, will, have, similar, distributions, in, the, SL, and, TL, texts, ., Sentence, length, methods, were, based, on, the, intuition, that, the, length, of, a, translated, sentence, is, likely, to, be, similar, to, that, of, the, source, sentence, ., Brown, ,, Lai, and, Mercer, (, CITSEG, ), used, word, count, as...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>623</th>\n",
              "      <td>0</td>\n",
              "      <td>[Several, methods, are, known, that, can, parse, languages, generated, by, Tree, Adjoining, Grammars, (, TAGs, ), in, worst, case, time, O, (, n~, ), ,, where, n, is, the, length, of, the, input, string, (, see, (, CITSEG, ), and, references, therein, ), ., Although, asymptotically, faster, methods, can, be, constructed, ,, as, discussed, in, (, CITSEG, ), ,, these, methods, are, not, of, prac...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>624</th>\n",
              "      <td>2</td>\n",
              "      <td>[Finally, ,, regular, expression, operators, can, be, defined, in, terms, of, operations, on, the, underlying, automaton, ., In, such, cases, ,, Prolog, hooks, for, manipulating, states, and, transitions, may, be, used, ., This, functionality, has, been, used, in, van, Noord, and, Gerdemann, (, 1999, ), to, provide, an, implementation, of, the, algorithm, in, CITSEG, .]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625</th>\n",
              "      <td>2</td>\n",
              "      <td>[Another, showed, on, -, line, effects, from, adjectives, and, determiners, during, noun, phrase, processing, ., constituency, ,, so, that, an, initial, fragment, of, a, sentence, ,, such, as, John, likes, ,, can, be, treated, as, a, constituent, ,, and, hence, be, assigned, a, type, and, a, semantics, ., This, approach, is, exemplified, by, Combinatory, Categorial, Grammar, ,, CCG, (, CITSEG,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>626</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, first, split, each, document, in, the, corpus, into, sentences, and, create, a, shallow, Discourse, Representation, Structure, (, following, Discourse, Representation, Theory, (, CITSEG, ), ), of, each, sentence, ., The, DRS, consists, of, semantic, predicates, and, named, entity, tags, ., We, use, Boxer, semantic, analyzer, (, CITSEG, ), to, extract, semantic, predicates, such, as, EVENT...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>627</th>\n",
              "      <td>2</td>\n",
              "      <td>[However, ,, for, this, sequence, labeling, problem, ,, CITSEG, work, in, a, two, stages, process, :, first, classifying, each, line, independently, to, assign, it, label, ,, then, adjusting, these, labels, based, on, an, additional, classifier, that, examines, larger, windows, of, labels, ., Solving, the, information, extraction, problem, in, two, steps, looses, the, tight, interaction, betwe...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, used, three, types, of, features, in, our, research, :, unigrams, ,, bigrams, ,, and, IE, patterns, ., The, Ngram, features, were, generated, using, the, Ngram, Statistics, Package, (, NSP, ), (, Banerjee, and, Pedersen, ,, 2003, ), ., 1, The, extraction, patterns, (, EPs, ), were, automatically, generated, using, the, Sundance, /, AutoSlog, software, package, (, CITSEG, ), ., AutoSlog, r...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>629</th>\n",
              "      <td>5</td>\n",
              "      <td>[Experiment, and, Discussion, Before, the, antecedents, in, indirect, anaphora, were, determined, ,, sentences, were, transformed, into, a, case, structure, by, the, case, analyzer, (, CITSEG, ), ., The, errors, made, by, the, analyzer, were, corrected, by, hand, ., We, used, the, IPAL, dictionary, (, IPAL, ,, 1987, ), as, a, verb, case, frame, dictionary, ., We, used, the, Japanese, Co-occurr...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630</th>\n",
              "      <td>1</td>\n",
              "      <td>[In, k=i, +1, δ(, e, ,, e, i, ), δ(, e, ,, e, k, ), ., The, function, δ(, •, ,, •, ), denotes, the, Kronecker, delta, ., The, resulting, training, procedure, is, analogous, to, the, one, presented, in, (, CITSEG, ), and, (, CITSEG, ), ., The, next, section, presents, variants, of, the, basic, unconstrained, model, by, putting, restrictions, on, the, valid, regions, of, triggers, (, in-phrase, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>631</th>\n",
              "      <td>1</td>\n",
              "      <td>[It, self, activates, to, bias, recognition, toward, historically, observed, patterns, but, is, not, otherwise, observable, ., The, VNLCE, processor, may, be, considered, to, be, a, learning, system, of, the, tradition, described, ,, for, example, ,, in, CITSEG, ., The, current, system, learns, finite, state, flowcharts, whereas, typical, learning, systems, usually, acquire, coefficient, value...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>632</th>\n",
              "      <td>0</td>\n",
              "      <td>[Various, parsing, techniques, have, been, developed, for, lexicalized, grammars, such, as, Lexicalized, Tree, Adjoining, Grammar, (, LTAG, ), (, CITSEG, ), ,, and, Head, -, Driven, Phrase, Structure, Grammar, (, HPSG, ), (, CITSEG, ), ., Along, with, the, independent, development, of, parsing, techniques, for, individual, grammar, formalisms, ,, some, of, them, have, been, adapted, to, other,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>633</th>\n",
              "      <td>2</td>\n",
              "      <td>[Productive, reduplication, is, so, troublesome, for, a, formal, account, based, on, regular, languages, (, or, regular, relations, ), because, unbounded, total, instances, like, Indonesian, noun, plural, (, orang, -orang, ', men, ', ), are, isomorphic, to, the, copy, language, ww, ,, which, is, context-sensitive, ., In, the, rest, of, this, paper, I, will, lay, out, a, proposal, for, handling...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>634</th>\n",
              "      <td>5</td>\n",
              "      <td>[For, example, ,, \", /, meeting, ;, conference, \", occurs, 43, times, as, a, head, for, roles, ,, of, which, 24, are, for, the, target, \", /, take, place, \", and, 19, for, \", /, pass, \", ., \", /, ceremony, \", occurs, 28, times, and, all, are, arguments, of, \", \", (, take, place, ), ., \", /, statement, \", occurs, 19, times, ,, 18, for, \", /, release, ;, publish, \", and, one, for, \", /, hope, \",...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>635</th>\n",
              "      <td>5</td>\n",
              "      <td>[A, visual, display, gives, direct, feedback, on, some, of, these, parameters, ., The, speech, and, language, processing, architecture, is, based, on, that, of, the, SRI, Command, Talk, system, (, CITSEG, ), ., The, system, comprises, a, suite, of, about, 20, agents, ,, connected, together, using, the, SPd, Open, Agent, Architecture, (, OAA, ;, (, CITSEG, ), ), ., Speech, recognition, is, perf...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>636</th>\n",
              "      <td>0</td>\n",
              "      <td>[Recent, theorizing, in, linguistics, brought, forth, a, level, of, representation, called, the, Predicate, -, Argument, Structure, (, PAS, ), ., PAS, acts, as, the, interface, between, lexical, semantics, and, d-structure, in, GB, (, CITSEG, ), ,, functional, structure, in, LFG, (, CITSEG, ), ,, and, complement, structure, in, HPSG, (, CITSEG, ), ., PAS, is, the, sole, level, of, representati...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>637</th>\n",
              "      <td>5</td>\n",
              "      <td>[It, is, reproduced, here, for, reference, :, Given, three, nouns, nl, ,, n, 2, and, nz, :, Only, more, recently, has, it, been, suggested, that, corpus, statistics, might, provide, the, oracle, ,, and, this, idea, is, the, basis, of, the, three, algorithms, which, use, the, adjacency, model, ., The, simplest, of, these, is, reported, in, CITSEG, ., Given, a, three, word, compound, ,, a, searc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>638</th>\n",
              "      <td>0</td>\n",
              "      <td>[This, measure, cannot, be, applied, in, our, case, since, we, look, at, structure, and, ignore, other, words, ,, and, consequently, algorithms, using, that, measure, cannot, be, applied, to, the, problem, we, deal, with, ., The, mentioned, studies, use, word, -, clusters, for, interpolated, n-gram, language, models, ., Another, application, of, hard, clustering, methods, (, in, particular, bo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>639</th>\n",
              "      <td>4</td>\n",
              "      <td>[Some, of, these, algorithms, have, been, originally, developed, for, processing, written, text, (, CITSEG, ), ., Others, are, specifically, adapted, for, processing, speech, input, by, adding, relevant, acoustic, features, such, as, pause, length, and, speaker, change, (, CITSEG, ), ., In, parallel, ,, researchers, ex-tensively, study, the, relationship, between, discourse, structure, and, in...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>640</th>\n",
              "      <td>2</td>\n",
              "      <td>[In, this, section, we, describe, a, fully, automated, approach, to, calculating, the, syntactic, similarity, between, verbs, ., Our, approach, is, strictly, empirical, ;, the, similarity, of, verbs, is, determined, by, examining, the, syntactic, contexts, in, which, they, appear, in, a, large, text, corpus, ., Our, approach, is, analogous, to, previous, work, in, extracting, collocations, fro...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>641</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, also, experimented, with, appending, POS, tags, to, every, word, via, Oliver, Mason, 's, Qtag, program, ., 12, This, serves, as, a, crude, form, of, word, sense, disambiguation, (, CITSEG, ), :, for, example, ,, it, would, distinguish, the, different, usages, of, \", love, \", in, \", I, love, this, movie, \", (, indicating, sentiment, orientation, ), versus, \", This, is, a, love, story, \", (...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>642</th>\n",
              "      <td>4</td>\n",
              "      <td>[How, might, one, evaluate, the, relative, contributions, of, each, of, these, factors, or, compare, two, approaches, to, the, same, problem, ?, In, order, to, take, steps, towards, establishing, a, methodology, for, doing, this, type, of, comparison, ,, we, conducted, a, case, study, ., We, attempt, to, evaluate, two, different, approaches, to, anaphoric, processing, in, discourse, by, compar...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>643</th>\n",
              "      <td>4</td>\n",
              "      <td>[The, monotone, translation, in, Figure, 1, would, become, non-cohesive, :, nobody, intersects, with, both, its, sibling, pay, and, with, its, head, likes, at, phrase, index, 1, ., This, complication, stems, from, the, use, of, multi-word, phrases, that, do, not, correspond, to, syntactic, constituents, ., Restricting, phrases, to, syntactic, constituents, has, been, shown, to, harm, performan...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>644</th>\n",
              "      <td>0</td>\n",
              "      <td>[A, prot, nising, way, of, generating, contours, from, tone, sequences, is, to, specify, one, or, more, pitch, targets, per, tone, and, then, to, interpolate, between, the, targets, ;, the, task, then, becomes, one, of, providing, a, suitable, sequence, of, targets, (, CITSEG, ), ., It, is, perhaps, less, clear, how, we, should, go, about, recognising, tone, sequences, from, pitch, contours, ....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>645</th>\n",
              "      <td>0</td>\n",
              "      <td>[Future, discourse, annotation, will, benefit, from, further, specifying, the, types, of, these, cases, ., (, III, ), The, way, in, which, spans, are, annotated, as, ar-guments, to, connectives, also, raises, a, challenge, ., First, ,, because, the, PDTB, annotates, both, structural, and, anaphoric, connectives, (, CITSEG, ), ,, a, span, can, serve, as, argument, to, &gt;1, connective, ., Secondl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>646</th>\n",
              "      <td>4</td>\n",
              "      <td>[Each, classifier, takes, as, input, the, corpus, documents, preprocessed, with, a, part-of, -, speech, tag, -, ger, 2, and, shallow, parser, 3, (, CITSEG, ), ., The, other, system, components, use, the, preprocessing, tools, only, as, part, of, candidate, generation, (, e.g., ,, to, identify, all, nouns, in, the, data, for, the, noun, classifier, ), ., The, choice, of, learning, algorithm, fo...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>647</th>\n",
              "      <td>0</td>\n",
              "      <td>[Different, terms, have, been, used, to, designate, this, relation, ;, CITSEG, speaks, of, reach, -, ability, ,, while, CITSEG, and, others, before, them, use, the, term, linking, for, the, relation, ., Whatever, term, one, takes, ,, an, important, aspect, of, the, relation, is, that, it, can, be, used, to, reduce, the, search, space, of, possible, syntactic, analyses, at, an, earlier, point, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>648</th>\n",
              "      <td>1</td>\n",
              "      <td>[Since, not, all, logically, permissible, models, are, linguistically, appropriate, ,, one, needs, a, place, ,, namely, the, metalevel, ,, to, put, constraints, on, types, of, models, ., Gricean, maxims, belong, there, ;, Section, 6, will, be, devoted, to, a, presentation, of, the, metalevel, rules, corresponding, to, them, ., We, have, shown, elsewhere, (, CITSEG, ), that, natural, language, ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>649</th>\n",
              "      <td>0</td>\n",
              "      <td>[Superscripts, are, illtended, to, make, the, nleaning, of, tile, I, ,, F, nlore, precise, and, he|me, |, nero, likely, to, imply, unary, inappings, between, argu|nents, and, vahlcs, ,, subscripts, a|e, used, to, reference, a, particular, semautic, COlllpOUellt, of, a, keyword, ., The, introduclion, of, such, devices, into, tile, account, of, l, ,, Fs, demtmstrates, hoth, the, need, tk, ), r, ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>650</th>\n",
              "      <td>1</td>\n",
              "      <td>[These, proposed, methods, for, extracting, word, correspondences, from, bilingual, corpora, have, the, following, drawbacks, ., First, ,, most, of, theln, assume, that, the, input, corpora, m'e, aligned, sentence, by, sentence, ,, which, reduces, their, applicability, remarkably, ., Although, a, number, of, automatic, sentence, alignment, methods, have, been, proposed, (, CITSEG, b, ;, CITSEG...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>651</th>\n",
              "      <td>5</td>\n",
              "      <td>[To, answer, these, questions, ,, we, have, performed, experiments, that, compare, the, parsing, qualities, of, grammars, induced, under, different, training, conditions, using, both, adaptation, and, direct, induction, ., We, vary, the, number, of, labeled, brackets, and, the, linguistic, classes, of, the, labeled, brackets, ., The, study, is, conducted, on, both, a, simple, Air, Travel, Info...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>652</th>\n",
              "      <td>4</td>\n",
              "      <td>[In, the, past, two, decades, computational, morphology, has, been, quite, successful, in, dealing, with, the, challenges, posed, by, natural, language, word, patterns, ., Using, finite-, state, methods, ,, it, has, been, possible, to, describe, both, word, formation, and, the, concomitant, phonological, modifications, in, many, languages, ,, ranging, from, straightforward, concatenative, comb...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>653</th>\n",
              "      <td>0</td>\n",
              "      <td>[In, an, incremental, semantics, ,, we, would, expect, the, informtttiou, state, ,, of, an, interpreter, to, be, updated, word, by, word, ., In, contrast, ,, in, dynamic, semantics, ,, the, ol:der, in, which, states, are, updated, is, determined, by, semantic, st;ructure, ,, not, by, left-toright, order, (, see, e.g., I, ,ewiu, ,, 1992, [, br, discussion, ), ., For, example, ,, in, 1, ), ynanf...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>654</th>\n",
              "      <td>4</td>\n",
              "      <td>[Kernel-, based, methods, such, as, support, vector, machines, (, SVMs, ), consider, feature, combinations, space, -, efficiently, by, using, a, polynomial, kernel, function, (, CITSEG, ), ., The, kernelbased, classification, is, ,, however, ,, known, to, be, very, slow, in, NLP, tasks, ,, so, efficient, classifiers, should, sum, up, the, weights, of, the, explicit, conjunctive, features, (, C...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>655</th>\n",
              "      <td>4</td>\n",
              "      <td>[Such, representations, have, been, successfully, applied, to, different, aspects, of, natural, language, processing, ,, such, as, morphological, analysis, and, generation, (, CITSEG, ), ,, parsing, (, CITSEG, ), ,, phonology, (, CITSEG, ), and, speech, recognition, (, CITSEG, ), ., Although, finite-, state, machines, have, been, used, for, part, -of, -, speech, tagging, (, CITSEG, ), ,, none,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>656</th>\n",
              "      <td>5</td>\n",
              "      <td>[Finally, ,, we, assign, adverbial, function, (, ADVFUNC, ), labels, (, e.g., locative, or, temporal, ), to, all, chunks, ., In, the, last, stage, of, the, cascade, ,, we, label, several, types, of, grammatical, relations, between, pairs, of, words, in, the, sentence, ., The, data, for, all, our, experiments, was, extracted, from, the, Penn, Treebank, II, Wall, Street, Journal, (, WSJ, ), corp...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>657</th>\n",
              "      <td>1</td>\n",
              "      <td>[Furthermore, ,, our, investigation, revealed, that, the, Inside, /, Outside, method, is, very, sensitive, to, the, length, of, the, phrases, ., Table, 6, shows, a, breakdown, of, the, performance, of, the, two, methods, on, SV, phrases, of, different, lengths, ., Perhaps, this, was, not, observed, earlier, since, (, CITSEG, ), studied, only, base, NPs, ,, most, of, which, are, short, ., The, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>658</th>\n",
              "      <td>0</td>\n",
              "      <td>[It, seems, ,, however, ,, that, Brown, et, al, ., expect, that, target, word, selection, would, be, determined, mainly, by, translation, probabilities, (, the, second, factor, in, the, above, term, ), ,, which, should, be, derived, from, a, bilingual, corpus, (, CITSEG, ,, p., 79, ), ., This, view, is, reflected, also, in, their, elaborate, method, for, target, word, selection, (, CITSEG, ), ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>659</th>\n",
              "      <td>5</td>\n",
              "      <td>[As, a, seinant{c, representation, of, words, ,, distltll, Ce, w~ctors, are, expected, to, depend, very, weakly, on, the, particular, source, dictionary, ., We, eolilpared, two, sets, of, distance, vectors, ,, one, from, I, ,, I), OCE, (, CITSEG, ), and, the, other, from, COBUILD, (, CITSEG, ), ,, and, verified, that, their, difference, is, at, least, snlaller, than, the, difDrence, of, the, w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>660</th>\n",
              "      <td>2</td>\n",
              "      <td>[The, simplest, part-of, -, speech, taggers, are, bigram, or, trigram, models, (, CITSEG, ), ., They, require, a, relatively, large, tagged, training, text, ., Transformation, -, based, tagging, as, introduced, by, CITSEG, also, requires, a, handtagged, text, for, training, ., No, pretagged, text, is, nec-essary, for, Hidden, Markov, Models, (, CITSEG, ), ., Still, ,, a, lexicon, is, needed, t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>661</th>\n",
              "      <td>5</td>\n",
              "      <td>[We, obtained, the, best, results, for, cosine, (, Experiment, 1, ), and, Skew, divergence, (, Experiment, 2, ), ., The, two, measures, are, shown, in, Figure, 2, ., The, Skew, divergence, represents, a, generalisation, of, the, Kullback, -, Leibler, divergence, and, was, proposed, by, CITSEG, as, a, linguistically, motivated, distance, measure, ., We, use, a, value, of, α, =, ., 99, ., We, ex...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>662</th>\n",
              "      <td>1</td>\n",
              "      <td>[This, strategy, is, certainly, the, right, one, to, start, out, with, ,, since, anaphora, is, always, the, more, typical, direction, of, reference, in, English, prose, (, CITSEG, ,, p., 329, ), ., Since, techniques, developed, elsewhere, may, prove, useful, ,, at, least, for, comparison, ,, it, is, worth, mentioning, at, this, point, that, the, proposed, metarules, are, distant, cousins, of, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>663</th>\n",
              "      <td>5</td>\n",
              "      <td>[It, consists, of, 176, relatively, short, commentaries, (, 12, -, 15, sentences, ), ,, with, 33.000, tokens, in, total, ., The, sentences, have, been, PoS-tagged, automatically, (, and, manually, checked, ), ;, sentence, syntax, was, annotated, semi-automatically, using, the, TIGER, scheme, (, CITSEG, ), and, Annotate, 3, tool, ., In, addition, ,, we, annotated, coreference, (, PoCos, (, CITS...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>664</th>\n",
              "      <td>0</td>\n",
              "      <td>[Our, research, builds, on, earlier, work, defining, illocutionary, points, of, speech, acts, (, CITSEG, ), ,, and, relating, such, speech, acts, to, email, and, workflow, tracking, (, CITSEG, ., Winograd, suggested, that, research, explicating, the, speech, -, act, based, \", language, -, action, perspective, \", on, human, communication, could, be, used, to, build, more, useful, tools, for, co...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>665</th>\n",
              "      <td>0</td>\n",
              "      <td>[paradigmatic, relation, :, how, the, words, are, associated, with, each, other, ., Similarity, between, words, can, be, defined, by, either, a, syntagmatic, or, a, paradigmatic, relation, ., Syntagmatic, similarity, is, based, on, co-occurrence, data, extracted, from, corpora, [, CITSEG, ], ,, definitions, in, dictionaries, [, CITSEG, ], ,, and, so, on, ., Paradigmatic, similarity, is, based,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>666</th>\n",
              "      <td>5</td>\n",
              "      <td>[Morph, Ana, :, Morphological, Analysis, provided, by, sines, yields, the, word, stems, of, nouns, ,, verbs, and, adjectives, ,, as, well, as, the, full, forms, of, unknown, words, ., We, are, using, a, lexicon, of, approx, ., 100000, word, stems, of, German, (, CITSEG, ), ., STP, -, Heuristics, :, Shallow, parsing, techniques, are, used, to, heuristically, identify, sentences, containing, rel...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>667</th>\n",
              "      <td>5</td>\n",
              "      <td>[First, ,, we, do, word, clustering, using, a, Porter, stemmer, ., All, words, in, the, vocabulary, sharing, the, same, root, form, are, grouped, together, ., Then, we, do, corpus, analysis, to, filter, out, the, words, which, are, clustered, incorrectly, ,, according, to, word, distributional, similarity, ,, following, (, CITSEG, ), ., The, rationale, behind, this, is, that, words, sharing, t...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>668</th>\n",
              "      <td>5</td>\n",
              "      <td>[According, to, table, 2.1, ,, a, classification, algorithm, was, designed, ,, and, we, use, two, resources, to, implement, our, algorithm, :, The, Contemporary, Chinese, Cihai, [, CITSEG, ], (, which, we, will, refer, to, as, the, Cihai, below, ), dictionary, and, the, Machine, Tractable, Dictionary, of, Contemporary, Chinese, Predicate, Verbs, [, CITSEG, ], (, which, we, will, refer, to, as,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>669</th>\n",
              "      <td>0</td>\n",
              "      <td>[Whether, we, mean, f, or, C, -f, should, be, clear, from, context, ., L2, (, q, ,, r, ), =, Ll, (, q, ,, r, ), =, cos, (, q, ,, r), =, Jac, (, q, ,, r, ), =, ~v, (, q, (, v, ), -, r, (, v, ), ), 2, Iq, (, v, ), -, r, (, v, ), l, V, ~-~v, q, (, v, ), r, (, v, ), X/~-~v, q, (v, ), 2, V/Y, ~-v, r, (v, ), 2, I, {v, :, q, (, v, ), &gt;, 0, and, r, (, v, ), &gt;, 0, ...]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>670</th>\n",
              "      <td>0</td>\n",
              "      <td>[~,, From, a, practical, perspective, ,, there, is, ample, evidence, that, limited, mixed, -, initiative, has, contributed, to, lack, of, system, usability, ., Many, researchers, have, noted, that, the, absence, of, mixed, -, initiative, gives, rise, to, two, problems, with, expert, systems, :, They, do, n't, allow, users, to, participate, in, the, reasoning, process, ,, or, to, ask, the, ques...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>671</th>\n",
              "      <td>4</td>\n",
              "      <td>[In, empirical, approaches, to, parsing, ,, lexical, /, semantic, collocation, extracted, from, corpus, has, been, proved, to, be, quite, useful, for, ranking, parses, in, syntactic, analysis, ., For, example, ,, CITSEG, proposed, statistical, parsing, models, which, incorporated, lexical, /, semantic, information, ., In, their, models, ,, syntactic, and, lexical, /, semantic, features, are, d...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>672</th>\n",
              "      <td>4</td>\n",
              "      <td>[In, our, experiments, we, work, with, a, set, of, English, -, Japanese, reordering, rules, 1, and, gold, reorderings, based, on, human, generated, correct, reordering, of, an, aligned, target, sentences, ., We, use, a, reordering, score, based, on, the, reordering, penalty, from, the, METEOR, scoring, metric, ., Though, we, could, have, used, a, further, downstream, measure, like, BLEU, ,, ME...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>673</th>\n",
              "      <td>1</td>\n",
              "      <td>[Yamada, also, reports, that, p, B, is, best, ., Although, his, system, attained, F, =, 83.7, %, for, 5, -, fold, cross, -validation, of, the, CRL, data, ,, our, system, attained, 86.8, %, ., Since, we, followed, Isozaki, 's, implementation, (, CITSEG, ), ,, our, system, is, different, from, Yamada, 's, system, in, the, following, points, :, 1, ), adjustment, of, word, boundaries, ,, 2, ), Cha...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>674</th>\n",
              "      <td>5</td>\n",
              "      <td>[(, 1, ), technical, terms, are, often, compound, word, ~, which, can, be, progressively, created, simply, by, combining, multiple, existing, morphemes, (, \", base, words, \", ), ,, and, therefore, it, is, not, entirely, satisfactory, to, exhaustively, enumerate, newly, emerging, terms, in, dictionaries, ,, (, 2, ), Asian, languages, often, represent, loanwords, based, on, their, special, phono...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>675</th>\n",
              "      <td>4</td>\n",
              "      <td>[Applying, the, subsumption, hierarchy, to, features, without, regard, to, performance, would, simply, eliminate, all, features, that, have, a, more, general, counterpart, in, the, feature, set, ., For, example, ,, all, bigrams, would, be, discarded, if, their, component, unigrams, were, also, present, in, the, hierarchy, ., To, estimate, the, quality, of, a, feature, ,, we, use, Information, ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>676</th>\n",
              "      <td>1</td>\n",
              "      <td>[Currently, ,, the, method, of, handling, unknown, words, that, seems, to, work, best, for, inflected, languages, is, a, suffix, analysis, as, proposed, in, (, CITSEG, ), ., Tag, probabilities, are, set, according, to, the, word, 's, ending, ., The, suffix, is, a, strong, predictor, for, word, classes, ,, e.g., ,, words, in, the, Wall, Street, Journal, part, of, the, Penn, Treebank, ending, in...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>677</th>\n",
              "      <td>4</td>\n",
              "      <td>[The, noisy, -, channel, model, (, CITSEG, ), has, been, the, foundation, for, statistical, machine, translation, (, SMT, ), for, over, ten, years, ., Recently, so-, called, reranking, techniques, ,, such, as, maximum, entropy, models, (, CITSEG, ), and, gradient, methods, (, CITSEG, ), ,, have, been, applied, to, machine, translation, (, MT, ), ,, and, have, provided, significant, improvement...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>678</th>\n",
              "      <td>0</td>\n",
              "      <td>[Note, :, In, our, translation, from, English, to, logic, we, are, assuming, that, \", it, \", is, anaphoric, (, with, the, pronoun, following, the, element, that, it, refers, to, ), ,, not, cataphoric, (, the, other, way, around, ), ., This, means, that, the, \", it, \", that, brought, the, disease, in, P1, will, not, be, considered, to, refer, to, the, infection, \", i, \", or, the, death, \", d, \"...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>679</th>\n",
              "      <td>4</td>\n",
              "      <td>[Graph-, based, approaches, for, joint, inference, in, sentiment, analysis, have, been, explored, previously, by, many, researchers, ., The, biggest, difference, between, this, work, and, theirs, is, in, what, the, links, represent, linguistically, ., Some, of, these, are, not, related, to, discourse, at, all, (, e.g., ,, lexical, similarities, (, CITSEG, ), ,, morphosyntactic, similarities, (...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>680</th>\n",
              "      <td>0</td>\n",
              "      <td>[In, this, type, of, translation, system, ,, a, large, amount, of, bi, /, multi-lingual, translation, examples, has, been, stored, in, a, textual, database, and, input, expressions, are, rendered, in, the, target, language, by, retrieving, from, the, database, that, example, which, is, most, similar, to, the, input, ., There, are, three, key, issues, which, pertain, to, example, -, based, tran...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681</th>\n",
              "      <td>1</td>\n",
              "      <td>[Ellipsis, interpretations, are, represented, as, simple, sets, of, substitutions, on, semantic, representations, of, the, antecedent, ., The, substitutions, can, be, built, up, in, an, order, -, independent, way, (, i.e., before, ,, after, or, during, scoping, ), ,, and, without, recourse, to, higherorder, unification, ., The, treatment, is, similar, to, the, discourse, copying, analysis, of,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>682</th>\n",
              "      <td>0</td>\n",
              "      <td>[In, terms, of, computational, experimentation, ,, work, by, CITSEG, ,, predicting, yes, and, no, votes, in, corpus, of, United, States, Congressional, floor, debate, speeches, ,, is, quite, relevant, ., They, combined, SVM, classification, with, a, min-cut, model, on, graphs, in, order, to, exploit, both, direct, textual, evidence, and, constraints, suggested, by, the, structure, of, Congress...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>683</th>\n",
              "      <td>1</td>\n",
              "      <td>[In, this, paper, we, present, a, linguistically, motivated, framework, for, uniform, lexicostructural, processing, ., It, has, been, used, for, transformations, of, conceptual, and, syntactic, structures, during, generation, in, monolingual, and, multilingual, natural, language, generation, (, NLG, ), and, for, transfer, in, machine, translation, (, MT, ), ., Our, work, extends, directions, t...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>684</th>\n",
              "      <td>0</td>\n",
              "      <td>[For, instance, ,, given, the, sentence, \", A, reduction, of, principal, and, interest, is, one, way, the, problem, may, be, solved, ., \", ,, since, the, word, \", interest, \", appears, as, a, noun, in, this, sentence, ,, LEXAS, will, only, consider, the, noun, senses, of, \", interest, \", but, not, it, s, verb, senses, ., That, is, ,, LEXAS, is, only, concerned, with, disambiguating, senses, of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>685</th>\n",
              "      <td>2</td>\n",
              "      <td>[A, separate, \", word, expert, \", is, learned, for, each, ambiguous, word, ,, using, a, concatenated, corpus, of, English, sense, -, (, CITSEG, ), ,, which, combines, two, Naive, Bayes, statistical, models, ,, one, based, on, surrounding, collocations, and, another, one, based, on, a, bag, of, words, around, the, target, word, ., The, statistical, models, are, built, based, on, SemCor, and, Wo...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>686</th>\n",
              "      <td>5</td>\n",
              "      <td>[Our, baseline, word, alignment, model, is, the, word, -, toword, Hidden, Markov, Model, (, CITSEG, ), ., Basic, models, in, two, translation, directions, are, trained, simultaneously, where, statistics, of, two, directions, are, shared, to, learn, symmetric, translation, lexicon, and, word, alignments, with, high, precision, motivated, by, (, CITSEG, ), and, (, CITSEG, ), ., The, baseline, tr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>687</th>\n",
              "      <td>2</td>\n",
              "      <td>[The, directional, nature, of, the, generative, models, used, to, recover, word, alignments, conflicts, with, their, interpretation, as, translations, ., In, practice, ,, we, see, that, the, choice, of, which, language, is, source, versus, target, matters, and, changes, the, mistakes, made, by, the, model, (, the, first, row, of, panels, in, Figure, 1, ), ., The, standard, approach, is, to, tr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>688</th>\n",
              "      <td>5</td>\n",
              "      <td>[For, instance, ,, the, speed, of, convergence, of, the, models, selected, by, MDL, to, the, true, model, is, known, to, be, near, optiinal, ., (, The, models, selected, by, MDL, converge, to, the, true, model, approximately, at, the, rate, of, 1, /s, where, s, is, the, nmnber, of, parameters, in, the, true, model, ,, whereas, for, MLE, the, rate, is, l, /t, ,, where, t, is, the, size, of, the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>689</th>\n",
              "      <td>0</td>\n",
              "      <td>[Perplexity, is, related, to, entropy, as, follows, ., The, observed, perplexity, Po, of, a, language, model, with, respect, to, an, (, imaginary, ), infinite, test, sequence, wl, ,, w2, ,, ..., is, defined, through, the, formula, (, see, [, CITSEG, ], ), In, Po, =, lim, --, lln, p, (, wi, ,, ..., ,, wn, ), rl, --*, OO, n, Here, p, (, wl, ,, ..., ,, Wn, ), denotes, the, probability, of, the, w...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>690</th>\n",
              "      <td>3</td>\n",
              "      <td>[We, conjecture, that, this, trend, may, continue, by, incorporating, additional, information, ,, e.g., ,, three, -, dimensional, models, as, proposed, by, CITSEG, ., In, the, current, work, morphological, analyses, and, lexical, probabilities, are, derived, from, a, small, Treebank, ,, which, is, by, no, means, the, best, way, to, go, ., Using, a, wide, -, coverage, morphological, analyzer, b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>691</th>\n",
              "      <td>0</td>\n",
              "      <td>[It, would, be, interesting, to, evaluate, the, retrieval, effectiveness, (, in, terms, of, precision, and, recall, ), of, different, versions, of, the, synonym, class, indexing, approach, in, those, cases, where, retrieval, using, word, or, subword, indexes, fails, due, to, a, complete, mismatch, between, query, and, documents, ., This, will, become, even, more, interesting, when, mappings, o...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>692</th>\n",
              "      <td>0</td>\n",
              "      <td>[Semantic, representations, could, be, tbrmed, word, by, word, by, extracting, ', default, ', syntax, trees, (, by, strengthening, dominance, links, into, immediated, dominance, links, wherever, possible, ), ., A, second, possibility, is, to, factor, out, recursive, structures, from, a, grammar, ., CITSEG, show, how, this, can, be, done, for, a, phrase, structure, grammar, (, creating, an, equ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>693</th>\n",
              "      <td>0</td>\n",
              "      <td>[This, minimum, amount, of, documents, turned, out, to, render, the, category, sufficiently, distinguishable, for, the, SML, tools, ., The, database, contained, 74, categories, with, at, least, 10, documents, ,, but, the, selected, ones, covered, 94, %, of, all, e-malls, ,, i.e., 4490, documents, ., It, has, not, yet, generally, been, investigated, how, the, type, of, data, influences, the, le...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>694</th>\n",
              "      <td>4</td>\n",
              "      <td>[Such, simple, univariate, outlier, detectors, are, ,, however, ,, inappropriate, for, identifying, outliers, in, a, high-, dimensional, textual, corpus, ., Subsequent, work, ,, such, as, the, Stahel, -, Donoho, Estimator, (, CITSEG, ), ,, PCout, (, CITSEG, ), ,, LOF, (, CITSEG, ), and, ABOD, (, CITSEG, ), have, generalized, univariate, methods, to, highdimensional, data, points, ., In, his, c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>1</td>\n",
              "      <td>[However, ,, as, the, manual, construction, of, lexical, resources, is, time, consuming, ,, error, prone, ,, expensive, ,, and, rarely, ever, complete, ,, it, is, often, the, case, that, the, limitations, of, NLP, systems, based, on, lexicalized, approaches, are, due, to, bottlenecks, in, the, lexicon, component, ., In, addition, ,, subcategorization, requirements, may, vary, across, linguisti...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>696</th>\n",
              "      <td>0</td>\n",
              "      <td>[They, proposed, that, text, segments, with, similar, vocabulary, are, likely, to, be, part, of, a, coherent, topic, segment, ., hnplementations, of, this, idea, use, word, stem, repetition, (, CITSEG, ), ,, context, vectors, (, CITSEG, ), ,, entity, repetition, (, CITSEG, ), ,, semantic, similarity, (, CITSEG, ), ,, word, distance, model, (, CITSEG, ), and, word, frequency, model, (, CITSEG, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>697</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, smoothing, method, discussed, above, is, simply, one, type, of, class, -, based, smoothing, ., Other, ,, more, sophisticated, class, -, based, methods, do, away, with, the, simplifying, assumption, that, the, argument, co-occurring, with, a, given, predicate, (, adjective, ,, noun, ,, verb, ), is, distributed, evenly, across, its, conceptual, classes, and, attempt, to, find, the, right, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>1</td>\n",
              "      <td>[CITSEG, provides, a, good, recent, survey, of, the, different, research, lines, that, use, citations, ., In, this, section, we, review, the, research, lines, that, are, relevant, to, our, work, and, show, how, our, work, is, different, ., One, line, of, research, that, is, related, to, our, work, has, to, do, with, identifying, what, CITSEG, call, the, citing, area, They, define, the, citing,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>699</th>\n",
              "      <td>5</td>\n",
              "      <td>[Our, baseline, coreference, system, uses, the, C4.5, decision, tree, learner, (, CITSEG, ), to, acquire, a, classifier, on, the, training, texts, for, determining, whether, two, NPs, are, coreferent, ., Following, previous, work, (, e.g., ,, CITSEG, ), ,, we, generate, training, instances, as, follows, :, a, positive, instance, is, created, for, each, anaphoric, NP, ,, NP, j, ,, and, its, clo...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>700</th>\n",
              "      <td>2</td>\n",
              "      <td>[is, defined, reflects, the, litct, that, agents, m'e, me, ,, 'mt, to, collaborate, on, the, tlksk, ., The, costs, that, ~u'e, deducted, liom, tbe, RAW, SCORE, are, the, costs, for, both, agents, ', communication, ,, inference, ,, m~d, retrieval, ., Thus, PERFORMANCE, is, a, measnre, of, LEAS, ', I, \", COLI, ,, ABORATIVE, EFFORT, [, CITSEG, ., Since, the, par~uneters, for, cognitive, ef-lk~rt,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701</th>\n",
              "      <td>0</td>\n",
              "      <td>[They, proposed, that, text, segments, with, similar, vocabulary, are, likely, to, be, part, of, a, coherent, topic, segment, ., hnplementations, of, this, idea, use, word, stem, repetition, (, CITSEG, ), ,, context, vectors, (, CITSEG, ), ,, entity, repetition, (, CITSEG, ), ,, semantic, similarity, (, CITSEG, ), ,, word, distance, model, (, CITSEG, ), and, word, frequency, model, (, CITSEG, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>702</th>\n",
              "      <td>0</td>\n",
              "      <td>[These, constraints, are, exemplified, by, the, fact, that, ,, in, the, sentence, he, Hkes, him, ,, the, entity, cospecified, by, he, can, not, be, the, same, as, that, cospecified, by, him, ., We, say, that, he, and, him, are, CONTRA, -, INDEXED, ., The, BFP, algorithm, depends, on, semantic, processing, to, precompute, these, constraints, ,, since, they, are, derived, from, the, syntactic, s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>703</th>\n",
              "      <td>0</td>\n",
              "      <td>[However, ,, these, algorithms, are, rather, well, behaved, in, practice, ,, and, this, complexity, is, not, a, problem, ., In, this, paper, we, shall, call, shared, forests, such, data, struc, -, 2, We, do, not, consider, CF, reco~zers, that, have, asymptotically, the, lowest, complexity, ,, but, are, only, of, theoretical, interest, here, [, ~, S, ,, 5, ], ., 3, There, are, several, other, p...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>704</th>\n",
              "      <td>0</td>\n",
              "      <td>[Secondly, ,, these, approaches, have, in, common, the, fact, that, the, probability, models, are, trained, on, treebanks, ,, i.e., ,, corpora, of, manually, disambiguated, sentences, ,, and, not, from, corpora, of, unannotated, sentences, ., In, all, of, the, cited, approaches, ,, the, Penn, Wall, Street, Journal, Treebank, (, CITSEG, ), is, used, ,, the, availability, of, which, o, b, viates...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>705</th>\n",
              "      <td>4</td>\n",
              "      <td>[P, (, m, ), conf, (, q, ,, r, ,, P, (, m, ), ), =, E, q, (, v, ), r, (, v, ), -p, -~(, v, ), \", V, Note, that, it, incorporates, unigram, probabilities, as, well, as, the, two, distributions, q, and, r., Finally, ,, Kendall, 's, %, which, appears, in, work, on, clustering, similar, adjectives, (, CITSEG, ), ,, is, a, nonparametric, measure, of, the, association, between, random, variables, (,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>706</th>\n",
              "      <td>0</td>\n",
              "      <td>[For, comparison, ,, a, variety, of, other, data, has, been, collected, ., Preliminary, tests, used, generated, errors, ,, from, a, program, that, produces, random, Damerau, slips, according, to, an, observed, distribution, (, CITSEG, ), ,, using, confusion, matrices, where, appropriate, (, CITSEG, ), ., Assembled, data, includes, the, Birkbeck, corpus, (, CITSEG, ), and, multifarious, misspel...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>707</th>\n",
              "      <td>5</td>\n",
              "      <td>[Now, we, deline, ti, =, h, iftl, --, I, [, ,, ,, IH, and, ii, =, l, ifti, =L, ,, ,, I.L., Generalising, our, equation, once, more, ,, we, have, the, following, ,, where, R, is, a, factor, called, the, transition, ratio, ., zi, -/, i, /'i, R, $-, ti-ltl, Xi--1, --ti--1, ~i--1, Zl, :, ~, ti_, ,, ti(, Xi--1, ), --, --, Rti_,tl.xi-1, ti-1, +, ti(, 1, -, Rt, ,, _, ,, t, ,, ), Now, I, shall, show, ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>708</th>\n",
              "      <td>4</td>\n",
              "      <td>[The, large, mice, =, The, largest, mice, The, large, mouse, =, The, largest, mouse, ., Viewed, in, this, way, ,, gradable, adjectives, are, an, extreme, example, of, the, \", efficiency, of, language, \", (, CITSEG, ), :, Far, from, meaning, something, concrete, like, \", larger, than, 8, cm, \", -, a, concept, that, would, have, very, limited, applicability, -, or, even, something, more, general...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>709</th>\n",
              "      <td>5</td>\n",
              "      <td>[Since, then, ,, there, haw, \", been, some, promising, results, from, using, co-occurrence, vectors, ,, such, as, word, sense, disambiguation, (, Schiitze, [, 993, ), ,, and, word, clustering, (, CITSEG, ), ., llowever, ,, using, the, co-occurrence, statistics, requires, a, huge, corpus, that, covers, even, most, rare, words, ., We, recently, developed, word, vectors, that, are, derived, from,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>710</th>\n",
              "      <td>2</td>\n",
              "      <td>[This, work, differs, from, the, above, work, in, that, we, design, a, novel, Bayesian, model, to, induce, unsupervised, U-trees, ,, and, prior, knowledge, can, be, encoded, into, the, model, more, freely, and, effectively, ., CITSEG, utilized, Bayesian, methods, to, learn, synchronous, context, free, grammars, (, SCFG, ), from, a, parallel, corpus, ., The, obtained, SCFG, is, further, used, i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, result, of, the, tagger, comparison, seems, to, support, the, maxime, \", the, simplest, is, the, best, \", ., However, ,, in, this, paper, we, clarify, a, number, of, details, that, are, omitted, in, major, previous, publications, concerning, tagging, with, Markov, models, ., As, two, examples, ,, (, CITSEG, ), and, (, CITSEG, ), give, good, overviews, of, the, techniques, and, equations,...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>712</th>\n",
              "      <td>1</td>\n",
              "      <td>[In, other, words, ,, this, method, solves, the, spurious, ambiguity, problem, between, higher, types, ,, but, not, among, higher, and, lower, types, ., One, can, try, to, remedy, this, problem, by, making, the, availability, of, types, dependent, on, some, measures, of, prominence, ,, e.g., ,, allowing, subjects, only, in, higher, types, to, account, for, subject, -, complement, asymmetries, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>713</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, accuracy, of, this, ensemble, disambiguating, the, nouns, interest, (, 89, %, ), and, line, (, 88, %, ), is, as, high, as, any, previously, published, results, ., However, ,, each, ensemble, consists, of, 81, Naive, Bayesian, classifiers, ,, making, it, difficult, to, determine, which, features, and, classifiers, were, contributing, most, significantly, to, disambiguation, ., The, frustr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>714</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, solution, given, in, this, paper, is, to, use, a, higher, -, order, logic, programming, language, ,, AProlog, ,, that, already, implements, these, concepts, ,, called, \", abstract, syntax, \", in, (, CITSEG, ), and, \", higher, -, order, abstract, syntax, \", in, (, CITSEG, ), ., This, allows, a, natural, and, elegant, implementation, of, the, grammatical, theory, ,, with, only, one, lexica...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>715</th>\n",
              "      <td>1</td>\n",
              "      <td>[Current, interfaces, to, cable, and, satellite, television, services, typically, use, direct, manipulation, of, a, graphical, user, interface, using, a, remote, control, ., In, order, to, find, content, ,, users, generally, have, to, either, navigate, a, complex, ,, pre-defined, ,, and, often, deeply, embedded, menu, structure, or, type, in, titles, or, other, key, phrases, using, an, onscree...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>716</th>\n",
              "      <td>0</td>\n",
              "      <td>[For, example, ,, if, a, natural, language, understanding, system, is, interfaced, with, a, speech, recognition, component, ,, chances, are, that, this, co~t, is, uncertain, about, the, actual, string, of, words, that, has, been, uttered, ,, and, thus, produces, a, word, lattice, of, the, most, promising, hypotheses, ,, rather, than, a, single, sequence, of, words, ., FSA, of, course, generali...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>717</th>\n",
              "      <td>4</td>\n",
              "      <td>[{, black, ,, eubank, ,, kashioka}@atr.itl.co.jp, G.LeechOcentl.lancs.ac.uk, A, treebank, is, a, body, of, natural, language, text, which, has, been, grammatically, annotated, by, hand, ,, in, terms, of, some, previously, -, established, scheme, of, grammatical, analysis, ., Treebanks, have, been, used, within, the, field, of, natural, language, processing, as, a, source, of, training, data, f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>718</th>\n",
              "      <td>4</td>\n",
              "      <td>[(, 5, ), Bill, became, upset, ,, and, Hillary, did, too, ., The, distribution, of, VP, -, ellipsis, has, also, been, shown, to, be, sensitive, to, the, coherence, relationship, extant, between, the, source, and, target, clauses, ,, but, in, a, different, respect, ., In, a, previous, paper, (, CITSEG, ), ,, five, contexts, for, VP-, ellipsis, were, examined, to, determine, whether, the, repres...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>719</th>\n",
              "      <td>1</td>\n",
              "      <td>[However, ,, clustering, may, also, give, us, significant, leverage, in, monolingual, cases, ., If, the, dialogue, handling, capabilities, of, a, system, are, relatively, rigid, ,, the, system, may, only, ask, the, user, a, small, number, of, different, questions, (, modulo, the, filling, of, slots, with, different, values, ), ., For, example, ,, the, CLARE, interface, to, the, Autoroute, PC, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>720</th>\n",
              "      <td>0</td>\n",
              "      <td>[We, now, consider, sentence, (, 21, ), ,, where, a, quantified, NP, is, shared, ., (, 21, ), Bill, supported, ,, and, Hillary, opposed, ,, two, trade, bills, ., CITSEG, observe, ,, and, we, agree, ,, that, the, quantifier, in, such, cases, only, scopes, once, ,, resulting, in, the, reading, where, Bill, supported, and, Hillary, opposed, the, same, two, bills, ., 5, Our, analysis, predicts, th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>721</th>\n",
              "      <td>4</td>\n",
              "      <td>[Different, languages, vary, with, respect, to, which, features, may, be, most, helpful, given, various, tradeoffs, among, these, three, factors, ., In, the, past, ,, it, has, been, shown, that, if, we, can, recognize, the, relevant, morphological, features, in, assignment, configurations, well, enough, ,, then, they, contribute, to, parsing, accuracy, ., For, example, ,, modeling, CASE, in, C...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>722</th>\n",
              "      <td>1</td>\n",
              "      <td>[This, implies, that, our, predictors, tend, to, break, up, long, base, NPs, into, smaller, ones, ., The, results, also, show, that, lexical, information, improves, the, performance, by, nearly, 2, %, ., This, is, similar, to, results, in, the, literature, (, CITSEG, ), ., What, we, found, surprising, is, that, the, second, predictor, ,, that, uses, additional, information, about, the, OIB, st...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723</th>\n",
              "      <td>2</td>\n",
              "      <td>[Rule, -, based, methods, for, this, task, employ, a, number, of, linguistic, rules, to, capture, various, relation, patterns, ., CITSEG, addressed, the, task, from, the, syntactic, parsing, viewpoint, and, integrated, various, tasks, such, as, POS, tagging, ,, NE, tagging, ,, syntactic, parsing, ,, template, extraction, and, relation, extraction, using, a, generative, model, ., Feature, -, ba...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>724</th>\n",
              "      <td>2</td>\n",
              "      <td>[Such, filtering, also, eliminated, spurious, relations, learned, using, the, graph, model, that, were, the, result, of, lexical, ambiguity, and, of, seed, hyponymy, relations, inappropriate, for, the, technique, ,, reducing, errors, by, 33, %, ., This, paper, suggests, many, possibilities, for, future, work, ., First, of, all, ,, it, would, be, interesting, to, apply, LSA, to, a, system, for,...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>725</th>\n",
              "      <td>4</td>\n",
              "      <td>[Finally, ,, we, have, only, scratched, the, surface, of, what, can, be, be, done, with, the, computation, of, best, configurations, in, Section, 5, ., The, algorithms, generalize, easily, to, weights, that, are, taken, from, an, arbitrary, ordered, semiring, (, CITSEG, ), and, to, computing, minimal, -, weight, rather, than, maximal, -, weight, configurations, ., It, is, also, useful, in, app...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>726</th>\n",
              "      <td>0</td>\n",
              "      <td>[These, techniques, are, all, based, on, a, dynamic, programming, paradigm, ., The, kind, of, structure, they, produce, to, represent, all, parses, of, the, analyzed, sentence, is, an, essential, characteristic, of, these, algorithm, ., Some, of, the, published, algorithms, produce, only, a, chart, as, described, by, Kay, in, [, CITSEG, ], ,, which, only, associates, nonterminal, categories, t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>727</th>\n",
              "      <td>4</td>\n",
              "      <td>[To, speed, up, the, annotation, process, ,, we, developed, a, customised, annotation, tool, ., A, total, of, 203,803, sentences, have, been, annotated, from, 1,034, paper-reference, pairs, ., Although, this, annotation, been, performed, by, the, first, author, only, ,, we, know, from, previous, work, that, similar, styles, of, annotation, can, achieve, acceptable, inter-annotator, agreement, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>728</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, extracted, translations, may, serve, as, training, data, for, statistical, machine, translation, systems, ., To, evaluate, their, effectiveness, for, this, purpose, ,, we, trained, a, baseline, phrase, -, based, SMT, system, (, CITSEG, ), with, the, FBIS, Chinese, -, English, parallel, text, (, CITSEG, ), ., We, then, added, the, extracted, translation, pairs, as, additional, parallel, t...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>729</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, grammar, employed, is, a, partial, characterisation, of, Chomsky, 's, Government, -, Binding, theory, [, CITSEG, ], and, only, takes, account, of, very, local, constralnts, (, i.e., X, -bar, ,, Theta, and, Case, ), ;, a, way, of, encoding, all, constraints, in, the, proper, branch, formalism, (, e.g., [, CITSEG, ], ), will, be, needed, before, a, grammar, of, sufficient, coverage, to, be...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>730</th>\n",
              "      <td>5</td>\n",
              "      <td>[TAG-, PRECISION, applies, classification, weights, based, on, the, accuracy, of, the, classifier, for, that, classification, ., PRECISION-RECALL, uses, classification, weights, that, combine, the, precision, of, the, classification, with, the, recall, of, the, competitors, ., And, finally, ,, TAGPAIR, uses, classification, pair, weights, based, on, the, probability, of, a, classification, for...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>731</th>\n",
              "      <td>4</td>\n",
              "      <td>[First, ,, subcorpusbased, domains, depend, on, provenance, information, ,, which, might, not, be, available, ,, or, on, manual, grouping, of, documents, into, subcorpora, ,, which, is, labor, intensive, and, often, carried, out, according, to, arbitrary, criteria, ., Second, ,, the, commonly, used, notion, of, a, domain, neglects, the, fact, that, topic, and, genre, are, two, distinct, proper...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>732</th>\n",
              "      <td>1</td>\n",
              "      <td>[Using, these, weights, ,, we, run, Hiero, 's, decoder, to, perform, the, actual, translation, of, the, MT, 2003, test, sentences, and, obtained, a, BLEU, score, of, 29.73, ,, as, shown, in, the, row, Hiero, of, Table, 1, ., This, is, higher, than, the, score, of, 28.77, reported, in, (, CITSEG, ), ,, perhaps, due, to, differences, in, word, segmentation, ,, etc., Note, that, comparing, with, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>733</th>\n",
              "      <td>4</td>\n",
              "      <td>[In, the, past, decade, ,, the, speech, recognition, community, has, had, huge, successes, in, applying, hidden, Markov, models, ,, or, HMM, 's, to, their, problems, ., More, recently, ,, the, natural, language, processing, community, has, effectively, employed, these, models, for, part-ofspeech, tagging, ,, as, in, the, seminal, (, CITSEG, ), and, other, ,, more, recent, efforts, (, CITSEG, )...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>734</th>\n",
              "      <td>1</td>\n",
              "      <td>[PCFGs, have, the, interesting, property, (, which, we, expect, most, linguistically, more, realistic, models, to, also, possess, ), that, the, distributions, they, define, are, not, always, properly, normalized, or, \", tight, \", ., In, a, non, -tight, PCFG, the, partition, function, (, i.e., ,, sum, of, the, \", probabilities, \", of, all, the, trees, generated, by, the, PCFG, ), is, less, than...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>735</th>\n",
              "      <td>1</td>\n",
              "      <td>[But, while, the, accuracy, of, SL-, DOP, decreases, after, n=14, and, converges, to, Simplicity, -, DOP, ,, the, accuracy, of, LS-, DOP, continues, to, increase, and, converges, to, Likelihood, -DOP, ., The, highest, accuracy, is, obtained, by, SL-, DOP, at, 12, n, 14, :, an, LP, of, 90.8, %, and, an, LR, of, 90.7, %, ., This, is, roughly, an, 11, %, relative, reduction, in, error, rate, over...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736</th>\n",
              "      <td>0</td>\n",
              "      <td>[An, early, attempt, at, automation, was, made, I, )y, Wilks, el, aL, (, t990, ), us, -., ing, co-occurrence, statistics, ., Since, then, ,, there, haw, \", been, some, promising, results, from, using, co-occurrence, vectors, ,, such, as, word, sense, disambiguation, (, Schiitze, [, 993, ), ,, and, word, clustering, (, CITSEG, ), ., llowever, ,, using, the, co-occurrence, statistics, requires, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>737</th>\n",
              "      <td>1</td>\n",
              "      <td>[The, PAR-SEVAL, (, Black, and, others, ,, 1991, ), measures, compare, a, proposed, parse, P, with, the, corresponding, correct, treebank, parse, T, as, follows, :, #, correct, constituents, in, P, Recall, =, #, constituents, in, T, #, correct, constituents, in, P, Precision, =, #, constituents, in, P, A, constituent, in, P, is, \", correct, \", if, there, exists, a, constituent, in, T, of, the,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>738</th>\n",
              "      <td>2</td>\n",
              "      <td>[This, problem, is, difficult, because, the, near-synonyms, have, senses, that, are, very, close, to, each, other, ,, and, therefore, they, occur, in, similar, contexts, ;, we, need, to, capture, the, subtle, differences, specific, to, each, near-synonym, ., Our, thesaurus, brings, up, only, alternatives, that, have, the, same, part-of, -, speech, with, the, target, word, ., The, choices, coul...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>739</th>\n",
              "      <td>5</td>\n",
              "      <td>[The, classification, algorithm, described, above, was, originally, developed, in, response, to, Sibun, and, Spitz, 's, work, ., There, is, another, approach, to, language, identification, ,, which, has, a, certain, Incorrect, 1560, 6, 128, 7, 37, 9, 18, 2, 5, 1, 5, 1, 2, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 2, 0, 1, 0, 7, 0, CITSEG, 135, 46, 20, 6, 6, 2, 2, 1, 3, 1, 2, 1, 7, Incorrect, 173, 0, 22...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>740</th>\n",
              "      <td>4</td>\n",
              "      <td>[Unlike, SURF, descriptors, ,, GIST, produces, a, single, vector, representation, for, an, image, ., The, vector, does, not, find, points, of, interest, in, the, image, ,, but, rather, attempts, to, provide, a, representation, for, the, overall, \", gist, \", of, the, whole, image, ., It, is, frequently, used, in, tasks, like, scene, identification, ,, and, CITSEG, shows, that, distance, in, GIS...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>741</th>\n",
              "      <td>4</td>\n",
              "      <td>[Materials, ., Stimuli, were, constructed, using, 11, verbs, of, killing, ,, which, are, widely, viewed, as, prototypical, for, the, semantic, properties, of, interest, here, (, CITSEG, ), :, X, killed, Y, normally, involves, conscious, ,, intentional, causation, by, X, of, a, kinetic, event, that, causes, a, (, rather, decisive, and, clearly, terminated, !, ), change, of, state, in, Y, ., The...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>742</th>\n",
              "      <td>0</td>\n",
              "      <td>[The, most, closely, related, effort, is, (, CITSEG, ), ,, which, aims, to, automatically, identify, adjacency, pairs, in, the, ICSI, Meeting, corpus, ,, a, large, corpus, of, 75, meetings, ,, using, a, small, tagset, ., Their, maximum, entropy, ranking, approach, achieved, 90, %, accuracy, on, the, 4, -, way, classification, into, agreement, ,, disagreement, ,, backchannel, and, other, ., Usi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>743</th>\n",
              "      <td>0</td>\n",
              "      <td>[Such, a, large, variety, of, vocabulary, naturally, leads, to, long, names, with, productive, use, of, general, words, ,, making, the, task, difficult, to, be, solved, by, systems, with, naive, Markov, assumption, of, label, sequences, ,, because, such, systems, must, perform, their, prediction, without, seeing, the, entire, string, of, the, entities, ., Importance, of, the, treatment, of, lo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>744</th>\n",
              "      <td>5</td>\n",
              "      <td>[While, these, are, vital, for, opinion, analysis, ,, they, do, not, capture, discourse-, level, associations, that, arise, from, relations, between, opinions, ., To, capture, this, information, ,, we, propose, discourse, -, level, opinion, graphs, for, classifying, opinion, polarity, ., In, order, to, build, our, computational, model, ,, we, combine, a, linguistic, scheme, opinion, frames, (,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>745</th>\n",
              "      <td>0</td>\n",
              "      <td>[And, ,, we, are, now, applying, it, to, text, segmentation, [, CITSEG, ], ,, i.e., to, capture, the, shifts, of, coherent, scenes, in, a, story, ., In, future, research, ,, we, intend, to, deal, with, syntagmatic, relations, between, words, ., Meaning, of, a, text, lies, in, the, texture, of, paradigmatic, and, syntagmatic, relations, between, words, [, CITSEG, ], ., Paradigme, provides, the,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>746</th>\n",
              "      <td>4</td>\n",
              "      <td>[CITSEG, proposed, a, system, to, attach, sentiment, information, to, the, citation, links, between, biomedical, papers, by, using, existing, semantic, lexical, resources, and, NLP, tools, ., A, common, approach, for, sentiment, detection, is, to, use, a, labelled, lexicon, to, score, sentences, (, CITSEG, ), ., However, ,, such, approaches, have, been, found, to, be, highly, topic, dependent,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>747</th>\n",
              "      <td>5</td>\n",
              "      <td>[Heuristic, Rules, for, Demonstratives, We, made, heuristic, rules, for, demonstratives, by, consulting, the, papers, (, NLRI, 81, ), (, Hayashi, 83, ), (, CITSEG, ), (, CITSEG, ), and, by, examining, Japanese, sentences, by, hand, ., Demonstratives, have, three, categories, :, demonstrative, pronouns, ,, demonstrative, adjectives, ,, and, demonstrative, adverbs, ., In, the, following, section...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>748</th>\n",
              "      <td>1</td>\n",
              "      <td>[However, ,, this, is, not, clearly, an, advantage, -, adding, extra, dependencies, introduces, data, sparseness, ,, and, it, is, an, empirical, question, whether, dependencies, on, the, current, state, are, actually, helpful, ., Our, probabilistic, decision, lists, can, thus, be, thought, of, as, a, competitive, way, to, probabilize, TBLs, ,, with, the, advantage, of, preserving, the, list-st...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>749</th>\n",
              "      <td>5</td>\n",
              "      <td>[q'hese, ,, increments, describe, lexical, items, or, semantic, relations, between, them, ., Single, input, increments, are, handed, over, to, objects, of, a, distril, ), uted, parallel, system, ,, each, of, which, tries, to, verbalize, the, structure, that, results, from, the, corresponding, input, increment, ., VM, -, O, ,, ]'~N, uses, ml, extension, of, Tree, Adjoining, Gra'm'mct, 'rs, (, T...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     prediction  ... true\n",
              "0             1  ...    0\n",
              "1             4  ...    0\n",
              "2             5  ...    0\n",
              "3             5  ...    5\n",
              "4             5  ...    0\n",
              "5             4  ...    4\n",
              "6             5  ...    5\n",
              "7             1  ...    4\n",
              "8             5  ...    5\n",
              "9             4  ...    1\n",
              "10            1  ...    0\n",
              "11            5  ...    1\n",
              "12            0  ...    0\n",
              "13            5  ...    5\n",
              "14            4  ...    1\n",
              "15            0  ...    0\n",
              "16            0  ...    0\n",
              "17            0  ...    2\n",
              "18            0  ...    0\n",
              "19            2  ...    0\n",
              "20            1  ...    1\n",
              "21            4  ...    0\n",
              "22            1  ...    1\n",
              "23            5  ...    0\n",
              "24            1  ...    1\n",
              "25            0  ...    0\n",
              "26            2  ...    2\n",
              "27            0  ...    1\n",
              "28            5  ...    0\n",
              "29            0  ...    0\n",
              "30            5  ...    5\n",
              "31            5  ...    5\n",
              "32            5  ...    5\n",
              "33            1  ...    5\n",
              "34            2  ...    1\n",
              "35            0  ...    1\n",
              "36            5  ...    0\n",
              "37            5  ...    0\n",
              "38            5  ...    0\n",
              "39            0  ...    0\n",
              "40            2  ...    5\n",
              "41            5  ...    1\n",
              "42            4  ...    5\n",
              "43            0  ...    0\n",
              "44            5  ...    5\n",
              "45            0  ...    0\n",
              "46            1  ...    1\n",
              "47            1  ...    0\n",
              "48            0  ...    1\n",
              "49            0  ...    0\n",
              "50            0  ...    0\n",
              "51            4  ...    4\n",
              "52            5  ...    5\n",
              "53            4  ...    4\n",
              "54            5  ...    0\n",
              "55            4  ...    1\n",
              "56            4  ...    4\n",
              "57            1  ...    0\n",
              "58            1  ...    1\n",
              "59            1  ...    5\n",
              "60            1  ...    1\n",
              "61            5  ...    5\n",
              "62            5  ...    5\n",
              "63            2  ...    2\n",
              "64            5  ...    5\n",
              "65            0  ...    1\n",
              "66            4  ...    4\n",
              "67            5  ...    0\n",
              "68            2  ...    2\n",
              "69            4  ...    4\n",
              "70            0  ...    0\n",
              "71            0  ...    0\n",
              "72            1  ...    1\n",
              "73            0  ...    0\n",
              "74            0  ...    0\n",
              "75            0  ...    0\n",
              "76            4  ...    0\n",
              "77            1  ...    1\n",
              "78            0  ...    0\n",
              "79            2  ...    0\n",
              "80            5  ...    1\n",
              "81            0  ...    0\n",
              "82            2  ...    0\n",
              "83            0  ...    1\n",
              "84            5  ...    5\n",
              "85            2  ...    2\n",
              "86            2  ...    0\n",
              "87            5  ...    0\n",
              "88            0  ...    0\n",
              "89            5  ...    5\n",
              "90            0  ...    0\n",
              "91            1  ...    1\n",
              "92            1  ...    1\n",
              "93            1  ...    1\n",
              "94            0  ...    0\n",
              "95            1  ...    0\n",
              "96            1  ...    5\n",
              "97            0  ...    0\n",
              "98            1  ...    1\n",
              "99            1  ...    1\n",
              "100           0  ...    0\n",
              "101           0  ...    0\n",
              "102           1  ...    1\n",
              "103           5  ...    1\n",
              "104           1  ...    1\n",
              "105           0  ...    4\n",
              "106           5  ...    0\n",
              "107           5  ...    5\n",
              "108           0  ...    0\n",
              "109           5  ...    5\n",
              "110           5  ...    0\n",
              "111           0  ...    3\n",
              "112           1  ...    1\n",
              "113           0  ...    0\n",
              "114           5  ...    5\n",
              "115           5  ...    5\n",
              "116           1  ...    1\n",
              "117           4  ...    4\n",
              "118           0  ...    0\n",
              "119           1  ...    1\n",
              "120           3  ...    0\n",
              "121           5  ...    5\n",
              "122           4  ...    0\n",
              "123           4  ...    4\n",
              "124           2  ...    0\n",
              "125           4  ...    1\n",
              "126           4  ...    1\n",
              "127           1  ...    0\n",
              "128           1  ...    0\n",
              "129           5  ...    5\n",
              "130           1  ...    1\n",
              "131           5  ...    5\n",
              "132           0  ...    2\n",
              "133           5  ...    2\n",
              "134           0  ...    5\n",
              "135           5  ...    5\n",
              "136           1  ...    1\n",
              "137           0  ...    1\n",
              "138           5  ...    1\n",
              "139           1  ...    0\n",
              "140           5  ...    5\n",
              "141           1  ...    1\n",
              "142           0  ...    0\n",
              "143           5  ...    0\n",
              "144           0  ...    5\n",
              "145           5  ...    0\n",
              "146           1  ...    1\n",
              "147           2  ...    2\n",
              "148           4  ...    0\n",
              "149           5  ...    5\n",
              "150           1  ...    1\n",
              "151           5  ...    0\n",
              "152           0  ...    0\n",
              "153           0  ...    5\n",
              "154           1  ...    1\n",
              "155           1  ...    1\n",
              "156           1  ...    1\n",
              "157           1  ...    5\n",
              "158           5  ...    5\n",
              "159           1  ...    1\n",
              "160           5  ...    5\n",
              "161           0  ...    5\n",
              "162           1  ...    3\n",
              "163           1  ...    1\n",
              "164           4  ...    1\n",
              "165           4  ...    0\n",
              "166           0  ...    0\n",
              "167           4  ...    4\n",
              "168           5  ...    5\n",
              "169           0  ...    0\n",
              "170           1  ...    1\n",
              "171           1  ...    1\n",
              "172           5  ...    1\n",
              "173           3  ...    3\n",
              "174           4  ...    2\n",
              "175           4  ...    0\n",
              "176           5  ...    5\n",
              "177           0  ...    0\n",
              "178           1  ...    1\n",
              "179           5  ...    4\n",
              "180           5  ...    5\n",
              "181           0  ...    0\n",
              "182           5  ...    5\n",
              "183           0  ...    0\n",
              "184           5  ...    5\n",
              "185           1  ...    3\n",
              "186           4  ...    0\n",
              "187           1  ...    0\n",
              "188           0  ...    1\n",
              "189           4  ...    1\n",
              "190           0  ...    0\n",
              "191           2  ...    0\n",
              "192           2  ...    0\n",
              "193           5  ...    1\n",
              "194           4  ...    4\n",
              "195           2  ...    1\n",
              "196           1  ...    5\n",
              "197           0  ...    0\n",
              "198           5  ...    1\n",
              "199           1  ...    5\n",
              "200           4  ...    0\n",
              "201           5  ...    5\n",
              "202           0  ...    0\n",
              "203           0  ...    0\n",
              "204           5  ...    5\n",
              "205           1  ...    2\n",
              "206           1  ...    1\n",
              "207           5  ...    0\n",
              "208           2  ...    0\n",
              "209           0  ...    0\n",
              "210           5  ...    5\n",
              "211           0  ...    0\n",
              "212           4  ...    1\n",
              "213           2  ...    2\n",
              "214           5  ...    0\n",
              "215           5  ...    0\n",
              "216           5  ...    5\n",
              "217           0  ...    1\n",
              "218           5  ...    5\n",
              "219           2  ...    0\n",
              "220           5  ...    5\n",
              "221           2  ...    1\n",
              "222           0  ...    0\n",
              "223           1  ...    1\n",
              "224           2  ...    0\n",
              "225           4  ...    0\n",
              "226           5  ...    5\n",
              "227           0  ...    0\n",
              "228           1  ...    4\n",
              "229           0  ...    0\n",
              "230           5  ...    1\n",
              "231           0  ...    0\n",
              "232           0  ...    0\n",
              "233           0  ...    0\n",
              "234           4  ...    5\n",
              "235           5  ...    5\n",
              "236           5  ...    5\n",
              "237           1  ...    0\n",
              "238           4  ...    0\n",
              "239           2  ...    2\n",
              "240           5  ...    5\n",
              "241           0  ...    0\n",
              "242           4  ...    4\n",
              "243           5  ...    4\n",
              "244           4  ...    0\n",
              "245           1  ...    1\n",
              "246           1  ...    1\n",
              "247           5  ...    5\n",
              "248           1  ...    1\n",
              "249           5  ...    4\n",
              "250           2  ...    1\n",
              "251           5  ...    0\n",
              "252           4  ...    0\n",
              "253           0  ...    5\n",
              "254           1  ...    0\n",
              "255           0  ...    0\n",
              "256           3  ...    0\n",
              "257           5  ...    5\n",
              "258           1  ...    1\n",
              "259           0  ...    4\n",
              "260           0  ...    0\n",
              "261           0  ...    0\n",
              "262           0  ...    3\n",
              "263           0  ...    4\n",
              "264           3  ...    0\n",
              "265           0  ...    1\n",
              "266           0  ...    0\n",
              "267           5  ...    5\n",
              "268           0  ...    0\n",
              "269           5  ...    5\n",
              "270           2  ...    5\n",
              "271           0  ...    0\n",
              "272           1  ...    1\n",
              "273           5  ...    0\n",
              "274           2  ...    0\n",
              "275           0  ...    0\n",
              "276           0  ...    0\n",
              "277           0  ...    0\n",
              "278           1  ...    1\n",
              "279           0  ...    4\n",
              "280           5  ...    2\n",
              "281           0  ...    1\n",
              "282           4  ...    0\n",
              "283           4  ...    0\n",
              "284           5  ...    0\n",
              "285           5  ...    5\n",
              "286           0  ...    0\n",
              "287           1  ...    4\n",
              "288           5  ...    0\n",
              "289           0  ...    1\n",
              "290           0  ...    1\n",
              "291           1  ...    1\n",
              "292           5  ...    0\n",
              "293           5  ...    5\n",
              "294           5  ...    5\n",
              "295           5  ...    1\n",
              "296           1  ...    1\n",
              "297           4  ...    1\n",
              "298           1  ...    0\n",
              "299           4  ...    4\n",
              "300           0  ...    1\n",
              "301           5  ...    5\n",
              "302           0  ...    0\n",
              "303           5  ...    5\n",
              "304           5  ...    5\n",
              "305           1  ...    1\n",
              "306           0  ...    0\n",
              "307           5  ...    0\n",
              "308           0  ...    0\n",
              "309           0  ...    0\n",
              "310           5  ...    5\n",
              "311           5  ...    5\n",
              "312           3  ...    1\n",
              "313           0  ...    1\n",
              "314           1  ...    5\n",
              "315           0  ...    0\n",
              "316           2  ...    1\n",
              "317           1  ...    1\n",
              "318           1  ...    1\n",
              "319           0  ...    0\n",
              "320           4  ...    3\n",
              "321           2  ...    2\n",
              "322           1  ...    1\n",
              "323           4  ...    4\n",
              "324           0  ...    0\n",
              "325           5  ...    5\n",
              "326           1  ...    4\n",
              "327           2  ...    5\n",
              "328           0  ...    1\n",
              "329           1  ...    1\n",
              "330           1  ...    1\n",
              "331           5  ...    5\n",
              "332           2  ...    5\n",
              "333           0  ...    0\n",
              "334           0  ...    0\n",
              "335           0  ...    0\n",
              "336           1  ...    1\n",
              "337           0  ...    0\n",
              "338           1  ...    1\n",
              "339           4  ...    1\n",
              "340           3  ...    3\n",
              "341           5  ...    5\n",
              "342           5  ...    1\n",
              "343           0  ...    0\n",
              "344           0  ...    0\n",
              "345           0  ...    0\n",
              "346           1  ...    0\n",
              "347           4  ...    1\n",
              "348           0  ...    0\n",
              "349           5  ...    5\n",
              "350           1  ...    2\n",
              "351           1  ...    1\n",
              "352           1  ...    1\n",
              "353           2  ...    1\n",
              "354           0  ...    0\n",
              "355           2  ...    1\n",
              "356           5  ...    0\n",
              "357           2  ...    0\n",
              "358           4  ...    0\n",
              "359           0  ...    0\n",
              "360           0  ...    0\n",
              "361           0  ...    4\n",
              "362           5  ...    5\n",
              "363           4  ...    4\n",
              "364           5  ...    5\n",
              "365           4  ...    4\n",
              "366           0  ...    1\n",
              "367           5  ...    4\n",
              "368           1  ...    1\n",
              "369           5  ...    5\n",
              "370           4  ...    2\n",
              "371           0  ...    1\n",
              "372           1  ...    5\n",
              "373           0  ...    0\n",
              "374           0  ...    0\n",
              "375           0  ...    0\n",
              "376           4  ...    0\n",
              "377           5  ...    0\n",
              "378           1  ...    3\n",
              "379           1  ...    1\n",
              "380           1  ...    1\n",
              "381           1  ...    1\n",
              "382           1  ...    0\n",
              "383           0  ...    4\n",
              "384           5  ...    0\n",
              "385           0  ...    5\n",
              "386           0  ...    0\n",
              "387           0  ...    0\n",
              "388           5  ...    5\n",
              "389           2  ...    0\n",
              "390           1  ...    1\n",
              "391           5  ...    1\n",
              "392           5  ...    5\n",
              "393           1  ...    0\n",
              "394           0  ...    0\n",
              "395           3  ...    3\n",
              "396           1  ...    1\n",
              "397           0  ...    0\n",
              "398           2  ...    0\n",
              "399           4  ...    0\n",
              "400           5  ...    5\n",
              "401           0  ...    0\n",
              "402           5  ...    1\n",
              "403           4  ...    0\n",
              "404           0  ...    1\n",
              "405           4  ...    0\n",
              "406           0  ...    0\n",
              "407           0  ...    4\n",
              "408           2  ...    0\n",
              "409           1  ...    1\n",
              "410           4  ...    0\n",
              "411           2  ...    5\n",
              "412           1  ...    1\n",
              "413           0  ...    4\n",
              "414           0  ...    3\n",
              "415           5  ...    0\n",
              "416           0  ...    0\n",
              "417           0  ...    0\n",
              "418           1  ...    2\n",
              "419           1  ...    3\n",
              "420           3  ...    1\n",
              "421           0  ...    0\n",
              "422           3  ...    0\n",
              "423           0  ...    0\n",
              "424           4  ...    1\n",
              "425           2  ...    2\n",
              "426           1  ...    1\n",
              "427           3  ...    1\n",
              "428           5  ...    5\n",
              "429           1  ...    1\n",
              "430           5  ...    5\n",
              "431           0  ...    2\n",
              "432           4  ...    1\n",
              "433           5  ...    5\n",
              "434           0  ...    0\n",
              "435           5  ...    1\n",
              "436           0  ...    0\n",
              "437           5  ...    5\n",
              "438           0  ...    0\n",
              "439           4  ...    0\n",
              "440           0  ...    0\n",
              "441           0  ...    0\n",
              "442           2  ...    2\n",
              "443           0  ...    0\n",
              "444           5  ...    0\n",
              "445           5  ...    0\n",
              "446           0  ...    0\n",
              "447           5  ...    5\n",
              "448           4  ...    4\n",
              "449           5  ...    5\n",
              "450           5  ...    5\n",
              "451           3  ...    0\n",
              "452           1  ...    2\n",
              "453           0  ...    5\n",
              "454           0  ...    5\n",
              "455           5  ...    5\n",
              "456           5  ...    5\n",
              "457           1  ...    1\n",
              "458           4  ...    0\n",
              "459           0  ...    0\n",
              "460           5  ...    5\n",
              "461           2  ...    0\n",
              "462           5  ...    0\n",
              "463           1  ...    1\n",
              "464           3  ...    1\n",
              "465           0  ...    0\n",
              "466           5  ...    1\n",
              "467           1  ...    1\n",
              "468           0  ...    3\n",
              "469           5  ...    5\n",
              "470           0  ...    0\n",
              "471           5  ...    5\n",
              "472           5  ...    5\n",
              "473           3  ...    3\n",
              "474           3  ...    0\n",
              "475           1  ...    1\n",
              "476           1  ...    0\n",
              "477           4  ...    4\n",
              "478           0  ...    0\n",
              "479           0  ...    0\n",
              "480           5  ...    5\n",
              "481           4  ...    0\n",
              "482           0  ...    0\n",
              "483           5  ...    2\n",
              "484           0  ...    0\n",
              "485           5  ...    5\n",
              "486           4  ...    4\n",
              "487           0  ...    4\n",
              "488           0  ...    0\n",
              "489           4  ...    0\n",
              "490           1  ...    1\n",
              "491           0  ...    0\n",
              "492           1  ...    4\n",
              "493           2  ...    5\n",
              "494           4  ...    4\n",
              "495           0  ...    0\n",
              "496           5  ...    5\n",
              "497           0  ...    0\n",
              "498           5  ...    5\n",
              "499           0  ...    0\n",
              "500           0  ...    0\n",
              "501           0  ...    0\n",
              "502           0  ...    0\n",
              "503           2  ...    5\n",
              "504           5  ...    2\n",
              "505           4  ...    4\n",
              "506           1  ...    1\n",
              "507           0  ...    0\n",
              "508           1  ...    1\n",
              "509           0  ...    0\n",
              "510           4  ...    1\n",
              "511           0  ...    0\n",
              "512           0  ...    0\n",
              "513           0  ...    0\n",
              "514           1  ...    1\n",
              "515           0  ...    0\n",
              "516           4  ...    0\n",
              "517           5  ...    5\n",
              "518           5  ...    5\n",
              "519           1  ...    1\n",
              "520           5  ...    1\n",
              "521           5  ...    5\n",
              "522           4  ...    0\n",
              "523           2  ...    1\n",
              "524           1  ...    2\n",
              "525           0  ...    0\n",
              "526           1  ...    1\n",
              "527           0  ...    4\n",
              "528           1  ...    1\n",
              "529           1  ...    0\n",
              "530           5  ...    5\n",
              "531           0  ...    0\n",
              "532           0  ...    0\n",
              "533           1  ...    0\n",
              "534           2  ...    0\n",
              "535           4  ...    0\n",
              "536           0  ...    0\n",
              "537           4  ...    1\n",
              "538           2  ...    0\n",
              "539           3  ...    1\n",
              "540           5  ...    5\n",
              "541           2  ...    0\n",
              "542           0  ...    0\n",
              "543           0  ...    0\n",
              "544           5  ...    2\n",
              "545           4  ...    5\n",
              "546           0  ...    0\n",
              "547           5  ...    5\n",
              "548           0  ...    0\n",
              "549           4  ...    4\n",
              "550           0  ...    0\n",
              "551           1  ...    1\n",
              "552           2  ...    1\n",
              "553           0  ...    1\n",
              "554           5  ...    4\n",
              "555           0  ...    0\n",
              "556           2  ...    5\n",
              "557           5  ...    5\n",
              "558           4  ...    1\n",
              "559           0  ...    0\n",
              "560           0  ...    0\n",
              "561           0  ...    0\n",
              "562           2  ...    1\n",
              "563           0  ...    0\n",
              "564           0  ...    1\n",
              "565           0  ...    0\n",
              "566           0  ...    0\n",
              "567           5  ...    4\n",
              "568           0  ...    0\n",
              "569           2  ...    0\n",
              "570           0  ...    5\n",
              "571           4  ...    0\n",
              "572           5  ...    1\n",
              "573           5  ...    5\n",
              "574           0  ...    1\n",
              "575           5  ...    5\n",
              "576           5  ...    1\n",
              "577           0  ...    0\n",
              "578           5  ...    1\n",
              "579           0  ...    4\n",
              "580           5  ...    5\n",
              "581           5  ...    5\n",
              "582           0  ...    0\n",
              "583           0  ...    0\n",
              "584           1  ...    1\n",
              "585           4  ...    4\n",
              "586           1  ...    1\n",
              "587           0  ...    0\n",
              "588           4  ...    4\n",
              "589           0  ...    1\n",
              "590           4  ...    0\n",
              "591           5  ...    0\n",
              "592           0  ...    1\n",
              "593           5  ...    1\n",
              "594           0  ...    0\n",
              "595           0  ...    0\n",
              "596           3  ...    1\n",
              "597           5  ...    0\n",
              "598           0  ...    2\n",
              "599           1  ...    1\n",
              "600           5  ...    5\n",
              "601           5  ...    5\n",
              "602           5  ...    0\n",
              "603           4  ...    1\n",
              "604           0  ...    0\n",
              "605           0  ...    0\n",
              "606           0  ...    0\n",
              "607           0  ...    0\n",
              "608           1  ...    1\n",
              "609           1  ...    0\n",
              "610           1  ...    2\n",
              "611           4  ...    0\n",
              "612           2  ...    3\n",
              "613           2  ...    0\n",
              "614           0  ...    0\n",
              "615           1  ...    1\n",
              "616           5  ...    5\n",
              "617           4  ...    0\n",
              "618           5  ...    5\n",
              "619           1  ...    1\n",
              "620           0  ...    0\n",
              "621           5  ...    5\n",
              "622           1  ...    0\n",
              "623           0  ...    0\n",
              "624           2  ...    0\n",
              "625           2  ...    0\n",
              "626           5  ...    5\n",
              "627           2  ...    5\n",
              "628           5  ...    5\n",
              "629           5  ...    5\n",
              "630           1  ...    1\n",
              "631           1  ...    1\n",
              "632           0  ...    0\n",
              "633           2  ...    2\n",
              "634           5  ...    5\n",
              "635           5  ...    5\n",
              "636           0  ...    0\n",
              "637           5  ...    0\n",
              "638           0  ...    0\n",
              "639           4  ...    1\n",
              "640           2  ...    1\n",
              "641           5  ...    1\n",
              "642           4  ...    0\n",
              "643           4  ...    4\n",
              "644           0  ...    0\n",
              "645           0  ...    0\n",
              "646           4  ...    4\n",
              "647           0  ...    1\n",
              "648           1  ...    4\n",
              "649           0  ...    5\n",
              "650           1  ...    1\n",
              "651           5  ...    5\n",
              "652           4  ...    0\n",
              "653           0  ...    0\n",
              "654           4  ...    1\n",
              "655           4  ...    0\n",
              "656           5  ...    5\n",
              "657           1  ...    0\n",
              "658           0  ...    1\n",
              "659           5  ...    0\n",
              "660           2  ...    0\n",
              "661           5  ...    5\n",
              "662           1  ...    1\n",
              "663           5  ...    5\n",
              "664           0  ...    2\n",
              "665           0  ...    0\n",
              "666           5  ...    5\n",
              "667           5  ...    5\n",
              "668           5  ...    5\n",
              "669           0  ...    0\n",
              "670           0  ...    0\n",
              "671           4  ...    1\n",
              "672           4  ...    4\n",
              "673           1  ...    5\n",
              "674           5  ...    5\n",
              "675           4  ...    4\n",
              "676           1  ...    4\n",
              "677           4  ...    0\n",
              "678           0  ...    4\n",
              "679           4  ...    0\n",
              "680           0  ...    0\n",
              "681           1  ...    0\n",
              "682           0  ...    1\n",
              "683           1  ...    2\n",
              "684           0  ...    1\n",
              "685           2  ...    2\n",
              "686           5  ...    0\n",
              "687           2  ...    1\n",
              "688           5  ...    0\n",
              "689           0  ...    5\n",
              "690           3  ...    1\n",
              "691           0  ...    3\n",
              "692           0  ...    0\n",
              "693           0  ...    0\n",
              "694           4  ...    0\n",
              "695           1  ...    4\n",
              "696           0  ...    0\n",
              "697           0  ...    0\n",
              "698           1  ...    1\n",
              "699           5  ...    5\n",
              "700           2  ...    0\n",
              "701           0  ...    0\n",
              "702           0  ...    0\n",
              "703           0  ...    1\n",
              "704           0  ...    0\n",
              "705           4  ...    0\n",
              "706           0  ...    5\n",
              "707           5  ...    5\n",
              "708           4  ...    1\n",
              "709           5  ...    0\n",
              "710           2  ...    1\n",
              "711           1  ...    2\n",
              "712           1  ...    0\n",
              "713           0  ...    1\n",
              "714           0  ...    0\n",
              "715           1  ...    1\n",
              "716           0  ...    0\n",
              "717           4  ...    0\n",
              "718           4  ...    0\n",
              "719           1  ...    0\n",
              "720           0  ...    0\n",
              "721           4  ...    4\n",
              "722           1  ...    1\n",
              "723           2  ...    1\n",
              "724           2  ...    3\n",
              "725           4  ...    1\n",
              "726           0  ...    1\n",
              "727           4  ...    1\n",
              "728           5  ...    5\n",
              "729           0  ...    0\n",
              "730           5  ...    0\n",
              "731           4  ...    0\n",
              "732           1  ...    0\n",
              "733           4  ...    4\n",
              "734           1  ...    5\n",
              "735           1  ...    1\n",
              "736           0  ...    0\n",
              "737           1  ...    5\n",
              "738           2  ...    0\n",
              "739           5  ...    1\n",
              "740           4  ...    4\n",
              "741           4  ...    5\n",
              "742           0  ...    0\n",
              "743           0  ...    0\n",
              "744           5  ...    5\n",
              "745           0  ...    0\n",
              "746           4  ...    0\n",
              "747           5  ...    5\n",
              "748           1  ...    1\n",
              "749           5  ...    0\n",
              "\n",
              "[750 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "missclass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smi0rcE7frGG"
      },
      "outputs": [],
      "source": [
        "missclass[\"true\"].replace({0: \"Background\", 1: \"Comparison or Contrast\",2:\"Extends\",3:\"Future\",4:\"Motivation\",5:\"Uses\"}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72XhlkscfsmG"
      },
      "outputs": [],
      "source": [
        "missclass['prediction'].replace({0: \"Background\", 1: \"Comparison or Contrast\",2:\"Extends\",3:\"Future\",4:\"Motivation\",5:\"Uses\"}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdrFalVQOM9c"
      },
      "outputs": [],
      "source": [
        "missclass.replace(',','', regex=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wal0Cn6Gfwrv"
      },
      "outputs": [],
      "source": [
        "missclass.to_csv('6functionselmocontext.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pH9CIIH0jeQw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89cdb5e7-b625-4795-d58d-817c2fb287e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "            Background       0.73      0.55      0.63       312\n",
            "Comparison or Contrast       0.61      0.48      0.54       184\n",
            "               Extends       0.19      0.38      0.25        32\n",
            "                Future       0.24      0.25      0.24        16\n",
            "            Motivation       0.29      0.54      0.38        56\n",
            "                  Uses       0.61      0.76      0.67       150\n",
            "\n",
            "              accuracy                           0.56       750\n",
            "             macro avg       0.44      0.49      0.45       750\n",
            "          weighted avg       0.61      0.56      0.57       750\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = [\"Background\",\"Comparison or Contrast\",\"Extends\",\"Future\",\"Motivation\",\"Uses\"]\n",
        "#target_names = [\"Future\",\"Neut\",\"PSim\",\"compare_contrast\",\"support\"]\n",
        "print(classification_report(true_y, pred_y, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMGVbs36jigp"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Generate the confusion matrix\n",
        "cf_matrix = confusion_matrix(true_y, pred_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3J_2yUUYjn4A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "47849001-f5e1-45be-e1de-7e0351df7a1a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(15, 15))\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues',fmt=\"d\")\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Category')\n",
        "ax.set_ylabel('Actual Category ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([\"Background\",\"Comparison or Contrast\",\"Extends\",\"Future\",\"Motivation\",\"Uses\"])\n",
        "ax.yaxis.set_ticklabels([\"Background\",\"Comparison or Contrast\",\"Extends\",\"Future\",\"Motivation\",\"Uses\"])\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-stshVhKtBbn"
      },
      "outputs": [],
      "source": [
        "classifier = CitationClassifier(hidden_dim=args.hidden_dim,num_layers=args.num_layers,label_size=len(vectorizer.category_vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xp5jfKtctOHx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624,
          "referenced_widgets": [
            "f161e2fc828245c69a010a9bc1dac220",
            "6b2f63dc38204a3ab41ff92d626a5826",
            "93f6b6299c51453687a5a256a994d551",
            "5d0ec7ceb0254349b57d6e0449e045f0",
            "c7a6713b3caf493280d8ecd9dbd1410f",
            "84c4a38418d1458383e37dfe0c15cce4",
            "2b8799f69a6a4a31889ca680874b3c2a",
            "94bb4223789a4d6791d005e2d3489c5d",
            "39804166cdd44a71914ae76e2bd649bd",
            "de81c69c455e44a6b5adf614e07754f1",
            "86ecb4f58df44550a300c4fc59762ac4",
            "59a491e8c4b24f2aaabbe11795d62d44",
            "80d9b24b9d2f4efeb5e56cecf64bafbd",
            "310301c92859477da6a18eecbcb2169d",
            "8a100b3c47954f70a78ec4170f19ea0a",
            "ce83b0fd406040a9ab27d16c1bfe4e56",
            "2932fd1b2f794310bda38925086da694",
            "21e4df5952eb4f8a84d1bae3fd02d013",
            "cf3809205b09451fbb84858894eaa426",
            "2b25c1b9793644e6afbf2acffaa6a40a",
            "bf47fe4bbb36472b87931ca068db1253",
            "e8f80521fefd4618b7ffc5b12e4e9a87",
            "3886dfa9ec934600b6b7f3aabeefc547",
            "cf1739177cc442c8ae671ce5dd2de9b2",
            "c71316296c1f4477a1b46a926963136d",
            "e278f9f6de414018b903271649a689c8",
            "51cb662640d840e28b65e87330da97cc",
            "56d7bd7496e2437993d9469135231de7",
            "ff5cdcf152384c5096d89cfc4066e9be",
            "a1bf2ce2af84469d81aa8f277d714315",
            "b95680b36b4144828f49aebb6da0b10e",
            "82f69e6480f54971bf2c5291222857dc",
            "bc5fe5fd98d54e3390a15b6e6b8df552"
          ]
        },
        "outputId": "e85355d4-0b62-4b1c-8bd9-47233fb8be75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f161e2fc828245c69a010a9bc1dac220",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "training routine:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59a491e8c4b24f2aaabbe11795d62d44",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "split=train:   0%|          | 0/83 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3886dfa9ec934600b6b7f3aabeefc547",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "split=val:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:116: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\t val_loss=1.7923115079219525\t val_acc=24.477317554240635\n",
            "Epoch 1\t val_loss=1.7922893441640413\t val_acc=24.477317554240635\n",
            "Epoch 2\t val_loss=1.7917871521069455\t val_acc=24.477317554240635\n",
            "Epoch 3\t val_loss=1.7908598551383386\t val_acc=24.477317554240635\n",
            "Epoch 4\t val_loss=1.789523381453294\t val_acc=24.477317554240635\n",
            "Epoch 5\t val_loss=1.787529014624082\t val_acc=27.29783037475345\n",
            "Epoch 6\t val_loss=1.7792841104360724\t val_acc=29.861932938856015\n",
            "Epoch 7\t val_loss=1.765588178084447\t val_acc=31.91321499013806\n",
            "Epoch 8\t val_loss=1.7569410709234385\t val_acc=33.57988165680474\n",
            "Epoch 9\t val_loss=1.7480515149923472\t val_acc=33.41222879684419\n",
            "Epoch 10\t val_loss=1.7349785337081323\t val_acc=30.335305719921113\n",
            "Epoch 11\t val_loss=1.7275722210223858\t val_acc=27.16962524654832\n",
            "Epoch 12\t val_loss=1.7155862542299123\t val_acc=26.360946745562128\n",
            "Epoch 13\t val_loss=1.7175302413793707\t val_acc=24.41814595660749\n",
            "Epoch 14\t val_loss=1.7203625532296987\t val_acc=24.714003944773168\n",
            "Epoch 15\t val_loss=1.713221632517301\t val_acc=23.24457593688363\n",
            "Epoch 16\t val_loss=1.7064710076038652\t val_acc=23.796844181459562\n",
            "Epoch 17\t val_loss=1.7086178018496587\t val_acc=22.662721893491124\n",
            "Epoch 18\t val_loss=1.7075259135319636\t val_acc=24.28994082840237\n",
            "Epoch 19\t val_loss=1.7168245682349572\t val_acc=22.859960552268248\n"
          ]
        }
      ],
      "source": [
        "predictions=[]\n",
        "prediction=[]\n",
        "y=[]\n",
        "classifier = classifier.to(args.device)\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\n",
        "    \n",
        "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
        "optimizer = optim.RMSprop(classifier.parameters(), lr=args.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                           mode='min', factor=0.5,\n",
        "                                           patience=1)\n",
        "\n",
        "train_state = make_train_state(args)\n",
        "\n",
        "epoch_bar = tqdm_notebook(desc='training routine', \n",
        "                          total=args.num_epochs,\n",
        "                          position=0)\n",
        "\n",
        "dataset.set_split('train')\n",
        "train_bar = tqdm_notebook(desc='split=train',\n",
        "                          total=dataset.get_num_batches(args.batch_size), \n",
        "                          position=1, \n",
        "                          leave=True)\n",
        "dataset.set_split('val')\n",
        "val_bar = tqdm_notebook(desc='split=val',\n",
        "                        total=dataset.get_num_batches(args.batch_size), \n",
        "                        position=1, \n",
        "                        leave=True)\n",
        "\n",
        "try:\n",
        "    for epoch_index in range(args.num_epochs):\n",
        "        train_state['epoch_index'] = epoch_index\n",
        "\n",
        "        # Iterate over training dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
        "\n",
        "        dataset.set_split('train')\n",
        "        batch_generator = batchify(dataset,bsz=args.batch_size,device=args.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        classifier.train()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # the training routine is these 5 steps:\n",
        "\n",
        "            # --------------------------------------\n",
        "            # step 1. zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # step 2. compute the output\n",
        "            y_pred = classifier(batch_dict[0],batch_dict[2])\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = loss_func(y_pred, batch_dict[1])\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # step 4. use loss to produce gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # step 5. use optimizer to take gradient step\n",
        "            optimizer.step()\n",
        "            # -----------------------------------------\n",
        "            # compute the accuracy\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict[1])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            # update bar\n",
        "            train_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                                  epoch=epoch_index)\n",
        "            train_bar.update()\n",
        "\n",
        "        train_state['train_loss'].append(running_loss)\n",
        "        train_state['train_acc'].append(running_acc)\n",
        "\n",
        "        # Iterate over val dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
        "        dataset.set_split('val')\n",
        "        batch_generator = batchify(dataset,bsz=args.batch_size,device=args.device)\n",
        "        running_loss = 0.\n",
        "        running_acc = 0.\n",
        "        classifier.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "            # compute the output\n",
        "            y_pred =  classifier(batch_dict[0],batch_dict[2])\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = loss_func(y_pred, batch_dict[1])\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            _, predictions = y_pred.max(dim=1)\n",
        "            prediction.append(predictions)\n",
        "            y.append(batch_dict[1])\n",
        "\n",
        "            # compute the accuracy\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict[1])\n",
        "            \n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                            epoch=epoch_index)\n",
        "            val_bar.update()\n",
        "        print('Epoch {}\\t val_loss={}\\t val_acc={}'.format(epoch_index, running_loss, running_acc))\n",
        "\n",
        "        train_state['val_loss'].append(running_loss)\n",
        "        train_state['val_acc'].append(running_acc)\n",
        "        # print(\"Test loss: {};\".format(train_state['val_loss']))\n",
        "        # print(\"Test Accuracy: {}\".format(train_state['val_acc']))\n",
        "\n",
        "        train_state = update_train_state(args=args, model=classifier,\n",
        "                                         train_state=train_state)\n",
        "\n",
        "        scheduler.step(train_state['val_loss'][-1])\n",
        "\n",
        "        if train_state['stop_early']:\n",
        "            break\n",
        "\n",
        "        train_bar.n = 0\n",
        "        val_bar.n = 0\n",
        "        epoch_bar.update()\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Exiting loop\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tY4PeaRtOif"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVY6qtYstRw7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49f8c863-bcf9-48e9-ca20-285f5b419180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:116: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ],
      "source": [
        "# compute the loss & accuracy on the test set using the best available model\n",
        "\n",
        "classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
        "\n",
        "classifier = classifier.to(args.device)\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\n",
        "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
        "\n",
        "dataset.set_split('val')\n",
        "batch_generator = batchify(dataset,bsz=args.batch_size,device=args.device)\n",
        "running_loss = 0.\n",
        "running_acc = 0.\n",
        "classifier.eval()\n",
        "predictions=[]\n",
        "prediction=[]\n",
        "y=[]\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "    # compute the output\n",
        "    y_pred =  classifier(batch_dict[0],batch_dict[2])\n",
        "\n",
        "    \n",
        "    # compute the loss\n",
        "    loss = loss_func(y_pred, batch_dict[1])\n",
        "    loss_t = loss.item()\n",
        "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "    _, predictions = y_pred.max(dim=1)\n",
        "    prediction.append(predictions)\n",
        "    y.append(batch_dict[1])\n",
        "    # compute the accuracy\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict[1])\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss\n",
        "train_state['test_acc'] = running_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V086NspDDvKP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99585e2d-0c47-4453-8030-e5b33ad8dc6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 1, 0, 2, 1, 1, 0, 1, 1, 1, 4, 0, 0, 3, 0, 5, 0, 0, 0, 4, 0, 0, 0,\n",
              "        5, 0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "y.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdK4DFk8Dv1G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "203af083-72dc-4d9c-9007-579e3bb85db6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 5, 1, 5, 5, 1, 5, 1, 1, 1, 1, 5, 1, 5, 1, 5, 5, 1, 1, 1, 5, 1, 5,\n",
              "        5, 1], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "prediction.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTFuv0PbtSTh"
      },
      "outputs": [],
      "source": [
        "y_tensor = torch.stack(y)\n",
        "pred_tensor = torch.stack(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jTdQ3dttWnT"
      },
      "outputs": [],
      "source": [
        "true_y=y_tensor.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_n7AARstYRY"
      },
      "outputs": [],
      "source": [
        "pred_y=pred_tensor.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6xtKXK6tZuX"
      },
      "outputs": [],
      "source": [
        "pred_y=pred_y.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGsP2cymtbd4"
      },
      "outputs": [],
      "source": [
        "true_y=true_y.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZPfyqAKtdZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b19d96a-54bf-4199-f7c0-bc7247405c75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "            Background       0.00      0.00      0.00       312\n",
            "Comparison or Contrast       0.37      0.26      0.30       184\n",
            "               Extends       0.00      0.00      0.00        32\n",
            "                Future       0.03      0.75      0.07        16\n",
            "            Motivation       0.00      0.00      0.00        56\n",
            "                  Uses       0.46      0.84      0.60       150\n",
            "\n",
            "              accuracy                           0.25       750\n",
            "             macro avg       0.14      0.31      0.16       750\n",
            "          weighted avg       0.18      0.25      0.19       750\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = [\"Background\",\"Comparison or Contrast\",\"Extends\",\"Future\",\"Motivation\",\"Uses\"]\n",
        "#target_names = [\"Future\",\"Neut\",\"PSim\",\"compare_contrast\",\"support\"]\n",
        "print(classification_report(true_y, pred_y, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpP8MXt3tfv3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Generate the confusion matrix\n",
        "cf_matrix = confusion_matrix(true_y, pred_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDoZRPArthzp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "3904aa72-b212-45bd-f338-6ebdc7a7f9df"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(15, 15))\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues',fmt=\"d\")\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Category')\n",
        "ax.set_ylabel('Actual Category ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([\"Background\",\"Comparison or Contrast\",\"Extends\",\"Future\",\"Motivation\",\"Uses\"])\n",
        "ax.yaxis.set_ticklabels([\"Background\",\"Comparison or Contrast\",\"Extends\",\"Future\",\"Motivation\",\"Uses\"])\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lg_3RzOKGLbW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYXNrp51MdSn"
      },
      "outputs": [],
      "source": [
        "# if you could generate a global attentive sentence vector and use that for classsification\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import os\n",
        "import numpy as np\n",
        "from allennlp.modules.elmo import Elmo\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "        \n",
        "        self.supports_masking = True\n",
        "\n",
        "        self.bias = bias\n",
        "        self.feature_dim = feature_dim\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "        \n",
        "        weight = torch.zeros(feature_dim, 1)\n",
        "        nn.init.kaiming_uniform_(weight)\n",
        "        self.weight = nn.Parameter(weight)\n",
        "        \n",
        "        if bias:\n",
        "            self.b = nn.Parameter(torch.zeros(step_dim))\n",
        "        \n",
        "    def forward(self, x, mask=None):\n",
        "        # print(\"x.shape\")\n",
        "        # print(x.shape)\n",
        "        feature_dim = self.feature_dim \n",
        "        # print(feature_dim)\n",
        "        step_dim = self.step_dim\n",
        "        # print(step_dim)\n",
        "\n",
        "        eij = torch.mm(x.contiguous().view(-1, feature_dim), self.weight).view(-1, step_dim)\n",
        "        # print(\"eij.shape\")\n",
        "        # print(eij.shape)\n",
        "        \n",
        "        if self.bias:\n",
        "            eij = eij + self.b\n",
        "            \n",
        "        eij = torch.tanh(eij)\n",
        "        a = torch.exp(eij)\n",
        "        \n",
        "        if mask is not None:\n",
        "            a = a * mask\n",
        "\n",
        "        a = a / (torch.sum(a, 1, keepdim=True) + 1e-10)\n",
        "\n",
        "        weighted_input = x * torch.unsqueeze(a, -1)\n",
        "        return torch.sum(weighted_input, 1)\n",
        "\n",
        "class CitationClassifier(nn.Module):\n",
        "    def __init__(self,hidden_dim,num_layers, label_size,dropout=0.5):\n",
        "        super(CitationClassifier, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.hidden_dim = hidden_dim\n",
        "        options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
        "        weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
        "        self.elmo = Elmo(options_file, weight_file, 1, dropout=dropout, do_layer_norm=False)\n",
        "        # elmo output\n",
        "#         Dict with keys:\n",
        "#         ``'elmo_representations'``: ``List[torch.Tensor]``\n",
        "#             A ``num_output_representations`` list of ELMo representations for the input sequence.\n",
        "#             Each representation is shape ``(batch_size, timesteps, embedding_dim)``\n",
        "#         ``'mask'``:  ``torch.Tensor``\n",
        "#             Shape ``(batch_size, timesteps)`` long tensor with sequence mask.\n",
        "        self.lstm = nn.LSTM(1024, hidden_dim,num_layers, bidirectional=True, batch_first=True)\n",
        "        # self.attention_layer = Attention(hidden_dim*2)\n",
        "        self.fc1 = nn.Linear(hidden_dim*2, 120)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(120, label_size)\n",
        "        self.act=nn.Softmax()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for name, param in self.hidden2label.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "        for name, param in self.conv1.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "        \n",
        "    def forward(self, sentences,citseg_id):\n",
        "        # print(\"sentences.shape\")\n",
        "        # print(sentences.shape)\n",
        "        elmo_out = self.elmo(sentences)\n",
        "        x = elmo_out['elmo_representations'][0]\n",
        "        # print(elmo_out['elmo_representations'][0].shape)\n",
        "        # print(\"x.shape\")\n",
        "        # print(x.shape)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.lstm(x)\n",
        "        l=packed_output.shape[1]\n",
        "        l=torch.tensor(l)\n",
        "        l=l.cuda()\n",
        "        h=torch.tensor(64)\n",
        "        h=h.cuda()\n",
        "        self.attention_layer = Attention(h,l).cuda()\n",
        "        packed_output = self.attention_layer(packed_output)\n",
        "        # print(packed_output.shape)\n",
        "        #packed_output=packed_output[torch.arange(packed_output.size(0)),citseg_id.long()]\n",
        "        # print(packed_output.shape)\n",
        "        out = self.fc1(packed_output)\n",
        "        # print(out.shape)\n",
        "        out = self.relu(out)\n",
        "        # print(out.shape)\n",
        "        out = self.fc2(out)\n",
        "        # print(out.shape)\n",
        "        pred1= self.act(out)\n",
        "        # print(pred1.shape)\n",
        "        return pred1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gx_mKl8vMzuh"
      },
      "outputs": [],
      "source": [
        "classifier = CitationClassifier(hidden_dim=args.hidden_dim,num_layers=args.num_layers,label_size=len(vectorizer.category_vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwcQ2VfyM8Sp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624,
          "referenced_widgets": [
            "36a0caab3fd24ae491ba052417ace72b",
            "71069ab5195748f3bf08ea3aaae53a92",
            "f0f22a63e0c542958717ce27fc6ecca9",
            "fb8cabe34a9141eda4b6da49047b429b",
            "28c967e66f6e4ad1badb83db0f8a1cd6",
            "58b603f0e4ca4e6babe2f258459a43b7",
            "c8a3571dc50b420aa00c90b77a5ac169",
            "7214931cd9a94879b0570560eec1967c",
            "b775dd0b1f53490b8d3a8586986ba048",
            "88acbd1d37994fa5a9fa1c57191d014f",
            "73b2e0f1c64146d39809f5a04c0c8b6f",
            "d7e4591570484bb09fa4c8187e19bc3e",
            "24014bd09cf2472fae8fdc84243e9d1b",
            "1bd584d002c948f6b33b818085cd49c9",
            "2d890e5b59b645afb91bd267b99477ce",
            "cc72fcd51db84d3fa22102e07eb86f79",
            "74a8dd196f7c4989be32262e0c60950f",
            "dac1701f794e45b6856253a9868bcd42",
            "87d9e8ff7751408fa0c8c71f96a9cb14",
            "c27dff29cf42484195962084fce570d2",
            "34c5be976a394aa6a276ff5f12718de2",
            "b2bfa2a47ab3446fbf4c76411b799c23",
            "1964701a39894be69ce5ab23fd510fc5",
            "cb53ade577564165875566723d404605",
            "9f7e1747ab1a402493c292f58bc65bb2",
            "f30f53ce82ec47cbbbf4d7211247a81c",
            "aaf4ee7d50294c2c89afd7c7fc5bdd0e",
            "51a7888fb4a9478b8e623c8280b9435a",
            "b8e8505ddaae4144b68ee98e8e93b244",
            "ef86ed65d49449eea87de49ac004cda5",
            "20ae19001cef4e31915a9bda81d9d108",
            "a2213f6128cb4d4a88fb772019304efd",
            "c5bcd805d4a1438299763c11e67f9838"
          ]
        },
        "outputId": "25fe6aa3-af0c-4002-9348-5f791d3e5b68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36a0caab3fd24ae491ba052417ace72b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "training routine:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7e4591570484bb09fa4c8187e19bc3e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "split=train:   0%|          | 0/83 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1964701a39894be69ce5ab23fd510fc5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "split=val:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\t val_loss=1.7796695645038896\t val_acc=18.136094674556215\n",
            "Epoch 1\t val_loss=1.73707017990259\t val_acc=25.355029585798817\n",
            "Epoch 2\t val_loss=1.6756898806645317\t val_acc=37.05128205128206\n",
            "Epoch 3\t val_loss=1.6547061846806455\t val_acc=44.2603550295858\n",
            "Epoch 4\t val_loss=1.6634651880997877\t val_acc=37.603550295857985\n",
            "Epoch 5\t val_loss=1.6460723693554218\t val_acc=36.74556213017752\n",
            "Epoch 6\t val_loss=1.6300639876952538\t val_acc=44.891518737672584\n",
            "Epoch 7\t val_loss=1.624892913378202\t val_acc=44.25049309664694\n",
            "Epoch 8\t val_loss=1.6548960529840908\t val_acc=36.35108481262327\n",
            "Epoch 9\t val_loss=1.638128143090468\t val_acc=36.18343195266272\n",
            "Epoch 10\t val_loss=1.6060823568930993\t val_acc=44.95069033530573\n",
            "Epoch 11\t val_loss=1.6203562204654396\t val_acc=41.60749506903352\n",
            "Epoch 12\t val_loss=1.6203834460331845\t val_acc=38.629191321499015\n",
            "Epoch 13\t val_loss=1.6085071517870972\t val_acc=44.65483234714003\n",
            "Epoch 14\t val_loss=1.6048901172784658\t val_acc=45.57199211045365\n",
            "Epoch 15\t val_loss=1.5946477789145252\t val_acc=44.39842209072978\n",
            "Epoch 16\t val_loss=1.5920168940837567\t val_acc=47.38658777120317\n",
            "Epoch 17\t val_loss=1.5917931244923518\t val_acc=44.18145956607495\n",
            "Epoch 18\t val_loss=1.5892530633853035\t val_acc=45.463510848126234\n",
            "Epoch 19\t val_loss=1.583527166109819\t val_acc=47.49506903353058\n"
          ]
        }
      ],
      "source": [
        "predictions=[]\n",
        "prediction=[]\n",
        "y=[]\n",
        "classifier = classifier.to(args.device)\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\n",
        "    \n",
        "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
        "optimizer = optim.RMSprop(classifier.parameters(), lr=args.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                           mode='min', factor=0.5,\n",
        "                                           patience=1)\n",
        "\n",
        "train_state = make_train_state(args)\n",
        "\n",
        "epoch_bar = tqdm_notebook(desc='training routine', \n",
        "                          total=args.num_epochs,\n",
        "                          position=0)\n",
        "\n",
        "dataset.set_split('train')\n",
        "train_bar = tqdm_notebook(desc='split=train',\n",
        "                          total=dataset.get_num_batches(args.batch_size), \n",
        "                          position=1, \n",
        "                          leave=True)\n",
        "dataset.set_split('val')\n",
        "val_bar = tqdm_notebook(desc='split=val',\n",
        "                        total=dataset.get_num_batches(args.batch_size), \n",
        "                        position=1, \n",
        "                        leave=True)\n",
        "\n",
        "try:\n",
        "    for epoch_index in range(args.num_epochs):\n",
        "        train_state['epoch_index'] = epoch_index\n",
        "\n",
        "        # Iterate over training dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
        "\n",
        "        dataset.set_split('train')\n",
        "        batch_generator = batchify(dataset,bsz=args.batch_size,device=args.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        classifier.train()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # the training routine is these 5 steps:\n",
        "\n",
        "            # --------------------------------------\n",
        "            # step 1. zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # step 2. compute the output\n",
        "            y_pred = classifier(batch_dict[0],batch_dict[2])\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = loss_func(y_pred, batch_dict[1])\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # step 4. use loss to produce gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # step 5. use optimizer to take gradient step\n",
        "            optimizer.step()\n",
        "            # -----------------------------------------\n",
        "            # compute the accuracy\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict[1])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            # update bar\n",
        "            train_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                                  epoch=epoch_index)\n",
        "            train_bar.update()\n",
        "\n",
        "        train_state['train_loss'].append(running_loss)\n",
        "        train_state['train_acc'].append(running_acc)\n",
        "\n",
        "        # Iterate over val dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
        "        dataset.set_split('val')\n",
        "        batch_generator = batchify(dataset,bsz=args.batch_size,device=args.device)\n",
        "        running_loss = 0.\n",
        "        running_acc = 0.\n",
        "        classifier.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "            # compute the output\n",
        "            y_pred =  classifier(batch_dict[0],batch_dict[2])\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = loss_func(y_pred, batch_dict[1])\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            _, predictions = y_pred.max(dim=1)\n",
        "            prediction.append(predictions)\n",
        "            y.append(batch_dict[1])\n",
        "\n",
        "            # compute the accuracy\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict[1])\n",
        "            \n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                            epoch=epoch_index)\n",
        "            val_bar.update()\n",
        "        print('Epoch {}\\t val_loss={}\\t val_acc={}'.format(epoch_index, running_loss, running_acc))\n",
        "\n",
        "        train_state['val_loss'].append(running_loss)\n",
        "        train_state['val_acc'].append(running_acc)\n",
        "        # print(\"Test loss: {};\".format(train_state['val_loss']))\n",
        "        # print(\"Test Accuracy: {}\".format(train_state['val_acc']))\n",
        "\n",
        "        train_state = update_train_state(args=args, model=classifier,\n",
        "                                         train_state=train_state)\n",
        "\n",
        "        scheduler.step(train_state['val_loss'][-1])\n",
        "\n",
        "        if train_state['stop_early']:\n",
        "            break\n",
        "\n",
        "        train_bar.n = 0\n",
        "        val_bar.n = 0\n",
        "        epoch_bar.update()\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Exiting loop\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLIXYiJMa3d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a6d36cc-44db-4ce0-ddf6-e59fc0928bf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ],
      "source": [
        "# compute the loss & accuracy on the test set using the best available model\n",
        "\n",
        "classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
        "\n",
        "classifier = classifier.to(args.device)\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\n",
        "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
        "\n",
        "dataset.set_split('val')\n",
        "batch_generator = batchify(dataset,bsz=args.batch_size,device=args.device)\n",
        "running_loss = 0.\n",
        "running_acc = 0.\n",
        "classifier.eval()\n",
        "predictions=[]\n",
        "prediction=[]\n",
        "y=[]\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "    # compute the output\n",
        "    y_pred =  classifier(batch_dict[0],batch_dict[2])\n",
        "\n",
        "    \n",
        "    # compute the loss\n",
        "    loss = loss_func(y_pred, batch_dict[1])\n",
        "    loss_t = loss.item()\n",
        "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "    _, predictions = y_pred.max(dim=1)\n",
        "    prediction.append(predictions)\n",
        "    y.append(batch_dict[1])\n",
        "    # compute the accuracy\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict[1])\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss\n",
        "train_state['test_acc'] = running_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X25pgDidNMV6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2822feda-8362-4960-8c32-e752084207d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 1, 0, 2, 1, 1, 0, 1, 1, 1, 4, 0, 0, 3, 0, 5, 0, 0, 0, 4, 0, 0, 0,\n",
              "        5, 0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "y.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37Lhn5UQNM9Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5997822d-5a83-405a-b903-0be73d7640b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 5, 0, 2, 5, 1, 5, 0, 1, 1, 1, 0, 0, 3, 0, 5, 2, 0, 0, 1, 0, 0, 4,\n",
              "        5, 0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "prediction.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-q7QjmLTNQUK"
      },
      "outputs": [],
      "source": [
        "y_tensor = torch.stack(y)\n",
        "pred_tensor = torch.stack(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPnYP4zBNTod"
      },
      "outputs": [],
      "source": [
        "true_y=y_tensor.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtj6aNX0NXID"
      },
      "outputs": [],
      "source": [
        "pred_y=pred_tensor.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71Iy6KWfNabq"
      },
      "outputs": [],
      "source": [
        "pred_y=pred_y.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2DOG1aTNd9k"
      },
      "outputs": [],
      "source": [
        "true_y=true_y.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_yeMPJuNiiL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2b2ccbb-fda3-4b31-a7fa-2d4d4c5fbdab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "            Background       0.72      0.44      0.55       312\n",
            "Comparison or Contrast       0.44      0.44      0.44       184\n",
            "               Extends       0.12      0.44      0.19        32\n",
            "                Future       0.34      0.62      0.44        16\n",
            "            Motivation       0.09      0.05      0.07        56\n",
            "                  Uses       0.50      0.66      0.57       150\n",
            "\n",
            "              accuracy                           0.46       750\n",
            "             macro avg       0.37      0.44      0.38       750\n",
            "          weighted avg       0.53      0.46      0.47       750\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = [\"Background\",\"Comparison or Contrast\",\"Extends\",\"Future\",\"Motivation\",\"Uses\"]\n",
        "#target_names = [\"Future\",\"Neut\",\"PSim\",\"compare_contrast\",\"support\"]\n",
        "print(classification_report(true_y, pred_y, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRsGAcjBNmcW"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Generate the confusion matrix\n",
        "cf_matrix = confusion_matrix(true_y, pred_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVzG_bwtNqmj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "d219a02a-9554-4345-d288-b5dcf69384cd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzcAAAOWCAYAAADSkWyRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd5hcZfXA8e/JJiQBkhBICIRAQAIiVaVIUQRBOkE6GFBsQcSC4E9FFFFUsCJIE0EIXUB6VwREJEDoIEV6TaGkQBpJzu+PmeCyZDNpLzM7+/08z32Ye+/sPWdnZ8Ocfc/73shMJEmSJKmj61LvBCRJkiRpUbC4kSRJktQULG4kSZIkNQWLG0mSJElNweJGkiRJUlOwuJEkSZLUFCxuJL1vIuKoiDi33nmUEBG7RsQLEfFmRHxkIa7zSERssQhTe99FxCci4vHCMd6MiA/M5fyzEbH1PF7rgIj41zw+d4Hfw838/pekRmFxI+k9IuLjEfHviJgQEa9HxO0RsWG981pYEbF8RJwREa9ExKSIeCwifhIRSyyCy/8G+HpmLpmZ9y3oRTJzrcy8ZRHk8y4RcUtEZESs1+b4ZdXjW8zjdTIihsztOZl5W2Z+cCHSran6Oj9dzemsiPhZyXiSpI7B4kbSu0REb+Bq4A/A0sAKwE+AafXMq62IaJnP5y8N3AH0BDbJzF7Ap4GlgFUXQUqDgUcWwXVKegL43OydiFgG2AQYt6gCRETXRXUtSZLml8WNpLZWB8jMCzJzZmZOycwbM/PB2U+IiC9GxKMR8UZE3BARg1udO77anjUxIu6JiE+0uX6PiPhLdeTk3tYjCRHxoeoIw/hqe9bQVufOiohTIuLaiHgL2LLaevSdiHiwOsr0l4jo0c73dSgwCdgvM5+tfo8vZOa3Zn9vEbFpRNxdvdbdEbFpq/i3RMTR1VGsSRFxY0T0i4juEfEm0AI8EBFPVZ//rhGO1qML1a+7uvp9vh4Rt0VEl+q5d9qpqtf+fUS8XN1+HxHdq+e2iIgXI+KwiBhbHY36Qo2f7XnA3q0Kw32By4DprfLcKCLuqOb2SkScGBGLVc/9s/q0B6ptYXu3yuN7ETEaOHP2serXrFr9Hj9a3R8YEePmNFIUEV+IiKta7f83Ii5utf9CRHy49esbEcOBYcB3qzld1eqSH57H90bbPBbmPTwwIv5a/R6fiYhvthOjR0ScGxGvVV/ruyNiwLzkJ0lqn8WNpLaeAGZGxIiI2D4i+rY+GRG7AD8AdgP6A7cBF7R6yt3Ah6mM+pwPXNzmQ+UuwMWtzl8eEd0iohtwFXAjsCzwDeC8iGjd3vRZ4OdAL2D2HIm9gO2AVYB1gQPa+b62Bi7NzFlzOhmVkZ1rgBOAZYDfAddEZXSjdfwvVPNbDPhOZk7LzCWr59fLzHkZBToMeJHK6zeAyuuZc3jeEcDGVF7P9YCNgB+2Or8c0IfK6NqXgJPa/rzaeBn4D7BNdf9zwNltnjMT+DbQj8qozlbA1wAyc/Pqc9artoX9pVUeS1MZvRre+mKZ+RTwPeDciFgcOBMY0U7r3a3AJyKiS0QMpPIabwIQlfk1SwIPtv6CzDyNStH2q2pOO7c6Pa/vjbYW9D3chcp7+AEqP5OtgEMiYts5xPg8lZ/dilTeb18FpsxjfpKkdljcSHqXzJwIfJzKh+0/AeMi4spWf1X+KnBMZj6amTOAX1D5C/ng6tefm5mvZeaMzPwt0B1oXaDck5mXZObbVAqIHlQ+wG9M5cPrsZk5PTP/QaU9bt9WX3tFZt6embMyc2r12AmZ+XJmvk7lg+WH2/nWlgFemcu3viPw38w8p5r7BcBjQOsPy2dm5hOZOQW4aC6xankbWB4YnJlvV+eozKm4GQb8NDPHZuY4Ku2B+7e5zk+r17gWeJN3v9ZzcjbwuYhYA1gqM+9ofTIz78nMkdXX4Fngj8Ana1xzFvDjaqH3ng/omfkn4Engzur3fcScLlKdQzOJyuu6OXAD8HI1108Ct7VXnLZjXt8bbfNY0PfwhkD/zPxp9T38NJXfoX3mEOZtKu/JIdUR0nuqv3uSpIVgcSPpPaqFywGZOQhYGxgI/L56ejBwfLWVZjzwOhBU/lJNtU3s0Wor0Hgqf53u1+ryL7SKM4vKCMbA6vZCmw+vz82+btuvbWV0q8eTqRRIc/IalQ/W7RlYjdda2/jzGquWX1P5sH9jRDwdEd+fx5yeqx6b7bVqgTk/OV0KfAr4OnBO25MRsXq1ZW50REykUrz2a/u8Nsa1Kjbb8ycq76U/ZObc5m/dCmxBpbi5FbiFSmHzyer+/Fign9dCvIcHAwNn/25Uv/YHVEbn2jqHSvF2YbXl8FfV0UtJ0kKwuJE0V5n5GHAWlQ+mUPlgd2BmLtVq65mZ/67OTfgulXagvpm5FDCBSvEz24qzH1TbeAZRaZd6GVhx9tyTqpWAl1qnsxDfyt+BXdtcv7WXqXw4ba1t/PkxGVi81f5ysx9k5qTMPCwzPwAMBQ6NiK3mIaeVqscWWGZOBq4DDmIOxQ1wCpURq9UyszeVD+cxh+e967JzOxkRS1Ipjs8Ajqq2ALZndnHzierjW6ld3CzM+6JtrgvzHn4BeKbN70avzNzhPQlXRtt+kplrApsCO9FqsQdJ0oKxuJH0LhGxRnWS+qDq/opUWsNGVp9yKnB4RKxVPd8nIvasnusFzKCy+lbXiDgS6N0mxPoRsVtUVtU6hMoqbCOptCxNpjIxvFt1wvnOwIWL6Fv7XTWXEbNb6CJihYj4XUSsC1wLrB4Rn42IrhGxN7Amlda4BXE/8NmIaImI7WjV2hURO1UnwweVD84zqbR2tXUB8MOI6B8R/YAjgUVxn5QfAJ+cvbBCG72AicCb1Xawg9qcHwO0e3+ZdhwPjMrML1OZ13TqXJ57K7Al0DMzX6Qyp2s7Ki1c7S2xvSA5tWdh3sN3AZOisrhCz+rPfu2YwzLqEbFlRKwTlcUdJlJpU5ufljtJ0hxY3EhqaxLwMeDOqKxKNhJ4mMokeDLzMuCXVNppJlbPbV/92huA66ksSvAcMJX3tpJdAewNvEFl/shu1b9iT6dSzGwPvAqcDHyuOnK00KrzLjal8iHyzoiYBNxEpbh4MjNfo/LX88OotLB9F9gpM19dwJDfovL9jKcyd+byVudWozKS9CaV5alPzsyb53CNnwGjqEyifwi4t3psoVTnobR308rvUFk4YRKVVrK/tDl/FJUCcXxE7FUrVnUBiu34X5F0KPDRiBjWTm5PUHldbqvuTwSeBm7PzJnthDkDWLOa0+XtPGdeLcx7eCaV99CHgWeovI9Pp9LW1tZywCVUCptHqRR1cxpJkyTNh5jzHFZJkiRJ6lgcuZEkSZLUFCxuJEmSJDUFixtJkiRJTcHiRpIkSVJTsLiRJEmS1BQsbiRJkiQ1BYsbSZIkSU3B4kaSJElSU7C4kSRJktQULG4kSZIkNQWLG0mSJElNweJGkiRJUlOwuJEkSZLUFCxuJEmSJDUFixtJkiRJTcHiRpIkSVJTsLiRJEmS1BQsbiRJkiQ1BYsbSZIkSU3B4kaSJElSU7C4kSRJktQULG4kSZIkNQWLG0mSJElNweJGkiRJUlOwuJEkSZLUFCxuJEmSJDUFixtJkiRJTcHiRpIkSVJTsLiRJEmS1BQsbiRJkiQ1BYsbSZIkSU3B4kaSJElSU7C4kSRJktQULG4kSZIkNQWLG0mSJElNoWu9E2hPz498PeudgxbMD359SL1T0EIYskzPeqeghbDN6gPqnYIW0FvTZtY7BS2EB14aX+8UtBB2XmdA1DuHedHon4+n3Hdi3V9HR24kSZIkNQWLG0mSJElNoWHb0iRJkiS1Eo5L1OIrJEmSJKkpWNxIkiRJagoWN5IkSZKagnNuJEmSpI4g6r7ScsNz5EaSJElSU7C4kSRJktQUbEuTJEmSOgKXgq7JV0iSJElSU7C4kSRJktQUbEuTJEmSOgJXS6vJkRtJkiRJTcHiRpIkSVJTsC1NkiRJ6ghcLa0mXyFJkiRJTcHiRpIkSVJTsC1NkiRJ6ghcLa0mR24kSZIkNQWLG0mSJElNweJGkiRJUlNwzo0kSZLUEbgUdE2+QpIkSZKagsWNJEmSpKZgW5okSZLUEbgUdE2O3EiSJElqChY3kiRJkpqCbWmSJElSR+BqaTX5CkmSJElqChY3kiRJkpqCbWmSJElSR+BqaTU5ciNJkiSpKVjcSJIkSWoKtqVJkiRJHYGrpdXkKyRJkiSpKVjcSJIkSWoKFjeSJEmSmoJzbiRJkqSOwKWga3LkRpIkSVJTKDJyExFXAdne+cwcWiKuJEmSpM6rVFvab6r/3Q1YDji3ur8vMKZQTEmSJKl5uRR0TUWKm8y8FSAifpuZG7Q6dVVEjCoRU5IkSVLnVrr8WyIiPjB7JyJWAZYoHFOSJElSJ1R6tbRvA7dExNNAAIOBAwvHlCRJkpqPbWk1FS1uMvP6iFgNWKN66LHMnFYypiRJkqTO6f24z836wMrVWOtFBJl59vsQV5IkSVInUrS4iYhzgFWB+4GZ1cMJWNxIkiRJ86OLN/GspfTIzQbAmpnZ7j1vJEmSJGlRKD0r6WEq97mRJEmSpKJKj9z0A/4TEXcB7ywkkJlDC8eVJEmSmourpdVUurg5qvD1JUmSJAkovxT0rSWvL0mSJEmzlV4tbRKV1dEAFgO6AW9lZu+ScSVJkqSmE66WVkvpkZtesx9HRAC7ABuXjClJkiSpc3rfZiVlxeXAtu9XTEmSJEmdR+m2tN1a7Xahct+bqSVjSpIkSeqcSq+WtnOrxzOAZ6m0pkmSJEmaHy4FXVPpOTdfKHl9SZIkSZqtaPkXEYMi4rKIGFvd/hoRg0rGlCRJktQ5lR7bOhO4EhhY3a6qHpMkSZI0PyIae2sApYub/pl5ZmbOqG5nAf0Lx5QkSZLUCZVeUOC1iNgPuKC6vy/wWuGYDeHUHw9j+83XZtzrk9hgz18AcOTXdmSnT67LrEzGvT6J4T8+l1fGTeDbn9uKvXfYEICuLV1YY5XlWPFT3+eNiZPr+S2oavrkNxl53gmMf+U5ADbZ7xAmj3+VB685nwljXmD7/zuOZQavVucs1Z5Zs2Zy2g8Oolfffgz73i94+qF7ufG8U8lMFuvRk88c9D2WWW6FeqepGi48dwRXXf5XiGDVIatxxFE/p3v37vVOS+34zc+O5M5/38pSfZfmT+ddBsDZp5/MtVdcSp++fQH44le/ycc2/UQ909RczJo5k99/bzh9lu7Hl37wSy46+VheeOpxyKTfwBXZ5+DD6d5z8XqnKb1H6ZGbLwJ7AaOBV4A9gE6xyMA5V41kl4NPetex40bcxEZ7H8PG+xzLdbc9zOHDt68cP/smNt7nWDbe51iO/MOV3HbPfy1sGsioS05j+TXXZ+iRf2THH5xIn+VWZKmBg9l8+BEsO2TteqenGkZedyn9Bq70zv7VZ/ye3b9xBAf98k+ss9lW/PPSc+uYnebFuLFjuPjC8/jzuRdx3sVXMGvWLP5+w7X1Tktzsc2OQ/nFcae85/ju++zHH8++mD+efbGFTYO77dpLGDBo8Dv7Qw/4Bof99kwO+91Z9O03gNuvv7SO2XVi0aWxtwZQLIuIaAF+kZlDM7N/Zi6bmZ/JzOdLxWwkt9/7FK9PeHeBMumt/93iZ/Ge3cnM93zdXtttwEXX31M8P82b6VPeYsyTDzNk020AaOnajcUWX5I+y61EnwGujdHoJrw2jv/eO5KPfmqHd45FwLTJld/NaZPfolffZeqVnubDzJkzmTZtKjNmzGDqlKn0679svVPSXKz7kQ3o1btPvdPQAhr/2lgevecONtpqx3eO9Vh8CQAyk7enTwMaY36F1FaxtrTMnBkRgyNiscycXipOR3PUwTszbKeNmPDmFLYbfsK7zvXs0Y1Pb/ohvn3sRXXKTm29+epoeizZhzvOOY43XnqGpVcawoZ7HEjX7j3qnZrmwfUjTuLTww5k2pT//aFh6PDvcN4vD6frYovRvecSfPnoE+uYoeZF/2UHsO/+B7DrDlvTvXsPNtpkUz62yWb1TksL4IpLLuRv113F6musxYHf/A69eveud0qagyvO/AM77X8QU6e8+4+0F550DI/dO5IBg1Zm588fXKfspLkrPX70NHB7RPwoIg6dvRWO2dCOOukqVtv+R1x43Si+uvfm7zq34+brcMf9T9uS1kBy1ixef+FJVv/EDux4+B/oulgPHr7x4nqnpXnw+D13sESfpRj4gdXfdfyOay9h2PeO4bCTL+IjW2zLDee8t3VGjWXixAncdss/uOTqG7nyhpuZMmUK119zVb3T0nzaebe9GXHJNZx69sUs3a8ffzzhN/VOSXPwn1H/Zsk+fRm06gffc26fgw/nyNMuZdlBg7n/9n/UITvVfTU0V0vjKeDqapxerbY5iojhETEqIkbNePWRwqnV11+uvZvPbPXhdx3bc9v1udiWtIay+FLLsPhS/ei3yhoADP7IZrz+wpN1zkrz4oUnHubxe/7NcV/fl0tOOJpnHrmP8355OGOee4pBq30IgLU22ZIXnmjuf2uawag7RzJwhUH07bs0Xbt1Y4tPbc1DD95X77Q0n/ouvQwtLS106dKFHXbZnccffajeKWkOnn38If5z9+38/KC9OO/3P+HJh+/l/OOPfud8l5YWPrzZp3ho5K11zFJqX9HV0jLzJ/P5/NOA0wB6fuTr752Q0sGtulJ/nnp+HAA7bbEuTzw75p1zvZfswcfXH8IXjhhRr/Q0Bz37LM3iffszYcyL9BkwiFcef4A+y61U+wtVd1vv+xW23vcrADzzyP38++qL2Oc7R/Obr+7Oqy+/QL+BK/L0g/fQfwV/no1uwHLL88hDDzB1yhS69+jBqLtGssaaLubR0bz26jiW6Ve5G8Ttt/yDlT/gKpONaIdhB7LDsAMBePLh+7j1ygvZ95s/5NVXXqTf8oPITP5z9+0s67+dalBFi5uIuApoW6RMAEYBf8zMqe/9quYw4pgD+MT6q9FvqSV58vqjOfrUa9nu42ux2uBlmTUref6V1/nmzy985/lDt1yPm0Y+xuSpTk9qNBvueSC3n/VrZs2YwZL9lmOT/Q/h+fv/zaiLT2XqmxO4+ZSj6DvoA2z19aNrX0x11dLSwtCvHMZFxx1FRNBjiV7s8tX/q3daqmGtddZly6224YBhe9LS0sLqH/wQu+y2Z73T0lz8/Mjv8uC9o5gwfjz7Dt2az335azxw3yieeuIxIoIByw/kkO8dWe80NY8ykwtP/AVTp7xFJgwcvCq7Dz+s3ml1Tg2yIlkjizmt2LXILh5xPJWbds6+z83ewEQqBU/vzNy/va9txpGbzuIHvz6k3iloIQxZpme9U9BC2Gb1AfVOQQvorWkz652CFsIDL42vdwpaCDuvM6AxJozU0HO73zX05+Mp1x9a99ex9E08N83MDVvtXxURd2fmhhFho7skSZKkRab02NaSEfFOU2b18ZLVXfuvJEmSJC0ypUduDgP+FRFPUbnb0yrA1yJiCcCZ85IkSdK8apDllhtZ6eLmOmA1YI3q/uNAZuY04PeFY0uSJEnqREq3pZ2RmdMy84HMfABoAa4tHFOSJElSJ1S6uHkpIk4GiIi+wN+AcwvHlCRJkppPdGnsrQEUzSIzfwS8GRGnAjcCv83MM0vGlCRJktQ5FZlzExG7tdq9E/gRcBeQEbFbZl5aIq4kSZKkzqvUggI7t9m/D+hWPZ6AxY0kSZI0P1wtraYixU1mfqHEdSVJkiSpPUXn3ETEiIhYqtV+34j4c8mYkiRJkjqn0ve5WTczx8/eycw3IuIjhWNKkiRJzadBViRrZKVfoS7VJaABiIilKV9QSZIkSeqEShcavwXuiIiLgQD2AH5eOKYkSZKkTqhocZOZZ0fEPcCW1UO7ZeZ/SsaUJEmSmpJtaTUVbxHLzEciYhzQAyAiVsrM50vHlSRJktS5lF4tbWhE/Bd4BrgVeBa4rmRMSZIkSZ1T6bGto4GNgScycxVgK2Bk4ZiSJElS84lo7K0BlC5u3s7M16ismtYlM28GNigcU5IkSVInVHrOzfiIWBL4J3BeRIwF3iocU5IkSVInVHrkZhdgMvBt4HrgKWDnwjElSZIkdUKll4KePUozKyKuAV7LzCwZU5IkSWpKLgVdU5FXKCI2johbIuLSiPhIRDwMPAyMiYjtSsSUJEmS1LmVGrk5EfgB0Af4B7B9Zo6MiDWAC6i0qEmSJEnSIlOquOmamTcCRMRPM3MkQGY+Fg2yTJwkSZLUofg5uqZSjXuzWj2e0uacc24kSZKkTigi/hwRY6vTVmYf+3VEPBYRD0bEZRGxVKtzh0fEkxHxeERsW+v6pYqb9SJiYkRMAtatPp69v06hmJIkSZIa21lA2zn4fwPWzsx1gSeAwwEiYk1gH2Ct6tecHBEtc7t4kba0zJxrUEmSJEnzqQlWS8vMf0bEym2O3dhqdySwR/XxLsCFmTkNeCYingQ2Au5o7/od/xWSJEmS1Cy+CFxXfbwC8EKrcy9Wj7XL4kaSJEnSQouI4RExqtU2fD6//ghgBnDeguZQ9CaekiRJkhaRBl8tLTNPA05bkK+NiAOAnYCtMnP2AmQvASu2etqg6rF2OXIjSZIkqW4iYjvgu8DQzJzc6tSVwD4R0T0iVgFWA+6a27UcuZEkSZL0voiIC4AtgH4R8SLwYyqro3UH/la9J+bIzPxqZj4SERcB/6HSrnZwZs6c2/UtbiRJkqQOIBq8LW1eZOa+czh8xlye/3Pg5/N6fdvSJEmSJDUFixtJkiRJTcHiRpIkSVJTcM6NJEmS1AE0w5yb0hy5kSRJktQULG4kSZIkNQXb0iRJkqSOwK60mhy5kSRJktQULG4kSZIkNQXb0iRJkqQOwNXSanPkRpIkSVJTsLiRJEmS1BRsS5MkSZI6ANvSanPkRpIkSVJTsLiRJEmS1BRsS5MkSZI6ANvSanPkRpIkSVJTsLiRJEmS1BQsbiRJkiQ1BefcSJIkSR2Ac25qc+RGkiRJUlOwuJEkSZLUFGxLkyRJkjoCu9JqcuRGkiRJUlOwuJEkSZLUFGxLkyRJkjoAV0urzZEbSZIkSU3B4kaSJElSU7AtTZIkSeoAbEurrWGLm9sv/0W9U9ACOuqGx+udghbC7msuX+8UpE6pW4sfWjqygb161jsFSdiWJkmSJKlJNOzIjSRJkqT/sS2tNkduJEmSJDUFixtJkiRJTcG2NEmSJKkDsC2tNkduJEmSJDUFixtJkiRJTcHiRpIkSVJTcM6NJEmS1BE45aamYiM3EbHKvByTJEmSpEWhZFvaX+dw7JKC8SRJkiR1You8LS0i1gDWAvpExG6tTvUGeizqeJIkSVJn4FLQtZWYc/NBYCdgKWDnVscnAV8pEE+SJEmSFn1xk5lXAFdExCaZeceivr4kSZIkzUnJOTe7RkTviOgWETdFxLiI2K9gPEmSJKlpRURDb42gZHGzTWZOpNKi9iwwBPi/gvEkSZIkdWIli5tu1f/uCFycmRMKxpIkSZLUyZW8iedVEfEYMAU4KCL6A1MLxpMkSZKaVqO0fjWyYiM3mfl9YFNgg8x8G3gL2KVUPEmSJEmdW8mRG4CBwNYR0fr+NmcXjilJkiSpEypW3ETEj4EtgDWBa4HtgX9hcSNJkiTNP7vSaiq5oMAewFbA6Mz8ArAe0KdgPEmSJEmdWMniZkpmzgJmRERvYCywYsF4kiRJkjqxknNuRkXEUsCfgHuAN4E7CsaTJEmS1IkVKW6isk7dMZk5Hjg1Iq4HemfmgyXiSZIkSc3OpaBrK1LcZGZGxLXAOtX9Z0vEkSRJkqTZSs65uTciNix4fUmSJEl6R8k5Nx8DhkXEc1Ru4BlUBnXWLRhTkiRJakq2pdVWsrjZtuC1JUmSJOldSral/Swzn2u9AT8rGE+SJElSJ1Zy5Gat1jsR0QKsXzCeJEmS1LRsS6ttkY/cRMThETEJWDciJla3SVRu4nnFoo4nSZIkSVCguMnMYzKzF/DrzOxd3Xpl5jKZefiijidJkiRJULAtLTMPj4gVgMGt42TmP0vFlCRJkpqVbWm1FStuIuJYYB/gP8DM6uEELG4kSZIkLXIlFxTYFfhgZk4rGEOSJEmSgLLFzdNAN8DiRpIkSVpYdqXVVLK4mQzcHxE30arAycxvFowpSZIkqZMqWdxcWd0kSZIkqbiSq6WNiIjFgNWrhx7PzLdLxZMkSZKamaul1VZytbQtgBHAs1Q6BFeMiM+7FLQkSZKkEkq2pf0W2CYzHweIiNWBC4D1C8aUJEmS1El1KXjtbrMLG4DMfILK6mmSJEmStMiVHLkZFRGnA+dW9/cDRhWMJ0mSJDUt59zUVrK4OQg4GJi99PM/gVMKxpMkSZLUiS3y4iYi+gP9M/M/wO+qGxGxFtAbGLeoY0qSJElSiTk3fwD6zeH40sDxBeJJkiRJTS8iGnprBCWKmyFzWu45M28D1i0QT5IkSZKKFDe95nLO1dIkSZIkFVGiuHkyInZoezAitgeeLhBPkiRJan7R4FsDKLFa2iHANRGxF3BP9dgGwCbATgXiSZIkSdKiH7nJzP8C6wC3AitXt1uBdas38pQkSZKkRa7IfW4ycxpwZolrS5IkSZ1Ro6xI1shKzLmRJEmSpPedxY0kSZKkplCkLS0iWoCzM3NYietLkiRJnY1tabUVGbnJzJnA4IhYrMT1JUmSJKmtIiM3VU8Dt0fElcBbsw9m5u8KxpQkSZLUSZUsbp6qbl2AXgXjSJIkSVK54iYzfwIQEUtW998sFUuSJElqds65qa3YamkRsXZE3Ac8AjwSEfdExFql4kmSJEnq3EouBX0acGhmDs7MwcBhwJ8KxpMkSZLUiZWcc7NEZt48eyczb4mIJQrGkyRJkpqWbWm1FV0tLSJ+BJxT3d+PygpqncprY0dz8q+PYsIbr0PAVjvsyva77stzTz3BGSccy9Qpk+k/YHkO/v7RLL7EkvVOV3MwdJ0BbPPB/iTJc69P4fhbn2GbNfozdO0BLN+nB8NG3MekaTPqnabm4NWxozn+mCMZ/8ZrBMGnd9qNnff47Dvnr7joHM465ThGXH4TveRV3R4AACAASURBVPv0rWOmquXCc0dw1eV/hQhWHbIaRxz1c7p3717vtNSOXx79I+741z9Zqu/SnHXhZQCccsJv+fdtt9CtWzcGrrAi3zvyaHr16l3nTNXW9OnT+Olhw5nx9tvMnDmDj31iK/b43IGMHf0Sf/jFEbw5cQKrrLYGX/vuT+narVu905Xeo2Rb2heB/sClwF+BftVjnUqXlq7sN/wQfnP6RRx9/JnceOUlvPjc05x23M/Y50sH86vTLmSDzbbk6ovPqX0xve+WXrwbO681gEMve4RvXPIIXSL4xKpL8+joN/nRNY8zZtK0eqeouejS0sIBB32bP5z1V3558giuu+IiXni28jeWV8eO5v6776D/gOXqnKVqGTd2DBdfeB5/Pvcizrv4CmbNmsXfb7i23mlpLrbbcRd+dfwp7zq2wUabcOYFl/Hn8y9lxZUGc/5Zp9cpO81Nt26L8cNfncKxp57PMaeczwOj7uC/jz7EBaefyPa7fZbjzrqMJZbszc3XX1HvVKU5KlbcZOYbmfnNzPxoZq6fmYdk5hul4jWqvsv0Y5XV1gCg5+JLsMJKK/P6q+N45cXn+dA6HwVg3Y9uxF3/unlul1EddekSLNa1C10Cunftwutvvc3Tr01m7JvT652aalh6mf6suvqHgMrv36CVVuG1V8cC8OeTfsvnDjwEcIi/I5g5cybTpk1lxowZTJ0ylX79l613SpqL9T66Ab1693nXsQ033pSuXSsNI2uuvR7jxo6pR2qqISLo0XNxAGbOmMHMmTOICB554G4+9olPAfCJT+/IqDturWeanVc0+NYASralqY1xo1/m2ScfZ8gaazFo5Q8w6t+3suFmWzDynzfx2jj/kW9Er09+m8sfHM0Zn12P6TNmcd+LE7n/pYn1TksLYOzol3nmycdZ/UNrc+e/bmHpfsuyypDV652W5kH/ZQew7/4HsOsOW9O9ew822mRTPrbJZvVOSwvh2qsuY8tPb1vvNNSOWTNncsTX92f0yy+yzc57suzyg1hiiV60tFQ+Ni7Tb1neqP6hSGo0JdvS1MrUKZM57qff43MHHcriSyzJgYceyd+uuoQffG1/pkyZTNeu9q02oiUWa+Fjg5fiKxc8yAHnPkCPbl3YYsgy9U5L82nKlMn88sjv8MWDD6OlpYW/nvdn9v3CV+udlubRxIkTuO2Wf3DJ1Tdy5Q03M2XKFK6/5qp6p6UFdM6fT6OlpYVPb7dTvVNRO7q0tHDMKedz4nnX8NTjj/DyC8/WOyVpnjVUcRMRwyNiVESMuvT8M+udziIzY8YMjvvp99jsU9ux0ccrQ7orrLQyPzj2RH5x8jlstuU2DBi4Qp2z1Jx8eIXejJk0jYlTZzAzkzueeYM1BrjwQ0cyY8bb/OrI77D51juwyeZbMfrlFxkz+iW+/eV9GL7Pjrw2biyHDR/GG6+/Wu9U1Y5Rd45k4AqD6Nt3abp268YWn9qahx68r95paQFcd/Xl3PGvW/nh0ce66lMHsMSSvVhzvfX576MP8dZbk5g5s7J4zmuvjqVvP1tD6yEiGnprBMXa0iKiP/AVYOXWcTKz3UUFMvM0KvfH4d7nJmap3N5PmclpvzuagSutzI57DHvn+IQ3XqdP36WZNWsWl53/Z7bacfc6Zqn2jHtzOh9cdkkWa+nC9JmzWG+F3vx33Fv1TkvzKDM56Vc/ZdDgVdhlr/0AGPyB1Rhx2U3vPGf4Pjvymz+e62ppDWzAcsvzyEMPMHXKFLr36MGou0ayxppr1zstzac77/gXF55zJsefeiY9evSsdzpqx8Txb9DStStLLNmL6dOm8tC9d7HzXp9jzfU24M7b/sGmW2zDbX+7hg022bzeqUpzVHLOzRXAbcDfgZkF4zS0xx95gNv+fi0rrjKE73+1sgTt3l88mNEvPc+NV14CwEYf34Ittt25nmmqHU+Me4vbn3md3+++JjNnJU+/NpkbHh3HTmsty27rLU/fxbtxwh5rcc8LEzjxn8/WO1218ejD93PL365h8AeG8O0v7wPAfl/+Outv/PE6Z6b5sdY667LlVttwwLA9aWlpYfUPfohddtuz3mlpLn76w+9y/z13M2H8ePbYaSu+8JWDOW/E6bw9fTqHfX04AGuuvS6HHX5knTNVW+Nff5VTfnMUs2bNImfNYuPNt+ajG3+CFQavwh9+cQQXn3UKg4d8kC223aXeqUpzFJllBkgi4v7M/PCCfn2zjNx0Rkfd8Hi9U9BCOHanNeudghbCgD7e+6Wjmj5jVr1T0EJ4+Y2p9U5BC2H9lXs3Rk9VDasedl1Dfz5+6rfb1/11LDnn5uqI2KHg9SVJkiTpHSWLm29RKXCmRsSk6uYaupIkSZKKKDbnJjN7lbq2JEmSJLVV9CaeETEUmL2cxi2ZeXXJeJIkSVKzapDVlhtasba0iDiWSmvaf6rbtyLimFLxJEmSJHVuJUdudgA+nJmzACJiBHAfcHjBmJIkSZI6qaJtacBSwOvVx30Kx5IkSZKaVtiXVlPJ4uYY4L6IuBkIKnNvvl8wniRJkqROrNicm8y8ANgYuBT4K7BJZv6lVDxJkiRJjS0i/hwRYyPi4VbHlo6Iv0XEf6v/7Vs9HhFxQkQ8GREPRsRHa12/5IICmwETM/NKoDfw3YgYXCqeJEmS1MwiGnubR2cB27U59n3gpsxcDbiJ/3V7bQ+sVt2GA6fUunjJm3ieAkyOiPWAQ4GngLMLxpMkSZLUwDLzn/xvTv5suwAjqo9HAJ9pdfzsrBgJLBURy8/t+iWLmxmZmdWkTsrMkwBv7ClJkiSptQGZ+Ur18WhgQPXxCsALrZ73YvVYu0ouKDApIg4H9gM2j4guQLeC8SRJkqSm1eirpUXEcCrtY7Odlpmnzc81MjMjIhc0h5LFzd7AZ4EvZeboiFgJ+HXBeJIkSZLqpFrIzFcxUzUmIpbPzFeqbWdjq8dfAlZs9bxB1WPtKrla2ujM/F1m3lbdfz4znXMjSZIkqbUrgc9XH38euKLV8c9VV03bGJjQqn1tjhb5yE1E/CszPx4Rk4DWQ0pBZaSp96KOKUmSJDW7Bu9KmycRcQGwBdAvIl4EfgwcC1wUEV8CngP2qj79WmAH4ElgMvCFWtdf5MVNZn68+l8XD5AkSZL0jszct51TW83huQkcPD/XL9KWFhEtEfFYiWtLkiRJ0pwUWVAgM2dGxOMRsVJmPl8ihiRJktSZdOnSBH1phZVcLa0v8EhE3AW8NftgZg4tGFOSJElSJ1WyuPlRwWtLkiRJ0rsUK24y89ZS15YkSZKktord5yYiNo6IuyPizYiYHhEzI2JiqXiSJElSM4to7K0RFCtugBOBfYH/Aj2BLwMnFYwnSZIkqRMrWdyQmU8CLZk5MzPPBLYrGU+SJElS51VyQYHJEbEYcH9E/Ap4hcLFlCRJktSsolF6vxpYyWJj/+r1v05lKegVgd0LxpMkSZLUiZVcLe256sjNysClwOOZOb1UPEmSJEmdW7HiJiJ2BE4FngICWCUiDszM60rFlCRJkpqVXWm1lZxz81tgy+qiAkTEqsA1gMWNJEmSpEWu5JybSbMLm6qngUkF40mSJEnqxEqO3IyKiGuBi4AE9gTujojdADLz0oKxJUmSpKbiamm1lSxuegBjgE9W98dRuZnnzlSKHYsbSZIkSYtMydXSvlDq2pIkSZLUVsnV0lYBvkFlKeh34mTm0FIxJUmSpGZlW1ptJdvSLgfOAK4CZhWMI0mSJElFi5upmXlCwetLkiRJ0jtKFjfHR8SPgRuBabMPZua9BWNKkiRJ6qRKFjfrAPsDn+J/bWlZ3ZckSZI0H5xyU1vJ4mZP4AOZOb1gDEmSJEkCoEvBaz8MLFXw+pIkSZL0jpIjN0sBj0XE3bx7zo1LQUuSJEnzyaWgaytZ3Py44LUlSZIk6V2KFTeZeWtEDAA2rB66KzPHloonSZIkqXMrNucmIvYC7qKysMBewJ0RsUepeJIkSVIzi2jsrRGUbEs7Athw9mhNRPQH/g5cUjCmJEmSpE6q5GppXdq0ob1WOJ4kSZKkTqzkyM31EXEDcEF1f2/guoLxJEmSpKblamm1lVxQ4P8iYjfg49VDp2XmZaXiSZIkSercFnlxExFDgAGZeXtmXgpcWj3+8YhYNTOfWtQxJUmSJKnEHJjfAxPncHxC9ZwkSZKk+VTv1dA6wmppJYqbAZn5UNuD1WMrF4gnSZIkSUWKm6Xmcq5ngXiSJEmSVGRBgVER8ZXM/FPrgxHxZeCeAvEkSZKkpudqabWVKG4OAS6LiGH8r5jZAFgM2LVAPEmSJEla9MVNZo4BNo2ILYG1q4evycx/LOpYkiRJkjRbyfvc3AzcXOr6kiRJktRaseJGkiRJ0qLjlJvaSqyWJkmSJEnvO4sbSZIkSU3BtjRJkiSpA3Ap6NocuZEkSZLUFCxuJEmSJDWFhm1L+9DA3vVOQQvozGEfqXcKWghTps+sdwpaCEt0b9h/1lXDEt3rnYEWRtcW/16s8uxKq83fREmSJElNweJGkiRJUlOwf0GSJEnqAFwtrTZHbiRJkiQ1BYsbSZIkSU3BtjRJkiSpA7ArrTZHbiRJkiQ1BYsbSZIkSU3B4kaSJElSU3DOjSRJktQBuBR0bY7cSJIkSWoKFjeSJEmSmoJtaZIkSVIHYFdabY7cSJIkSWoKFjeSJEmSmoJtaZIkSVIH4GpptTlyI0mSJKkpWNxIkiRJagq2pUmSJEkdgG1ptTlyI0mSJKkpWNxIkiRJagq2pUmSJEkdgF1ptTlyI0mSJKkpWNxIkiRJagoWN5IkSZKagnNuJEmSpA7ApaBrc+RGkiRJUlOwuJEkSZLUFGxLkyRJkjoAu9Jqc+RGkiRJUlOwuJEkSZLUFGxLkyRJkjoAV0urzZEbSZIkSU3B4kaSJElSU7AtTZIkSeoA7EqrzZEbSZIkSU3B4kaSJElSU7AtTZIkSeoAutiXVpMjN5IkSZKagsWNJEmSpKZgW5okSZLUAdiVVpsjN5IkSZKagsWNJEmSpKZgcSNJkiSpKTjnRpIkSeoAwkk3NTlyI0mSJKkpWNxIkiRJagq2pUmSJEkdQBe70mpy5EaSJElSU7C4kSRJktQUiralRcRmwP2Z+VZE7Ad8FDg+M58rGVeSJElqNq6WVlvpkZtTgMkRsR5wGPAUcHbhmJIkSZI6odLFzYzMTGAX4MTMPAnoVTimJEmSpE6o9GppkyLicGA/YPOI6AJ0KxxTkiRJajp2pdVWeuRmb2Aa8KXMHA0MAn5dOKYkSZKkTqjoyE21oPldq/3ncc6NJEmSpAKKFDcRMQnI9s5nZu8ScSVJkqRmFdiXVkuR4iYzewFExNHAK8A5QADDgOVLxJQkSZLUuZWeczM0M0/OzEmZOTEzT6GycpokSZIkLVKli5u3ImJYRLRERJeIGAa8VTimJEmSpE6o9FLQnwWOr24J3F49JkmSJGk+dHHKTU2lV0t7FtvQJEmSJL0PihY3EdEf+AqwcutYmfnFknElSZIkdT6l59xcAfQB/g5c02rrtH78w8PZcvNN2P0zO9U7FS2AC88dwbA9hjJsz1048vDvMG3atHqnpLn49c+OZPftP8mXPrvre85ddN4Ittp4XSaMf6MOmWl+3X7bPxm647bstN2nOeNPp9U7Hc0nf34d10Xnn8P+e+3CfnsO5aLzvVVhvUVEQ2/z+D18OyIeiYiHI+KCiOgREatExJ0R8WRE/CUiFlvQ16h0cbN4Zn4vMy/KzL/O3grHbGhDP7MbJ596er3T0AIYN3YMF194Hn8+9yLOu/gKZs2axd9vuLbeaWkutt1xKMccd8p7jo8dM5p77rqDZZdzZfqOYObMmfzi5z/l5FNP57Irr+H6a6/mqSefrHdamkf+/Dqup5/8L1ddfgl/GnEhZ11wKbffdisvvvBcvdNSBxYRKwDfBDbIzLWBFmAf4JfAcZk5BHgD+NKCxihd3FwdETsUjtGhrL/BhvTu06feaWgBzZw5k2nTpjJjxgymTplKv/7L1jslzcW6H9mA3r3f+/t28u9/xfCvf9uboXUQDz/0ICuuOJhBK65It8UWY7sdduSWm2+qd1qaR/78Oq5nn3maNddelx49e9K1a1c+8tENuPUff693Wur4ugI9I6IrsDiVe2J+Criken4E8JkFvXjp4uZbVAqcqRExMSImRcTEwjGlIvovO4B99z+AXXfYmqHbbMGSvZbkY5tsVu+0NJ9u/+fN9Ou/LKuu9sF6p6J5NHbMGJZbfrl39pcdMIAxY8bUMSPND39+HdcHhgzhgfvuYcL48UydMoU7br+NsWNG1zutTi2isbdaMvMl4DfA81SKmgnAPcD4zJxRfdqLwAoL+hoVLW4ys1dmdsnMHpnZu7rfu2RMqZSJEydw2y3/4JKrb+TKG25mypQpXH/NVfVOS/Nh6tQpnH/Wnzhg+MH1TkWSGt7Kq6zKfp//Et8++Csc9o0DWW31NejSpfTfxdWRRcTwiBjVahve5nxfKisprwIMBJYAtluUORR9h0bFfhHxo+r+ihGx0Vye/84LcsbpTjhUYxl150gGrjCIvn2Xpmu3bmzxqa156MH76p2W5sPLL77A6FdeYvh+e/LZz2zHuHFj+Orn9+b1116td2qai2UHDGD0K//7a/HYMWMYMGBAHTPS/PDn17Ht9Jnd+fN5F3PS6WfTq3dvVlxp5XqnpAaWmadl5gattrYf6LcGnsnMcZn5NnApsBmwVLVNDWAQ8NKC5lC6/D4Z2IT/3bjzTeCk9p7c+gX50peHt/c0qS4GLLc8jzz0AFOnTCEzGXXXSFZeZdV6p6X58IEhq/PX627l/Muv5/zLr6d//wGcOuIvLL1Mv3qnprlYa+11eP75Z3nxxRd4e/p0rr/2Gj655afqnZbmkT+/ju2N118DYPQrL3PrP/7Op7ffsc4ZdW5dIhp6mwfPAxtHxOJRWV5tK+A/wM3AHtXnfJ7KissLpOh9boCPZeZHI+I+gMx8Y2GWdmsG3/+/Qxl1912MH/8G22y1OQd97Rvsuvue9U5L82CtddZly6224YBhe9LS0sLqH/wQu+zmz66R/exH3+WBe0cxYfx49t55az7/la+xw9Dd6p2W5lPXrl05/IgjOWj4l5k1ayaf2XV3hgxZrd5paR758+vYjvi/Q5g4YTwtXbty6Pd/SK9ezi7QgsvMOyPiEuBeYAZwH3AalVvFXBgRP6seO2NBY0RmLopc53zxiDuBTYG7q0VOf+DGzPxIra+d8jblElNRk6fPqP0kNawp02fWOwUthH69utc7BalTmjTV//d1ZP2X7Nohls/c7Yx7Gvrz8aVfWr/ur2PpkZsTgMuAZSPi51SGm35UOKYkSZLUdObxPpmdWtHiJjPPi4h7qPTTBfCZzHy0ZExJkiRJnVPR4iYizsnM/YHH5nBMkiRJkhaZ0m1pa7XeiYgWYP3CMSVJkqSmE/al1VRkKeiIODwiJgHrRsTE6jYJGAtcWSKmJEmSpM6tSHGTmcdkZi/g15nZu7r1ysxlMvP7JWJKkiRJ6txK38TzydY7EdESET8uHFOSJElSJ1S6uNkqIq6NiOUjYm1gJNCrcExJkiSp6UQ09tYISi8F/dmI2Bt4CHgL+Gxm3l4ypiRJkqTOqejITUSsBnwL+CvwHLB/RCxeMqYkSZKkzqn0UtBXAQdn5k1RWbvuUOBu2iwRLUmSJGnuujRK71cDK13cbJSZEwEyM4HfRsRVhWNKkiRJ6oRK3efmuwCZOTEi9mxz+oASMSVJkiR1bqXm3OzT6vHhbc5tVyimJEmS1LSiwbdGUKq4iXYez2lfkiRJkhZaqeIm23k8p31JkiRJWmilFhRYLyImUhml6Vl9THW/R6GYkiRJUtMKV0urqUhxk5ktJa4rSZIkSe0pehNPSZIkSXq/lL7PjSRJkqRFoItdaTU5ciNJkiSpKVjcSJIkSWoKFjeSJEmSmoJzbiRJkqQOwKWga3PkRpIkSVJTsLiRJEmS1BRqFjcR8duIWOv9SEaSJEnSnEU09tYI5mXk5lHgtIi4MyK+GhF9SiclSZIkSfOrZnGTmadn5mbA54CVgQcj4vyI2LJ0cpIkSZI0r+ZptbSIaAHWqG6vAg8Ah0bEgZm5T8H8JEmSJOFqafOiZnETEccBOwH/AH6RmXdVT/0yIh4vmZwkSZIkzau5FjdRKQ9fBz6cmW/N4SkbFclKkiRJkubTXOfcZGYCe7VT2JCZE4pkJUmSJOldukRjb41gXlZLuzciNiyeiSRJkiQthHlZUOBjwLCIeA54CwgqgzrrFs1MkiRJkubDvBQ32xbPQpIkSf/P3n3HyVVXjR//nIQSSEhISAggJQEDCCgqqBSlCwhSFBARpPkjVkAQBX1AwIIoPoryiBiKoNJ784kFCL33pg+9JiGUAEICKef3x9yFScju7G5yd3buft55zStzvzN7v2funbkzZ77nfkfqkLOlNdaZ37l5ClgS2K64LFm0SZIkSVKv0TC5iYgDgTOBpYvLXyJi/7IDkyRJkqSu6ExZ2leAT7TNmBYRPwduBk4oMzBJkiRJ6orOJDcBzKpbnlW0SZIkSeohfgBvrDPJzR+BWyPi4mJ5R+DU8kKSJEmSpK5rmNxk5q8iYgLwyaJpn8y8u9SoJEmSJKmLGiY3ETEMeLK4tLUtnJkzygtLkiRJUr1+TgXdUMPZ0oC7gCnA/wGPFNefjIi7ImKdMoOTJEmSpM7qTHLzD2CbzByemUsBnwGuAL4BnFhmcJIkSZLUWZ1JbtbLzL+1LWTm34H1M/MWYNHSIpMkSZL0jojefekNOjNb2sSIOBQ4p1jeFZgcEf2B2aVFJkmSJEld0JmRmy8BywOXABcDKxRt/YEvlBeaJEmSJHVeZ6aCfhHYPyIGZuYbc938aDlhSZIkSaoXvaX2qxdrOHITERtExEPAw8Xy2hHhRAKSJEmSepXOlKX9GtgKeAkgM+8FNiozKEmSJEnqqs5MKEBmPjPXMNiscsKRJEmSNC9WpTXWmeTmmYjYAMiIWBg4kKJETZIkSZJ6i86UpX0N+CbwPuA54MPUfsBTkiRJknqNzozcrJaZu9c3RMSGwI3lhCRJkiRpbv2sS2uoMyM3J3SyTZIkSZKapt2Rm4hYH9gAGBERB9fdNJjaD3hKkiRJUq/RUVnaIsCg4j5L1LW/BuxcZlCSJEmS1FXtJjeZeS1wbUScnplP9WBMkiRJkubiKTeNdWZCgTcj4jhgTWBAW2NmblZaVJIkSZLURZ2ZUOBM4F/AaOBo4Eng9hJjkiRJkqQu68zIzVKZeWpEHFhXqmZyI0mSJPWgsC6toc4kNzOK/ydGxLbA88Cw8kKSJEmSpK7rTHLzk4gYAnyH2u/bDAYOKjUqtbTFFnam8Fa2+CKdOSyot3pt2ozGd1KvNHixhZsdgubDwEV875N6g4afYjLziuLqq8Cm5YYjSZIkaV46c7J8X9fuNoqI4yLiq/No/2pEHFtuWJIkSZLUNR0lgJsB4+bRfjLw2XLCkSRJkqTu6agsbdHMzLkbM3N2OFWDJEmS1KP8CN5YRyM30yJizNyNRdu08kKSJEmSpK7raOTmh8D/RsRPgDuLtnWB7wPfLjswSZIkSeqKdpObzPzfiNgR+C6wf9H8ALBTZt7fE8FJkiRJqulnVVpDHU4FnZkPAHv1UCySJEmS1G1Oly1JkiSpEkxuJEmSJFVCh2VpkiRJknoHz7lprN3kJiJOAN7zOzdtMvOAUiKSJEmSpG7oaOTmjh6LQpIkSZLmU0dTQZ/Rk4FIkiRJal+EdWmNNDznJiJGAIcCawAD2tozc7MS45IkSZKkLunMbGlnAg8Do4GjgSeB20uMSZIkSZK6rDOzpS2VmadGxIGZeS1wbUSY3EiSJEk9yNnSGutMcjOj+H9iRGwLPA8MKy8kSZIkSeq6ziQ3P4mIIcB3gBOAwcBBpUYlSZIkSV3UMLnJzCuKq68Cm5YbjiRJkqR5cbK0xjozW9ofmcePeWbmvqVEJEmSJEnd0JmytCvqrg8APkftvBtJkiRJ6jU6U5Z2Yf1yRJwN3FBaRJIkSZLeo591aQ115ndu5jYGWHpBByJJkiRJ86Mz59y8zpzn3EwCDi0tIkmSJEnqhs6UpS3RE4FIkiRJal93Sq76mobbKCKu6kybJEmSJDVTuyM3ETEAWBwYHhFDgbYzmAYD7+uB2CRJkiSp0zoqS/sq8G1gOeBO3k1uXgP+p+S4JEmSJKlL2k1uMvM3wG8iYv/MPKEHY5IkSZI0F2eCbqwz5yXNjogl2xYiYmhEfKPEmCRJkiSpyzqT3OyXmVPbFjLzFWC/8kKSJEmSpK5rOBU00D8iIjMTICL6A4uUG5YkSZKkev2sS2uoM8nNeODciPhDsfzVok2SJEmSeo3OJDeHAmOBrxfL/wBOLi0iSZIkSeqGhslNZs4GTiouRMSngBOAb5YbmiRJkqQ2VqU11pmRGyLiI8BuwBeAJ4CLygxKkiRJkrqq3eQmIlalltDsBrwInAtEZm7aQ7FJkiRJUqd1NHLzL+B64LOZ+ShARBzUI1FJkiRJmkM/y9Ia6uh3bj4PTASuiYiTI2JzwE0qSZIkqVdqN7nJzEsy84vA6sA1wLeBpSPi9xGxZU8FKEmSJEmd0ZnZ0t4AzgLOioihwC7Upof+e8mxSZIkSSr4I56NdVSW9h6Z+UpmjsvMzcsKSJIkSZK6o0vJjSRJkiT1ViY3kiRJkiqhUz/iKUmSJKm5POWmMUduJEmSJPWIiFgyIi6IiH9FxMMRsX5EDIuIf0TEI8X/Q7u7fpMbSZIkST3lN8D4zFwdWBt4GDgMuCozxwBXFcvdYlmaJEmS1AL6tXhZWkQMATYC9gbIzLeBtyNiB2CT4m5nABOo/fRMlzlyI0mSJKknjAamAH+MiLsj4pSIGAiMzMyJxX0mASO724HJjSRJkqT5FhFjI+KO63eXegAAIABJREFUusvYue6yEPBR4PeZ+RHgDeYqQcvMBLK7MViWJkmSJLWAoHfXpWXmOGBcB3d5Fng2M28tli+gltxMjohlM3NiRCwLvNDdGBy5kSRJklS6zJwEPBMRqxVNmwMPAZcBexVtewGXdrcPR24kSZIk9ZT9gTMjYhHgcWAfagMu50XEV4CngC90d+WlJzcRsRIwJjP/GRGLAQtl5utl9ytJkiRVSavPlgaQmfcA687jps0XxPpLLUuLiP2o1dL9oWhaHrikzD4lSZIk9U1ln3PzTWBD4DWAzHwEWLrkPiVJkiT1QWWXpb2VmW9H1MbQImIh5mNqN0mSJKmvqkJZWtnKHrm5NiJ+ACwWEZ8GzgcuL7lPSZIkSX1Q2cnNodR+hfR+4KvAX4HDS+5TkiRJUh9UWllaRPQHHszM1YGTy+pHkiRJkqDE5CYzZ0XEvyNixcx8uqx+JEmSpL6g7Tx2ta/sCQWGAg9GxG3AG22Nmbl9yf1KkiRJ6mPKTm6OKHn9LefIw7/PdddNYNiwpbjwkiuaHY66YNKkiRzxg0N56aWXiAh22vkLfGmPPZsdljrJ117r+dnRh3PTDdcxdOgw/nRe7SfSXnv1VY78/neYNPF5lll2OX507H+zxOAhTY5Ujdx4/XX8/NifMnvWbD630y58Zb+xzQ5JneR7n1pNqRMKZOa187qU2Wdvt/2On+fEk05pdhjqhv79+3PwIYdy0aVX8qczz+Hcc87ksccebXZY6iRfe63nM9vtyC9POGmOtr+cfgrrfHw9zr74r6zz8fX4y+mnNik6ddasWbM45qc/4sSTTuHiy65k/F+v4LFHPXa2Ct/7epd+0bsvvUGpyU1EvB4RrxWX6RExKyJeK7PP3m6ddT/G4CF+y9iKRoxYmg+ssSYAAwcOYvToVZgyeXKTo1Jn+dprPR/+6LoMnmtU5oZrr2Hrz+4AwNaf3YHrJ1zdjNDUBQ/cfx8rrLASy6+wAgsvsghbb7MtE665qtlhqZN871OrKbUsLTOXaLsetTOgdgDWK7NPqSc8/9yz/PtfD7PWh9ZudihSn/LKyy8xfPgIAJZaajivvPxSkyNSIy9Mnswyyy7zzvLSI0dy/333NTEidZfvfWoFZf/OzTuy5hJgq/buExFjI+KOiLjj1FPG9VRoUpe8+eYbHHLQARxy6PcZNGhQs8OR+qyIAGcOknqE7329Q9thr7deeoNSR24i4vN1i/2AdYHp7d0/M8cB4wCmzSDLjE3qjhkzZnDIQQfwmW23Y/Mttmx2OFKfM3TYUrz44hSGDx/Biy9OYejQYc0OSQ0sPXIkkyZOemf5hcmTGTlyZBMjUlf53qdWUvbIzXZ1l62A16mVpkktJzM5+sjDGb3yKnx5r32aHY7UJ2248SaMv+JSAMZfcSmf3HjTJkekRtZc64M8/fSTPPvsM8x4+23G//VKNt50s2aHpU7yvU+tJjLLGyCJiA0z88ZGbfNS1ZGbw757MHfcfhtTp77CsKWW4uvf2J/P7bRLs8NaoMp8TjXT3Xfdyb577c6YMasS/WrfC3zrgIP41EYbNzmyBauqPxDWF157AK9Pn9HsEBaYo37wXe6+83ZenTqVYUstxb5jv8GnNtmcH37/O7wwaSIjl12OH/3svyszUcTgxRZudgiluf66a/nFsccwe/YsdvzcTuz31a83O6QFbvZs3/ta2eKLtMab3/HXP9Grn2jf/tTopm/HspObuzLzo43a5qWqyU1fUNXkpq+oanLTV1Qpuelrqpzc9AVVTW76CpObBaM3JDelnHMTEesDGwAjIuLgupsGA/3L6FOSJElS31bWhAKLAIOK9S9R1/4asHNJfUqSJEmV1Vt+KLM3KyW5ycxrgWsj4vTMfKqMPiRJkiSpXqlTQQOnR8R7agMz02lSJEmSJC1QZSc3h9RdHwDsBMwsuU9JkiSpclpj2oPmKjW5ycw752q6MSJuK7NPSZIkSX1TqclNRNT/dHQ/YB2gGj9IIEmSJKlXKbssrX7kZibwBPCVkvuUJEmS1AeV9Ts3K2bm05k5uoz1S5IkSX1NPzzpppF+Ja33krYrEXFhSX1IkiRJ0jvKSm7q08qVS+pDkiRJkt5R1jk32c51SZIkSd3gVNCNlZXcrB0Rr1EbwVmsuE6xnJk5uKR+JUmSJPVRpSQ3mdm/jPVKkiRJUnvKngpakiRJ0gLQz7K0hsqaUECSJEmSepTJjSRJkqRKsCxNkiRJagH9nC6tIUduJEmSJFWCyY0kSZKkSrAsTZIkSWoBVqU15siNJEmSpEowuZEkSZJUCSY3kiRJkirBc24kSZKkFuBU0I05ciNJkiSpEkxuJEmSJFWCZWmSJElSC7AqrTFHbiRJkiRVgsmNJEmSpEqwLE2SJElqAY5KNOY2kiRJklQJJjeSJEmSKsGyNEmSJKkFhNOlNeTIjSRJkqRKMLmRJEmSVAmWpUmSJEktwKK0xhy5kSRJklQJJjeSJEmSKsGyNEmSJKkF9HO2tIYcuZEkSZJUCSY3kiRJkirB5EaSJElSJXjOjSRJktQCPOOmMUduJEmSJFWCyY0kSZKkSrAsTZIkSWoBzgTdmCM3kiRJkirB5EaSJElSJViWJkmSJLWAsC6tIUduJEmSJFWCyY0kSZKkSrAsTZIkSWoBjko05jaSJEmSVAkmN5IkSZIqwbI0SZIkqQU4W1pjjtxIkiRJqgSTG0mSJEmVYHIjSZIkqRI850aSJElqAZ5x05gjN5IkSZIqweRGkiRJUiVYliZJkiS1AKeCbqzXJjdvvj2z2SGom6a+MaPZIWg+DBzQaw8L6oQhiy3c7BDUTTNnZbND0HyY+ubbzQ5B82HxRRZtdghaQCxLkyRJklQJfkUrSZIktQBHJRpzG0mSJEmqBJMbSZIkSZVgWZokSZLUApwtrTFHbiRJkiRVgsmNJEmSpEqwLE2SJElqARalNebIjSRJkqRKMLmRJEmSVAkmN5IkSZIqwXNuJEmSpBbgTNCNOXIjSZIkqRJMbiRJkiRVgmVpkiRJUgvo52TQDTlyI0mSJKkSTG4kSZIkVYJlaZIkSVILcLa0xhy5kSRJklQJJjeSJEmSKsGyNEmSJKkFhLOlNeTIjSRJkqRKMLmRJEmSVAmWpUmSJEktwNnSGnPkRpIkSVIlmNxIkiRJqgTL0iRJkqQW0M/Z0hpy5EaSJElSJZjcSJIkSaoEkxtJkiRJlWByI0mSJLWAiN596fzjiP4RcXdEXFEsj46IWyPi0Yg4NyIW6e42MrmRJEmS1JMOBB6uW/458OvMfD/wCvCV7q7Y5EaSJElSj4iI5YFtgVOK5QA2Ay4o7nIGsGN31+9U0JIkSVIL6ErpVzNExFhgbF3TuMwcN9fdjge+ByxRLC8FTM3MmcXys8D7uhuDyY0kSZKk+VYkMnMnM++IiM8CL2TmnRGxSRkxmNxIkiRJ6gkbAttHxDbAAGAw8BtgyYhYqBi9WR54rrsdeM6NJEmS1AKil/9rJDO/n5nLZ+Yo4IvA1Zm5O3ANsHNxt72AS7u7jUxuJEmSJDXTocDBEfEotXNwTu3uiixLkyRJktSjMnMCMKG4/jjw8QWxXpMbSZIkqQX06+WzpfUGlqVJkiRJqgSTG0mSJEmVYFmaJEmS1AI6MyNZX+fIjSRJkqRKKHXkJiJGAPsBo+r7ysx9y+xXkiRJUt9TdlnapcD1wD+BWSX3JUmSJKkPKzu5WTwzDy25D0mSJKnywlNuGir7nJsrImKbkvuQJEmSpNKTmwOpJTjTI+L14vJayX1KkiRJ6oNKLUvLzCXKXL8kSZLUVzgVdGOl/85NRGwPbFQsTsjMK8ruU5IkSVLfU2pZWkQcS6007aHicmBE/KzMPiVJkiT1TWWP3GwDfDgzZwNExBnA3cD3S+5XkiRJqpR+VqU1VPaEAgBL1l0f0gP9SZIkSeqDyh65+Rlwd0RcAwS1c28OK7lPSZIkSX1Q2bOlnR0RE4CPFU2HZuakMvuUJEmSqsjZ0horpSwtIlYv/v8osCzwbHFZrmiTJEmSpAWqrJGbg4GxwH/P47YENiupX0mSJEl9VCnJTWaOLa5+JjOn198WEQPK6FOSJEmqsrAqraGyZ0u7qZNtkiRJkjRfShm5iYhlgPcBi0XER+Cds58GA4uX0ackSZKkvq2sc262AvYGlgd+Vdf+OvCDkvqUJEmSKsuqtMbKOufmDOCMiNgpMy8sow9JkiRJqlf279xcGBHbAmsCA+raf1Rmv73dOX85g8svuRAiWOX9Y/ivo37Koosu2uywNA+//tmR3HbTdSw5dBi//1MtT3/80X/zP7/8KdOmvcnIZZbjez88hsUHDmpypJqXY390ODffcB1Dhw7j9HMvAeCaf/6N08edyFNPPs5Jp5/N6mus1eQo1RlHHv59rrtuAsOGLcWFl1zR7HDUBW+99Rb77bMHb7/9NrNmzWLzLbbka988oNlhqQPH/eSH3HLjtSw5dBinnnXxHLedd+YZ/OGE/+ai8dcyZMmhTYpQal+pEwpExEnArsD+1EbSdgFWKrPP3m7KC5M5/5wzOe0v53Hm+Zcye/Zs/vm3vzY7LLVji89sz49/eeIcbb/5+dHs89UD+P0ZF7DBRptxwdlnNCk6NfKZz+7Icb89aY620au8nx//4njW/sg6TYpK3bH9jp/nxJNOaXYY6oZFFlmEk045nXMuuJSzzruYm268gfvvvafZYakDW227PT/79e/f0/7C5EncedvNLL3Msk2ISuqcsmdL2yAz9wReycyjgfWBVUvus9ebNWsWb701nZkzZzJ92nSGj1i62SGpHR/88DosMXjwHG3PPfM0a3249sH4I+uux40TrmpGaOqEtT+6LksMHjJH26jRq7DiqNFNikjdtc66H2PwkCGN76heJyJYfPGBAMycOZOZM2c6n20v96GPrMvgwe99vZ14/C8Y+62DCM/8aJp+Eb360huUndxMK/5/MyKWA2YAfTrdH7H0SHb78t58bpst2H7LTRi0xCA+sf6GzQ5LXbDS6JW5+fprALj+mn/w4guTmhyRJPVus2bNYrddduTTm2zIeutvwAc/tHazQ1IX3XjdNQwfsTSrjFmt2aFIHSo7ubkiIpYEjgPuAp4EzmrvzhExNiLuiIg7zjjt5JJDa47XXnuV6ydczQVX/J3L/nYN06ZNY/yVlzc7LHXBtw87misvOY8DvrIb06a9wUILL9zskCSpV+vfvz9nn38J//uPCTzwwH08+sj/NTskdcH06dM46/ST2XvsN5sditRQ2RMK/Li4emFEXAEMyMxXO7j/OGAcwEtvzMwyY2uWO269heXetzxDhw4DYJPNtuD+++5m6223a3Jk6qwVVhrNT39VO4/j2aef4vabr29yRJLUGpYYPJh1P/YJbrrxet4/ps9XqbeM5599hkkTn2PsHrsAMGXKZL6216787rSzGLbU8CZH17f0jsKv3q3sCQXui4gfRMQqmflWR4lNXzFymWV58P57mT5tGpnJHbfdwqjRqzQ7LHXB1FdeBmD27Nmc86eT2WaHXZockST1Xq+8/DKvv/YaANOnT+fWm29i1OiVmxyVumLl96/Khf97LWddMp6zLhnPiBEjOemMc01s1CuVOnIDbEdttrTzImI2cC5wXmY+XXK/vdaaH/wQm26+JXvvvgv9+/dn1dU+wA6f98Nxb/Xzow7jvrvv4LVXp/Llz2/JHvt+nWnT3uSKi84FYMONN+fT2+zQ5CjVnqP/67vcc+ftvDp1Kjtvuzn7jP0GSwwewm9/+TOmvvIyhx30Dd6/6ur88oRxzQ5VDRz23YO54/bbmDr1FbbcfCO+/o39+dxOHjtbwYsvTuHIww9j1qxZ5Oxki622ZqONN212WOrAT474HvfedQevTp3KrtttwV77fYNttv98s8OSOiUye6b6KyLGAEcAu2dm/0b3r2pZWl8w9Y0ZzQ5B82HggLK/81CZhizmOWCtatZs3/Za2dQ33252CJoPyw9dtCUqvm55bGqvPlCst8qSTd+OpX+KiYiVqI3e7ArMAr5Xdp+SJEmS+p5Sk5uIuBVYGDgf2CUzHy+zP0mSJEl9V9kjN3tm5r9L7kOSJEmqPH9AtbFSkpuI2CMz/wJsGxHbzn17Zv6qjH4lSZIk9V1ljdwMLP5fYh639eoToSRJkiS1plKSm8z8Q3H1n5l5Y/1tEbFhGX1KkiRJVRZWpTVU6o94Aid0sk2SJEmS5ktZ59ysD2wAjIiIg+tuGgw0/I0bSZIkSeqqss65WQQYVKy//ryb14CdS+pTkiRJUh9W1jk31wLXRsTpmflURAwq2v9TRn+SJElS1XnKTWNl/87NEhFxNzAMICJeBPbKzAdK7leSJElSH1P2hALjgIMzc6XMXAn4TtEmSZIkSQtU2SM3AzPzmraFzJwQEQM7+gNJkiRJ82BdWkNlJzePR8QRwJ+L5T2Ax0vuU5IkSVIfVHZZ2r7ACOCi4jKiaJMkSZKkBarUkZvMfAU4oMw+JEmSpL4grEtrqKwf8byso9szc/sy+pUkSZLUd5U1crM+8AxwNnArnv4kSZIkqWRlJTfLAJ8GdgO+BFwJnJ2ZD5bUnyRJklRp4XBBQ6VMKJCZszJzfGbuBawHPApMiIhvldGfJEmSJJU2oUBELApsS230ZhTwW+DisvqTJEmS1LeVNaHAn4C1gL8CR2fmA2X0I0mSJPUVVqU1VtbIzR7AG8CBwAHxboFgAJmZg0vqV5IkSVIfVUpyk5ll/zioJEmSJM3BJESSJElSJZQ2oYAkSZKkBciTbhpy5EaSJElSJZjcSJIkSaoEy9IkSZKkFhDWpTXkyI0kSZKkSjC5kSRJklQJlqVJkiRJLSCsSmvIkRtJkiRJlWByI0mSJKkSLEuTJEmSWoBVaY05ciNJkiSpEkxuJEmSJFWCZWmSJElSK7AurSFHbiRJkiRVgsmNJEmSpEqwLE2SJElqAWFdWkOO3EiSJEmqBJMbSZIkSZVgciNJkiSpEjznRpIkSWoB4Sk3DTlyI0mSJKkSTG4kSZIkVYJlaZIkSVILsCqtMUduJEmSJFWCyY0kSZKkSrAsTZIkSWoF1qU15MiNJEmSpEowuZEkSZJUCZalSZIkSS0grEtryJEbSZIkSZVgciNJkiSpEixLkyRJklpAWJXWkCM3kiRJkirB5EaSJElSJZjcSJIkSaoEz7mRJEmSWoCn3DTmyI0kSZKkSjC5kSRJklQJvbYsbdrbs5odgrppwCL9mx2C5sPr02Y2OwTNh8EDeu1hXQ30s96kpW153LXNDkHz4aFjtmx2CJ3jcaIhR24kSZIkVYLJjSRJkqRKsH5BkiRJagFhXVpDjtxIkiRJqgSTG0mSJEmVYFmaJEmS1ALCqrSGHLmRJEmSVAkmN5IkSZIqwbI0SZIkqQVYldaYIzeSJEmSKsHkRpIkSVIlWJYmSZIktQLr0hpy5EaSJElSJZjcSJIkSSpdRKwQEddExEMR8WBEHFi0D4uIf0TEI8X/Q7vbh8mNJEmSpJ4wE/hOZq4BrAd8MyLWAA4DrsrMMcBVxXK3eM6NJEmS1AKixU+6ycyJwMTi+usR8TDwPmAHYJPibmcAE4BDu9OHIzeSJEmS5ltEjI2IO+ouYzu47yjgI8CtwMgi8QGYBIzsbgyO3EiSJEmab5k5DhjX6H4RMQi4EPh2Zr4W8e6IVGZmRGR3YzC5kSRJklpAtHZVGgARsTC1xObMzLyoaJ4cEctm5sSIWBZ4obvrtyxNkiRJUumiNkRzKvBwZv6q7qbLgL2K63sBl3a3D0duJEmSJPWEDYEvA/dHxD1F2w+AY4HzIuIrwFPAF7rbgcmNJEmS1AJavSotM2+g/Yex+YLow7I0SZIkSZVgciNJkiSpEixLkyRJklpBq9el9QBHbiRJkiRVgsmNJEmSpEqwLE2SJElqAWFdWkOO3EiSJEmqBJMbSZIkSZVgciNJkiSpEjznRpIkSWoB4Sk3DTlyI0mSJKkSTG4kSZIkVYJlaZIkSVILsCqtMUduJEmSJFWCyY0kSZKkSrAsTZIkSWoF1qU15MiNJEmSpEowuZEkSZJUCZalSZIkSS0grEtryJEbSZIkSZVgciNJkiSpEixLkyRJklpAWJXWkCM3kiRJkirB5EaSJElSJZjcSJIkSaoEz7mRJEmSWoCn3DTmyI0kSZKkSjC5kSRJklQJlqVJkiRJLcCpoBtz5EaSJElSJZjcSJIkSaoEy9IkSZKklmBdWiOO3EiSJEmqBJMbSZIkSZVgWZokSZLUApwtrTFHbiRJkiRVQqnJTUSsEhGLFtc3iYgDImLJMvuUJEmS1DeVPXJzITArIt4PjANWAM4quU9JkiSpcqKXX3qDspOb2Zk5E/gccEJmfhdYtuQ+JUmSJPVBZSc3MyJiN2Av4IqibeGS+5QkSZLUB5U9W9o+wNeAn2bmExExGvhzyX1KkiRJleNsaY2Vmtxk5kMRcSiwYrH8BPDzMvvsjY77yQ+55cZrWXLoME496+I5bjvvzDP4wwn/zUXjr2XIkkObFKHa84sfH8EtN17HkkOHcdrZtX132kkncNP11xDRjyWHDuPQH/6E4SOWbnKkmpcpkyfxq2MOZ+rLLxMBW223Ezvssjuvv/YqPz/qe0ye+Dwjl12Ow44+jkFLDG52uGrHpEkTOeIHh/LSSy8REey08xf40h57NjssdZL7r/XsscGK7PKx5Qng/Nuf5c83Pc1qywziyB3XYPFF+vPcK9P53nn38cZbs5odqvQeZc+Wth1wDzC+WP5wRFxWZp+90Vbbbs/Pfv3797S/MHkSd952M0sv42lIvdVWn92BY4+fc9/tusc+nHLmRZz8lwtY/5Mb8+dTT2pSdGqkf//+fOUb3+H3f76IX570Z668+FyefvIxzj/zNNb+6Cc4+ezLWfujn+D8v5zW7FDVgf79+3PwIYdy0aVX8qczz+Hcc87ksccebXZY6iT3X2t5/8hB7PKx5dn1xFv43Ak3s8nqI1hx2GL86PNr8qu/PcKOv72Zqx6azL6fGtXsUKV5Kvucm6OAjwNTATLzHmDlkvvsdT70kXUZPHjIe9pPPP4XjP3WQUSvmV9Cc1t7Hvtu4KBB71yfPm2aY8S92LDhI3j/ah8AYPHFB7LCSivz0pQXuPWGCWy+9XYAbL71dtxywzXNDFMNjBixNB9YY00ABg4cxOjRqzBl8uQmR6XOcv+1llVGDOS+Z6YyfcZsZs1Obn/iFbZYcySjhi/OHU+8AsBNj77ElmuNbHKk0ryVPqFAZr46V9vskvtsCTdedw3DRyzNKmNWa3Yo6oZTf/9bdt1uC/75tyvZZ+w3mx2OOmHyxOd4/JF/sdoaH2TqKy8xbPgIAIYuNZypr7zU5OjUWc8/9yz//tfDrPWhtZsdirrB/df7PTL5P6wzaihDFluYAQv3Y6PVhrPskgN4dPIbbP6B2nFzq7WWYZkhA5ocad8Uvfxfb1B2cvNgRHwJ6B8RYyLiBOCm9u4cEWMj4o6IuOPM008pObTmmT59GmedfjJ7+6G4ZX3l6wdw7uX/ZIuttuWS889udjhqYNqbb3LMEYew3/7fZfGBg+a4LaI3zc6vjrz55hscctABHHLo9xk0aFDjP1Cv4v5rDY9PeYNTrn2SU/Zdh3F7r8O/Jr7OrNnJ4Rc9wBfXW4Hzv7keAxftz4xZflet3qns5GZ/YE3gLeBs4DXg2+3dOTPHZea6mbnu7nv/v5JDa57nn32GSROfY+weu/ClHbdmypTJfG2vXXn5pRebHZq6aPOtt+W6a/7Z7DDUgZkzZ3DMEd9hk09vwwYbbw7AkkOX4uUXpwDw8otTWHLosGaGqE6YMWMGhxx0AJ/Zdjs232LLZoejLnL/tZaL7nyOXX53C3uefDuvTZvBky++yRNT3mS/P97FLr+7hSvvncTTL01rdpjSPJWa3GTmm5n5X5n5MeATwM8zc3qZfbaCld+/Khf+77Wcdcl4zrpkPCNGjOSkM85l2FLDmx2aOuHZp5965/qN113NiiuNbmI06khm8pufH80KK43mc7t++Z32T2y4MVeNvxyAq8Zfzic+uUmTIlRnZCZHH3k4o1dehS/vtU+zw1EXuf9az7CBiwCw7JABbLHmSK68d+I7bRHwtU1X5rzbnmlmiH1X9PJLL1DqVNARcRa137mZBdwODI6I32TmcWX229v85Ijvce9dd/Dq1Knsut0W7LXfN9hm+883Oyx1wo8P/x733nU7r06dyhc+uzl7j/0mt954Pc88/ST9+gVLL7McBx16RLPDVDseuv8ervnbFYxaeQz77/sFAPbcb3923n1fjj3ye/z9yotZepnlOOzoXzQ5UnXknrvv4srLL2XMmFXZdecdAfjWAQfxqY02bnJk6gz3X+v5ze5rs+TiCzNjVvKTyx7m9ekz2WODFfnSeisA8I8HX+CiO59vcpTSvEVmlrfyiHsy88MRsTvwUeAw4M7M/FCjv332lbfKC0ylCmcPa2lv+rsFLe19Qz3JV2qGdY/6R7ND0Hx46JgtW+LDy6TXZvTqz8fLDF646dux1JEbYOGIWBjYEfifzJwREb16p0iSJEm9UdMzhxZQ9oQCJwFPAAOB6yJiJWqTCkiSJEnSAlXKyE1EHFy3+GsggT2AG4BNy+hTkiRJUt9W1sjNEnWXQcX/6wL/C+xcUp+SJElSZUX07ktvUMrITWYePa/2iBgG/BM4p4x+JUmSJPVdZZ9zM4fMfBnPhZIkSZJUgrJnS5tDRGwKvNKTfUqSJElVEI4RNFTWhAL3U5tEoN4w4HlgzzL6lCRJktS3lTVy89m5lhN4KTPfKKk/SZIkSX1cWRMKPFXGeiVJkiSpPT16zo0kSZKkbvKUm4Z6dLY0SZIkSSqLyY0kSZKkSrAsTZIkSWoBVqU15siNJEmSpEowuZEkSZJUCZalSZIkSS0grEtryJEbSZLIwmcCAAATtUlEQVQkSZVgciNJkiSpEixLkyRJklpAOF9aQ47cSJIkSaoEkxtJkiRJlWBZmiRJktQCnC2tMUduJEmSJFWCyY0kSZKkSjC5kSRJklQJJjeSJEmSKsHkRpIkSVIlmNxIkiRJqgSngpYkSZJagFNBN+bIjSRJkqRKMLmRJEmSVAmWpUmSJEktILAurRFHbiRJkiRVgsmNJEmSpEqwLE2SJElqAc6W1pgjN5IkSZIqweRGkiRJUiVYliZJkiS1AKvSGnPkRpIkSVIlmNxIkiRJqgTL0iRJkqRWYF1aQ47cSJIkSaoEkxtJkiRJlWByI0mSJKkSPOdGkiRJagHhSTcNOXIjSZIkqRJMbiRJkiRVgmVpkiRJUgsIq9IacuRGkiRJUiWY3EiSJEmqBMvSJEmSpBZgVVpjjtxIkiRJqgSTG0mSJEmVYFmaJEmS1AqsS2vIkRtJkiRJlWByI0mSJKkSLEuTJEmSWkBYl9aQIzeSJEmSKsHkRpIkSVIlmNxIkiRJ6hERsXVE/DsiHo2Iwxb0+j3nRpIkSWoB0eKn3EREf+B3wKeBZ4HbI+KyzHxoQfXhyI0kSZKknvBx4NHMfDwz3wbOAXZYkB302pGb5Ycu2uK5acciYmxmjmt2HOoe91/rct+1Nvdf66r6vnvomC2bHUKpqr7/WsWAhXr3dGkRMRYYW9c0bq7nzfuAZ+qWnwU+sSBjcOSmecY2vot6Mfdf63LftTb3X+ty37U2958aysxxmblu3aXHE2KTG0mSJEk94Tlghbrl5Yu2BcbkRpIkSVJPuB0YExGjI2IR4IvAZQuyg157zk0fYN1qa3P/tS73XWtz/7Uu911rc/9pvmXmzIj4FvA3oD9wWmY+uCD7iMxckOuTJEmSpKawLE2SJElSJZjcSJIkSaoEkxsgImZFxD0RcW9E3BURG3RzPadHxM4LOr75FRGbRMQVPdDPMhFxTkQ8FhF3RsRfI2LVsvvtjIi4qdkxzC0iVi220SPF8+68iBjZzXX9YAHGtWNErLGg1rcg1L1G2y6HNbj/Atsexfr+syDX19fNY3+O6uC+m3T3mKzOi4iMiL/ULS8UEVMavXfMvX8i4msRsWc3Y9g7IparWz6ltx2LqiYiRkXEA3O1HRURhzQrJml+OaFAzbTM/DBARGwF/AzYuCcDiIiFMnNmT/a5IEVEABcDZ2TmF4u2tYGRwP81Ma6FMnNmZjb1w9Hc+zciBgBXAgdn5uVF2ybACGByN7r4AXDMPPoNaufWze7CunYErgAe6kYcZXnnNdpJ89we6jW6sj83Af4DdPoLilY/njbJG8BaEbFYZk4DPk3npmfdhLr9k5knzUcMewMPAM8X6/p/87EuSX2UIzfvNRh4BSAiBkXEVcW36vdHxA5td4qIPSPivmK0589zryQiflyM5PSPiG0i4l/FaMZv274JK74d+XNE3Aj8ufgG5epivVdFxIrF/eYYEWr7Frn4xmxCRFxQrP/M4sMsEbF10XYX8PkSt1ebTYEZ9W9smXlvZl4fNcdFxAPFdty1Lv5rI+LSiHg8Io6NiN0j4rbifqvUPf6TIuKOiPi/iPhs0T4qIq4v9s87I27Feq+PiMsoPqDXbbNlI+K64tviByLiU0X7bkWfD0TEz9seQ0T8JyJ+WuznW2IeIysRMSwiLin22y0R8aGifY79O9effQm4uS2xKbbXhMx8ICIGRMQfi3jujohNi/XtHREXRcT4qI32/KJoPxZYrHhMZxbb5d8R8SdqHxRWiIjfF9vvwYg4ui72YyPioSL2XxbbcHvguGJ9q3T9qdAzImJI8ThXK5bPjoj95t4exW17FM+reyLiDxHRv2if5/6N2hSVNxf74Cd1fc7z+aP5FxFPRsTw4vq6xbFtFPA14KBim38qOj4evvO6j9qx97iIuL14fn+1CQ+r1fwV2La4vhtwdtsN8zrOtbN/joqIQyJi9Yi4re7vR0XE/cX1Hxb75YGIGBc1OwPrAmcW61qseA6sW/xNt4/R6p6IOKDu/eGcom1gRJxWHE/vjuJzUUSsWXeMvS8ixjQ3evVpmdnnL8As4B7gX8CrwDpF+0LA4OL6cOBRIIA1qY1GDC9uG1b8fzqwM3AccFJx3wHAM8Do4j5nA1cU148C7gQWK5YvB/Yqru8LXFK/3rp4/1P8v0kR7/LUEtWbgU/W9TmmiOG8tj5L3IYHAL9u57adgH9Qm/JvJPA0sGwR/9Ti+qLUviU8uvibA4Hj6x7/+OIxjgGeLR7j4sCA4j5jgDvqtssbbdt8rm32HeC/iuv9gSWA5YqYRhT7/Gpgx+I+CWxXXP8FcPg8Ht8JwJHF9c2Ae+a1f+f6m18BB7azvb5DbWpEgNWL2AZQ+1bzcWBIsfwUsEL94yuujwJmA+vVtQ2re8wTgA8BSwH/5t1ZE5ec1/OtN1x49zXadtm1aP908bz/IjB+7v1dXP8AtdfWwsXyicCeHe1fanPut93nmx09f5q9bVrxMtf+vLhoe5J3j6nrAhOK60cBh9T97RzPT+Y8Hr7zuqf2a+pt+3NR4A7qjgle3rNP/lMcFy4oji/3FNu07f2qo+Nc/f55Z7lYR9v+OLRufwyru/+f616DE4B1626bUDwX5usY7aXD/T4KeGCutqOAQ6iNoC1atLW9PxwD7NHWRu2z0MDi+bF70b4I83jf8+Klpy6O3NRMy8wPZ+bqwNbAnyJq5TzAMRFxH/BP4H3UPpxvBpyfmS8CZObLdes6AhiSmV/LzKT24fTxzHyiuP1s5nRZ1koAANYHziqu/5laotLIbZn5bNbKju6hdqBaHXgiMx8pYvhLRyvoAZ8Ezs7MWZk5GbgW+Fhx2+2ZOTEz3wIeA/5etN9P7bG0OS8zZ2fmI9Q+4K8OLAycXHwbeD5QX5t9W902r3c7sE9EHAV8MDNfL2KZkJlTslbKciawUXH/t6mVaEEtURnFe32SYmQmM68GloqIwcVt9fu3sz5Jsc8y81/Ukpi2c5euysxXM3M6tVGpldpZx1OZeUvd8heiNop3N7XkfA1qifF04NSI+DzwZhfj7Eltr9G2y7kAmfkPas+V3wHtlbBsDqwD3B4R9xTLKxe3tbd/N+Td12r9qNu8nj/quvr9+bkFuN761/2WwJ7FPr+VWjLvt8kdyMz7qL0GdqM2ilOvo+Nce84Ddi2u7wqcW1zfNCJuLY7dm1E7JnVkfo/Ral97vweSwH3URtL2ANrKPLcEDiteVxOoJcIrUvuS6QcRcSiwUjfe96QFxuRmLpl5M7VRmhHA7sX/62StPnwytRdyR24H1omIYZ3s8o1O3Gcmxb6KiH7UvhVp81bd9Vk07zyqB6l9gOyq+vhn1y3PZs7HMvcBOIGDqO2Ttal9u1e/Xea5XTPzOmpvis8Bp0fjE19nFAkidG/7trd/F8T26iied/qNiNHUvoXbPDM/RO1cnwHFh4SPU/um9rPURsdaSvF6+AC1xGxoe3ejdi5Y24fp1TLzqOK2jvbve970u/H8Uee9c5yj4+NsR8fD+tdbAPvX7ffRmfl31MhlwC957xdx3XEutS9WVgUyMx+J2vmGJ1IbffsgcDKN31c7Mr/H6L7uJd577BwGvEitRPF3wEepfTm0ELXX1U51r6sVM/PhzDyLWknzNOCvEbFZzz0EaU4mN3OJiNWplZu8RK3854XMnBG18x7aviW/GtglIpYq/qY+kRkPHAtcGRFLUCv7WTnenQ1oV9p3E7XyGqglVtcX15/k3Q/C21MbsejIv4BR8e75Ers1uP+CcDWwaESMbWsoarI/Re1x7FrUwI+g9uHwtnbW055dIqJf8ZhWprZdhwATi1GrL1Pbbx2KiJWAyZl5MnAKtYP2bcDGETE8audi7EZtdKmzrqe2v9omBXgxM19r8DdnARtERFt9OxGxUUSsNdf6VqX2rdi/G6xvRkS097wYTO1D36tFPfpninUPojbK+FdqieLaxf1fp1au1woOAh6mdg7TH+u2Qf32uArYOSKWhnfOHWhvxKvNjcz5WqT423k9f7RgPMm7x7md6trnfj7W36+j4+HfgK+3PQ+iNjvhwAUVbIWdRq08+P652ts7zrV7vMjMx6glHEfw7qhNWyLzYnEMqp9htL11ze8xWu3IzP8AE9uSkeLzzNbADdTKnq+hVlI4BBhE7XW1f1HdQkR8pPh/ZWpVKr8FLqVW4ig1hd9w1CxWDLFC7VuJvTJzVtRORr68GDq/g1rSQGY+GBE/Ba6NiFnUSn32bltZZp5fJDaXAdsA3wDGR8Qb1EZ22rM/tQ9o3wWmAPsU7ScDl0bEvdSSpw5HezJzepFkXBkRb1J7Uyr1w2pmZkR8Dji+GJaeTu1DyLepHSTXB+6l9m349zJzUpFIdtbT1N7gBgNfKx7jicCFxbfnDbdLYRPguxExg1qN+Z6ZOTFqUwtfQ23/X5mZl3YhtqOA04ryxTeBvRr9QWZOi9rECMdHxPHADGolAAdS+1bz98Xzbiawd2a+VbyXtGcccF9RevZfc/V1b0TcTe35+wy1D+5Qe05cWnyTGsDBRfs51Mr9DqD27epjjR5PD6h/jUJtf/+RWinaxzPz9Yi4DjgcOJK67ZGZu0fE4cDfi2/6Z1A7j+apDvo7EDireC7XPxc2Ya7nz4J5eAKOplYi+WNq5S5tLgcuKE5c3p/OHw9PoVaidFfxQWwKtZkA1YHMfBb47TxuOop5H+fm3j9zO5faeaiji/VPjYiTqU12Mok53xNPB06KiGnU3jPaYprfY7Q6tifwu4j4VbF8NLX33GsiYgi1bf7bYt/9GDie2vG1H/AEtZH/LwBfLo6Nk3C2SjVR24nEKlFEDMrM/xRvsL8DHsnMXzc7rlYREadTO6n1gmbHIkmSpN7LsrSesV/xrfOD1IZ2/9DkeCRJkqTKceRGkiRJUiU4ciNJkiSpEkxuJEmSJFWCyY0kSZKkSjC5kSRJklQJJjeSJEmSKsHkRpIkSVIlmNxIkiRJqgSTG0mSJEmVYHIjSZIkqRJMbiRJkiRVgsmNJEmSpEowuZEkSZJUCSY3kiRJkirB5EaSJElSJZjcSNJcImJWRNwTEQ9ExPkRsfh8rOv0iNi5uH5KRKzRwX03iYgNutHHkxExfB7tgyLiDxHxWETcGRETIuITDdb1g672L0lSb2FyI0nvNS0zP5yZawFvA1+rvzEiFurOSjPz/2XmQx3cZROgy8lNB04BXgbGZOY6wD7Ae5KguZSe3HR3+0mS1IjJjSR17Hrg/cWoyvURcRnwUET0j4jjIuL2iLgvIr4KEDX/ExH/joh/Aku3ragYOVm3uL51RNwVEfdGxFURMYpaEnVQMWr0qYgYEREXFn3cHhEbFn+7VET8PSIejIhTgJg76IhYBfgEcHhmzgbIzCcy88ri9kuK0ZwHI2Js0XYssFjR/5lF2x4RcVvR9oeI6F+0fyUi/q+47eSI+J+ifVREXF1sk6siYsWi/fSIOCkibgV+ERGPRMSI4rZ+EfFo27IkSd3lt2eS1I5ihOEzwPii6aPAWpn5RJEQvJqZH4uIRYEbI+LvwEeA1YA1gJHAQ8Bpc613BHAysFGxrmGZ+XJEnAT8JzN/WdzvLODXmXlDkST8DfgAcCRwQ2b+KCK2Bb4yj/DXBO7JzFntPLx9iz4XA26PiAsz87CI+FZmfrjo/wPArsCGmTkjIk4Edi+StiOK7fE6cDVwb7HeE4AzMvOMiNgX+C2wY3Hb8sAGmTkrIl4FdgeOB7YA7s3MKe3uDEmSOsHkRpLea7GIuKe4fj1wKrVysdsy84mifUvgQ23n0wBDgDHARsDZRVLxfERcPY/1rwdc17auzHy5nTi2ANaIeGdgZvD/b+d+XrSq4jiOvz9lkDQubCG4kGgj7Vwk0SxK05W1yQwSBxdGBC1m3Cq00E1E/0EyqPhjEVLTD4QcEXTAjIwg0VyoFEoLgxhCraDFaXHOHR8fx9QHQ3p6v1b3ufd8z/3eu3q+fO85SUbaPV5rsYeTzA7wjBNJ1rfjZS33X/vGrAWepRY/AAuBX4DngBNd3kkOActbzGiXG7Af+KBnvkM9xdZu4DNqcfMmsGeAZ5Ak6RYWN5J0uz+67kWn/bm/0XsKGC+lHOkb9/IDzOMR4PlSyp/z5HI354AVSR7t794kWU0tnEZLKb8nOQ48Ps8coXZhtvfFvzrP2Hsx9/5KKVeSXE2yhlosjQ04pyRJc1xzI0mDOQK8k+QxgCTLkzwBzABvtDU5S4GX5on9GngxydMt9sl2/hqwqGfcNDDe/UjSFVwzwKZ2bh2wuP8GpZRLwLfAzrRqqK2HeYXaZZpthc0z1E5S56/umYBjwOtJlnR5JnkKOA2sSrK4fbq3oSf+K2BjOx6jdr7uZBI4wK0dHUmSBmZxI0mDmaSup/kuyVngQ2o3fAq40K7tA071B7a1JW8DnyT5HvioXfoCWN9tKABMACvb4vwfuLlr205qcXSO+gnY5Tvk+BZ13c/FluNe6mdlXwILkpwH3qcWW51dwJkkB9vObu8C00nOAEeBpaWUn4H3gG+Ak8BPwG8tfhzY0sZvBrb+wzv8HBjBT9IkSQ9ISikPOwdJ0n9MkpFSyvXWuZkCdpdSpu5zjpXUDRNe+FeSlCT979i5kSQNYkfbdOEs8CPw6f0EJ9kGfAxsv9tYSZLulZ0bSZIkSUPBzo0kSZKkoWBxI0mSJGkoWNxIkiRJGgoWN5IkSZKGgsWNJEmSpKFgcSNJkiRpKPwNPM/pW7TC7bsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(15, 15))\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues',fmt=\"d\")\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Category')\n",
        "ax.set_ylabel('Actual Category ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([\"Background\",\"Comparison or Contrast\",\"Extends\",\"Future\",\"Motivation\",\"Uses\"])\n",
        "ax.yaxis.set_ticklabels([\"Background\",\"Comparison or Contrast\",\"Extends\",\"Future\",\"Motivation\",\"Uses\"])\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PT_Dvw0OZoX9"
      },
      "outputs": [],
      "source": [
        "#whether you can replace the sentence vector with max pooling of the sentence (as the sentence vector)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import os\n",
        "import numpy as np\n",
        "from allennlp.modules.elmo import Elmo\n",
        "\n",
        "class CitationClassifier1(nn.Module):\n",
        "    def __init__(self,hidden_dim,num_layers, label_size,dropout=0.5):\n",
        "        super(CitationClassifier1, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.hidden_dim = hidden_dim\n",
        "        options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
        "        weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
        "        self.elmo = Elmo(options_file, weight_file, 1, dropout=dropout, do_layer_norm=False)\n",
        "        # elmo output\n",
        "#         Dict with keys:\n",
        "#         ``'elmo_representations'``: ``List[torch.Tensor]``\n",
        "#             A ``num_output_representations`` list of ELMo representations for the input sequence.\n",
        "#             Each representation is shape ``(batch_size, timesteps, embedding_dim)``\n",
        "#         ``'mask'``:  ``torch.Tensor``\n",
        "#             Shape ``(batch_size, timesteps)`` long tensor with sequence mask.\n",
        "        self.lstm = nn.LSTM(1024, hidden_dim,num_layers, bidirectional=True, batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_dim*2, 120)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(120, label_size)\n",
        "        self.act=nn.Softmax()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for name, param in self.hidden2label.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "        for name, param in self.conv1.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "        \n",
        "    def forward(self, sentences,citseg_id):\n",
        "        # print(\"sentences.shape\")\n",
        "        # print(sentences.shape)\n",
        "        elmo_out = self.elmo(sentences)\n",
        "        x = elmo_out['elmo_representations'][0]\n",
        "        # print(\"x.shape\")\n",
        "        # print(x.shape)\n",
        "        packed_output, (hidden, cell) = self.lstm(x)\n",
        "        #packed_output=packed_output[torch.arange(packed_output.size(0)),citseg_id.long()]\n",
        "        # print(packed_output.shape)\n",
        "        packed_output=torch.max(packed_output, 1)\n",
        "        out = self.fc1(packed_output)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        pred1= self.act(out)\n",
        "        return pred1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfjWJLRHcfbb"
      },
      "outputs": [],
      "source": [
        "classifier = CitationClassifier(hidden_dim=args.hidden_dim,num_layers=args.num_layers,label_size=len(vectorizer.category_vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pt4H8Evlc6x5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624,
          "referenced_widgets": [
            "7a2944fc70c7445586315e14d161f5af",
            "d484426d9d864b7f8ee5bdccd2be1279",
            "02ef7e4645444d65951a2ad342e2219a",
            "25cd383cdb3847b5aed0e510b0b1dff4",
            "0997d7e015704d7bb6bf8749ca49070c",
            "f68af971101041acb9289981246f3149",
            "137edf3f912e455389298c9393db0c10",
            "9dbe121936564c5dbe4f47bd0df3cf68",
            "be677b7526694e72b88bda9b6c1614c9",
            "b4bfee8f366c415ea6b82f16bb92ba93",
            "0b85ee7452ba4386995415f33dbdaae0",
            "f5c10bd4a1de40dfbde5abd646de7785",
            "a8c479a0a68946138cc1e52f2222a4b2",
            "ccabb3ad0c424dd281841ad6e95a22fb",
            "9757ce26d27648aeab68125d05485147",
            "892b2273753449cab6378cd990b08c50",
            "7bbc4c9ab6c544208d80bb2b0c71e0bc",
            "6bc5a820f646421aa92a02a29cd9adf7",
            "92925a9e945a48a3af458186c076ee1f",
            "a0c1c17c4c684e35b9d73f55b445c207",
            "bd214b9d694846dcb319beba789b47d3",
            "52ade7f2cb8f42bc85519dfac69c87dd",
            "d563ce2d024d4421974db865ee039c46",
            "fed133f7d2214fa3b067392cd74cf271",
            "1e23daa2dbcf4ed68af81ea392f7b992",
            "da2e9be4517e41b6a44adc2000cb532f",
            "9b640299ff5d47299ad99252167ff56b",
            "aa3c5d44cc1c48e1b0fff2986b7e5de5",
            "8827812a95484d6493486c9bb9e72b67",
            "2be00107a21946b291861a131d2a480b",
            "833b35a6e13b495eb01df7de14b869c3",
            "1ff3dd3d001c40248850f88153d8a733",
            "92b3e60d6bf648f6ad84ecfacbc6cd7d"
          ]
        },
        "outputId": "7e3952be-1c44-4a80-d552-df2a878768c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a2944fc70c7445586315e14d161f5af",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "training routine:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5c10bd4a1de40dfbde5abd646de7785",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "split=train:   0%|          | 0/83 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d563ce2d024d4421974db865ee039c46",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "split=val:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\t val_loss=1.7656011535571172\t val_acc=15.80867850098619\n",
            "Epoch 1\t val_loss=1.7308490092937765\t val_acc=18.26429980276134\n",
            "Epoch 2\t val_loss=1.7307908626703117\t val_acc=21.459566074950686\n",
            "Epoch 3\t val_loss=1.652729726754702\t val_acc=43.777120315581854\n",
            "Epoch 4\t val_loss=1.6447756244586067\t val_acc=37.14003944773176\n",
            "Epoch 5\t val_loss=1.6416612542592561\t val_acc=40.621301775147934\n",
            "Epoch 6\t val_loss=1.6478588856183565\t val_acc=39.29980276134122\n",
            "Epoch 7\t val_loss=1.6480642006947441\t val_acc=33.106508875739635\n",
            "Epoch 8\t val_loss=1.6536490046061003\t val_acc=33.63905325443787\n",
            "Epoch 9\t val_loss=1.6494574088316698\t val_acc=39.81262327416174\n",
            "Epoch 10\t val_loss=1.632195559831766\t val_acc=41.44970414201184\n",
            "Epoch 11\t val_loss=1.648012853585757\t val_acc=38.826429980276124\n",
            "Epoch 12\t val_loss=1.6361273389596205\t val_acc=41.62721893491124\n",
            "Epoch 13\t val_loss=1.642610756250528\t val_acc=41.66666666666667\n",
            "Epoch 14\t val_loss=1.6355758401063771\t val_acc=40.51282051282052\n",
            "Epoch 15\t val_loss=1.6405723140789914\t val_acc=41.02564102564102\n",
            "Epoch 16\t val_loss=1.6512839931708114\t val_acc=40.98619329388559\n",
            "Epoch 17\t val_loss=1.64646589756012\t val_acc=40.36489151873767\n",
            "Epoch 18\t val_loss=1.639033033297612\t val_acc=41.90335305719921\n",
            "Epoch 19\t val_loss=1.6371282018147983\t val_acc=40.897435897435905\n"
          ]
        }
      ],
      "source": [
        "predictions=[]\n",
        "prediction=[]\n",
        "y=[]\n",
        "classifier = classifier.to(args.device)\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\n",
        "    \n",
        "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
        "optimizer = optim.RMSprop(classifier.parameters(), lr=args.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                           mode='min', factor=0.5,\n",
        "                                           patience=1)\n",
        "\n",
        "train_state = make_train_state(args)\n",
        "\n",
        "epoch_bar = tqdm_notebook(desc='training routine', \n",
        "                          total=args.num_epochs,\n",
        "                          position=0)\n",
        "\n",
        "dataset.set_split('train')\n",
        "train_bar = tqdm_notebook(desc='split=train',\n",
        "                          total=dataset.get_num_batches(args.batch_size), \n",
        "                          position=1, \n",
        "                          leave=True)\n",
        "dataset.set_split('val')\n",
        "val_bar = tqdm_notebook(desc='split=val',\n",
        "                        total=dataset.get_num_batches(args.batch_size), \n",
        "                        position=1, \n",
        "                        leave=True)\n",
        "\n",
        "try:\n",
        "    for epoch_index in range(args.num_epochs):\n",
        "        train_state['epoch_index'] = epoch_index\n",
        "\n",
        "        # Iterate over training dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
        "\n",
        "        dataset.set_split('train')\n",
        "        batch_generator = batchify(dataset,bsz=args.batch_size,device=args.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        classifier.train()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # the training routine is these 5 steps:\n",
        "\n",
        "            # --------------------------------------\n",
        "            # step 1. zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # step 2. compute the output\n",
        "            y_pred = classifier(batch_dict[0],batch_dict[2])\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = loss_func(y_pred, batch_dict[1])\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # step 4. use loss to produce gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # step 5. use optimizer to take gradient step\n",
        "            optimizer.step()\n",
        "            # -----------------------------------------\n",
        "            # compute the accuracy\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict[1])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            # update bar\n",
        "            train_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                                  epoch=epoch_index)\n",
        "            train_bar.update()\n",
        "\n",
        "        train_state['train_loss'].append(running_loss)\n",
        "        train_state['train_acc'].append(running_acc)\n",
        "\n",
        "        # Iterate over val dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
        "        dataset.set_split('val')\n",
        "        batch_generator = batchify(dataset,bsz=args.batch_size,device=args.device)\n",
        "        running_loss = 0.\n",
        "        running_acc = 0.\n",
        "        classifier.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "            # compute the output\n",
        "            y_pred =  classifier(batch_dict[0],batch_dict[2])\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = loss_func(y_pred, batch_dict[1])\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            _, predictions = y_pred.max(dim=1)\n",
        "            prediction.append(predictions)\n",
        "            y.append(batch_dict[1])\n",
        "\n",
        "            # compute the accuracy\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict[1])\n",
        "            \n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                            epoch=epoch_index)\n",
        "            val_bar.update()\n",
        "        print('Epoch {}\\t val_loss={}\\t val_acc={}'.format(epoch_index, running_loss, running_acc))\n",
        "\n",
        "        train_state['val_loss'].append(running_loss)\n",
        "        train_state['val_acc'].append(running_acc)\n",
        "        # print(\"Test loss: {};\".format(train_state['val_loss']))\n",
        "        # print(\"Test Accuracy: {}\".format(train_state['val_acc']))\n",
        "\n",
        "        train_state = update_train_state(args=args, model=classifier,\n",
        "                                         train_state=train_state)\n",
        "\n",
        "        scheduler.step(train_state['val_loss'][-1])\n",
        "\n",
        "        if train_state['stop_early']:\n",
        "            break\n",
        "\n",
        "        train_bar.n = 0\n",
        "        val_bar.n = 0\n",
        "        epoch_bar.update()\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Exiting loop\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyY67UOPc6x8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa752553-36b8-41c2-e65d-a2ba94318e2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ],
      "source": [
        "# compute the loss & accuracy on the test set using the best available model\n",
        "\n",
        "classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
        "\n",
        "classifier = classifier.to(args.device)\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\n",
        "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
        "\n",
        "dataset.set_split('val')\n",
        "batch_generator = batchify(dataset,bsz=args.batch_size,device=args.device)\n",
        "running_loss = 0.\n",
        "running_acc = 0.\n",
        "classifier.eval()\n",
        "predictions=[]\n",
        "prediction=[]\n",
        "y=[]\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "    # compute the output\n",
        "    y_pred =  classifier(batch_dict[0],batch_dict[2])\n",
        "\n",
        "    \n",
        "    # compute the loss\n",
        "    loss = loss_func(y_pred, batch_dict[1])\n",
        "    loss_t = loss.item()\n",
        "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "    _, predictions = y_pred.max(dim=1)\n",
        "    prediction.append(predictions)\n",
        "    y.append(batch_dict[1])\n",
        "    # compute the accuracy\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict[1])\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss\n",
        "train_state['test_acc'] = running_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YESvAVp4c6x-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "094e4b65-1d47-47f0-82c7-65e903907a46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 1, 0, 2, 1, 1, 0, 1, 1, 1, 4, 0, 0, 3, 0, 5, 0, 0, 0, 4, 0, 0, 0,\n",
              "        5, 0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ],
      "source": [
        "y.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRmsokPEc6yA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89b1d83a-68f5-4e3d-d01d-2d135981d333"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 5, 2, 0, 5, 1, 2, 0, 1, 1, 1, 0, 0, 1, 0, 5, 2, 0, 0, 0, 0, 0, 2,\n",
              "        5, 0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "prediction.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_Nu8WyJc6yA"
      },
      "outputs": [],
      "source": [
        "y_tensor = torch.stack(y)\n",
        "pred_tensor = torch.stack(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29vu485Qc6yB"
      },
      "outputs": [],
      "source": [
        "true_y=y_tensor.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgXvEWJZc6yB"
      },
      "outputs": [],
      "source": [
        "pred_y=pred_tensor.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdV9kaC1c6yB"
      },
      "outputs": [],
      "source": [
        "pred_y=pred_y.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tf6BpW6Qc6yB"
      },
      "outputs": [],
      "source": [
        "true_y=true_y.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yX-nI66Ic6yB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3604fb44-d77d-4152-a9b2-5a8808ec653d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "            Background       0.59      0.41      0.48       312\n",
            "Comparison or Contrast       0.37      0.35      0.36       184\n",
            "               Extends       0.06      0.28      0.10        32\n",
            "                Future       0.24      0.50      0.32        16\n",
            "            Motivation       0.00      0.00      0.00        56\n",
            "                  Uses       0.49      0.59      0.54       150\n",
            "\n",
            "              accuracy                           0.40       750\n",
            "             macro avg       0.29      0.35      0.30       750\n",
            "          weighted avg       0.44      0.40      0.41       750\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = [\"Background\",\"Comparison or Contrast\",\"Extends\",\"Future\",\"Motivation\",\"Uses\"]\n",
        "#target_names = [\"Future\",\"Neut\",\"PSim\",\"compare_contrast\",\"support\"]\n",
        "print(classification_report(true_y, pred_y, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGQpveddc6yC"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Generate the confusion matrix\n",
        "cf_matrix = confusion_matrix(true_y, pred_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOqBNIwnc6yD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "0d161989-3ebc-494b-9860-4f8a1975cf43"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(15, 15))\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues',fmt=\"d\")\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Category')\n",
        "ax.set_ylabel('Actual Category ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([\"Background\",\"Comparison or Contrast\",\"Extends\",\"Future\",\"Motivation\",\"Uses\"])\n",
        "ax.yaxis.set_ticklabels([\"Background\",\"Comparison or Contrast\",\"Extends\",\"Future\",\"Motivation\",\"Uses\"])\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqGqdjVj3jhx"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c76GgtlH3j7I"
      },
      "outputs": [],
      "source": [
        "# if you could append a global attentive sentence vector to citeseg and send the new feature vector for classsification\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import os\n",
        "import numpy as np\n",
        "from allennlp.modules.elmo import Elmo\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "        \n",
        "        self.supports_masking = True\n",
        "\n",
        "        self.bias = bias\n",
        "        self.feature_dim = feature_dim\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "        \n",
        "        weight = torch.zeros(feature_dim, 1)\n",
        "        nn.init.kaiming_uniform_(weight)\n",
        "        self.weight = nn.Parameter(weight)\n",
        "        \n",
        "        if bias:\n",
        "            self.b = nn.Parameter(torch.zeros(step_dim))\n",
        "        \n",
        "    def forward(self, x, mask=None):\n",
        "        # print(\"x.shape\")\n",
        "        # print(x.shape)\n",
        "        feature_dim = self.feature_dim \n",
        "        # print(feature_dim)\n",
        "        step_dim = self.step_dim\n",
        "        # print(step_dim)\n",
        "\n",
        "        eij = torch.mm(x.contiguous().view(-1, feature_dim), self.weight).view(-1, step_dim)\n",
        "        # print(\"eij.shape\")\n",
        "        # print(eij.shape)\n",
        "        \n",
        "        if self.bias:\n",
        "            eij = eij + self.b\n",
        "            \n",
        "        eij = torch.tanh(eij)\n",
        "        a = torch.exp(eij)\n",
        "        \n",
        "        if mask is not None:\n",
        "            a = a * mask\n",
        "\n",
        "        a = a / (torch.sum(a, 1, keepdim=True) + 1e-10)\n",
        "\n",
        "        weighted_input = x * torch.unsqueeze(a, -1)\n",
        "        return torch.sum(weighted_input, 1)\n",
        "\n",
        "class CitationClassifier(nn.Module):\n",
        "    def __init__(self,hidden_dim,num_layers, label_size,dropout=0.5):\n",
        "        super(CitationClassifier, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.hidden_dim = hidden_dim\n",
        "        options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
        "        weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
        "        self.elmo = Elmo(options_file, weight_file, 1, dropout=dropout, do_layer_norm=False)\n",
        "        # elmo output\n",
        "#         Dict with keys:\n",
        "#         ``'elmo_representations'``: ``List[torch.Tensor]``\n",
        "#             A ``num_output_representations`` list of ELMo representations for the input sequence.\n",
        "#             Each representation is shape ``(batch_size, timesteps, embedding_dim)``\n",
        "#         ``'mask'``:  ``torch.Tensor``\n",
        "#             Shape ``(batch_size, timesteps)`` long tensor with sequence mask.\n",
        "        self.lstm = nn.LSTM(1024, hidden_dim,num_layers, bidirectional=True, batch_first=True)\n",
        "        # self.attention_layer = Attention(hidden_dim*2)\n",
        "        self.fc1 = nn.Linear(hidden_dim*2*2, 120)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(120, label_size)\n",
        "        self.act=nn.Softmax()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for name, param in self.hidden2label.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "        for name, param in self.conv1.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "        \n",
        "    def forward(self, sentences,citseg_id):\n",
        "        # print(\"sentences.shape\")\n",
        "        # print(sentences.shape)\n",
        "        elmo_out = self.elmo(sentences)\n",
        "        x = elmo_out['elmo_representations'][0]\n",
        "        # print(elmo_out['elmo_representations'][0].shape)\n",
        "        # print(\"x.shape\")\n",
        "        # print(x.shape)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.lstm(x)\n",
        "        l=packed_output.shape[1]\n",
        "        l=torch.tensor(l)\n",
        "        l=l.cuda()\n",
        "        h=torch.tensor(64)\n",
        "        h=h.cuda()\n",
        "        self.attention_layer = Attention(h,l).cuda()\n",
        "        packed_output1 = self.attention_layer(packed_output)\n",
        "        # print(packed_output.shape)\n",
        "        packed_output2=packed_output[torch.arange(packed_output.size(0)),citseg_id.long()]\n",
        "        # print(packed_output.shape)\n",
        "        att_citeseg=torch.cat([packed_output1,packed_output2],dim=1)\n",
        "        out = self.fc1(att_citeseg)\n",
        "        # print(out.shape)\n",
        "        out = self.relu(out)\n",
        "        # print(out.shape)\n",
        "        out = self.fc2(out)\n",
        "        # print(out.shape)\n",
        "        pred1= self.act(out)\n",
        "        # print(pred1.shape)\n",
        "        return pred1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQQ5tCje3j7K"
      },
      "outputs": [],
      "source": [
        "classifier = CitationClassifier(hidden_dim=args.hidden_dim,num_layers=args.num_layers,label_size=len(vectorizer.category_vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kG-kMZKX3j7L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624,
          "referenced_widgets": [
            "7b63d666fb6147d887335b13f52345db",
            "b26dea4d08564f24b50be9dae108809d",
            "72c60c6939d04a37acf3a2bd12ddfb40",
            "6ab27d256e3d4a328ee1b135ecfefab0",
            "ab749ddfc9a2451894704d8769049dca",
            "c509e6e5c8dd4f14b76a72c9461ac9ae",
            "4276572a48e84c4380f1e7f388dbf88f",
            "e1fe24e21e424ffd85d9cd6c3dd3742c",
            "0d0a323417da4569880d84da1fea0df2",
            "694dfa2483e4489cb8e241dd6135bb63",
            "9cde22f5a322428f8984fed0895491f0",
            "94f92120fd3d4487961d8aac0cf7856b",
            "4fc95c17581b4c78a56d2d57a19f1c80",
            "e6a53e8508314967b2f2b192c64705ad",
            "c1bf16e640914f9ea0778d6b8af5f4c7",
            "56674f6dfd0d4177b3c64b323d92b2b0",
            "b11a56ccc05e4427879d3f967cbb25ba",
            "b46ed027ff6e43e58a4bc9b215503d3d",
            "3162bf2c2f8746cca5bc622707962739",
            "5d571d7c953e432dbf0d50ff5e9792a6",
            "46ba01e94e874dd1a350ff3d03f507b9",
            "36274a1a035e400facb605cb21ee4615",
            "1791eeeb500546039d7cbf14510013ac",
            "128b535e417d452cb7c7887a450928be",
            "44f118c80b314db290a753d8c21a9c5e",
            "6a1650492045488d9f074b7e9c42d5ec",
            "39ee37bffbc744a59c8c333d678b9ebf",
            "1ca848823078419f8846abfc6d504edd",
            "f760deaa3aad44aeaec39cc59414e966",
            "4473d1060e794e20bdcf8d7de358dc33",
            "88dc8eb73b8d4803b130cf1d9055e46f",
            "3e5c27a5e3fc4979bc56768c9e524f84",
            "d0a693536792496db6815e5f68ebd810"
          ]
        },
        "outputId": "c9dd2496-8186-4223-a3fd-ed2aebd9937d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b63d666fb6147d887335b13f52345db",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "training routine:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94f92120fd3d4487961d8aac0cf7856b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "split=train:   0%|          | 0/83 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1791eeeb500546039d7cbf14510013ac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "split=val:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:115: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\t val_loss=1.7154275545707114\t val_acc=45.700197238658774\n",
            "Epoch 1\t val_loss=1.6937492168866672\t val_acc=26.93293885601578\n",
            "Epoch 2\t val_loss=1.6662969039036677\t val_acc=36.86390532544379\n",
            "Epoch 3\t val_loss=1.668403533788828\t val_acc=33.530571992110445\n",
            "Epoch 4\t val_loss=1.5932454420970037\t val_acc=43.60946745562131\n",
            "Epoch 5\t val_loss=1.5929492299373333\t val_acc=40.769230769230774\n",
            "Epoch 6\t val_loss=1.5778541473241956\t val_acc=41.15384615384615\n",
            "Epoch 7\t val_loss=1.5661213031181922\t val_acc=44.487179487179496\n",
            "Epoch 8\t val_loss=1.5514065210635843\t val_acc=45.729783037475336\n",
            "Epoch 9\t val_loss=1.515338393358084\t val_acc=52.366863905325445\n",
            "Epoch 10\t val_loss=1.5495943014438334\t val_acc=42.978303747534504\n",
            "Epoch 11\t val_loss=1.5620124431756828\t val_acc=48.65877712031557\n",
            "Epoch 12\t val_loss=1.5171842345824609\t val_acc=52.15976331360946\n",
            "Epoch 13\t val_loss=1.5059353204873893\t val_acc=53.22485207100591\n",
            "Epoch 14\t val_loss=1.5110781834675717\t val_acc=53.905325443786985\n",
            "Epoch 15\t val_loss=1.4900900996648345\t val_acc=52.731755424063124\n",
            "Epoch 16\t val_loss=1.5513857144575853\t val_acc=45.532544378698226\n",
            "Epoch 17\t val_loss=1.4876368504304152\t val_acc=52.98816568047338\n",
            "Epoch 18\t val_loss=1.465982125355647\t val_acc=55.82840236686391\n",
            "Epoch 19\t val_loss=1.4794715184431808\t val_acc=55.71992110453648\n"
          ]
        }
      ],
      "source": [
        "predictions=[]\n",
        "prediction=[]\n",
        "y=[]\n",
        "classifier = classifier.to(args.device)\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\n",
        "    \n",
        "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
        "optimizer = optim.RMSprop(classifier.parameters(), lr=args.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                           mode='min', factor=0.5,\n",
        "                                           patience=1)\n",
        "\n",
        "train_state = make_train_state(args)\n",
        "\n",
        "epoch_bar = tqdm_notebook(desc='training routine', \n",
        "                          total=args.num_epochs,\n",
        "                          position=0)\n",
        "\n",
        "dataset.set_split('train')\n",
        "train_bar = tqdm_notebook(desc='split=train',\n",
        "                          total=dataset.get_num_batches(args.batch_size), \n",
        "                          position=1, \n",
        "                          leave=True)\n",
        "dataset.set_split('val')\n",
        "val_bar = tqdm_notebook(desc='split=val',\n",
        "                        total=dataset.get_num_batches(args.batch_size), \n",
        "                        position=1, \n",
        "                        leave=True)\n",
        "\n",
        "try:\n",
        "    for epoch_index in range(args.num_epochs):\n",
        "        train_state['epoch_index'] = epoch_index\n",
        "\n",
        "        # Iterate over training dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
        "\n",
        "        dataset.set_split('train')\n",
        "        batch_generator = batchify(dataset,bsz=args.batch_size,device=args.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        classifier.train()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # the training routine is these 5 steps:\n",
        "\n",
        "            # --------------------------------------\n",
        "            # step 1. zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # step 2. compute the output\n",
        "            y_pred = classifier(batch_dict[0],batch_dict[2])\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = loss_func(y_pred, batch_dict[1])\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # step 4. use loss to produce gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # step 5. use optimizer to take gradient step\n",
        "            optimizer.step()\n",
        "            # -----------------------------------------\n",
        "            # compute the accuracy\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict[1])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            # update bar\n",
        "            train_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                                  epoch=epoch_index)\n",
        "            train_bar.update()\n",
        "\n",
        "        train_state['train_loss'].append(running_loss)\n",
        "        train_state['train_acc'].append(running_acc)\n",
        "\n",
        "        # Iterate over val dataset\n",
        "\n",
        "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
        "        dataset.set_split('val')\n",
        "        batch_generator = batchify(dataset,bsz=args.batch_size,device=args.device)\n",
        "        running_loss = 0.\n",
        "        running_acc = 0.\n",
        "        classifier.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "            # compute the output\n",
        "            y_pred =  classifier(batch_dict[0],batch_dict[2])\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = loss_func(y_pred, batch_dict[1])\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            _, predictions = y_pred.max(dim=1)\n",
        "            prediction.append(predictions)\n",
        "            y.append(batch_dict[1])\n",
        "\n",
        "            # compute the accuracy\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict[1])\n",
        "            \n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                            epoch=epoch_index)\n",
        "            val_bar.update()\n",
        "        print('Epoch {}\\t val_loss={}\\t val_acc={}'.format(epoch_index, running_loss, running_acc))\n",
        "\n",
        "        train_state['val_loss'].append(running_loss)\n",
        "        train_state['val_acc'].append(running_acc)\n",
        "        # print(\"Test loss: {};\".format(train_state['val_loss']))\n",
        "        # print(\"Test Accuracy: {}\".format(train_state['val_acc']))\n",
        "\n",
        "        train_state = update_train_state(args=args, model=classifier,\n",
        "                                         train_state=train_state)\n",
        "\n",
        "        scheduler.step(train_state['val_loss'][-1])\n",
        "\n",
        "        if train_state['stop_early']:\n",
        "            break\n",
        "\n",
        "        train_bar.n = 0\n",
        "        val_bar.n = 0\n",
        "        epoch_bar.update()\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Exiting loop\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFRIrLXd3j7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "299066c4-2dac-4421-bf9d-a2f5262a9595"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:115: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ],
      "source": [
        "# compute the loss & accuracy on the test set using the best available model\n",
        "\n",
        "classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
        "\n",
        "classifier = classifier.to(args.device)\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\n",
        "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
        "\n",
        "dataset.set_split('val')\n",
        "batch_generator = batchify(dataset,bsz=args.batch_size,device=args.device)\n",
        "running_loss = 0.\n",
        "running_acc = 0.\n",
        "classifier.eval()\n",
        "predictions=[]\n",
        "prediction=[]\n",
        "y=[]\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "    # compute the output\n",
        "    y_pred =  classifier(batch_dict[0],batch_dict[2])\n",
        "\n",
        "    \n",
        "    # compute the loss\n",
        "    loss = loss_func(y_pred, batch_dict[1])\n",
        "    loss_t = loss.item()\n",
        "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "    _, predictions = y_pred.max(dim=1)\n",
        "    prediction.append(predictions)\n",
        "    y.append(batch_dict[1])\n",
        "    # compute the accuracy\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict[1])\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss\n",
        "train_state['test_acc'] = running_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPGkqkcT3j7Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10308df3-f9af-4330-c5e5-4ef0102630ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 1, 0, 2, 1, 1, 0, 1, 1, 1, 4, 0, 0, 3, 0, 5, 0, 0, 0, 4, 0, 0, 0,\n",
              "        5, 0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ],
      "source": [
        "y.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3ZCp9tF3j7Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52bb3257-3096-45a7-e19a-1edd7927c6c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 0, 5, 0, 2, 1, 0, 0, 0, 1, 1, 1, 0, 0, 3, 4, 5, 0, 0, 0, 0, 0, 0, 2,\n",
              "        5, 1], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "prediction.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgbqDatQ3j7R"
      },
      "outputs": [],
      "source": [
        "y_tensor = torch.stack(y)\n",
        "pred_tensor = torch.stack(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3npEj60z3j7S"
      },
      "outputs": [],
      "source": [
        "true_y=y_tensor.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfwJqVSy3j7T"
      },
      "outputs": [],
      "source": [
        "pred_y=pred_tensor.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOfpqtLt3j7T"
      },
      "outputs": [],
      "source": [
        "pred_y=pred_y.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVmCEvto3j7U"
      },
      "outputs": [],
      "source": [
        "true_y=true_y.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NQ68NWx3j7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bb6c0bf-4ef8-46a3-aaf2-b657e883ec5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "            Background       0.67      0.54      0.60       312\n",
            "Comparison or Contrast       0.56      0.50      0.53       184\n",
            "               Extends       0.15      0.28      0.20        32\n",
            "                Future       0.44      0.69      0.54        16\n",
            "            Motivation       0.30      0.48      0.37        56\n",
            "                  Uses       0.63      0.69      0.66       150\n",
            "\n",
            "              accuracy                           0.55       750\n",
            "             macro avg       0.46      0.53      0.48       750\n",
            "          weighted avg       0.58      0.55      0.56       750\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = [\"Background\",\"Comparison or Contrast\",\"Extends\",\"Future\",\"Motivation\",\"Uses\"]\n",
        "#target_names = [\"Future\",\"Neut\",\"PSim\",\"compare_contrast\",\"support\"]\n",
        "print(classification_report(true_y, pred_y, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLLlUv_Y3j7U"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Generate the confusion matrix\n",
        "cf_matrix = confusion_matrix(true_y, pred_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GKqapxq3j7V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "0982d730-4b0d-439b-ddb3-2d059163786d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(15, 15))\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues',fmt=\"d\")\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Category')\n",
        "ax.set_ylabel('Actual Category ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([\"Background\",\"Comparison or Contrast\",\"Extends\",\"Future\",\"Motivation\",\"Uses\"])\n",
        "ax.yaxis.set_ticklabels([\"Background\",\"Comparison or Contrast\",\"Extends\",\"Future\",\"Motivation\",\"Uses\"])\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyaIyFgUCkp-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGp44o0rQSxA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "6 functions BILSTM ELMO final citation context.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03548bea8145471ca8238d9f6375eaa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_012b46362ca74fb589238f178b6cc7b2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2ee857958b40428d893f4b3cf0c92f8c",
              "IPY_MODEL_b1fee2be454f45c9bcad277b5cf9aa18",
              "IPY_MODEL_c01ae07344844aa6bd239fee264d0c01"
            ]
          }
        },
        "012b46362ca74fb589238f178b6cc7b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ee857958b40428d893f4b3cf0c92f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_739f1789866e4a9989d057ac55ca0b94",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "training routine: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_82439f1d3d9e4a7f941c508a95219eb6"
          }
        },
        "b1fee2be454f45c9bcad277b5cf9aa18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_05ced7f11e8349a886b2a16ce9c18388",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 20,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 20,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e60d8603fffd4bb7a56051838a37b2f3"
          }
        },
        "c01ae07344844aa6bd239fee264d0c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e70ea070996243e398542af4993c3d87",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 20/20 [25:46&lt;00:00, 75.21s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_51f8fbffd0f3470bbe5fc90f6e5c69e3"
          }
        },
        "739f1789866e4a9989d057ac55ca0b94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "82439f1d3d9e4a7f941c508a95219eb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "05ced7f11e8349a886b2a16ce9c18388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e60d8603fffd4bb7a56051838a37b2f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e70ea070996243e398542af4993c3d87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "51f8fbffd0f3470bbe5fc90f6e5c69e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a04915a4b9b0440a83f1abd353bb2fc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_84080c71cd0f460496ddb2b6ccc78872",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_650712c76dbc4277b5d0468d4b5f84fc",
              "IPY_MODEL_52dd054586774fd78f42d7931435b4f8",
              "IPY_MODEL_647633f5e81b478995096f06839b91fa"
            ]
          }
        },
        "84080c71cd0f460496ddb2b6ccc78872": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "650712c76dbc4277b5d0468d4b5f84fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_23ff315bf0b2436f96044e03a86ea0e7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "split=train:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_03245cd096a34e83a198670063e5f4d4"
          }
        },
        "52dd054586774fd78f42d7931435b4f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_73276a84c02e4f70b521c355bcbdacdd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 83,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0157f3e4474b426caaa0d1acf7516dc8"
          }
        },
        "647633f5e81b478995096f06839b91fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c04b45c7c6aa481885815a6dd902153a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/83 [25:46&lt;00:49,  1.67it/s, acc=66.3, epoch=19, loss=1.31]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec4e678a393e44fa98a9f33d17fb890a"
          }
        },
        "23ff315bf0b2436f96044e03a86ea0e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "03245cd096a34e83a198670063e5f4d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73276a84c02e4f70b521c355bcbdacdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0157f3e4474b426caaa0d1acf7516dc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c04b45c7c6aa481885815a6dd902153a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec4e678a393e44fa98a9f33d17fb890a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c745ef9c7d1242dba73b618d1924e0ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3a8b29d33ac9417fa11d62ad59eab9e8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_609252dad3a742d0a427e097b8c41052",
              "IPY_MODEL_4bd1353be4ae43639501722bb5addaa4",
              "IPY_MODEL_f4e8ed03f508409c9f2e644880dae3ef"
            ]
          }
        },
        "3a8b29d33ac9417fa11d62ad59eab9e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "609252dad3a742d0a427e097b8c41052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_da14b2f2eeb44811a3f9861768342a60",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "split=val:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e4a84b978b8404da7faddbad80529ef"
          }
        },
        "4bd1353be4ae43639501722bb5addaa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2eb0cabdf6f3420080a50aeaa2faebaf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 25,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_efc5e86fb4264983973fa3cbd07cd7f8"
          }
        },
        "f4e8ed03f508409c9f2e644880dae3ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4fe923411b7e4051b9b90df4446f5e4a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/25 [25:46&lt;00:16,  1.47it/s, acc=50.2, epoch=19, loss=1.48]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_130be9244f2b461cac8aa69ea62450e0"
          }
        },
        "da14b2f2eeb44811a3f9861768342a60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e4a84b978b8404da7faddbad80529ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2eb0cabdf6f3420080a50aeaa2faebaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "efc5e86fb4264983973fa3cbd07cd7f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4fe923411b7e4051b9b90df4446f5e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "130be9244f2b461cac8aa69ea62450e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f5e3dd48a8a4dbc9f56aef5182b1832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f01bc57f3d9b484dba2a5158e7b6a334",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_581f72be3d604868b0f2ed71069f449c",
              "IPY_MODEL_d89ba4367b894825b73b80a243efc287",
              "IPY_MODEL_5e163eb23ddb4408be01d6658879f943"
            ]
          }
        },
        "f01bc57f3d9b484dba2a5158e7b6a334": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "581f72be3d604868b0f2ed71069f449c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8d7440718d8e4d79af562de54ea6f415",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "training routine: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e77cea3af48246f39440a8f2940acf5e"
          }
        },
        "d89ba4367b894825b73b80a243efc287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1fb9f6b26bdf40e1925427519e02c0d6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 20,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 20,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd4c1cd4c49f4e91ad2d7b8c5d672354"
          }
        },
        "5e163eb23ddb4408be01d6658879f943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ef051299aa524714a302c3f796b2946e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 20/20 [25:34&lt;00:00, 74.99s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22545a7dd6624d9eb1e39f493136c1fa"
          }
        },
        "8d7440718d8e4d79af562de54ea6f415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e77cea3af48246f39440a8f2940acf5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1fb9f6b26bdf40e1925427519e02c0d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd4c1cd4c49f4e91ad2d7b8c5d672354": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef051299aa524714a302c3f796b2946e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22545a7dd6624d9eb1e39f493136c1fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a68b4aa93f64c65bb9967cb05a5802a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1d75e25eddaa42ff9a60739156ca6b79",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_44036aacaf2a4f00a3024f64362031b1",
              "IPY_MODEL_d81d91b5ca93425aa945a6f5ebf52511",
              "IPY_MODEL_e0806f683b744234a2565aa0692c92d7"
            ]
          }
        },
        "1d75e25eddaa42ff9a60739156ca6b79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44036aacaf2a4f00a3024f64362031b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_61b1640ca27948f6897a9dcd5615fbc8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "split=train:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb88a2a537524587a90b7c8ad9dd3983"
          }
        },
        "d81d91b5ca93425aa945a6f5ebf52511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f818b79fcc994eb9b1af161d4592a335",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 83,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c25ee4568fae4060b303817ef72c08a4"
          }
        },
        "e0806f683b744234a2565aa0692c92d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a89f53194dc34b168860272fe510416b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/83 [25:34&lt;00:50,  1.65it/s, acc=67.7, epoch=19, loss=1.31]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_90fdca6387144598a6c70a0982091991"
          }
        },
        "61b1640ca27948f6897a9dcd5615fbc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb88a2a537524587a90b7c8ad9dd3983": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f818b79fcc994eb9b1af161d4592a335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c25ee4568fae4060b303817ef72c08a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a89f53194dc34b168860272fe510416b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "90fdca6387144598a6c70a0982091991": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fbbf8c098d3f485b9459577522f7c64d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5687b1e6af9446889f8a62a9e67bec93",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4b94c3e183c347dfad905ab5eb67ad2a",
              "IPY_MODEL_f43733946f28468092c2c74ea04573a1",
              "IPY_MODEL_c4be538a77ec4e66970ed51daa8e42f1"
            ]
          }
        },
        "5687b1e6af9446889f8a62a9e67bec93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b94c3e183c347dfad905ab5eb67ad2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4697afdfab2d4f0889e9eca734ad172f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "split=val:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_65d7748b17e7426699bfde525eb3ccbb"
          }
        },
        "f43733946f28468092c2c74ea04573a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9e8641913eb24a8b8d16a1390c45b1a7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 25,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b99bf73f8e744a38ae98e9b564108a5"
          }
        },
        "c4be538a77ec4e66970ed51daa8e42f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3d7034d94d084334b878afac6b66f357",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/25 [25:34&lt;00:17,  1.45it/s, acc=55.9, epoch=19, loss=1.52]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3faee3e35bfa4e95ab87b967795d5845"
          }
        },
        "4697afdfab2d4f0889e9eca734ad172f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "65d7748b17e7426699bfde525eb3ccbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e8641913eb24a8b8d16a1390c45b1a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b99bf73f8e744a38ae98e9b564108a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d7034d94d084334b878afac6b66f357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3faee3e35bfa4e95ab87b967795d5845": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f161e2fc828245c69a010a9bc1dac220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6b2f63dc38204a3ab41ff92d626a5826",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_93f6b6299c51453687a5a256a994d551",
              "IPY_MODEL_5d0ec7ceb0254349b57d6e0449e045f0",
              "IPY_MODEL_c7a6713b3caf493280d8ecd9dbd1410f"
            ]
          }
        },
        "6b2f63dc38204a3ab41ff92d626a5826": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "93f6b6299c51453687a5a256a994d551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_84c4a38418d1458383e37dfe0c15cce4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "training routine: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b8799f69a6a4a31889ca680874b3c2a"
          }
        },
        "5d0ec7ceb0254349b57d6e0449e045f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_94bb4223789a4d6791d005e2d3489c5d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 20,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 20,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_39804166cdd44a71914ae76e2bd649bd"
          }
        },
        "c7a6713b3caf493280d8ecd9dbd1410f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_de81c69c455e44a6b5adf614e07754f1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 20/20 [25:40&lt;00:00, 75.21s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_86ecb4f58df44550a300c4fc59762ac4"
          }
        },
        "84c4a38418d1458383e37dfe0c15cce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b8799f69a6a4a31889ca680874b3c2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94bb4223789a4d6791d005e2d3489c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "39804166cdd44a71914ae76e2bd649bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de81c69c455e44a6b5adf614e07754f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "86ecb4f58df44550a300c4fc59762ac4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "59a491e8c4b24f2aaabbe11795d62d44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_80d9b24b9d2f4efeb5e56cecf64bafbd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_310301c92859477da6a18eecbcb2169d",
              "IPY_MODEL_8a100b3c47954f70a78ec4170f19ea0a",
              "IPY_MODEL_ce83b0fd406040a9ab27d16c1bfe4e56"
            ]
          }
        },
        "80d9b24b9d2f4efeb5e56cecf64bafbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "310301c92859477da6a18eecbcb2169d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2932fd1b2f794310bda38925086da694",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "split=train:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21e4df5952eb4f8a84d1bae3fd02d013"
          }
        },
        "8a100b3c47954f70a78ec4170f19ea0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cf3809205b09451fbb84858894eaa426",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 83,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b25c1b9793644e6afbf2acffaa6a40a"
          }
        },
        "ce83b0fd406040a9ab27d16c1bfe4e56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bf47fe4bbb36472b87931ca068db1253",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/83 [25:40&lt;00:50,  1.64it/s, acc=24.7, epoch=19, loss=1.71]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8f80521fefd4618b7ffc5b12e4e9a87"
          }
        },
        "2932fd1b2f794310bda38925086da694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21e4df5952eb4f8a84d1bae3fd02d013": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf3809205b09451fbb84858894eaa426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b25c1b9793644e6afbf2acffaa6a40a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf47fe4bbb36472b87931ca068db1253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8f80521fefd4618b7ffc5b12e4e9a87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3886dfa9ec934600b6b7f3aabeefc547": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cf1739177cc442c8ae671ce5dd2de9b2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c71316296c1f4477a1b46a926963136d",
              "IPY_MODEL_e278f9f6de414018b903271649a689c8",
              "IPY_MODEL_51cb662640d840e28b65e87330da97cc"
            ]
          }
        },
        "cf1739177cc442c8ae671ce5dd2de9b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c71316296c1f4477a1b46a926963136d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_56d7bd7496e2437993d9469135231de7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "split=val:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff5cdcf152384c5096d89cfc4066e9be"
          }
        },
        "e278f9f6de414018b903271649a689c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a1bf2ce2af84469d81aa8f277d714315",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 25,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b95680b36b4144828f49aebb6da0b10e"
          }
        },
        "51cb662640d840e28b65e87330da97cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_82f69e6480f54971bf2c5291222857dc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/25 [25:40&lt;00:16,  1.56it/s, acc=22.9, epoch=19, loss=1.72]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc5fe5fd98d54e3390a15b6e6b8df552"
          }
        },
        "56d7bd7496e2437993d9469135231de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff5cdcf152384c5096d89cfc4066e9be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1bf2ce2af84469d81aa8f277d714315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b95680b36b4144828f49aebb6da0b10e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "82f69e6480f54971bf2c5291222857dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc5fe5fd98d54e3390a15b6e6b8df552": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36a0caab3fd24ae491ba052417ace72b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_71069ab5195748f3bf08ea3aaae53a92",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f0f22a63e0c542958717ce27fc6ecca9",
              "IPY_MODEL_fb8cabe34a9141eda4b6da49047b429b",
              "IPY_MODEL_28c967e66f6e4ad1badb83db0f8a1cd6"
            ]
          }
        },
        "71069ab5195748f3bf08ea3aaae53a92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0f22a63e0c542958717ce27fc6ecca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_58b603f0e4ca4e6babe2f258459a43b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "training routine: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c8a3571dc50b420aa00c90b77a5ac169"
          }
        },
        "fb8cabe34a9141eda4b6da49047b429b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7214931cd9a94879b0570560eec1967c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 20,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 20,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b775dd0b1f53490b8d3a8586986ba048"
          }
        },
        "28c967e66f6e4ad1badb83db0f8a1cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_88acbd1d37994fa5a9fa1c57191d014f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 20/20 [25:37&lt;00:00, 75.06s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_73b2e0f1c64146d39809f5a04c0c8b6f"
          }
        },
        "58b603f0e4ca4e6babe2f258459a43b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c8a3571dc50b420aa00c90b77a5ac169": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7214931cd9a94879b0570560eec1967c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b775dd0b1f53490b8d3a8586986ba048": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88acbd1d37994fa5a9fa1c57191d014f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "73b2e0f1c64146d39809f5a04c0c8b6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d7e4591570484bb09fa4c8187e19bc3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_24014bd09cf2472fae8fdc84243e9d1b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1bd584d002c948f6b33b818085cd49c9",
              "IPY_MODEL_2d890e5b59b645afb91bd267b99477ce",
              "IPY_MODEL_cc72fcd51db84d3fa22102e07eb86f79"
            ]
          }
        },
        "24014bd09cf2472fae8fdc84243e9d1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1bd584d002c948f6b33b818085cd49c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_74a8dd196f7c4989be32262e0c60950f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "split=train:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dac1701f794e45b6856253a9868bcd42"
          }
        },
        "2d890e5b59b645afb91bd267b99477ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_87d9e8ff7751408fa0c8c71f96a9cb14",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 83,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c27dff29cf42484195962084fce570d2"
          }
        },
        "cc72fcd51db84d3fa22102e07eb86f79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_34c5be976a394aa6a276ff5f12718de2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/83 [25:36&lt;00:51,  1.62it/s, acc=47.7, epoch=19, loss=1.54]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b2bfa2a47ab3446fbf4c76411b799c23"
          }
        },
        "74a8dd196f7c4989be32262e0c60950f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dac1701f794e45b6856253a9868bcd42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "87d9e8ff7751408fa0c8c71f96a9cb14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c27dff29cf42484195962084fce570d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34c5be976a394aa6a276ff5f12718de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b2bfa2a47ab3446fbf4c76411b799c23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1964701a39894be69ce5ab23fd510fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cb53ade577564165875566723d404605",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9f7e1747ab1a402493c292f58bc65bb2",
              "IPY_MODEL_f30f53ce82ec47cbbbf4d7211247a81c",
              "IPY_MODEL_aaf4ee7d50294c2c89afd7c7fc5bdd0e"
            ]
          }
        },
        "cb53ade577564165875566723d404605": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f7e1747ab1a402493c292f58bc65bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_51a7888fb4a9478b8e623c8280b9435a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "split=val:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b8e8505ddaae4144b68ee98e8e93b244"
          }
        },
        "f30f53ce82ec47cbbbf4d7211247a81c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ef86ed65d49449eea87de49ac004cda5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 25,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20ae19001cef4e31915a9bda81d9d108"
          }
        },
        "aaf4ee7d50294c2c89afd7c7fc5bdd0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a2213f6128cb4d4a88fb772019304efd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/25 [25:36&lt;00:16,  1.56it/s, acc=47.5, epoch=19, loss=1.58]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c5bcd805d4a1438299763c11e67f9838"
          }
        },
        "51a7888fb4a9478b8e623c8280b9435a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b8e8505ddaae4144b68ee98e8e93b244": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef86ed65d49449eea87de49ac004cda5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20ae19001cef4e31915a9bda81d9d108": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a2213f6128cb4d4a88fb772019304efd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c5bcd805d4a1438299763c11e67f9838": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a2944fc70c7445586315e14d161f5af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d484426d9d864b7f8ee5bdccd2be1279",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_02ef7e4645444d65951a2ad342e2219a",
              "IPY_MODEL_25cd383cdb3847b5aed0e510b0b1dff4",
              "IPY_MODEL_0997d7e015704d7bb6bf8749ca49070c"
            ]
          }
        },
        "d484426d9d864b7f8ee5bdccd2be1279": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "02ef7e4645444d65951a2ad342e2219a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f68af971101041acb9289981246f3149",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "training routine: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_137edf3f912e455389298c9393db0c10"
          }
        },
        "25cd383cdb3847b5aed0e510b0b1dff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9dbe121936564c5dbe4f47bd0df3cf68",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 20,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 20,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be677b7526694e72b88bda9b6c1614c9"
          }
        },
        "0997d7e015704d7bb6bf8749ca49070c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b4bfee8f366c415ea6b82f16bb92ba93",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 20/20 [25:35&lt;00:00, 75.48s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b85ee7452ba4386995415f33dbdaae0"
          }
        },
        "f68af971101041acb9289981246f3149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "137edf3f912e455389298c9393db0c10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9dbe121936564c5dbe4f47bd0df3cf68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be677b7526694e72b88bda9b6c1614c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4bfee8f366c415ea6b82f16bb92ba93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b85ee7452ba4386995415f33dbdaae0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5c10bd4a1de40dfbde5abd646de7785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a8c479a0a68946138cc1e52f2222a4b2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ccabb3ad0c424dd281841ad6e95a22fb",
              "IPY_MODEL_9757ce26d27648aeab68125d05485147",
              "IPY_MODEL_892b2273753449cab6378cd990b08c50"
            ]
          }
        },
        "a8c479a0a68946138cc1e52f2222a4b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ccabb3ad0c424dd281841ad6e95a22fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7bbc4c9ab6c544208d80bb2b0c71e0bc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "split=train:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6bc5a820f646421aa92a02a29cd9adf7"
          }
        },
        "9757ce26d27648aeab68125d05485147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_92925a9e945a48a3af458186c076ee1f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 83,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a0c1c17c4c684e35b9d73f55b445c207"
          }
        },
        "892b2273753449cab6378cd990b08c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bd214b9d694846dcb319beba789b47d3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/83 [25:34&lt;00:50,  1.63it/s, acc=44, epoch=19, loss=1.57]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_52ade7f2cb8f42bc85519dfac69c87dd"
          }
        },
        "7bbc4c9ab6c544208d80bb2b0c71e0bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6bc5a820f646421aa92a02a29cd9adf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92925a9e945a48a3af458186c076ee1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a0c1c17c4c684e35b9d73f55b445c207": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd214b9d694846dcb319beba789b47d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "52ade7f2cb8f42bc85519dfac69c87dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d563ce2d024d4421974db865ee039c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fed133f7d2214fa3b067392cd74cf271",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1e23daa2dbcf4ed68af81ea392f7b992",
              "IPY_MODEL_da2e9be4517e41b6a44adc2000cb532f",
              "IPY_MODEL_9b640299ff5d47299ad99252167ff56b"
            ]
          }
        },
        "fed133f7d2214fa3b067392cd74cf271": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e23daa2dbcf4ed68af81ea392f7b992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aa3c5d44cc1c48e1b0fff2986b7e5de5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "split=val:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8827812a95484d6493486c9bb9e72b67"
          }
        },
        "da2e9be4517e41b6a44adc2000cb532f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2be00107a21946b291861a131d2a480b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 25,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_833b35a6e13b495eb01df7de14b869c3"
          }
        },
        "9b640299ff5d47299ad99252167ff56b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1ff3dd3d001c40248850f88153d8a733",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/25 [25:34&lt;00:16,  1.55it/s, acc=40.9, epoch=19, loss=1.64]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_92b3e60d6bf648f6ad84ecfacbc6cd7d"
          }
        },
        "aa3c5d44cc1c48e1b0fff2986b7e5de5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8827812a95484d6493486c9bb9e72b67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2be00107a21946b291861a131d2a480b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "833b35a6e13b495eb01df7de14b869c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ff3dd3d001c40248850f88153d8a733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "92b3e60d6bf648f6ad84ecfacbc6cd7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b63d666fb6147d887335b13f52345db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b26dea4d08564f24b50be9dae108809d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_72c60c6939d04a37acf3a2bd12ddfb40",
              "IPY_MODEL_6ab27d256e3d4a328ee1b135ecfefab0",
              "IPY_MODEL_ab749ddfc9a2451894704d8769049dca"
            ]
          }
        },
        "b26dea4d08564f24b50be9dae108809d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72c60c6939d04a37acf3a2bd12ddfb40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c509e6e5c8dd4f14b76a72c9461ac9ae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "training routine: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4276572a48e84c4380f1e7f388dbf88f"
          }
        },
        "6ab27d256e3d4a328ee1b135ecfefab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e1fe24e21e424ffd85d9cd6c3dd3742c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 20,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 20,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d0a323417da4569880d84da1fea0df2"
          }
        },
        "ab749ddfc9a2451894704d8769049dca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_694dfa2483e4489cb8e241dd6135bb63",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 20/20 [25:06&lt;00:00, 75.22s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9cde22f5a322428f8984fed0895491f0"
          }
        },
        "c509e6e5c8dd4f14b76a72c9461ac9ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4276572a48e84c4380f1e7f388dbf88f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1fe24e21e424ffd85d9cd6c3dd3742c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d0a323417da4569880d84da1fea0df2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "694dfa2483e4489cb8e241dd6135bb63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9cde22f5a322428f8984fed0895491f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94f92120fd3d4487961d8aac0cf7856b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4fc95c17581b4c78a56d2d57a19f1c80",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e6a53e8508314967b2f2b192c64705ad",
              "IPY_MODEL_c1bf16e640914f9ea0778d6b8af5f4c7",
              "IPY_MODEL_56674f6dfd0d4177b3c64b323d92b2b0"
            ]
          }
        },
        "4fc95c17581b4c78a56d2d57a19f1c80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6a53e8508314967b2f2b192c64705ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b11a56ccc05e4427879d3f967cbb25ba",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "split=train: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b46ed027ff6e43e58a4bc9b215503d3d"
          }
        },
        "c1bf16e640914f9ea0778d6b8af5f4c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3162bf2c2f8746cca5bc622707962739",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 83,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 83,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d571d7c953e432dbf0d50ff5e9792a6"
          }
        },
        "56674f6dfd0d4177b3c64b323d92b2b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_46ba01e94e874dd1a350ff3d03f507b9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 83/83 [24:49&lt;00:00,  1.65it/s, acc=67.3, epoch=19, loss=1.32]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_36274a1a035e400facb605cb21ee4615"
          }
        },
        "b11a56ccc05e4427879d3f967cbb25ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b46ed027ff6e43e58a4bc9b215503d3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3162bf2c2f8746cca5bc622707962739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d571d7c953e432dbf0d50ff5e9792a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "46ba01e94e874dd1a350ff3d03f507b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "36274a1a035e400facb605cb21ee4615": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1791eeeb500546039d7cbf14510013ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_128b535e417d452cb7c7887a450928be",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_44f118c80b314db290a753d8c21a9c5e",
              "IPY_MODEL_6a1650492045488d9f074b7e9c42d5ec",
              "IPY_MODEL_39ee37bffbc744a59c8c333d678b9ebf"
            ]
          }
        },
        "128b535e417d452cb7c7887a450928be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44f118c80b314db290a753d8c21a9c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1ca848823078419f8846abfc6d504edd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "split=val: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f760deaa3aad44aeaec39cc59414e966"
          }
        },
        "6a1650492045488d9f074b7e9c42d5ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4473d1060e794e20bdcf8d7de358dc33",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 25,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 25,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_88dc8eb73b8d4803b130cf1d9055e46f"
          }
        },
        "39ee37bffbc744a59c8c333d678b9ebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3e5c27a5e3fc4979bc56768c9e524f84",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 25/25 [25:05&lt;00:00,  1.44it/s, acc=55.7, epoch=19, loss=1.48]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0a693536792496db6815e5f68ebd810"
          }
        },
        "1ca848823078419f8846abfc6d504edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f760deaa3aad44aeaec39cc59414e966": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4473d1060e794e20bdcf8d7de358dc33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "88dc8eb73b8d4803b130cf1d9055e46f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e5c27a5e3fc4979bc56768c9e524f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0a693536792496db6815e5f68ebd810": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}