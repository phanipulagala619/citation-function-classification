The discipline of citation analysis has been the subject of ongoing research for many years. Many statistical approaches, such as counting the number of citations directed towards a certain publication, have been used in the past, but they have proven ineffective, and the focus has shifted from how often a work is referenced to why it is cited for a variety of reasons. Multiple Machine Learning models, such as SVM, K-means, and Hierarchical clustering, were later used to determine the quality of publications and the author's desire to cite the work; however, these machine learning techniques are time consuming and require the compilation of a large number of manual features. Following the statistical and machine learning phases, various attempts were made to use deep learning to analyse citation functions in order to avoid constructing manual features, but none were very successful or empirically persuasive. This was caused by a lack of a large-scale benchmark dataset for objective evaluation, as well as a failure to incorporate state-of-the-art natural language processing achievements into pretrained models and deep learning architectures. The goal of this study is to conduct the first large-scale evaluation and development of cutting-edge deep learning algorithms for citation context analysis utilising the Bi-LSTM model and Bi-LSTM with Attention. To represent text as numerical vectors, I employed the Global Vectors for Word Representation (GloVe) and Embeddings from Language Models (ELMo) embedding approaches. Experiments were carried out in this work using Prof. Simone Teufel's technique of annotating 12 class citation functions scheme and Jurgens' scheme which merges some of Teufelâ€™s citation functions into 6 coarser-grained classes. The best results were obtained utilising Bi-LSTM and ELMo embeddings for 6 class citation functions, with 57 percent accuracy and weighted average F1 score of 59 percent.
